[
    {
        "question_id": "38560748",
        "question": "\nI have a lot of different table (and other unstructured data in an excel sheet) .. I need to create a dataframe out of range 'A3:D20' from 'Sheet2' of Excel sheet 'data'.\nAll examples that I come across drilldown up to sheet level, but not how to pick it from an exact range.\nimport openpyxl\nimport pandas as pd\n\nwb = openpyxl.load_workbook('data.xlsx')\nsheet = wb.get_sheet_by_name('Sheet2')\nrange = ['A3':'D20']   #<-- how to specify this?\nspots = pd.DataFrame(sheet.range) #what should be the exact syntax for this?\n\nprint (spots)\n\nOnce I get this, I plan to look up data in column A and find its corresponding value in column B.\nEdit 1: I realised that openpyxl takes too long, and so have changed that to pandas.read_excel('data.xlsx','Sheet2') instead, and it is much faster at that stage at least.\nEdit 2: For the time being, I have put my data in just one sheet and:\n\nremoved all other info\nadded column names,  \napplied index_col on my leftmost column\nthen used wb.loc[]\n\n",
        "all_answers": [
            "\nThere is a way to make it more pythonic (works with three or more letters and uses less magic numbers):\ndef col2num(col):\n    num = 0\n    for c in col:\n        if c in string.ascii_letters:\n            num = num * 26 + (ord(c.upper()) - ord('A')) + 1\n    return num\n\nAnd as a one-liner using reduce (does not check input and is less readable so I don't recommend it):\ncol2num = lambda col: reduce(lambda x, y: x*26 + y, [ord(c.upper()) - ord('A') + 1 for c in col])\n\n",
            "\nUse the following arguments from pandas read_excel documentation:\n\n\nskiprows : list-like\n\nRows to skip at the beginning (0-indexed)\n\n\nnrows: int, default None\n\nNumber of rows to parse.\n\n\nparse_cols : int or list, default None\n\nIf None then parse all columns,\nIf int then indicates last column to be parsed\nIf list of ints then indicates list of column numbers to be parsed\nIf string then indicates comma separated list of column names and column ranges (e.g. “A:E” or “A,C,E:F”)\n\n\n\n\nI imagine the call will look like:\ndf = read_excel(filename, 'Sheet2', skiprows = 2, nrows=18,  parse_cols = 'A:D')\n\nEDIT:\nin later version of pandas parse_cols has been renamed to usecols so the above call should be rewritten as:\ndf = read_excel(filename, 'Sheet2', skiprows = 2, nrows=18,  usecols= 'A:D')\n\n",
            "\nOne way to do this is to use the openpyxl module.\nHere's an example:\nfrom openpyxl import load_workbook\n\nwb = load_workbook(filename='data.xlsx', \n                   read_only=True)\n\nws = wb['Sheet2']\n\n# Read the cell values into a list of lists\ndata_rows = []\nfor row in ws['A3':'D20']:\n    data_cols = []\n    for cell in row:\n        data_cols.append(cell.value)\n    data_rows.append(data_cols)\n\n# Transform into dataframe\nimport pandas as pd\ndf = pd.DataFrame(data_rows)\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "excel",
            "pandas"
        ]
    },
    {
        "question_id": "4934913",
        "question": "\nMy teacher in an upper level Java class on threading said something that I wasn't sure of.\nHe stated that the following code would not necessarily update the ready variable.  According to him, the two threads don't necessarily share the static variable, specifically in the case when each thread (main thread versus ReaderThread) is running on its own processor and therefore doesn't share the same registers/cache/etc and one CPU won't update the other.\nEssentially, he said it is possible that ready is updated in the main thread, but NOT in the ReaderThread, so that ReaderThread will loop infinitely.\nHe also claimed it was possible for the program to print 0 or 42.  I understand how 42 could be printed, but not 0.  He mentioned this would be the case when the number variable is set to the default value.\nI thought perhaps it is not guaranteed that the static variable is updated between the threads, but this strikes me as very odd for Java.  Does making ready volatile correct this problem?\nHe showed this code:  \npublic class NoVisibility {  \n    private static boolean ready;  \n    private static int number;  \n    private static class ReaderThread extends Thread {   \n        public void run() {  \n            while (!ready)   Thread.yield();  \n            System.out.println(number);  \n        }  \n    }  \n    public static void main(String[] args) {  \n        new ReaderThread().start();  \n        number = 42;  \n        ready = true;  \n    }  \n}\n\n",
        "all_answers": [
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nWithin a single classloader, static fields are always shared.  To explicitly scope data to threads, you'd want to use a facility like ThreadLocal.\n",
            "\nThere isn't anything special about static variables when it comes to visibility. If they are accessible any thread can get at them, so you're more likely to see concurrency problems because they're more exposed.\nThere is a visibility issue imposed by the JVM's memory model. Here's an article talking about the memory model and how writes become visible to threads. You can't count on changes one thread makes becoming visible to other threads in a timely manner (actually the JVM has no obligation to make those changes visible to you at all, in any time frame), unless you establish a happens-before relationship.\nHere's a quote from that link (supplied in the comment by Jed Wesley-Smith):\n\nChapter 17 of the Java Language Specification defines the happens-before relation on memory operations such as reads and writes of shared variables. The results of a write by one thread are guaranteed to be visible to a read by another thread only if the write operation happens-before the read operation. The synchronized and volatile constructs, as well as the Thread.start() and Thread.join() methods, can form happens-before relationships. In particular:\n\nEach action in a thread happens-before every action in that thread that comes later in the program's order.\n\nAn unlock (synchronized block or method exit) of a monitor happens-before every subsequent lock (synchronized block or method entry) of that same monitor. And because the happens-before relation is transitive, all actions of a thread prior to unlocking happen-before all actions subsequent to any thread locking that monitor.\n\nA write to a volatile field happens-before every subsequent read of that same field. Writes and reads of volatile fields have similar memory consistency effects as entering and exiting monitors, but do not entail mutual exclusion locking.\n\nA call to start on a thread happens-before any action in the started thread.\n\nAll actions in a thread happen-before any other thread successfully returns from a join on that thread.\n\n\n\n"
        ],
        "answer": "A3",
        "tags": [
            "java",
            "multithreading",
            "concurrency",
            "static",
            "memory-visibility"
        ]
    },
    {
        "question_id": "19441155",
        "question": "\nI have subdomain.example.com that I use for development purposes. My web application solution contains a web API etc, that I need to call from external systems, hence I am not using localhost.\nI now need to test for SSL and need a certificate for my subdomain.example.com development domain name.\nI have tried creating a self-signed certificate as outlined in http://technet.microsoft.com/en-us/library/cc753127(v=ws.10).aspx, but this certificate only works for localhost. Can this certificate be used for my purpose or will I have to create a self-signed for my development subdomain? If I have to create a self-signed certification for my development subdomain, what utility or online service (Free) can I use for this?\n",
        "all_answers": [
            "\nWith IIS's self-signed certificate feature, you cannot set the common name (CN) for the certificate, and therefore cannot create a certificate bound to your choice of subdomain.\nOne way around the problem is to use makecert.exe, which is bundled with the .Net 2.0 SDK. On my server it's at:\nC:\\Program Files\\Microsoft.Net\\SDK\\v2.0 64bit\\Bin\\makecert.exe\n\nYou can create a signing authority and store it in the LocalMachine certificates repository as follows (these commands must be run from an Administrator account or within an elevated command prompt):\nmakecert.exe -n \"CN=My Company Development Root CA,O=My Company,\n OU=Development,L=Wallkill,S=NY,C=US\" -pe -ss Root -sr LocalMachine\n -sky exchange -m 120 -a sha1 -len 2048 -r\n\nYou can then create a certificate bound to your subdomain and signed by your new authority:\n(Note that the the value of the -in parameter must be the same as the CN value used to generate your authority above.)\nmakecert.exe -n \"CN=subdomain.example.com\" -pe -ss My -sr LocalMachine\n -sky exchange -m 120 -in \"My Company Development Root CA\" -is Root\n -ir LocalMachine -a sha1 -eku 1.3.6.1.5.5.7.3.1\n\nYour certificate should then appear in IIS Manager to be bound to your site as explained in Tom Hall's post.\nAll kudos for this solution to Mike O'Brien for his excellent blog post at http://www.mikeobrien.net/blog/creating-self-signed-wildcard\n",
            "\nUsing PowerShell\nFrom Windows 8.1 and Windows Server 2012 R2 (Windows PowerShell 4.0) and upwards, you can create a self-signed certificate using the new New-SelfSignedCertificate cmdlet:\nExamples:\nNew-SelfSignedCertificate -DnsName www.mydomain.example -CertStoreLocation cert:\\LocalMachine\\My\n\nNew-SelfSignedCertificate -DnsName subdomain.mydomain.example -CertStoreLocation cert:\\LocalMachine\\My\n\nNew-SelfSignedCertificate -DnsName *.mydomain.example -CertStoreLocation cert:\\LocalMachine\\My\n\nUsing the IIS Manager\n\nLaunch the IIS Manager\nAt the server level, under IIS, select Server Certificates\nOn the right hand side under Actions select Create Self-Signed Certificate\nWhere it says \"Specify a friendly name for the certificate\" type in an appropriate name for reference.\n\nExamples: www.domain.example or subdomain.domain.example\n\n\nThen, select your website from the list on the left hand side\nOn the right hand side under Actions select Bindings\nAdd a new HTTPS binding and select the certificate you just created (if your certificate is a wildcard certificate you'll need to specify a hostname)\nClick OK and test it out.\n\n"
        ],
        "answer": "A1",
        "tags": [
            "windows",
            "ssl",
            "iis",
            "ssl-certificate",
            "self-signed"
        ]
    },
    {
        "question_id": "12070631",
        "question": "\nI have json file mydata.json, and in this file is some json-encoded data.\nI want obtain this data in file index.html and process this data in JavaScript. But a don't know how to connect.json file in .html file?\nTell me please. \nHere is my json file:\n{\n    \"items\": [\n        {\n            \"movieID\": \"65086\",\n            \"title\": \"The Woman in Black\",\n            \"poster\": \"/kArMj2qsOnpxBCpSa3RQ0XemUiX.jpg\"\n        },\n        {\n            \"movieID\": \"76726\",\n            \"title\": \"Chronicle\",\n            \"poster\": \"/853mMoSc5d6CH8uAV9Yq0iHfjor.jpg\"\n        }\n    ]\n} \n\nThinking that I am getting json file from server, how to use that file in my html, so that I can display the data in tables in html page. I am using JavaScript to parse the json file. I am new to this field. Help out please.\n",
        "all_answers": [
            "\n<html>\n<head>\n<script type=\"text/javascript\" src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.6.2/jquery.min.js\"> </script>\n\n<script>\n\n    $(function() {\n\n\n   var people = [];\n\n   $.getJSON('people.json', function(data) {\n       $.each(data.person, function(i, f) {\n          var tblRow = \"<tr>\" + \"<td>\" + f.firstName + \"</td>\" +\n           \"<td>\" + f.lastName + \"</td>\" + \"<td>\" + f.job + \"</td>\" + \"<td>\" + f.roll + \"</td>\" + \"</tr>\"\n           $(tblRow).appendTo(\"#userdata tbody\");\n     });\n\n   });\n\n});\n</script>\n</head>\n\n<body>\n\n<div class=\"wrapper\">\n<div class=\"profile\">\n   <table id= \"userdata\" border=\"2\">\n  <thead>\n            <th>First Name</th>\n            <th>Last Name</th>\n            <th>Email Address</th>\n            <th>City</th>\n        </thead>\n      <tbody>\n\n       </tbody>\n   </table>\n\n</div>\n</div>\n\n</body>\n</html>\n\nMy JSON file:\n{\n   \"person\": [\n       {\n           \"firstName\": \"Clark\",\n           \"lastName\": \"Kent\",\n           \"job\": \"Reporter\",\n           \"roll\": 20\n       },\n       {\n           \"firstName\": \"Bruce\",\n           \"lastName\": \"Wayne\",\n           \"job\": \"Playboy\",\n           \"roll\": 30\n       },\n       {\n           \"firstName\": \"Peter\",\n           \"lastName\": \"Parker\",\n           \"job\": \"Photographer\",\n           \"roll\": 40\n       }\n   ]\n}\n\nI succeeded in integrating a JSON file to HTML table after working a day on it!!!\n",
            "\nuse jQuery's $.getJSON \n$.getJSON('mydata.json', function(data) {\n    //do stuff with your data here\n});\n\n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "jquery",
            "html",
            "json",
            "get"
        ]
    },
    {
        "question_id": "19222520",
        "question": "\nHow can I populate \"components\" in the example document:\n  {\n    \"__v\": 1,\n    \"_id\": \"5252875356f64d6d28000001\",\n    \"pages\": [\n      {\n        \"__v\": 1,\n        \"_id\": \"5252875a56f64d6d28000002\",\n        \"page\": {\n          \"components\": [\n            \"525287a01877a68528000001\"\n          ]\n        }\n      }\n    ],\n    \"author\": \"Book Author\",\n    \"title\": \"Book Title\"\n  }\n\nThis is my JS where I get document by Mongoose:\n  Project.findById(id).populate('pages').exec(function(err, project) {\n    res.json(project);\n  });\n\n",
        "all_answers": [
            "\nYou will get an error if you try to close/disconnect outside of the method. The best solution is to close the connection in both callbacks in the method. The dummy code is here.\nconst newTodo = new Todo({text:'cook dinner'});\n\nnewTodo.save().then((docs) => {\n  console.log('todo saved',docs);\n  mongoose.connection.close();\n},(e) => {\n  console.log('unable to save');\n});\n\n",
            "\nYou can close the connection with\nmongoose.connection.close()\n\n",
            "\nThe other answer didn't work for me. I had to use mongoose.disconnect(); as stated in this answer. \n",
            "\nThat works for me:\n Project.find(query)\n  .lean()\n  .populate({ path: 'pages' })\n  .exec(function(err, docs) {\n\n    var options = {\n      path: 'pages.components',\n      model: 'Component'\n    };\n\n    if (err) return res.json(500);\n    Project.populate(docs, options, function (err, projects) {\n      res.json(projects);\n    });\n  });\n\nDocumentation: Model.populate\n",
            "\nYou can set the connection to a variable then disconnect it when you are done:\nvar db = mongoose.connect('mongodb://localhost:27017/somedb');\n\n// Do some stuff\n\ndb.disconnect();\n\n",
            "\nJust as Jake Wilson said: You can set the connection to a variable then disconnect it when you are done:\nlet db;\nmongoose.connect('mongodb://localhost:27017/somedb').then((dbConnection)=>{\n    db = dbConnection;\n    afterwards();\n});\n\n\nfunction afterwards(){\n\n    //do stuff\n\n    db.disconnect();\n}\n\nor if inside Async function:\n(async ()=>{\n    const db = await mongoose.connect('mongodb://localhost:27017/somedb', { useMongoClient: \n                  true })\n\n    //do stuff\n\n    db.disconnect()\n})\n\notherwise when i was checking it in my environment it has an error.\n",
            "\nmongoose.connection.close(function(){\nconsole.log('Mongoose default connection disconnected through app termination');\nprocess.exit(0);\n});\n\nThis will close the mongoose connection and will also notify you by message in your console.\n",
            "\nMongoose 4.5 support this\nProject.find(query)\n  .populate({ \n     path: 'pages',\n     populate: {\n       path: 'components',\n       model: 'Component'\n     } \n  })\n  .exec(function(err, docs) {});\n\nAnd you can join more than one deep level.\nEdit 03/17/2021: This is the library's implementation, what it do behind the scene is make another query to fetch thing for you and then join in memory. Although this work but we really should not rely on. It will make your db design look like SQL tables. This is costly operation  and does not scale well. Please try to design your document so that it reduce join.\n"
        ],
        "answer": "A8",
        "tags": [
            "node.js",
            "mongodb",
            "mongoose"
        ]
    },
    {
        "question_id": "5879043",
        "question": "\nI have a PHP script that may be placed on a windows system or a linux system. I need to run different commands in either case. \nHow can I detect which environment I am in? (preferably something PHP rather than clever system hacks)\nUpdate\nTo clarify, the script is running from the command line.\n",
        "all_answers": [
            "\nYou can check if the directory separator is / (for unix/linux/mac) or \\ on windows. The constant name is DIRECTORY_SEPARATOR.\nif (DIRECTORY_SEPARATOR === '/') {\n    // unix, linux, mac\n}\n\nif (DIRECTORY_SEPARATOR === '\\\\') {\n    // windows\n}\n\n",
            "\nCore Predefined Constants: http://us3.php.net/manual/en/reserved.constants.php which has the PHP_OS (string) constant.\nOr if you want to detect the OS of the client:\n<?php\n    echo $_SERVER['HTTP_USER_AGENT'] . \"\\n\\n\";\n\n    $browser = get_browser(null, true);\n    print_r($browser);\n?>\n\nFrom http://us3.php.net/manual/en/function.get-browser.php\n\nAccording to your edit you can refer to this dublicate PHP Server Name from Command Line\nYou can use\nstring php_uname ([ string $mode = \"a\" ] )\n\nSo\nphp_uname(\"s\")\n\n\n's': Operating system name. eg.\n  FreeBSD.\n\nWould do the trick for you, see here http://php.net/manual/en/function.php-uname.php\n",
            "\nThe php_uname function can be used to detect this.\necho php_uname();\n\n",
            "\nCheck the value of the PHP_OS constantDocs.\nIt will give you various values on Windows like WIN32, WINNT or Windows.\nSee as well: Possible Values For: PHP_OS and php_unameDocs:\nif (strtoupper(substr(PHP_OS, 0, 3)) === 'WIN') {\n    echo 'This is a server using Windows!';\n} else {\n    echo 'This is a server not using Windows!';\n}\n\n"
        ],
        "answer": "A4",
        "tags": [
            "php",
            "windows",
            "linux",
            "operating-system",
            "detect"
        ]
    },
    {
        "question_id": "8633981",
        "question": "\nI'm having a problem with my git repo. For the last couple of days whenever I do a push to the server I get this message: \"Auto packing the repository for optimum performance\", and it does not seem to go away and return the shell.\nI also tried checking out to a new branch and then doing a rebase on my previous branch and then did git gc to remove the unused history objects and then did a push but still this message appears. Please let me know what's going on with my repo.\n",
        "all_answers": [
            "\nShort version: it means what it says, and if you just let it finish, all will be well.\nDuring most operations which can potentially increase the number of loose (unpacked) objects in the repository (including pushes), Git invokes git gc --auto. If there are enough loose objects (by default, at least 6700), it will then invoke git repack -d -l to pack them. If there are too many separate packs, it will also repack them into one.\nA pack is a delta-compressed single file, containing a large number of objects. It's more efficient to store objects in packs, but it takes time to pack (compress) objects, so Git initially creates loose objects, then packs them in batches now and then, via automatic invocation of git gc --auto.\nIf you let Git finish repacking, this won't happen again for a while. It can indeed take a while, especially if you have a lot of large binary objects, but if it's triggering, then it's a sign that it will probably drastically reduce the amount of disk space taken by the repo. If you really don't want it to happen, you can change the config parameter gc.auto. If you increase it to something much larger than 6700, it will happen less frequently, but take longer when it does. If you decrease it, it'll still have to do your current repack, but subsequently it will happen more often and finish more quickly. If you set it to 0, it will disable automatic repacking.\nSee man git-gc (under --auto) and man git-config (under gc.auto) for more information.\n",
            "\nGit is running git-repack, which packs many objects(=files, commits and trees) into one pack file. Git does this sometimes, when a heuristic says that there can be space saved (a pack file contains compressed object deltas, while each file in the objects/ directory contains the compressed full file content)\n",
            "\nJust do:\ngit push origin <your_branch_name> --force\n\nor if you have a specific repo:\ngit push https://git.... --force\n\nThis will delete your previous commit(s) and push your current one.\nIt may not be proper, but if anyone stumbles upon this page, thought they might want a simple solution...\nShort flag\nAlso note that -f is short for --force, so\ngit push origin <your_branch_name> -f\n\nwill also work.\n"
        ],
        "answer": "A1",
        "tags": [
            "git",
            "git-rebase",
            "git-push"
        ]
    },
    {
        "question_id": "2128701",
        "question": "\nIf i use UDP sockets for interprocess communication, can i expect that all send data is received by the other process in the same order? \nI know this is not true for UDP in general.\n",
        "all_answers": [
            "\nNo. I have been bitten by this before. You may wonder how it can possibly fail, but you'll run into issues of buffers of pending packets filling up, and consequently packets will be dropped. How the network subsystem drops packets is implementation-dependent and not specified anywhere.\n",
            "\nMinGW is an implementation of most of the GNU building utilities, like gcc and make on windows, while gcc is only the compiler. Cygwin is a lot bigger and sophisticated package, wich installs a lot more than MinGW.\n",
            "\nThe socket interface will probably not flow control the originator of the data, so you will probably see reliable transmission if you have higher level flow control but there is always the possibility that a memory crunch could still cause a dropped datagram.\nWithout flow control limiting kernel memory allocation for datagrams I imagine it will be just as unreliable as network UDP.\n",
            "\nMinGW is a suite of development tools that contains GCC (among others), and GCC is a C compiler within that suite.\n",
            "\nTo compile C program you need a C implementation for your specific computer.\nC implementations consist, basically, of a compiler (its preprocesser and headers) and a library (the ready-made executable code).\nOn a computer with Windows installed, the library that contains most ready-made executable code is not compatible with gcc compiler ... so to use this compiler in Windows you need a different library: that's where MinGW enters. MinGW provides, among other things, the library(ies) needed for making a C implementation together with gcc.\n\nThe Windows library and MSVC together make a different implementation.\n",
            "\nIn short, no. You shouldn't be making any assumptions about the order of data received on a UDP socket, even over localhost. It might work, it might not, and it's not guaranteed to.\n",
            "\nMinGW is a complete GCC toolchain (including half a dozen frontends, such as C, C++, Ada, Go, and whatnot) for the Windows platform which compiles for and links to the Windows OS component C Runtime Library in msvcrt.dll. Rather it tries to be minimal (hence the name).\nThis means, unlike Cygwin, MinGW does not attempt to offer a complete POSIX layer on top of Windows, but on the other hand it does not require you to link with a special compatibility library.\nIt therefore also does not have any GPL-license implications for the programs you write (notable exception: profiling libraries, but you will not normally distribute those so that does not matter).\nThe newer MinGW-w64 comes with a roughly 99% complete Windows API binding (excluding ATL and such) including x64 support and experimental ARM implementations. You may occasionally find some exotic constant undefined, but for what 99% of the people use 99% of the time, it just works perfectly well.\nYou can also use the bigger part of what's in POSIX, as long as it is implemented in some form under Windows. The one major POSIX thing that does not work with MinGW is fork, simply because there is no such thing under Windows (Cygwin goes through a lot of pain to implement it).\nThere are a few other minor things, but all in all, most things kind of work anyway.\nSo, in a very very simplified sentence: MinGW(-w64) is a \"no-frills compiler thingie\" that lets you write native binary executables for Windows, not only in C and C++, but also other languages.\n"
        ],
        "answer": "A1",
        "tags": [
            "c",
            "windows",
            "sockets",
            "udp",
            "winsock"
        ]
    },
    {
        "question_id": "41140975",
        "question": "\nuse App\\Order;\n \npublic function show(Order $order) {\n    $data = $order->all();\n    return dd($order->getQueryLog());\n\nIs there any way to display the query built by Eloquent in Laravel?\nI tried getQueryLog(); but its not working\n",
        "all_answers": [
            "\nFirst you have to enable query log\nit can be done using\nDB::connection()->enableQueryLog();\n\nthen you can use below code to see the query log\n$queries = DB::getQueryLog();\n\nif you want to see the last executed query\n$last_query = end($queries);\n\nto know more about logging see this https://laravel.com/docs/5.0/database#query-logging\nExample\npublic function show(Order $order){\n    \\DB::connection()->enableQueryLog();\n    $data = $order->all();\n    $queries = \\DB::getQueryLog();\n\n    dd($queries);\n}\n\n",
            "\nTo use getQueryLog() you need to enable it first:\nDB::enableQueryLog();\nDB::getQueryLog();\n\nIf you want to see real queries, you can use Laravel Debugbar, it will show all real queries Laravel created during current request.\nSometimes ->toSql() is also useful.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "laravel"
        ]
    },
    {
        "question_id": "5446124",
        "question": "\nRecently I've learned the wonder of indexes, and performance has improved dramatically. However, with all I've learned, I can't seem to find the answer to this question.\nIndexes are great, but why couldn't someone just index all fields to make the table incredibly fast? I'm sure there's a good reason to not do this, but how about three fields in a thirty-field table? 10 in a 30 field? Where should one draw the line, and why?\n",
        "all_answers": [
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nIndexes take up space in memory (RAM); Too many or too large of indexes and the DB is going to have to be swapping them to and from the disk.  They also increase insert and delete time (each index must be updated for every piece of data inserted/deleted/updated). \nYou don't have infinite memory. Making it so all indexes fit in RAM = good.\nYou don't have infinite time. Indexing only the columns you need indexed minimizes the insert/delete/update performance hit.\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nYou have to balance CRUD needs.  Writing to tables becomes slow.  As for where to draw the line, that depends on how the data is being acessed (sorting filtering, etc.).\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n"
        ],
        "answer": "A6",
        "tags": [
            "mysql",
            "sql",
            "indexing"
        ]
    },
    {
        "question_id": "143815",
        "question": "\nCan I use JavaScript to check (irrespective of scrollbars) if an HTML element has overflowed its content? For example, a long div with small, fixed size, the overflow property set to visible, and no scrollbars on the element.\n",
        "all_answers": [
            "\nNormally, you can compare the client[Height|Width] with scroll[Height|Width] in order to detect this... but the values will be the same when overflow is visible. So, a detection routine must account for this:\n// Determines if the passed element is overflowing its bounds,\n// either vertically or horizontally.\n// Will temporarily modify the \"overflow\" style to detect this\n// if necessary.\nfunction checkOverflow(el)\n{\n   var curOverflow = el.style.overflow;\n\n   if ( !curOverflow || curOverflow === \"visible\" )\n      el.style.overflow = \"hidden\";\n\n   var isOverflowing = el.clientWidth < el.scrollWidth \n      || el.clientHeight < el.scrollHeight;\n\n   el.style.overflow = curOverflow;\n\n   return isOverflowing;\n}\n\nTested in FF3, FF40.0.2, IE6, Chrome 0.2.149.30.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nTry comparing element.scrollHeight / element.scrollWidth to element.offsetHeight / element.offsetWidth\nhttp://developer.mozilla.org/en/DOM/element.offsetWidth\nhttp://developer.mozilla.org/en/DOM/element.offsetHeight\nhttp://developer.mozilla.org/en/DOM/element.scrollWidth\nhttp://developer.mozilla.org/en/DOM/element.scrollHeight\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "html",
            "css"
        ]
    },
    {
        "question_id": "41661383",
        "question": "\nEspecially during the transition from webpack v1 to v2, it would be important to programmatically determine what webpack version is installed, but I cannot seem to find the appropriate API.\n",
        "all_answers": [
            "\nFor those who are using yarn\nyarn list webpack will do the trick\n$ yarn list webpack\nyarn list v0.27.5\n└─ [email protected]\nDone in 1.24s.\n\n",
            "\nVersion Installed:\nUsing webpack CLI: (--version, -v  Show version number [boolean])\nwebpack --version\n\nor:\nwebpack -v\n\nUsing npm list command:\nnpm list webpack\n\nResults in name@version-range:\n<projectName>@<projectVersion> /path/to/project\n└── webpack@<version-range>\n\nUsing yarn list command:\nyarn list webpack\n\n\nHow to do it programmatically?\nWebpack 2 introduced Configuration Types.\n\nInstead of exporting a configuration object, you may return a function\n  which accepts an environment as argument. When running webpack, you\n  may specify build environment keys via --env, such as --env.production\n  or --env.platform=web.\n\nWe will use a build environment key called --env.version.\nwebpack --env.version $(webpack --version)\n\nor:\nwebpack --env.version $(webpack -v)\n\nFor this to work we will need to do two things:\nChange our webpack.config.js file and use DefinePlugin.\n\nThe DefinePlugin allows you to create global constants which can be\n  configured at compile time.\n\n-module.exports = {\n+module.exports = function(env) {\n+  return {\n    plugins: [\n      new webpack.DefinePlugin({\n+        WEBPACK_VERSION: JSON.stringify(env.version) //<version-range>\n      })\n    ]\n+  };\n};\n\nNow we can access the global constant like so:\nconsole.log(WEBPACK_VERSION);\n\n\nLatest version available:\nUsing npm view command will return the latest version available on the registry:\n\nnpm view [<@scope>/]<name>[@<version>] [<field>[.<subfield>]...]\n\n\nFor webpack use:\nnpm view webpack version\n\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nwebpack 4 now offers a version property that can be used!\n"
        ],
        "answer": "A4",
        "tags": [
            "javascript",
            "node.js",
            "webpack",
            "webpack-2",
            "webpack-3"
        ]
    },
    {
        "question_id": "42925447",
        "question": "\nI am ready to send my first app to beta testers, so i click on 'Manage Beta' > 'Manage testers'\n.\nand 'Save' and 'Resume'\nAPK is uploaded > 'Review'\nThe review summary says 'This release is ready to be rolled out.', but the button labled with 'Start to rollout to beta' is disabled: .\n",
        "all_answers": [
            "\nThey are missing a tooltip over the disabled button that should read something like: \"Please make sure there are no warnings in sections on the left sidenav to enable publishing.\"  \nIf you only see green checkmarks in the other sections you should be good to go.\n",
            "\nIf this is your first app, the problem will be due to payment processing which can take up to 48 hours according to your Google Play Developer Console under Account Details. Here is the actual text:\nPayment Pending\nYour payment is still processing, which will take up to 48 hours.\nYou can already start to upload APKs and prepare Store listings but not publish any applications yet.\nWe will notify you when the payment went through and you can publish your applications. \n",
            "\nIt will be active when nothing on left is grey but green ticked as shownenter image description here\n",
            "\nTo see what still needs to be done, you can hover your mouse over the grayed out checkmark. There will be a popup that tells you what you still need to finish.\n\n",
            "\nYou also need to make sure that you made it available in at least one country.\nBy default not one country is selected!\n",
            "\nYou will need to complete the Store listing, Pricing & distribution and Content rating before you can publish the app, once these task have been completed you should be able to publish the app.\n",
            "\n\nUpdate : The answer below is outdated. These days you should see a list of options on the left, that have grayed out ticks in-front of them. Hover over the tick and it should display the list of tasks you need done to complete that category. Visit each of these items and complete them (make sure the icon becomes green - check the screenshot below) to enable the button.\n\n\nNot sure whether this is the actual answer or what you are expecting, but I am stuck at the same place (I just created an account, application and a release. Saw the disabled button and started googling). However there is a link on the top right side of the screen (barely visible, i should add), with the text \"Why can't I publish?\". And when I click on it I get list of error messages(I think). So as of now i am stuck on that list. Probably, fixing them might enable the button.\n",
            "\n\nYou have to add \"Content rating\", \"Pricing & Distribution\" information first so all checkboxes at the left are green\nThen you have to click Save\n\nThen you'll be able to click Review.\n",
            "\nMake Sure the following are checked\n\n",
            "\nSaranga is right from my experience.  Before I could send out a beta version I had to ensure I had the images under store listing included.  Just look at the side bar (see image) and see whats greyed out and thats where the problem was for me.\n\n",
            "\nThis can happen if payment for a recently created account is still processing, even if all mandatory sections are completed. I just created an account and I had this issue. I realized that my payment for the account creation was still processing. Once it's processed it's possible to publish the app.\n",
            "\nI had the same problem. In my case I had to agree to \"Content guidelines\" and \"US export laws\" listed under \"Consent\" in \"Pricing & distribution\" section.\n"
        ],
        "answer": "A4",
        "tags": [
            "android",
            "google-play"
        ]
    },
    {
        "question_id": "2907335",
        "question": "\nI want to disable the orange highlight that occurs when touching a listView row. So far in my xml I have tried the following:\nandroid:focusable=\"false\"\nandroid:focusableInTouchMode=\"false\"\nandroid:clickable=\"false\"\n\nMore information: I want there to be zero difference when a user touches the screen on this listView object.\n",
        "all_answers": [
            "\nThe orange highlight effect is a style on the ListView.  This article gives a good overview of how to override the listView style.\nEssentially, you have a selector that specifies different style elements based on the current state. \nsee this for short and quick solution https://stackoverflow.com/a/12242564/185022\n",
            "\nAdd this to your xml:\nandroid:listSelector=\"@android:color/transparent\"\n\nAnd for the problem this may work (I'm not sure and I don't know if there are better solutions):\nYou could apply a ColorStateList to your TextView.\n"
        ],
        "answer": "A2",
        "tags": [
            "android",
            "android-listview",
            "highlighting"
        ]
    },
    {
        "question_id": "4617291",
        "question": "\nI have a SQLAlchemy query object and want to get the text of the compiled SQL statement, with all its parameters bound (e.g. no %s or other variables waiting to be bound by the statement compiler or MySQLdb dialect engine, etc).\nCalling str() on the query reveals something like this:\nSELECT id WHERE date_added <= %s AND date_added >= %s ORDER BY count DESC\n\nI've tried looking in query._params but it's an empty dict.  I wrote my own compiler using this example of the sqlalchemy.ext.compiler.compiles decorator but even the statement there still has %s where I want data.\nI can't quite figure out when my parameters get mixed in to create the query; when examining the query object they're always an empty dictionary (though the query executes fine and the engine prints it out when you turn echo logging on).\nI'm starting to get the message that SQLAlchemy doesn't want me to know the underlying query, as it breaks the general nature of the expression API's interface all the different DB-APIs.  I don't mind if the query gets executed before I found out what it was; I just want to know!\n",
        "all_answers": [
            "\nThis blogpost by Nicolas Cadou provides an updated answer.\nQuoting from the blog post, this is suggested and worked for me:\n\nfrom sqlalchemy.dialects import postgresql\nprint str(q.statement.compile(dialect=postgresql.dialect()))\n\n\nWhere q is defined as:\n\nq = DBSession.query(model.Name).distinct(model.Name.value) \\\n             .order_by(model.Name.value)\n\n\nOr just any kind of session.query().\n",
            "\nFor the MySQLdb backend I modified albertov's awesome answer (thanks so much!) a bit.  I'm sure they could be merged to check if comp.positional was True but that's slightly beyond the scope of this question.\ndef compile_query(query):\n    from sqlalchemy.sql import compiler\n    from MySQLdb.converters import conversions, escape\n\n    dialect = query.session.bind.dialect\n    statement = query.statement\n    comp = compiler.SQLCompiler(dialect, statement)\n    comp.compile()\n    enc = dialect.encoding\n    params = []\n    for k in comp.positiontup:\n        v = comp.params[k]\n        if isinstance(v, unicode):\n            v = v.encode(enc)\n        params.append( escape(v, conversions) )\n    return (comp.string.encode(enc) % tuple(params)).decode(enc)\n\n",
            "\nThing is, sqlalchemy never mixes the data with your query. The query and the data are passed separately to your underlying database driver - the interpolation of data happens in your database.\nSqlalchemy passes the query as you've seen in str(myquery) to the database, and the values will go in a separate tuple.\nYou could use some approach where you interpolate the data with the query yourself (as albertov suggested below), but that's not the same thing that sqlalchemy is executing.\n",
            "\nThis should work with Sqlalchemy >= 0.6\nfrom sqlalchemy.sql import compiler\n\nfrom psycopg2.extensions import adapt as sqlescape\n# or use the appropiate escape function from your db driver\n\ndef compile_query(query):\n    dialect = query.session.bind.dialect\n    statement = query.statement\n    comp = compiler.SQLCompiler(dialect, statement)\n    comp.compile()\n    enc = dialect.encoding\n    params = {}\n    for k,v in comp.params.iteritems():\n        if isinstance(v, unicode):\n            v = v.encode(enc)\n        params[k] = sqlescape(v)\n    return (comp.string.encode(enc) % params).decode(enc)\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "sql",
            "mysql",
            "sqlalchemy"
        ]
    },
    {
        "question_id": "8763497",
        "question": "\nIn a recent interview, I was asked a really strange question. The interviewer asked me how can I compute 1+2+3+...+1000 just using compiler features. This means that I am not allowed to write a program and execute it, but I should just write a program that could drive the compiler to compute this sum while compilation and print the result when compilation completes. As a hint, he told me that I may use generics and pre-processor features of the compiler. It is possible to use C++, C# or Java compiler. Any ideas???\nThis question is not related to computing the sum without any loops asked here. In addition, It should be noted that the sum SHOULD be calculated during compilation. Printing just the result using C++ compiler directives is not acceptable. \n\nReading more about the posted answers, I found that solving problems during compilation using C++ templates is called metaprogramming. This is a technique that was discovered accidentally by Dr. Erwin Unruh,  during the process of standardizing the C++ language. You may read more about this topic on wiki page of meta-programming.\nIt seems that it is possible to write the program in Java using java annotations. You may take a look at maress's answer below. \nA nice book about meta-programming in C++ is this one. Worth to take a look if interested. \nA useful C++ meta-programming library is Boost's MPL this link.\n",
        "all_answers": [
            "\nYou can use (and mostly abuse) C++ macros/templates to do metaprogramming.\nAFAIK, Java doesn't allow the same kind of thing.\n",
            "\nUpdated Now with improved recursion depth! Works on MSVC10 and GCC without increased depth. :)\n\nSimple compile-time recursion + addition:\ntemplate<unsigned Cur, unsigned Goal>\nstruct adder{\n  static unsigned const sub_goal = (Cur + Goal) / 2;\n  static unsigned const tmp = adder<Cur, sub_goal>::value;\n  static unsigned const value = tmp + adder<sub_goal+1, Goal>::value;\n};\n\ntemplate<unsigned Goal>\nstruct adder<Goal, Goal>{\n  static unsigned const value = Goal;\n};\n\nTestcode:\ntemplate<unsigned Start>\nstruct sum_from{\n  template<unsigned Goal>\n  struct to{\n    template<unsigned N>\n    struct equals;\n\n    typedef equals<adder<Start, Goal>::value> result;\n  };\n};\n\nint main(){\n  sum_from<1>::to<1000>::result();\n}\n\nOutput for GCC:\n\nerror: declaration of ‘struct sum_from<1u>::to<1000u>::equals<500500u>’\n\nLive example on Ideone.\nOutput for MSVC10:\nerror C2514: 'sum_from<Start>::to<Goal>::equals<Result>' : class has no constructors\n      with\n      [\n          Start=1,\n          Goal=1000,\n          Result=500500\n      ]\n\n",
            "\nI am also a bit curious with the answer.\nThe most satisfying answer that I find is from Artemix in another post here (I'm renaming the AClass with Person class):\nWhy have class-level access modifiers instead of object-level?\n\nThe private modifier enforces Encapsulation principle.\nThe idea is that 'outer world' should not make changes to Person internal processes because Person implementation may change over time (and you would have to change the whole outer world to fix the differences in implementation - which is nearly to impossible).\nWhen instance of Person accesses internals of other Person instance - you can be sure that both instances always know the details of implementation of Person. If the logic of internal to Person processes is changed - all you have to do is change the code of Person.\n\nEDIT:\nPlease vote Artemix' answer. I'm just copy-pasting it.\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "java",
            "c++",
            "compiler-construction",
            "metaprogramming"
        ]
    },
    {
        "question_id": "29486583",
        "question": "\n\nTable storage engine for <TABLE> doesn't have this option.\n\nThis is the error returned by MySQL on an order by query. The column type is varchar(2000).\nQuery:\nselect * from `dbo.table_1` order by textT;\n\nError returned:\n\nERROR 1031 (HY000): Table storage engine for 'dbo.table_1' doesn't have this option.\n\nWhy does this happen? And how can I fix it?\n",
        "all_answers": [
            "\nI get the same error when I import a table definition that's InnoDB with ROW_FORMAT=DYNAMIC in it. The table was created with a MyISAM engine but I later switched it to InnoDB. When I removed the ROW_FORMAT=DYNAMIC from the create table statement and recreated the table it worked fine. My solution to your problem would be this.\nshow create table `dbo.table_1`;\n\nthen take the output from that command and remove the ROW_FORMAT=DYNAMIC then rename the table to dbo.table_1_old\nrename table `dbo.table_1` to `dbo.table_1_old`;\n\nThen execute the create table statement from the first step i.e.\n-- don't use this create as there are missing columns use yours\ncreate table `dbo.table_1` (textT VARCHAR(255)); \n\nThen repopulate your table with the old data.\ninsert into `dbo.table_1` select * from `dbo.table_1_old`;\n\nThen you should be able to execute your original SQL\nselect * from `dbo.table_1` order by textT;\n\n",
            "\nThis problem appears to occur when you're importing a table definition that had been created with MyISAM but later was switched to InnoDB; the resulting ROW_FORMAT options appear to be invalid.\nIf you're trying to import an exported database and encounter this problem, you can simply search and replace ROW_FORMAT=FIXED with nothing.\nI used the following to do so really quickly:\nsed -ie 's/ROW_FORMAT=FIXED//g' backup.sql\n\nProblem solved! Thanks to jbrahy for pointing out that it was the ROW_FORMAT that was the problem.\nEDIT: Updated to work for more platforms as per @seven's suggestion\nEDIT2: Also note, as per @Steen-Schütt, this may be a safer fix\nsed -ie 's/ROW_FORMAT=FIXED/ROW_FORMAT=COMPACT/g' backup.sql\n\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n"
        ],
        "answer": "A2",
        "tags": [
            "mysql",
            "sql"
        ]
    },
    {
        "question_id": "18700219",
        "question": "\nI'm trying to put my app into production and image and css asset paths aren't working.\nHere's what I'm currently doing:\n\nImage assets live in /app/assets/images/image.jpg \nStylesheets live in /app/assets/stylesheets/style.css\nIn my layout, I reference the css file like this: <%= stylesheet_link_tag    \"styles\", media: \"all\", \"data-turbolinks-track\" => true %>\nBefore restarting unicorn, I run RAILS_ENV=production bundle exec rake assets:precompile and it succeeds and I see the fingerprinted files in the public/assets directory.\n\nWhen I browse to my site, I get a 404 not found error for mysite.com/stylesheets/styles.css. \nWhat am I doing wrong?\nUpdate:\nIn my layout, it looks like this:\n<%= stylesheet_link_tag    \"bootstrap.min\", media: \"all\", \"data-turbolinks-track\" => true %>\n<%= stylesheet_link_tag    \"styles\", media: \"all\", \"data-turbolinks-track\" => true %>\n<%= javascript_include_tag \"application\", \"data-turbolinks-track\" => true %>\n\nThe generate source is this:\n<link data-turbolinks-track=\"true\" href=\"/stylesheets/bootstrap.min.css\" media=\"all\" rel=\"stylesheet\" />\n<link data-turbolinks-track=\"true\" href=\"/stylesheets/styles.css\" media=\"all\" rel=\"stylesheet\" />\n<script data-turbolinks-track=\"true\" src=\"/assets/application-0c647c942c6eff10ad92f1f2b0c64efe.js\"></script>\n\nLooks like Rails is not properly looking for the compiled css files. But it's very confusing why it's working correctly for javascripts (notice the /assets/****.js path).\n",
        "all_answers": [
            "\nRails 4 no longer generates the non fingerprinted version of the asset: stylesheets/style.css will not be generated for you.\nIf you use stylesheet_link_tag then the correct link to your stylesheet will be generated\nIn addition styles.css should be in config.assets.precompile which is the list of things that are precompiled\n",
            "\nIn /config/environments/production.rb I had to add this:\nRails.application.config.assets.precompile += %w( *.js ^[^_]*.css *.css.erb )\n\nThe .js was getting precompiled already, but I added it anyway. The .css and .css.erb apparently don't happen automatically. The ^[^_] excludes partials from being compiled -- it's a regexp.\nIt's a little frustrating that the docs clearly state that asset pipeline IS enabled by default but doesn't clarify the fact that only applies to javascripts.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "asset-pipeline",
            "ruby-on-rails-4"
        ]
    },
    {
        "question_id": "4220126",
        "question": "\nI want to trigger an ajax request when the user has finished typing in a text box. I don't want it to run the function on every time the user types a letter because that would result in A LOT of ajax requests, however I don't want them to have to hit the enter button either.\nIs there a way so I can detect when the user has finished typing and then do the ajax request?\nUsing jQuery here!\n",
        "all_answers": [
            "\nOnce you detect focus on the text box, on key up do a timeout check, and reset it each time it's triggered.\nWhen the timeout completes, do your ajax request.\n",
            "\nSo, I'm going to guess finish typing means you just stop for a while, say 5 seconds.  So with that in mind, let's start a timer when the user releases a key and clear it when they press one.  I decided the input in question will be #myInput.\nMaking a few assumptions...\n//setup before functions\nvar typingTimer;                //timer identifier\nvar doneTypingInterval = 5000;  //time in ms, 5 seconds for example\nvar $input = $('#myInput');\n\n//on keyup, start the countdown\n$input.on('keyup', function () {\n  clearTimeout(typingTimer);\n  typingTimer = setTimeout(doneTyping, doneTypingInterval);\n});\n\n//on keydown, clear the countdown \n$input.on('keydown', function () {\n  clearTimeout(typingTimer);\n});\n\n//user is \"finished typing,\" do something\nfunction doneTyping () {\n  //do something\n}\n\n",
            "\nWell, strictly speaking no, as the computer cannot guess when the user has finished typing. You could of course fire a timer on key up, and reset it on every subsequent key up. If the timer expires, the user hasn't typed for the timer duration - you could call that \"finished typing\".\nIf you expect users to make pauses while typing, there's no way to know when they are done.\n(Unless of course you can tell from the data when they are done) \n",
            "\nYou can use the onblur event to detect when the textbox loses focus:\nhttps://developer.mozilla.org/en/DOM/element.onblur\nThat's not the same as \"stops typing\", if you care about the case where the user types a bunch of stuff and then sits there with the textbox still focused.\nFor that I would suggest tying a setTimeout to the onclick event, and assuming that after x amount of time with no keystrokes, the user has stopped typing.\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "jquery",
            "keyboard"
        ]
    },
    {
        "question_id": "4805269",
        "question": "\nI'd like to know what is the best practice/way of programmatically register a broadcast receiver. I want to register specific receivers according to user choice.\nAs the registration is done through the manifest file, I'm wondering if there's a proper way to achieve this in code.\n",
        "all_answers": [
            "\nAccording to Listening For and Broadcasting Global Messages, and Setting Alarms in Common Tasks and How to Do Them in Android:\n\nIf the receiving class is not\n  registered using  in its\n  manifest, you can dynamically\n  instantiate and register a receiver by\n  calling Context.registerReceiver().\n\nTake a look at registerReceiver  (BroadcastReceiver  receiver, IntentFilter  filter) for more info.\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nIn your onCreate method you can register a receiver like this:\nprivate BroadcastReceiver receiver;\n\n@Override\npublic void onCreate(Bundle savedInstanceState){\n\n  // your oncreate code should be\n\n  IntentFilter filter = new IntentFilter();\n  filter.addAction(\"SOME_ACTION\");\n  filter.addAction(\"SOME_OTHER_ACTION\");\n\n  receiver = new BroadcastReceiver() {\n    @Override\n    public void onReceive(Context context, Intent intent) {\n      //do something based on the intent's action\n    }\n  };\n     registerReceiver(receiver, filter);\n}\n\nRemember to run this in the onDestroy method:\n @Override\n protected void onDestroy() {\n  if (receiver != null) {\n   unregisterReceiver(receiver);\n   receiver = null;\n  }\n  super.onDestroy();\n }\n\n",
            "\nIt sounds like you want to control whether  components published in your manifest are active, not dynamically register a receiver (via Context.registerReceiver()) while running.\nIf so, you can use PackageManager.setComponentEnabledSetting() to control whether these components are active:\nhttp://developer.android.com/reference/android/content/pm/PackageManager.html#setComponentEnabledSetting(android.content.ComponentName, int, int)\nNote if you are only interested in receiving a broadcast while you are running, it is better to use registerReceiver().  A receiver component is primarily useful for when you need to make sure your app is launched every time the broadcast is sent.\n"
        ],
        "answer": "A6",
        "tags": [
            "android",
            "broadcastreceiver"
        ]
    },
    {
        "question_id": "7483515",
        "question": "\nI am very new in Rails.\nafter I created a new rails project.\nrails new test project\n\nI ran \nrake db:create \n\nIn order to create a database. \nFound the following error message:\nrake aborted!\nno such file to load -- bundler/setup\n\nI am running \n Rails 3.1.0 \n Ruby 1.9.2p290 \n rvm 1.8.3 \nThank you very much!\nmy $PATH\n    /Users/Mac/.rvm/scripts/rvm:/Users/Mac/.rvm/bin:/Users/Mac/.local/bin:/opt/local/bin:/opt/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/usr/local/git/bin:/usr/X11/bin:{ANT_HOME}/bin\n",
        "all_answers": [
            "\nRun:\ngem install bundler\nbundle install\nbundle exec rake db:create\n\nYou might want to learn about Bundler.\nSee the link on \"Creating new Rails Project\".\n",
            "\ntry \n\ngem install bundler \nbundle install\n\nto install the gems needed.\nrake tasks will fail if you do not have the gems necessary for the rails app.\n",
            "\nHave you tried to gem install bundler? I'd be surprised it doesn't install when you install the rails gem, but it seems that's your issue...\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails"
        ]
    },
    {
        "question_id": "2369744",
        "question": "\nI have a rails application running over Postgres.\nI have two servers: one for testing and the other for production.\nVery often I need to clone the production DB on the test server.\nThe command I'm runnig via Vlad is:\nrake RAILS_ENV='test_server' db:drop db:create\n\nThe problem I'm having is that I receive the following error:\nActiveRecord::StatementInvalid: PGError: ERROR: database <database_name> is being accessed by other users DROP DATABASE IF EXISTS <database_name>\n\nThis happens if someone has accessed the application via web recently (postgres keeps a \"session\" opened)\nIs there any way that I can terminate the sessions on the postgres DB?\nThank you.\nEdit\nI can delete the database using phppgadmin's interface but not with the rake task.\nHow can I replicate phppgadmin's drop with a rake task?\n",
        "all_answers": [
            "\nIf you kill the running postgresql connections for your application, you can then run db:drop just fine.  So how to kill those connections?  I use the following rake task:\n# lib/tasks/kill_postgres_connections.rake\ntask :kill_postgres_connections => :environment do\n  db_name = \"#{File.basename(Rails.root)}_#{Rails.env}\"\n  sh = <<EOF\nps xa \\\n  | grep postgres: \\\n  | grep #{db_name} \\\n  | grep -v grep \\\n  | awk '{print $1}' \\\n  | xargs kill\nEOF\n  puts `#{sh}`\nend\n\ntask \"db:drop\" => :kill_postgres_connections\n\nKilling the connections out from under rails will sometimes cause it to barf the next time you try to load a page, but reloading it again re-establishes the connection.\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nRails is likely connecting to the database to drop it but when you log in via phppgadmin it is logging in via the template1 or postgres database, thus you are not affected by it.\n",
            "\nLet your application close the connection when it's done. PostgreSQL doesn't keep connections open , it's the application keeping the connection.\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "postgresql"
        ]
    },
    {
        "question_id": "7698764",
        "question": "\nI realize one can specify a custom graphic to be a replacement bullet character, using CSS attribute:\nlist-style-image\n\nAnd then giving it a URL.\nHowever, in my case, I just want to use the '+' symbol. I don't want to have to create a graphic for that and then point to it. I'd rather just instruct the unordered list to use a plus symbol as the bullet symbol.\nCan this be done or am I forced to make it a graphic first?\n",
        "all_answers": [
            "\nYou can use the :before pseudo-selector to insert content in front of the list item. You can find an example on Quirksmode, at http://www.quirksmode.org/css/beforeafter.html. I use this to insert giant quotes around blockquotes...\nHTH.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nThe following is quoted from Taming Lists:\n\nThere may be times when you have a list, but you don’t want any bullets, or you want to use some other character in place of the bullet. Again, CSS provides a straightforward solution. Simply add list-style: none; to your rule and force the LIs to display with hanging indents. The rule will look something like this:\nul {\n   list-style: none;\n   margin-left: 0;\n   padding-left: 1em;\n   text-indent: -1em;\n}\n\nEither the padding or the margin needs to be set to zero, with the other one set to 1em. Depending on the “bullet” that you choose, you may need to modify this value. The negative text-indent causes the first line to be moved to the left by that amount, creating a hanging indent.\nThe HTML will contain our standard UL, but with whatever character or HTML entity that you want to use in place of the bullet preceding the content of the list item. In our case we'll be using », the right double angle quote: ».\n\n» Item 1\n» Item 2\n» Item 3\n» Item 4\n» Item 5 we'll make\n   a bit longer so that\n   it will wrap\n\n\n"
        ],
        "answer": "A4",
        "tags": [
            "html",
            "css",
            "webkit",
            "mobile-webkit"
        ]
    },
    {
        "question_id": "42170561",
        "question": "\nI love VSCode on save autoformat until it messed up with my template code.\nIt wrongly formats my django template syntax into one line code (sometimes really long line). So instead of having this code\n{% for row in 'ABCDEFGH' %}\n<tr>\n  {% for col in '123456789012345' %}\n    <td>\n      {% with forloop.counter|stringformat:\"s\" as counter %}\n        {% with row|add:counter as seat_num %}\n          {% if seat_num not in oc_seats %}\n            <input type=\"checkbox\" value=\"{{ row }}{{ forloop.counter }}\" name=\"seats\">\n          {% endif %}\n          <br> {{ seat_num }} \n        {% endwith %}\n      {% endwith %}\n     </td>    \n   {% endfor %}\n</tr>\n{% endfor %}\n\nI end up have this code\n{% for row in 'ABCDEFGH' %}\n<tr>\n  {% for col in '123456789012345' %}\n  <td style=\"text-align: center; border: 1px solid #aaa;\">\n    {% with forloop.counter|stringformat:\"s\" as counter %} {% with row|add:counter as seat_num %} {% if seat_num not in oc_seats %}\n    <input type=\"checkbox\" value=\"{{ row }}{{ forloop.counter }}\" name=\"seats\"> {% endif %} {{ seat_num }} {% endwith %} {% endwith %}\n  </td>\n  {% endfor %}\n</tr>\n{% endfor %}\n\nI tried to disable format on save by changing user settings into {\"editor.formatOnSave\": false} but still haven't gotten any luck.\nIs there any configuration that I can use to make it work better?\nPS: \nI'm using VSCode version 1.9 on Sierra MacOSx\n",
        "all_answers": [
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nyou can disable the default html formatter, goto File > Preferences > User or Workspace Settings, in HTML settings you will find :\n// Enable/disable default HTML formatter (requires restart)\n  \"html.format.enable\": true,\n\nI think VSCode uses js-beautify as default formatter, you can use beautify extension to override it settings with .jsbeautifyrc in project directory\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nHad the same issue, found a post where the person disabled JS-CSS-HTML Formatter extension (https://stackoverflow.com/a/42100808/4812548) and it fixed the issue. Tested on mine and it seems to have worked too. Hope that helps\n"
        ],
        "answer": "A2",
        "tags": [
            "html",
            "django",
            "django-templates",
            "visual-studio-code"
        ]
    },
    {
        "question_id": "1560572",
        "question": "\nI often find myself writing this:\nparams.delete(:controller)  \nparams.delete(:action)  \nparams.delete(:other_key)  \nredirect_to my_path(params)  \n\nThe trail of deletes doesn't feel right and neither does:\n[:controller, :action, :other_key].each do |k|\n  params.delete(k)\nend\n\nIs there anything simpler and cleaner?\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nI'm guessing you're unaware of the Hash#except method ActiveSupport adds to Hash.\nIt would allow your code to be simplified to:\nredirect_to my_path(params.except(:controller, :action, :other_key))\n\nAlso, you wouldn't have to monkey patch, since the Rails team did it for you!\n",
            "\nFire up a monkey patch?\nclass Hash\n  def delete_keys!(*keys)\n    keys.flatten.each do |k|\n      delete(k)\n    end\n\n    self\n  end\n\n  def delete_keys(*keys)\n    _dup = dup\n    keys.flatten.each do |k|\n      _dup.delete(k)\n    end\n\n    _dup\n  end\nend\n\n",
            "\nAnother way to phrase dmathieu's answer might be\nparams.delete_if { |k,v| [:controller, :action, :other_key].include? k }\n\n",
            "\nI'd be completely happy with the code you originally posted in your question.\n[:controller, :action, :other_key].each { |k| params.delete(k) }\n\n",
            "\nI don't know what you think is wrong with your proposed solution.  I suppose you want a delete_all method on Hash or something?  If so, tadman's answer provides the solution.  But frankly, for a one-off, I think your solution is extremely easy to follow.  If you're using this frequently, you might want to wrap it up in a helper method.\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "ruby"
        ]
    },
    {
        "question_id": "1066453",
        "question": "\nI want to be able to select a bunch of rows from a table of e-mails and group them by the from sender.  My query looks like this:\nSELECT \n    `timestamp`, `fromEmail`, `subject`\nFROM `incomingEmails` \nGROUP BY LOWER(`fromEmail`) \nORDER BY `timestamp` DESC\n\nThe query almost works as I want it — it selects records grouped by e-mail. The problem is that the subject and timestamp don't correspond to the most recent record for a particular e-mail address.\nFor example, it might return:\nfromEmail: [email protected], subject: hello\nfromEmail: [email protected], subject: welcome\n\nWhen the records in the database are:\nfromEmail: [email protected], subject: hello\nfromEmail: [email protected], subject: programming question\nfromEmail: [email protected], subject: welcome\n\nIf the \"programming question\" subject is the most recent, how can I get MySQL to select that record when grouping the e-mails?\n",
        "all_answers": [
            "\nAccording to SQL standard you cannot use non-aggregate columns in select list.\nMySQL allows such usage (uless ONLY_FULL_GROUP_BY mode used) but result is not predictable.\nONLY_FULL_GROUP_BY\nYou should first select fromEmail, MIN(read), and then, with second query (or subquery) - Subject.\n",
            "\nHere's one approach:\nSELECT cur.textID, cur.fromEmail, cur.subject, \n     cur.timestamp, cur.read\nFROM incomingEmails cur\nLEFT JOIN incomingEmails next\n    on cur.fromEmail = next.fromEmail\n    and cur.timestamp < next.timestamp\nWHERE next.timestamp is null\nand cur.toUserID = '$userID' \nORDER BY LOWER(cur.fromEmail)\n\nBasically, you join the table on itself, searching for later rows.  In the where clause you state that there cannot be later rows.  This gives you only the latest row.\nIf there can be multiple emails with the same timestamp, this query would need refining.  If there's an incremental ID column in the email table, change the JOIN like:\nLEFT JOIN incomingEmails next\n    on cur.fromEmail = next.fromEmail\n    and cur.id < next.id\n\n",
            "\nA simple solution is to wrap the query into a subselect with the ORDER statement first and applying the GROUP BY later:\nSELECT * FROM ( \n    SELECT `timestamp`, `fromEmail`, `subject`\n    FROM `incomingEmails` \n    ORDER BY `timestamp` DESC\n) AS tmp_table GROUP BY LOWER(`fromEmail`)\n\nThis is similar to using the join but looks much nicer.\nUsing non-aggregate columns in a SELECT with a GROUP BY clause is non-standard. MySQL will generally return the values of the first row it finds and discard the rest. Any ORDER BY clauses will only apply to the returned column value, not to the discarded ones.\nIMPORTANT UPDATE\nSelecting non-aggregate columns used to work in practice but should not be relied upon. Per the MySQL documentation \"this is useful primarily when all values in each nonaggregated column not named in the GROUP BY are the same for each group. The server is free to choose any value from each group, so unless they are the same, the values chosen are indeterminate.\"\nAs of 5.7.5 ONLY_FULL_GROUP_BY is enabled by default so non-aggregate columns cause query errors (ER_WRONG_FIELD_WITH_GROUP)\nAs @mikep points out below the solution is to use ANY_VALUE() from 5.7 and above\nSee\nhttp://www.cafewebmaster.com/mysql-order-sort-group\nhttps://dev.mysql.com/doc/refman/5.6/en/group-by-handling.html\nhttps://dev.mysql.com/doc/refman/5.7/en/group-by-handling.html\nhttps://dev.mysql.com/doc/refman/5.7/en/miscellaneous-functions.html#function_any-value\n"
        ],
        "answer": "A3",
        "tags": [
            "mysql",
            "sql",
            "group-by",
            "sql-order-by",
            "aggregate-functions"
        ]
    },
    {
        "question_id": "2140282",
        "question": "\nI'm creating a log function that will log my errors in a file.\nI thought it will contain which class and method the error occurred in.\nIs there a way of logging in which class and method the error occurred in so I don't have to type it manually each time?\n",
        "all_answers": [
            "\nget_called_class() get's the current class. This might also be interesting: debug_print_backtrace().\n",
            "\nI'm not big on PHP but I believe it has \"magic constants\" similar to C/C++. Take a look here: This seems to indicate you could use\n__LINE__, __FILE__, __FUNCTION__, __CLASS__, and __METHOD__\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "574941",
        "question": "\nIn my experience, input type=\"text\" onchange event usually occurs only after you leave (blur) the control.\nIs there a way to force browser to trigger onchange every time textfield content changes? If not, what is the most elegant way to track this “manually”?\nUsing onkey* events is not reliable, since you can right-click the field and choose Paste, and this will change the field without any keyboard input.\nIs setTimeout the only way?.. Ugly :-)\n",
        "all_answers": [
            "\nUpdate:\nSee Another answer (2015).\n\nOriginal 2009 Answer:\nSo, you want the onchange event to fire on keydown, blur, and paste? That's magic.\nIf you want to track changes as they type, use \"onkeydown\". If you need to trap paste operations with the mouse, use \"onpaste\" (IE, FF3) and \"oninput\" (FF, Opera, Chrome, Safari1).\n1Broken for <textarea> on Safari. Use textInput instead\n",
            "\nYou could use the keydown, keyup and keypress events as well.\n",
            "\nThese solutions will work:\nAs mentioned in comments use defer:\n<script src=\"deferMe.js\" defer></script>\n\nor\n<body onload=\"script();\">\n\nor\ndocument.onload = function ...\n\nor even\nwindow.onload = function ...\n\nNote that the last option is a better way to go since it is unobstrusive and is considered more standard.\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "html",
            "forms"
        ]
    },
    {
        "question_id": "14251398",
        "question": "\nI have an LG-E405 phone running Android 2.3.6.\nI connected my phone with a USB cable and selected the mode as Charge Only.\nNow when I try to turn on USB Debugging, I find that that the option is greyed out.\nSo, how can I enable USB debugging in this case.\n",
        "all_answers": [
            "\nOK, since I had another Huawei Ascend I ran into the same problem. This time I have the exact answer. Follow these instructions (from denispyr's answer on  Why doesn't logcat show anything in my Android?)\n\nDial\n*#*#2846579#*#*\n\nand you will see a hidden menu. Go to the Project Menu > Background Setting > Log setting and define the log availability (log switch) and level (log level setting).\n\nAnd then make sure you restart your phone.\nPlease note this probably only applies to Huawei phones.\nAlso note that if you're on a Huawei tablet (e.g. MediaPad M3), instead of dialing, you launch the Huawei Calculator in landscape and enter ()()2846579()().\n",
            "\nFor Huawei with Android 8.0+\nwe must dial the code: *#*#2846579#*#*\nand selecting the option AP Log will be enough to display the messages in the LogCat.\n\n",
            "\nIf any one having Letv Phone (LeEco Le Max 2 or 1) above solution won't work. Try the below USSD. Fig.1 for reference.\nPress Dialer *#*#76937#*#*\n\nSelect \"Enable All Logs\"\n\n",
            "\nYou have to enable USB debugging before plugging your device in to the computer. Unplug device then try to enable USB debugging. This should work. If so, you can then plug it back into the computer and it should work\n",
            "\nFinally figured out the solution to the problem, with the help of this post.\nWhen you connect your phone to your PC, using the USB cable, select the mode as PC Software.\nNow you should be able to enable USB Debugging.\n",
            "\nInstead of using\nLog.d(TAG, msg);\n\nTry this.\nLog.wtf(TAG, msg);\n\nwork for me.\n"
        ],
        "answer": "A5",
        "tags": [
            "android",
            "usb",
            "adb"
        ]
    },
    {
        "question_id": "8740868",
        "question": "\nWhen try to connect to the mysql server through my rails application, I get the following error\nD:/Program_Files/Ruby192/lib/ruby/site_ruby/1.9.1/rubygems/custom_require.rb:36:in `require': \nIncorrect MySQL client library version! This gem was compiled for 6.0.0 but the client library is 5.0.27. (RuntimeError)\n\nHow can I rectify it? \n",
        "all_answers": [
            "\nIf you are using 64bit version of mysql and 32bit version of ruby, then check this solution on  http://blog.mmediasys.com/2011/07/07/installing-mysql-on-windows-7-x64-and-using-ruby-with-it/\nYou basically have to download a single connector from mysql website, and compile mysql or mysql2 with connector you downloaded.\nfor Ruby 1.9.2:\ngem install mysql --platform=ruby -- --with-mysql-dir=C:/mysql-connector-c-noinstall-6.0.2-win32\n\nfor Ruby 1.9.3: (showing mysql2 variant)\ngem pristine mysql2 -- --with-mysql-config=C:\\mysql-connector-c-noinstall-6.0.2-win32    \n\nNote the use of forward slashes for the directory where MySQL Connector/C was extracted.\n",
            "\nI had the same problem as you, or at least the symptom was the same.\nBackground: I was using Rails 3, the mysql2 gem, and MySQL community server version 5.5.21 (32-bit) installed locally on my Windows machine. I grabbed the client library (libmysql.dll) from the MySQL installation and copied it to my ruby installation's bin folder.\nWhen I ran bundle exec rake db:create, I got the same error message as you and I thought \"Hey, how can the client library be outdated when I got it from the latest MySQL release?\"\nThere's a helpful message that is shown when you gem install mysql2. Unfortunately, if you install the gem with Bundler, Bundler eats the message. Here it is:\n=========================================================================\nYou've installed the binary version of mysql2. It was built using MySQL \nConnector/C version 6.0.2. It's recommended to use the exact same version\nto avoid potential issues.\n\nAt the time of building this gem, the necessary DLL files where available\nin the following download:\n\nhttp://dev.mysql.com/get/Downloads/Connector-C/mysql-connector-c-noinstall-6.0.2-win32.zip/from/pick\n\nAnd put lib\\libmysql.dll file in your Ruby bin directory, for example\nC:\\Ruby\\bin\n\nFollowing these instructions solved the problem for me.\nReferenced link\n"
        ],
        "answer": "A2",
        "tags": [
            "mysql",
            "ruby-on-rails",
            "windows",
            "mysql2"
        ]
    },
    {
        "question_id": "10040291",
        "question": "\nUsing PHP, I want to convert UNIX timestamps to date strings similar to this: 2008-07-17T09:24:17Z\nHow do I convert a timestamp such as 1333699439 to 2008-07-17T09:24:17Z?\n",
        "all_answers": [
            "\nTry gmdate like this:\n<?php\n$timestamp=1333699439;\necho gmdate(\"Y-m-d\\TH:i:s\\Z\", $timestamp);\n?>\n\n",
            "\nAssuming you are using PHP5.3 then the modern way of handling dates is via the native DateTime class. To get the current time you can just call\n$currentTime = new DateTime();\n\nTo create a DateTime object from a specific timestamp (i.e. not now)\n$currentTime = DateTime::createFromFormat( 'U', $timestamp );\n\nTo get a formatted string you can then call\n$formattedString = $currentTime->format( 'c' );\n\nSee the manual page here\n",
            "\nuse date function  date ( string $format [, int $timestamp = time() ] )\nUse date('c',time()) as format to convert to ISO 8601 date (added in PHP 5) - 2012-04-06T12:45:47+05:30\nuse date(\"Y-m-d\\TH:i:s\\Z\",1333699439) to get 2012-04-06T13:33:59Z\nHere are some of the formats date function supports\n<?php\n$today = date(\"F j, Y, g:i a\");                 // March 10, 2001, 5:16 pm\n$today = date(\"m.d.y\");                         // 03.10.01\n$today = date(\"j, n, Y\");                       // 10, 3, 2001\n$today = date(\"Ymd\");                           // 20010310\n$today = date('h-i-s, j-m-y, it is w Day');     // 05-16-18, 10-03-01, 1631 1618 6 Satpm01\n$today = date('\\i\\t \\i\\s \\t\\h\\e jS \\d\\a\\y.');   // it is the 10th day.\n$today = date(\"D M j G:i:s T Y\");               // Sat Mar 10 17:16:18 MST 2001\n$today = date('H:m:s \\m \\i\\s\\ \\m\\o\\n\\t\\h');     // 17:03:18 m is month\n$today = date(\"H:i:s\");                         // 17:16:18\n?>\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "unix-timestamp"
        ]
    },
    {
        "question_id": "255517",
        "question": "\nI would like to construct a query that displays all the results in a table, but is offset by 5 from the start of the table. As far as I can tell, MySQL's LIMIT requires a limit as well as an offset. Is there any way to do this?\n",
        "all_answers": [
            "\nAs you mentioned it LIMIT is required, so you need to use the biggest limit possible, which is 18446744073709551615 (maximum of unsigned BIGINT)\nSELECT * FROM somewhere LIMIT 18446744073709551610 OFFSET 5\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\nFrom the MySQL Manual on LIMIT:\n\nTo retrieve all rows from a certain\n  offset up to the end of the result\n  set, you can use some large number for\n  the second parameter. This statement\n  retrieves all rows from the 96th row\n  to the last:\n\nSELECT * FROM tbl LIMIT 95, 18446744073709551615;\n\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n"
        ],
        "answer": "A3",
        "tags": [
            "mysql",
            "sql",
            "sql-limit"
        ]
    },
    {
        "question_id": "11248073",
        "question": "\nHow do I uninstall all packages installed by pip from my currently activated virtual environment?\n",
        "all_answers": [
            "\nThe quickest way is to remake the virtualenv completely.  I'm assuming you have a requirements.txt file that matches production, if not:\n# On production:\npip freeze > reqs.txt\n\n# On your machine:\nrm $VIRTUALENV_DIRECTORY\nmkdir $VIRTUALENV_DIRECTORY\npip install -r reqs.txt\n\n",
            "\nType pip install -h to list help:\n\n-U, --upgrade         Upgrade all packages to the newest available version\n\nSo, if you already have a package installed, it will upgrade the package for you. Without the -U switch it'll tell you the package is already installed and exit.\nEach pip subcommand has its own help listing. pip -h shows you overall help, and pip [subcommand] -h gives you help for that sub command, such as install.\nYou can also find the full reference documentation online; the General Options section covers switches available for every pip subcommand, while each subcommand has a separate Options section to cover subcommand-specific switches; see the pip install options section, for example.\n",
            "\nI've found this snippet as an alternative solution. It's a more graceful removal of libraries than remaking the virtualenv:\npip freeze | xargs pip uninstall -y\n\n\nIn case you have packages installed via VCS, you need to exclude those lines and remove the packages manually (elevated from the comments below):\npip freeze | grep -v \"^-e\" | xargs pip uninstall -y\n\n\nIf you have packages installed directly from github/gitlab, those will have @.\nLike:\ndjango @ git+https://github.com/django.git@<sha>\nYou can add cut -d \"@\" -f1 to get just the package name that is required to uninstall it.\npip freeze | cut -d \"@\" -f1 | xargs pip uninstall -y\n\n",
            "\nIn most situations the best solution is to rely on the so-called \"user site\" location (see the PEP for details) by running:\npip install --user package_name\n\nBelow is a more \"manual\" way from my original answer, you do not need to read it if the above solution works for you.\n\nWith easy_install you can do:\neasy_install --prefix=$HOME/local package_name\n\nwhich will install into \n$HOME/local/lib/pythonX.Y/site-packages\n\n(the 'local' folder is a typical name many people use, but of course you may specify any folder you have permissions to write into).\nYou will need to manually create \n$HOME/local/lib/pythonX.Y/site-packages\n\nand add it to your PYTHONPATH environment variable (otherwise easy_install will complain -- btw run the command above once to find the correct value for X.Y).\nIf you are not using easy_install, look for a prefix option, most install scripts let you specify one.\nWith pip you can use:\npip install --install-option=\"--prefix=$HOME/local\" package_name\n\n",
            "\nSure, you can, just use #\npip docs:\n\nA line that begins with # is treated as a comment and ignored. Whitespace followed by a # causes the # and the remainder of the line to be treated as a comment.\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "pip",
            "virtualenv",
            "python-packaging"
        ]
    },
    {
        "question_id": "1136524",
        "question": "\nIn a SQL Server Execution plan what is the difference between an Index Scan and an Index Seek\nI'm on SQL Server 2005.\n",
        "all_answers": [
            "\nA scan touches every row in the table even if its what you are after or not\nA seek looks only at the rows that are what you are looking for. \nSeeks are always better to have than scans as they are more efficient in the way it looks data up.\nA good explanation can be found here\n",
            "\nAn index scan is where SQL server reads the whole of the index looking for matches - the time this takes is proportional to the size of the index.\nAn index seek is where SQL server uses the b-tree structure of the index to seek directly to matching records (see http://mattfleming.com/node/192 for an idea on how this works) - time taken is only proportional to the number of matching records.\n\nIn general an index seek is preferable to an index scan (when the number of matching records is proprtionally much lower than the total number of records), as the time taken to perform an index seek is constant regardless of the toal number of records in your table.\nNote however that in certain situations an index scan can be faster than an index seek (sometimes significantly faster) - usually when the table is very small, or when a large percentage of the records match the predicate.\n\n",
            "\nWith an Index Scan, all rows in the index are being scanned to find a matching row. This can be efficient for small tables.\nWith an Index Seek, it only needs to touch the rows that actually meet the criteria and so is generally more performant\n",
            "\nAn Index Scan happens when the index definition cannot find on a single row to satisfy search predicates. In this case SQL Server has to scan multiple pages to find a range of rows which satisfy the search predicates.\nIn the case of a Index Seek, SQL Server finds a single row matching search predicates using index definition.\nIndex Seeks are better and more effective.\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "sql-server",
            "sql-execution-plan"
        ]
    },
    {
        "question_id": "3063320",
        "question": "\nIn C# WinApp, how can I add both Text and Value to the items of my ComboBox?\nI did a search and usually the answers are using \"Binding to a source\".. but in my case I do not have a binding source ready in my program...\nHow can I do something like this:\ncombo1.Item[1] = \"DisplayText\";\ncombo1.Item[1].Value = \"useful Value\"\n\n",
        "all_answers": [
            "\nYou can use Cursor.Current.\n// Set cursor as hourglass\nCursor.Current = Cursors.WaitCursor;\n\n// Execute your time-intensive hashing code here...\n\n// Set cursor as default arrow\nCursor.Current = Cursors.Default;\n\nHowever, if the hashing operation is really lengthy (MSDN defines this as more than 2-7 seconds), you should probably use a visual feedback indicator other than the cursor to notify the user of the progress. For a more in-depth set of guidelines, see this article.\nEdit:\nAs @Am pointed out, you may need to call Application.DoEvents(); after Cursor.Current = Cursors.WaitCursor; to ensure that the hourglass is actually displayed. \n",
            "\nYou must create your own class type and override the ToString() method to return the text you want.  Here is a simple example of a class you can use:\npublic class ComboboxItem\n{\n    public string Text { get; set; }\n    public object Value { get; set; }\n\n    public override string ToString()\n    {\n        return Text;\n    }\n}\n\nThe following is a simple example of its usage:\nprivate void Test()\n{\n    ComboboxItem item = new ComboboxItem();\n    item.Text = \"Item text1\";\n    item.Value = 12;\n\n    comboBox1.Items.Add(item);\n\n    comboBox1.SelectedIndex = 0;\n\n    MessageBox.Show((comboBox1.SelectedItem as ComboboxItem).Value.ToString());\n}\n\n",
            "\nActually, \nCursor.Current = Cursors.WaitCursor;\n\ntemporarily sets the Wait cursor, but doesn’t ensure that the Wait cursor shows until the end of your operation. Other programs or controls within your program can easily reset the cursor back to the default arrow as in fact happens when you move mouse while operation is still running. \nA much better way to show the Wait cursor is to set the UseWaitCursor property in a form to true:\nform.UseWaitCursor = true;\n\nThis will display wait cursor for all controls on the form until you set this property to false.\nIf you want wait cursor to be shown on Application level you should use:\nApplication.UseWaitCursor = true;\n\n",
            "\nThis is one of the ways that just came to mind: \ncombo1.Items.Add(new ListItem(\"Text\", \"Value\"))\nAnd to change text of or value of an item, you can do it like this:\ncombo1.Items[0].Text = 'new Text';\n\ncombo1.Items[0].Value = 'new Value';\n\nThere is no class called ListItem in Windows Forms. It only exists in ASP.NET, so you will need to write your own class before using it, the same as @Adam Markowitz did in his answer.  \nAlso check these pages, they may help:  \n\nHow add an item to a combobox\nHow to: Add and Remove Items from a Windows Forms ComboBox, ListBox, or CheckedListBox Control\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "winforms",
            "combobox"
        ]
    },
    {
        "question_id": "37435369",
        "question": "\nHow to draw a rectangle on an image, like this:\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nim = np.array(Image.open('dog.png'), dtype=np.uint8)\nplt.imshow(im)\n\nI don't know how to proceed.\n",
        "all_answers": [
            "\nHere is an alternative solution that I found on the matplotlib mailing list:\nimport matplotlib.pylab as plt\n\nx = range(1000)\nax = plt.axes()\nax.semilogx(x, x)\nax.xaxis.set_ticks_position('none') \n\n\n",
            "\nTry this to remove the labels (but not the ticks):\nimport matplotlib.pyplot as plt\n\nplt.setp( ax.get_xticklabels(), visible=False)\n\nexample\n",
            "\nAlternatively, you can pass an empty tick position and label as\n# for matplotlib.pyplot\n# ---------------------\nplt.xticks([], [])\n# for axis object\n# ---------------\n# from Anakhand May 5 at 13:08\n# for major ticks\nax.set_xticks([])\n# for minor ticks\nax.set_xticks([], minor=True)\n\n",
            "\nYou can add a Rectangle patch to the matplotlib Axes.\nFor example (using the image from the tutorial here):\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\n\nim = Image.open('stinkbug.png')\n\n# Create figure and axes\nfig, ax = plt.subplots()\n\n# Display the image\nax.imshow(im)\n\n# Create a Rectangle patch\nrect = patches.Rectangle((50, 100), 40, 30, linewidth=1, edgecolor='r', facecolor='none')\n\n# Add the patch to the Axes\nax.add_patch(rect)\n\nplt.show()\n\n\n",
            "\nThis snippet might help in removing the xticks only.\nfrom matplotlib import pyplot as plt    \nplt.xticks([])\n\nThis snippet might help in removing the xticks and yticks both.\nfrom matplotlib import pyplot as plt    \nplt.xticks([]),plt.yticks([])\n\n",
            "\nNot exactly what the OP was asking for, but a simple way to disable all axes lines, ticks and labels is to simply call:\nplt.axis('off')\n\n",
            "\nThere is a better, and simpler, solution than the one given by John Vinyard. Use NullLocator:\nimport matplotlib.pyplot as plt\n\nplt.plot(range(10))\nplt.gca().xaxis.set_major_locator(plt.NullLocator())\nplt.show()\nplt.savefig('plot')\n\n",
            "\nThe plt.tick_params method is very useful for stuff like this.  This code turns off major and minor ticks and removes the labels from the x-axis.\nNote that there is also ax.tick_params for matplotlib.axes.Axes objects.\nfrom matplotlib import pyplot as plt\nplt.plot(range(10))\nplt.tick_params(\n    axis='x',          # changes apply to the x-axis\n    which='both',      # both major and minor ticks are affected\n    bottom=False,      # ticks along the bottom edge are off\n    top=False,         # ticks along the top edge are off\n    labelbottom=False) # labels along the bottom edge are off\nplt.show()\nplt.savefig('plot')\nplt.clf()\n\n\n",
            "\nYou need use patches.\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nfig2 = plt.figure()\nax2 = fig2.add_subplot(111, aspect='equal')\n\nax2.add_patch(\n     patches.Rectangle(\n        (0.1, 0.1),\n        0.5,\n        0.5,\n        fill=False      # remove background\n     ) ) \nfig2.savefig('rect2.png', dpi=90, bbox_inches='tight')\n\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "image",
            "matplotlib"
        ]
    },
    {
        "question_id": "37914702",
        "question": "\nI am getting this error while running server, how do I fix this?\n\n",
        "all_answers": [
            "\nYou better install Ruby 2.2.5 for compatibility. The Ruby version in your local machine is different from the one declared in Gemfile.\nIf you're using rvm:\nrvm install 2.2.5\nrvm use 2.2.5\n\nelse if you're using rbenv:\nrbenv install 2.2.5\nrbenv local 2.2.5\n\nelse if you can not change ruby version by rbenv,\nread here\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nYour Gemfile has a line reading\nruby '2.2.5'\n\nChange it to\nruby '2.3.0'\n\nThen run\nbundle install\n\n",
            "\nAdd the following to your Gemfile\nruby '2.3.0'\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "rubygems"
        ]
    },
    {
        "question_id": "16940293",
        "question": "\nAs we all know, there's list comprehension, like\n[i for i in [1, 2, 3, 4]]\n\nand there is dictionary comprehension, like\n{i:j for i, j in {1: 'a', 2: 'b'}.items()}\n\nbut\n(i for i in (1, 2, 3))\n\nwill end up in a generator, not a tuple comprehension. Why is that?\nMy guess is that a tuple is immutable, but this does not seem to be the answer.\n",
        "all_answers": [
            "\nUse a dict comprehension (Python 2.7 and later):\n{key: value for key, value in zip(keys, values)}\n\n\nAlternatively, use the dict constructor (for str keys only):\npairs = [('a', 1), ('b', 2)]\ndict(pairs)                          # → {'a': 1, 'b': 2}\ndict((k, v + 10) for k, v in pairs)  # → {'a': 11, 'b': 12}\n\nGiven separate lists of keys and values, use the dict constructor with zip:\nkeys = ['a', 'b']\nvalues = [1, 2]\ndict(zip(keys, values))              # → {'a': 1, 'b': 2}\n\n",
            "\nIn fact, you don't even need to iterate over the iterable if it already comprehends some kind of mapping, the dict constructor doing it graciously for you:\n>>> ts = [(1, 2), (3, 4), (5, 6)]\n>>> dict(ts)\n{1: 2, 3: 4, 5: 6}\n>>> gen = ((i, i+1) for i in range(1, 6, 2))\n>>> gen\n<generator object <genexpr> at 0xb7201c5c>\n>>> dict(gen)\n{1: 2, 3: 4, 5: 6}\n\n",
            "\nYou can use a generator expression:\ntuple(i for i in (1, 2, 3))\n\nbut parentheses were already taken for … generator expressions.\n",
            "\nMy best guess is that they ran out of brackets and didn't think it would be useful enough to warrent adding an \"ugly\" syntax ...\n",
            "\nIn Python 3 and Python 2.7+, dictionary comprehensions look like the below:\nd = {k:v for k, v in iterable}\n\nFor Python 2.6 or earlier, see fortran's answer.\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "tuples",
            "list-comprehension",
            "dictionary-comprehension",
            "set-comprehension"
        ]
    },
    {
        "question_id": "13752424",
        "question": "\nI'm trying to connect to mysql server command line from my windows prompt\nI write the next line in cmd but i get an error.\ncd C:\\MYSQL\\bin\\\n\nAnd then i execute \nmysql.exe -u=root -p=admin\n\nbut i getting this error\nERROR 1045: <28000>: Access denied for user 'root'@'localhost' <using password:YES>\n\nThanks, \n",
        "all_answers": [
            "\nIn CentOS/RedHat (assuming you installed the jenkins package)\nvim /etc/sysconfig/jenkins\n....\n# Port Jenkins is listening on.\n# Set to -1 to disable\n#\nJENKINS_PORT=\"8080\"\n\nchange it to any port you want.\n",
            "\nOpen the jenkins.xml in the jenkins home folder (usually C:\\Program Files (x86)\\Jenkins) and change the port number:\nhttpPort=xxxx\nto\nhttpPort=yyyy\n\nthen restart the service. it should change the setting permanently.\n",
            "\nWith Ubuntu 14.4 I had to change the file /etc/default/jenkins\nE.g.\n   #HTTP_PORT=8080\n   HTTP_PORT=8083\n\nand restart the service \n\nservice jenkins restart\n\n",
            "\nUse the following command at command prompt:\njava -jar jenkins.war --httpPort=9090\n\nIf you want to use https use the following command:\njava -jar jenkins.war --httpsPort=9090\n\nDetails are here\n",
            "\nOn Windows (with Windows Service).\nEdit the file C:\\Program Files (x86)\\Jenkins\\jenkins.xml with 8083 if you want 8083 port.\n<arguments>-Xrs -Xmx256m -Dhudson.lifecycle=hudson.lifecycle.WindowsServiceLifecycle -jar \"%BASE%\\jenkins.war\" --httpPort=8083</arguments>\n\n",
            "\nThe cd in your question is invalid (quoting it here because you've removed it once, and it was there when this answer was posted):\ncd CD:\\MYSQL\\bin\\\n\nYou can't cd to CD:\\ anything, because CD:\\ isn't a valid directory in Windows. CD: would indicate a drive, except that drives are restricted to a single letter between A and Z. \nIf your \\MYSQL\\BIN is on drive C:, then your commands need to be:\nC:\\>cd \\MYSQL\\Bin\nC:\\MYSQL\\Bin>mysql -u root -p admin\n\nIf you're not already on C: (which you'll know by looking at the prompt in the cmd window), or your MySQL folder is on another drive (for instance, D:), change to that drive too:\nC:\\> cd /d D:\\MYSQL\\Bin\nD:\\MYSQL\\Bin>mysql -u root -p admin\n\nThe .exe after mysql is optional, since .exe is an executable extension on Windows. If you type mysql, Windows will automatically look for an executable file with that name and run it if it finds it.\nNote that in both my examples of running mysql, there are no = signs. You should just use -p with no password, and wait to be prompted for it instead.\n",
            "\nYou are logging in incorrectly; you should not include = in your login.  So to log in, type:\nmysql.exe -uroot -padmin\n\nIf that doesn't work, then you may not have your system configured.  If so, then here's a good tutorial on getting started with the MySQL prompt:\nhttp://breakdesign.blogspot.com/2007/11/getting-started-with-php-and-mysql-in_11.html\n",
            "\nFor the benefit of Linux users who find themselves here: I found /etc/sysconfig/jenkins has a JENKINS_PORT=\"8080\", which you should probably change too.\n"
        ],
        "answer": "A6",
        "tags": [
            "mysql",
            "windows",
            "command-prompt"
        ]
    },
    {
        "question_id": "6889119",
        "question": "\nI would like to rename file from README to README.md. What is the best practice to do that?\n\nI have only one repo called \"change-z-index\".\n\nI open and login like that:\nssh -T git@github.com\n\n\nAnd I enter my passphrase.\n\nI try to rename the file like that:\ngit mv README README.md\ngit commit -m \"renamed\"\ngit push origin master\n\n\nIt gives me an error saying bad source.\nI think I need to select my repo first... its name is \"change-z-index\". I have read manual many times, but still can't understand how to do it.\n",
        "all_answers": [
            "\nYou can rename a file using git's mv command:\n$ git mv file_from file_to\n\nExample:\n$ git mv helo.txt hello.txt\n\n$ git status\n# On branch master\n# Changes to be committed:\n#   (use \"git reset HEAD <file>...\" to unstage)\n#\n#   renamed:    helo.txt -> hello.txt\n#\n\n$ git commit -m \"renamed helo.txt to hello.txt\"\n[master 14c8c4f] renamed helo.txt to hello.txt\n 1 files changed, 0 insertions(+), 0 deletions(-)\n rename helo.txt => hello.txt (100%)\n\n",
            "\nAs far as I can tell, GitHub does not provide shell access, so I'm curious about how you managed to log in in the first place.\n$ ssh -T git@github.com\nHi username! You've successfully authenticated, but GitHub does not provide\nshell access.\n\nYou have to clone your repository locally, make the change there, and push the change to GitHub.\n$ git clone git@github.com:username/reponame.git\n$ cd reponame\n$ git mv README README.md\n$ git commit -m \"renamed\"\n$ git push origin master\n\n",
            "\nDo a git status to find out if your file is actually in your index or the commit. \nIt is easy as a beginner to misunderstand the index/staging area. \nI view it as a 'progress pinboard'. I therefore have to add the file to the pinboard before I can commit it (i.e. a copy of the complete pinboard), I have to update the pinboard when required, and I also have to deliberately remove files from it when I've finished with them - simply creating, editing or deleting a file doesn't affect the pinboard. It's like 'storyboarding'.\nEdit: As others noted, You should do the edits locally and then push the updated repo, rather than attempt to edit directly on github.\n"
        ],
        "answer": "A2",
        "tags": [
            "git",
            "github"
        ]
    },
    {
        "question_id": "1179874",
        "question": "\nWhat is the difference between PDOStatement::bindParam() and PDOStatement::bindValue()?\n",
        "all_answers": [
            "\nThe answer is in the documentation for bindParam:\n\nUnlike PDOStatement::bindValue(), the variable is bound as a reference and will only be evaluated at the time that PDOStatement::execute() is called. \n\nAnd execute\n\ncall PDOStatement::bindParam() to bind PHP variables to the parameter markers: bound variables pass their value as input and receive the output value, if any, of their associated parameter markers\n\nExample:\n$value = 'foo';\n$s = $dbh->prepare('SELECT name FROM bar WHERE baz = :baz');\n$s->bindParam(':baz', $value); // use bindParam to bind the variable\n$value = 'foobarbaz';\n$s->execute(); // executed with WHERE baz = 'foobarbaz'\n\nor\n$value = 'foo';\n$s = $dbh->prepare('SELECT name FROM bar WHERE baz = :baz');\n$s->bindValue(':baz', $value); // use bindValue to bind the variable's value\n$value = 'foobarbaz';\n$s->execute(); // executed with WHERE baz = 'foo'\n\n",
            "\nHere are some I can think about :\n\nWith bindParam, you can only pass variables ; not values\nwith bindValue, you can pass both (values, obviously, and variables)\nbindParam works only with variables because it allows parameters to be given as input/output, by \"reference\" (and a value is not a valid \"reference\" in PHP) : it is useful with drivers that (quoting the manual) : \n\n\nsupport the invocation of stored\n  procedures that return data as output\n  parameters, and some also as\n  input/output parameters that both send\n  in data and are updated to receive it.\n\nWith some DB engines, stored procedures can have parameters that can be used for both input (giving a value from PHP to the procedure) and ouput (returning a value from the stored proc to PHP) ; to bind those parameters, you've got to use bindParam, and not bindValue.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "pdo",
            "bindparam",
            "bindvalue"
        ]
    },
    {
        "question_id": "1685860",
        "question": "\nI have a table into which new data is frequently inserted. I need to get the very last ID of the table. How can I do this?\nIs it similar to SELECT MAX(id) FROM table?\n",
        "all_answers": [
            "\nIf you're using PDO, use PDO::lastInsertId.\nIf you're using Mysqli, use mysqli::$insert_id.\nIf you're still using Mysql:\n\nPlease, don't use mysql_* functions in new code. They are no longer maintained and are officially deprecated. See the red box? Learn about prepared statements instead, and use PDO or MySQLi - this article will help you decide which. If you choose PDO, here is a good tutorial.\n\nBut if you have to, use mysql_insert_id.\n",
            "\nWhat you wrote would get you the greatest id assuming they were unique and auto-incremented that would be fine assuming you are okay with inviting concurrency issues.\nSince you're using MySQL as your database, there is the specific function LAST_INSERT_ID() which only works on the current connection that did the insert.\nPHP offers a specific function for that too called mysql_insert_id.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "mysql"
        ]
    },
    {
        "question_id": "1231195",
        "question": "\nI (sort of) already know the answer to this question.  But I figured it is one that gets asked so frequently on the R Users list, that there should be one solid good answer.  To the best of my knowledge there is no multiline comment functionality in R.  So, does anyone have any good workarounds?\nWhile quite a bit of work in R usually involves interactive sessions (which casts doubt on the need for multiline comments), there are times when I've had to send scripts to colleagues and classmates, much of which involves nontrivial blocks of code.  And for people coming from other languages it is a fairly natural question.  \nIn the past I've used quotes. Since strings support linebreaks, running an R script with\n\"\nHere's my multiline comment.\n\n\"\na <- 10\nrocknroll.lm <- lm(blah blah blah)\n ...\n\nworks fine.  Does anyone have a better solution?\n",
        "all_answers": [
            "\nI can think of two options. The first option is to use an editor that allows to block comment and uncomment (eg. Eclipse). The second option is to use an if statement. But that will only allow you to 'comment' correct R syntax.  Hence a good editor is the prefered workaround.\nif(FALSE){\n     #everything in this case is not executed\n\n}\n\n",
            "\nThis does come up on the mailing list fairly regularly, see for example this recent thread on r-help.  The consensus answer usually is the one shown above: that given that the language has no direct support, you have to either\n\nwork with an editor that has region-to-comment commands, and most advanced R editors do \nuse the if (FALSE) constructs suggested earlier but note that it still requires complete parsing and must hence be syntactically correct\n\n"
        ],
        "answer": "A2",
        "tags": [
            "r",
            "comments",
            "r-faq"
        ]
    },
    {
        "question_id": "9185942",
        "question": "\nI have a couple of PDF template files with complex content and several blank regions/areas in them. I need to be able to write text in those blank regions and save the resulting PDFs in a folder.\nI googled for answers on this question quite intensively, but I didn't find definite answers. One of the better solutions is PDF::Toolkit, but it would require the purchase of Adobe Acrobat to add replaceable attributes to existing PDF documents.\nThe PHP world is blessed with FPDI that can be used to simply open a PDF file and write/draw on it over the existing content. There is a Ruby port of this library, but the last commit for it happened at the beginning of 2009. Also that project doesn't look like it is widely used and supported.\nThe question is: What is the better Ruby way of editing, writing or drawing on existing PDFs?\nThis question also doesn't seem to be answered on here. These questions are related, but not really the same:\n\nPrawn gem: How to create the .pdf from an *existing* file (.xls)\nwatermark existing pdf with ruby\nRuby library for manipulating existing PDF\nHow to replace a word in an existing PDF using Ruby Prawn?\n\n",
        "all_answers": [
            "\nThe best I can think of is Rails-latex, it doesn't allow you to edit existing PDF files but it would allow you to set up template *.tex.erb which you may dynamically modify and compile them into PDF format (along with dvi and a number of others).  \n",
            "\nyou have to definitely check out Prawn gem, by which you can generate any custom pdf files. You can actually use prawn to write in text into existing pdfs by treating the existing PDF as a template for your new Prawn document.\nFor example:\nfilename = \"#{Prawn::DATADIR}/pdfs/multipage_template.pdf\"\nPrawn::Document.generate(\"full_template.pdf\", :template => filename) do\n  text \"THis content is written on the first page of the template\", :align => :center\nend\n\nThis will write text onto the first page of the old pdf.\nSee more here: \nhttp://prawn.majesticseacreature.com/manual.pdf\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "pdf-generation",
            "fpdi"
        ]
    },
    {
        "question_id": "6292332",
        "question": "\nI was looking at STL containers and trying to figure what they really are (i.e. the data structure used), and the deque stopped me: I thought at first that it was a double linked list, which would allow insertion and deletion from both ends in constant time, but I am troubled by the promise made by the operator [] to be done in constant time. In a linked list, arbitrary access should be O(n), right?\nAnd if it's a dynamic array, how can it add elements in constant time? It should be mentioned  that reallocation may happen, and that O(1) is an amortized cost, like for a vector.\nSo I wonder what is this structure that allows arbitrary access in constant time, and at the same time never needs to be moved to a new bigger place.\n",
        "all_answers": [
            "\nYou can't easily use a range here because the iterator you get from a map refers to a std::pair, where the iterators you would use to insert into a vector refers to an object of the type stored in the vector, which is (if you are discarding the key) not a pair.\nI really don't think it gets much cleaner than the obvious:\n#include <map>\n#include <vector>\n#include <string>\nusing namespace std;\n\nint main() {\n    typedef map <string, int> MapType;\n    MapType m;  \n    vector <int> v;\n\n    // populate map somehow\n\n    for( MapType::iterator it = m.begin(); it != m.end(); ++it ) {\n        v.push_back( it->second );\n    }\n}\n\nwhich I would probably re-write as a template function if I was going to use it more than once. Something like:\ntemplate <typename M, typename V> \nvoid MapToVec( const  M & m, V & v ) {\n    for( typename M::const_iterator it = m.begin(); it != m.end(); ++it ) {\n        v.push_back( it->second );\n    }\n}\n\n",
            "\nA deque is somewhat recursively defined: internally it maintains a double-ended queue of chunks of fixed size. Each chunk is a vector, and the queue (“map” in the graphic below) of chunks itself is also a vector.\n\nThere’s a great analysis of the performance characteristics and how it compares to the vector over at CodeProject.\nThe GCC standard library implementation internally uses a T** to represent the map. Each data block is a T* which is allocated with some fixed size __deque_buf_size (which depends on sizeof(T)).\n",
            "\nway mentioned by @dirkgently ( v.begin() + index ) nice and fast for vectors  \nbut std::advance( v.begin(), index ) most generic way and for random access iterators works constant time too.  \nEDIT\ndifferences in usage:  \nstd::vector<>::iterator it = ( v.begin() + index );\n\nor \nstd::vector<>::iterator it = v.begin();\nstd::advance( it, index );\n\nadded after @litb notes.\n",
            "\nTry this:\nvector<Type>::iterator nth = v.begin() + index;\n\n",
            "\nYou can always use std::advance to move the iterator a certain amount of positions in constant time:\nstd::vector<int>::iterator it = myvector.begin();\nstd::advance(it, 2);\n\n",
            "\n\ndeque = double ended queue\n\nA container which can grow in either direction. \nDeque is typically implemented as a vector of vectors (a list of vectors can't give constant time random access). While the size of the secondary vectors is implementation dependent, a common algorithm is to use a constant size in bytes.\n",
            "\nAlso; auto it = std::next(v.begin(), index);\nUpdate: Needs a C++11x compliant compiler\n"
        ],
        "answer": "A2",
        "tags": [
            "c++",
            "stl",
            "deque"
        ]
    },
    {
        "question_id": "5273436",
        "question": "\nWhat method should I call to know if an Activity has its contentView (once the method setContentView() has been called)?\n",
        "all_answers": [
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nYou may want to try View.getRootView().\n",
            "\nYou can also override onContentChanged() which is among others fired when setContentView() has been called.\n",
            "\nthis.getWindow().getDecorView().findViewById(android.R.id.content)\n\nor\nthis.findViewById(android.R.id.content)\n\nor\nthis.findViewById(android.R.id.content).getRootView()\n\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nYou can get the view Back if you put an ID to your Layout.\n<RelativeLayout\n    android:id=\"@+id/my_relative_layout_id\"\n\nAnd call it from findViewById ...\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nThere is no \"isContentViewSet\" method. You may put some dummy requestWindowFeature call into try/catch block before setContentView like this:\n\ntry {\n  requestWindowFeature(Window.FEATURE_CONTEXT_MENU);\n  setContentView(...)\n} catch (AndroidRuntimeException e) {\n  // do smth or nothing\n}\n\nIf content view was already set, requestWindowFeature will throw an exception.\n"
        ],
        "answer": "A4",
        "tags": [
            "android"
        ]
    },
    {
        "question_id": "19707237",
        "question": "\nThese two pieces of code are identical at the first blush:\nclass IndexView(generic.ListView):\n    template_name = 'polls/index.html'\n    context_object_name = 'latest_poll_list'\n    queryset = Poll.active.order_by('-pub_date')[:5]\n\nand\nclass IndexView(generic.ListView):\n    template_name = 'polls/index.html'\n    context_object_name = 'latest_poll_list'\n\n    def get_queryset(self):\n        return Poll.active.order_by('-pub_date')[:5]\n\nIs there any difference between them? And if it is:\nWhat approach is better? Or when setting queryset variable is better than override the get_queryset method? And vice versa.\n",
        "all_answers": [
            "\nIn your example, overriding queryset and get_queryset have the same effect. I would slightly favour setting queryset because it's less verbose.\nWhen you set queryset, the queryset is created only once, when you start your server. On the other hand, the get_queryset method is called for every request. \nThat means that get_queryset is useful if you want to adjust the query dynamically. For example, you could return objects that belong to the current user:\nclass IndexView(generic.ListView):\n    def get_queryset(self):\n        \"\"\"Returns Polls that belong to the current user\"\"\"\n        return Poll.active.filter(user=self.request.user).order_by('-pub_date')[:5]\n\nAnother example where get_queryset is useful is when you want to filter based on a callable, for example, return today's polls:\nclass IndexView(generic.ListView):\n    def get_queryset(self):\n        \"\"\"Returns Polls that were created today\"\"\"\n        return Poll.active.filter(pub_date=date.today())\n\nIf you tried to do the same thing by setting queryset, then date.today() would only be called once, when the view was loaded, and the view would display incorrect results after a while.\nclass IndexView(generic.ListView):\n    # don't do this!\n    queryset = Poll.active.filter(pub_date=date.today())\n\n",
            "\nThe MRO is basically depth-first, left-to-right. See Method Resolution Order (MRO) in new style Python classes for some more info.\nYou can look at the __mro__ attribute of the class to check, but FooMixin should be first if you want to do \"check A\" first.\nclass UltimateBase(object):\n    def dispatch(self, *args, **kwargs):\n        print 'base dispatch'\n\nclass FooMixin(object):\n    def dispatch(self, *args, **kwargs):\n        print 'perform check A'\n        return super(FooMixin, self).dispatch(*args, **kwargs)\n\nclass BarMixin(object):\n    def dispatch(self, *args, **kwargs):\n        print 'perform check B'\n        return super(BarMixin, self).dispatch(*args, **kwargs)\n\nclass FooBar(FooMixin, BarMixin, UltimateBase):\n    pass\n\nFooBar().dispatch()\n\nPrints:\nperform check A\nperform check B\nbase dispatch\n\nView has to be last so that it \"catches\" any attribute lookups that weren't on any mixins, without hiding any methods on those mixins. I'm not sure I understand that part of your question -- what it \"why is it added at all\" or \"why is it added last\"?\n",
            "\nThe queryset attribute is used internally, always use the method (you will often have to perform custom queries based on request or session vars for example)\n",
            "\nFor python3 you have to decode body first:\nreceived_json_data = json.loads(request.body.decode(\"utf-8\"))\n\n",
            "\nYou're confusing form-encoded and JSON data here. request.POST['foo'] is for form-encoded data. You are posting raw JSON, so you should use request.body.\nreceived_json_data=json.loads(request.body)\n\n",
            "\nWith debug turned off Django won't handle static files for you any more - your production web server (Apache or something) should take care of that.\n"
        ],
        "answer": "A1",
        "tags": [
            "django",
            "django-views",
            "django-generic-views"
        ]
    },
    {
        "question_id": "3473438",
        "question": "\nI have an array int arr[5] that is passed to a function fillarr(int arr[]):\nint fillarr(int arr[])\n{\n    for(...);\n    return arr;\n}\n\n\nHow can I return that array?\nHow will I use it, say I returned a pointer how am I going to access it?\n\n",
        "all_answers": [
            "\nint *fillarr(int arr[])\n\nYou can still use the result like\nint *returned_array = fillarr(some_other_array);\nif(returned_array[0] == 3)\n    do_important_cool_stuff();\n\n",
            "\nIn this case, your array variable arr can actually also be treated as a pointer to the beginning of your array's block in memory, by an implicit conversion.  This syntax that you're using:\nint fillarr(int arr[])\n\nIs kind of just syntactic sugar.  You could really replace it with this and it would still work:\nint fillarr(int* arr)\n\nSo in the same sense, what you want to return from your function is actually a pointer to the first element in the array:\nint* fillarr(int arr[])\n\nAnd you'll still be able to use it just like you would a normal array:\nint main()\n{\n  int y[10];\n  int *a = fillarr(y);\n  cout << a[0] << endl;\n}\n\n",
            "\n\nI don't want to return a copied value because it's inefficient\n\nProve it.\nLook up RVO and NRVO, and in C++0x move-semantics. In most cases in C++03, an out parameter is just a good way to make your code ugly, and in C++0x you'd actually be hurting yourself by using an out parameter.\nJust write clean code, return by value. If performance is a problem, profile it (stop guessing), and find what you can do to fix it. It likely won't be returning things from functions.\n\nThat said, if you're dead set on writing like that, you'd probably want to do the out parameter. It avoids dynamic memory allocation, which is safer and generally faster. It does require you have some way to construct the object prior to calling the function, which doesn't always make sense for all objects.\nIf you want to use dynamic allocation, the least that can be done is put it in a smart pointer. (This should be done all the time anyway) Then you don't worry about deleting anything, things are exception-safe, etc. The only problem is it's likely slower than returning by value anyway!\n",
            "\nJust return a object like this:\nThing calculateThing() \n{\n   Thing thing();\n   // do calculations and modify thing\n   return thing;\n}\n\nThis will invoke the copy constructor on Things, so you might want to do your own implementation of that. Like this:\nThing(const Thing& aThing) {}\n\nThis might perform a little slower, but it might not be an issue at all.\nUpdate\nThe compiler will probably optimize the call to the copy constructor, so there will be no extra overhead. (Like dreamlax pointed out in the comment).\n",
            "\nDid you try to use smart pointers (if Thing is really big and heavy object), like shared_ptr:\n\n\n    std::shared_ptr calculateThing()\n    {\n        std::shared_ptr<Thing> thing(new Thing);\n        // .. some calculations\n        return thing;\n    }\n    \n    // ...\n    {\n        std::shared_ptr<Thing> thing = calculateThing();\n        // working with thing\n    \n        // shared_ptr frees thing \n    }\n\n\n",
            "\nJust create the object and return it\nThing calculateThing() {\n    Thing thing;\n    // do calculations and modify thing\n     return thing;\n}\n\nI think you'll do yourself a favor if you forget about optimization and just write readable code (you'll need to run a profiler later - but don't pre-optimize).\n"
        ],
        "answer": "A2",
        "tags": [
            "c++",
            "arrays",
            "pointers",
            "function",
            "return"
        ]
    },
    {
        "question_id": "12590739",
        "question": "\nis it possible to specify that the strings in a file within the value-* directories are purposely not translated into other languages? I have a bunch of strings that are common for all the languages and need no translation, so I've created an unlocalized-strings.xml file within values directory.. Running Android Lint to check for problems it keeps saying that some translations are missing.. I do not want to disable this check on the whole project, I'd like to disable it only in some XML files.. is it possible? \n\"title_widget_updater_service\" is not translated in de, en, en-rUS, it\n\nIssue: Checks for incomplete translations where not all strings are translated\nId: MissingTranslation\n\nIf an application has more than one locale, then all the strings declared in one language     \nshould also be translated in all other languages.\n\nBy default this detector allows regions of a language to just provide a subset of the \nstrings and fall back to the standard language strings. You can require all regions to \nprovide a full translation by setting the environment variable \nANDROID_LINT_COMPLETE_REGIONS.\n\nHow can defined this region of unlocalized strings?\n",
        "all_answers": [
            "\nThe Resource class also has a method getDimensionPixelSize() which I think will fit your needs.\n",
            "\nI don't know how to ignore all the file, but you can do it string by string using:\n<string name=\"hello\" translatable=\"false\">hello</string>\n\n",
            "\nYou can use getDimensionPixelOffset() instead of getDimension, so you didn't have to cast to int.\nint valueInPixels = getResources().getDimensionPixelOffset(R.dimen.test)\n\n",
            "\nIn my dimens.xml I have\n<dimen name=\"test\">48dp</dimen>\n\nIn code If I do\nint valueInPixels = (int) getResources().getDimension(R.dimen.test)\n\nthis will return 72 which as docs state is multiplied by density of current phone (48dp x 1.5 in my case)\nexactly as docs state :\n\nRetrieve a dimensional for a particular resource ID. Unit conversions\nare based on the current DisplayMetrics associated with the resources.\n\nso if you want exact dp value just as in xml just divide it with DisplayMetrics density\nint dp = (int) (getResources().getDimension(R.dimen.test) / getResources().getDisplayMetrics().density);\n\ndp will be 48 now\n",
            "\nI think that what you need instead of disabling lint is to mark them with attribute\ntranslatable=\"false\"\n\n",
            "\nContext.getResources().getDimension(int id);\n\n",
            "\nUse a Kotlin Extension\nYou can add an extension to simplify this process. It enables you to just call context.dp(R.dimen. tutorial_cross_marginTop) to get the Float value\nfun Context.px(@DimenRes dimen: Int): Int = resources.getDimension(dimen).toInt()\n\nfun Context.dp(@DimenRes dimen: Int): Float = px(dimen) / resources.displayMetrics.density\n\nIf you want to handle it without context, you can use Resources.getSystem():\nval Int.dp get() = this / Resources.getSystem().displayMetrics.density // Float\n\nval Int.px get() = (this * Resources.getSystem().displayMetrics.density).toInt()\n\nFor example, on an xhdpi device, use 24.dp to get 12.0 or 12.px to get 24\n",
            "\nFor those who just need to save some int value in the resources, you can do the following.\nintegers.xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<resources>\n    <integer name=\"default_value\">100</integer>\n</resources> \n\nCode\nint defaultValue = getResources().getInteger(R.integer.default_value);\n\n"
        ],
        "answer": "A2",
        "tags": [
            "android",
            "android-resources",
            "android-lint"
        ]
    },
    {
        "question_id": "12396545",
        "question": "\n\n\n\n\nPossible Duplicate:\nHow to develop or migrate apps for iPhone 5 screen resolution? \n\nI was just wondering with how should we deal with the iPhone 5 bigger screen size.\nAs it has more pixels in height, things like GCRectMake that use coordinates (and just doubled the pixels with the retina/non retina problem) won't work seamlessly between versions, as it happened when we got the Retina.\nAnd will we have to design two storyboards, just like for the iPad?\nI personally don't think Apple will require you to check the screen size every time you have to draw something, like many answers say. Does that happen with the iPad? \n",
        "all_answers": [
            "\nAll apps will continue to work in the vertically stretched screen from what I could tell in today's presentation. They will be letterboxed or basically the extra 88 points in height would simply be black.\nIf you only plan to support iOS 6+, then definitely consider using Auto Layout. It removes all fixed layout handling and instead uses constraints to lay things out. Nothing will be hard-coded, and your life will become a lot simpler.\nHowever, if you have to support older iOS's, then it really depends on your application. A majority of applications that use a standard navigation bar, and/or tab bar, could simply expand the content in the middle to use up that extra points. Set the autoresizing mask of the center content to expand in both directions.\nview.autoresizingMask = UIViewAutoresizingFlexibleWidth | UIViewAutoresizingFlexibleHeight;\n\nIt works great out of the box for table views, however, if your app used pixel-perfect layout for displaying content, then your best bet would be to re-imagine the content so that it can accommodate varying heights.\nIf that's not a possibility, then the only remaining option is to have two UIs (pre iPhone 5, and iPhone 5).\nIf that sounds ugly, then you could go with the default letterboxed model where the extra points/pixels just show up black.\nEdit\nTo enable your apps to work with iPhone 5, you need to add a retina version of the launcher image. It should be named Default-568h@2x.png. And it has to be retina quality - there's no backward compatibility here :) \nYou could also select this image from within Xcode. Go to the target, and under the Summary section, look for Launch Images. The image has to be 640x1136 pixels in size. Here's a screenshot of where to find it, if that helps.\n\n",
            "\n\nAs it has more pixels in height, things like GCRectMake that use coordinates won't work seamlessly between versions, as it happened when we got the Retina.\n\nWell, they do work the same with Retina displays - it's just that 1 unit in the CoreGraphics coordinate system will correspond to 2 physical pixels, but you don't/didn't have to do anything, the logic stayed the same. (Have you actually tried to run one of your non-retina apps on a retina iPhone, ever?)\nFor the actual question: that's why you shouldn't use explicit CGRectMakes and co... That's why you have stuff like [[UIScreen mainScreen] applicationFrame].\n",
            "\nI think you can use [UIScreen mainScreen].bounds.size.height and calculate step for your objects. when you calculate step you can set coordinates for two resolutions. \nOr you can get height like above and if(iphone5) then... else if(iphone4) then... else if(ipad). Something like this.\nIf you use storyboards then you have to create new for new iPhone i think.\n"
        ],
        "answer": "A1",
        "tags": [
            "iphone",
            "ios",
            "iphone-5"
        ]
    },
    {
        "question_id": "401277",
        "question": "\nIn Django, I've got loggers all over the place, currently with hard-coded names.\nFor module-level logging (i.e., in a module of view functions) I have the urge to do this.\nlog = logging.getLogger(__name__)\n\nFor class-level logging (i.e., in a class __init__ method) I have the urge to do this.\nself.log = logging.getLogger(\"%s.%s\" % (\n    self.__module__, self.__class__.__name__))\n\nI'm looking for second opinions before I tackle several dozen occurrences of getLogger(\"hard.coded.name\").\nWill this work?  Anyone else naming their loggers with the same unimaginative ways?  \nFurther, should I break down and write a class decorator for this log definition?\n",
        "all_answers": [
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nI typically don't use or find a need for class-level loggers, but I keep my modules at a few classes at most. A simple:\nimport logging\nLOG = logging.getLogger(__name__)\n\nAt the top of the module and subsequent:\nLOG.info('Spam and eggs are tasty!')\n\nfrom anywhere in the file typically gets me to where I want to be. This avoids the need for self.log all over the place, which tends to bother me from both a put-it-in-every-class perspective and makes me 5 characters closer to 79 character lines that fit.\nYou could always use a pseudo-class-decorator:\n>>> import logging\n>>> class Foo(object):\n...     def __init__(self):\n...             self.log.info('Meh')\n... \n>>> def logged_class(cls):\n...     cls.log = logging.getLogger('{0}.{1}'.format(__name__, cls.__name__))\n... \n>>> logged_class(Foo)\n>>> logging.basicConfig(level=logging.DEBUG)\n>>> f = Foo()\nINFO:__main__.Foo:Meh\n\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nThat looks like it will work, except that self won't have a __module__ attribute; its class will.  The class-level logger call should look like:\nself.log = logging.getLogger( \"%s.%s\" % ( self.__class__.__module__, self.__class__.__name__ ) )\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "django",
            "logging",
            "python-logging"
        ]
    },
    {
        "question_id": "30992338",
        "question": "\nI have an iOS app written in Swift that is leaking memory - in certain situation some objects should be released but they are not. I have learnt about the issue by simply adding deinit debug messages like this:\ndeinit {\n    println(\"DEINIT: KeysProvider released\")\n}\n\nSo, the deinit message should be present in console after such events that should cause the object to release. However, for some of the objects that should be released, the message is missing. Still, Leaks Developer Tool does not show any leaks. How do I solve such situation?\n",
        "all_answers": [
            "\nIn Xcode 8, you can click on the \"Debug Memory Graph\" button,  in the debug toolbar (shown at the bottom of the screen):\n\nSee Apple’s Diagnosing and Resolving Bugs in Your Running App: Visualize and Diagnose Increasing Memory Usage.\nJust identify the object in the left panel that you think should have been deallocated, and it will show you the object graph (shown in the main canvas, above). This is very useful in quickly identifying where the strong references were established on the object in question. From here, you can start your research, diagnosing why those strong references were not resolved (e.g. if the object in question has a strong reference from something else that should have been deallocated, look at that object's graph, too, and you may find the issue (e.g. strong reference cycles, repeating timers, etc.).\nNotice, that in the right panel, I'm seeing the call tree. I got that by turning on the \"malloc stack\" logging option in the scheme settings:\n\nAnyway, having done that, one can then click on the arrow next to the relevant method call shown in the stack trace in the right panel of the first screen snapshot above, and you can see where that strong reference was originally established:\n\n\nThe traditional Instruments technique (especially useful if using older versions of Xcode) is described below, in my original answer.\n\nI would suggest using Instruments' \"Allocations\" tool with the \"Record Reference Counts\" feature:\n\nYou can then run the app in Instruments and then search for your class that you know is leaking and drill in by clicking on the arrow:\n\nYou can then drill into the details and look at the stack trace using the \"Extended Details\" panel on the right:\n\nIn that \"Extended Details\" panel, focus on your code in black rather than the system calls in gray. Anyway, from the \"Extended Details\" panel, you can then drill into your source code, right in Instruments::\n\nFor more information and demonstrations in using Instruments to track down memory problems, please refer to:\n\nWWDC 2021 video Detect and diagnose memory issues\nWWDC 2019 video Getting Started with Instruments\nWWDC 2018 video iOS Memory Deep Dive\nWWDC 2013 video Fixing Memory Issues\nWWDC 2012 video iOS App Performance: Memory\n\n",
            "\nUse instruments to check for leaks and memory loss due to retained but not leaked memory. The latter is unused memory that is still pointed to. Use Mark Generation (Heapshot) in the Allocations instrument on Instruments.\nFor HowTo use Heapshot to find memory creap, see: bbum blog\nBasically the method is to run Instruments allocate tool, take a heapshot, run an iteration of your code and take another heapshot repeating 3 or 4 times. This will indicate memory that is allocated and not released during the iterations.\nTo figure out the results disclose to see the individual allocations.\nIf you need to see where retains, releases and autoreleases occur for an object use instruments:\nRun in instruments, in Allocations set \"Record reference counts\" on (For Xcode 5 and lower you have to stop recording to set the option). Cause the app to run, stop recording, drill down and you will be able to see where all retains, releases and autoreleases occurred.\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "swift",
            "memory-management",
            "memory-leaks",
            "automatic-ref-counting"
        ]
    },
    {
        "question_id": "3477422",
        "question": "\nWhat is the use of LayoutInflater in Android?\n",
        "all_answers": [
            "\nThe LayoutInflater class is used to instantiate the contents of layout XML files into their corresponding View objects.\nIn other words, it takes an XML file as input and builds the View objects from it.\n",
            "\nYou can use this outside activities - all you need is to provide a Context:\nLayoutInflater inflater = (LayoutInflater) context.getSystemService( Context.LAYOUT_INFLATER_SERVICE );\n\nThen to retrieve your different widgets, you inflate a layout:\nView view = inflater.inflate( R.layout.myNewInflatedLayout, null );\nButton myButton = (Button) view.findViewById( R.id.myButton );\n\n\nEDIT as of July 2014\nDavide's answer on how to get the LayoutInflater is actually more correct than mine (which is still valid though).\n",
            "\nLayoutInflater.from(context).inflate(R.layout.row_payment_gateway_item, null);\n\n",
            "\nYou inflate an XML resource. See the LayoutInflater doc .\nIf your layout is in a mylayout.xml, you would do something like:\nView view; \nLayoutInflater inflater = (LayoutInflater)   getContext().getSystemService(Context.LAYOUT_INFLATER_SERVICE); \nview = inflater.inflate(R.layout.mylayout, null);\n\nRelativeLayout item = (RelativeLayout) view.findViewById(R.id.item);\n\n",
            "\nUsing context object you can get LayoutInflater from following code\nLayoutInflater inflater = (LayoutInflater)context.getSystemService(Context.LAYOUT_INFLATER_SERVICE);\n\n",
            "\nI'm not sure I have followed your question- are you trying to attach a child view to the RelativeLayout? If so you want to do something along the lines of:\nRelativeLayout item = (RelativeLayout)findViewById(R.id.item);\nView child = getLayoutInflater().inflate(R.layout.child, null);\nitem.addView(child);\n\n",
            "\nWhen you use a custom view in a ListView you must define the row layout.\nYou create an xml where you place android widgets and then in the adapter's code you have to do something like this:\npublic MyAdapter(Context context, List<MyObject> objects) extends ArrayAdapter {\n  super(context, 1, objects);\n  /* We get the inflator in the constructor */\n  mInflater = (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE);\n}\n\n@Override\npublic View getView(int position, View convertView, ViewGroup parent) {\n  View view;\n  /* We inflate the xml which gives us a view */\n  view = mInflater.inflate(R.layout.my_list_custom_row, parent, false);\n\n  /* Get the item in the adapter */\n  MyObject myObject = getItem(position);\n\n  /* Get the widget with id name which is defined in the xml of the row */\n  TextView name = (TextView) view.findViewById(R.id.name);\n\n  /* Populate the row's xml with info from the item */\n  name.setText(myObject.getName());\n\n  /* Return the generated view */\n  return view;\n}\n\nRead more in the official documentation.\n",
            "\nOr ...\nLayoutInflater inflater = LayoutInflater.from(context);\n\n",
            "\nThough late answer, \nbut would like to add that one way to get this\nLayoutInflater layoutInflater = (LayoutInflater)this.getSystemService(Context.LAYOUT_INFLATER_SERVICE);\n    View view = layoutInflater.inflate(R.layout.mylayout, item );\n\nwhere item is the parent layout where you want to add a child layout.\n",
            "\nor \nView.inflate(context, layout, parent)\n",
            "\nIt's helpful to add to this, even though it's an old post, that if the child view that is being inflated from xml is to be added to a viewgroup layout, you need to call inflate with a clue of what type of viewgroup it is going to be added to. Like:\nView child = getLayoutInflater().inflate(R.layout.child, item, false);\n\nThe inflate method is quite overloaded and describes this part of the usage in the docs. I had a problem where a single view inflated from xml wasn't aligning in the parent properly until I made this type of change.\n",
            "\nLayoutInflater inflater = (LayoutInflater) context.getSystemService( Context.LAYOUT_INFLATER_SERVICE );\n\nUse this instead!\n"
        ],
        "answer": "A7",
        "tags": [
            "android",
            "layout-inflater",
            "android-inflate"
        ]
    },
    {
        "question_id": "4502633",
        "question": "\nWhat I want to do is when a certain div is hovered, it'd affect the properties of another div.\nFor example, in this JSFiddle demo, when you hover over #cube it changes the background-color but what I want is that when I hover over #container, #cubeis affected.\n\n\ndiv {\n  outline: 1px solid red;\n}\n\n#container {\n  width: 200px;\n  height: 30px;\n}\n\n#cube {\n  width: 30px;\n  height: 100%;\n  background-color: red;\n}\n\n#cube:hover {\n  width: 30px;\n  height: 100%;\n  background-color: blue;\n}\n<div id=\"container\">\n  <div id=\"cube\">\n  </div>\n</div>\n\n\n\n",
        "all_answers": [
            "\nIf the cube is directly inside the container:\n#container:hover > #cube { background-color: yellow; }\n\nIf cube is next to (after containers closing tag) the container:\n#container:hover + #cube { background-color: yellow; }\n\nIf the cube is somewhere inside the container:\n#container:hover #cube { background-color: yellow; }\n\nIf the cube is a sibling of the container:\n#container:hover ~ #cube { background-color: yellow; }\n\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nIn this particular example, you can use:\n#container:hover #cube {\n    background-color: yellow;   \n}\n\nThis example only works since cube is a child of container. For more complicated scenarios, you'd need to use different CSS, or use JavaScript.\n"
        ],
        "answer": "A1",
        "tags": [
            "html",
            "css",
            "hover"
        ]
    },
    {
        "question_id": "24196956",
        "question": "\nI'm just starting to learn Docker, and I'm trying to get a simple setup with boot2docker on Windows. I could not find in any tutorial or samples online how to make my project files accessible to the boot2docker VM.\nI downloaded boot2docker, and succeeded in installing it and getting it up and running. I can also ssh into it and run the hello world docker example, so I know I have a working Docker installation in the VM.\nNow, the question: How do I get my Dockerfile and my application files on the boot2docker VM so that I can build a Docker container?\nIn other words, I'm trying to do this from the boot2docker VM:\n$ cd /some-directory-from-my-host-os\n$ docker build .\n\nI tried following the instructions on https://github.com/boot2docker/boot2docker#folder-sharing and setup a SAMBA share, and I can successfully connect from Windows to the share at \\\\192.168.59.103\\data but that doesn't tell me how to access that same directory from within the boot2docker VM.\nI feel like the answer might be obvious, but I'm sure I'm not the only one who will hit that wall. Thanks for your help!\n\nUpdate - Now Built-In in boot2docker 1.3!\nSince boot2docker 1.3, the ability to mount a shared folder has been added, so the VM can share your dev folder directly. More information here: https://github.com/boot2docker/boot2docker#virtualbox-guest-additions\n",
        "all_answers": [
            "\nThe container images will use the underlying OS license. Microsoft calls it supplmental license.\n\nYou are licensed to use this Supplement in conjunction with the\n  underlying host operating system software (“Host Software”) solely to\n  assist running the containers feature in the Host Software. The Host\n  Software license terms apply to your use of the Supplement. You may\n  not use it if you do not have a license for the Host Software. You may\n  use this Supplement with each validly licensed copy of the Host\n  Software.\n\n",
            "\nFollowing your current progress, and presuming your samba container is running,\nyou can find the path to the /data folder on your Boot2docker VM by running:\n$ docker inspect <samba_container_id>\n\nThis will list the containers configuration details.\nNear the very bottom you should see:\n\n\"Volumes\": {\n    \"/data\": \"/mnt/sda1/var/lib/docker/vfs/dir/<long_id_here>\n\n\nThat's your boot2docker vm /data path.\nSimply cd into that folder\n$ cd /mnt/sda1/var/lib/docker/vfs/dir/<long_id_here>\n\nFrom Windows Explorer, Navigate to:\n\\\\192.168.59.103\\data\n\nNow you can paste/copy/create some files into that data folder and you should see them populate on your Boot2docker VM at path: /mnt/sda1/var/lib/docker/vfs/dir/<long_folder_id_here>\n",
            "\nNot sure if it helps under windows. But for Mac see:\nboot2docker together with VirtualBox Guest Additions\nHow to mount /Users into boot2docker\nhttps://medium.com/boot2docker-lightweight-linux-for-docker/boot2docker-together-with-virtualbox-guest-additions-da1e3ab2465c\n\ntl;dr Build your own custom boot2docker.iso with VirtualBox Guest\n  Additions (see link) or download\n  http://static.dockerfiles.io/boot2docker-v1.0.1-virtualbox-guest-additions-v4.3.12.iso\n  and save it to ~/.boot2docker/boot2docker.iso.\n\n",
            "\nIMHO the best way would be to use scp. As you can ssh, you can use winscp to send the Dockerfile to the VM.\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "docker",
            "boot2docker"
        ]
    },
    {
        "question_id": "1972006",
        "question": "\nFor some reason the item \"description\" returns NULL with the following code:\n<?php\ninclude('db.php');\n\n$result = mysql_query('SELECT * FROM `staff` ORDER BY `id` DESC LIMIT 2') or die(mysql_error());\n$rows = array();\nwhile($row = mysql_fetch_assoc($result)){\n    $rows[] = $row;\n}\n\necho json_encode($rows);\n?>\n\nHere is the schema for my database:\nCREATE TABLE `staff` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `name` longtext COLLATE utf8_unicode_ci,\n  `description` longtext COLLATE utf8_unicode_ci,\n  `icon` longtext COLLATE utf8_unicode_ci,\n  `date` longtext COLLATE utf8_unicode_ci,\n  `company` longtext COLLATE utf8_unicode_ci,\n  `companyurl` longtext COLLATE utf8_unicode_ci,\n  `appurl` longtext COLLATE utf8_unicode_ci,\n  PRIMARY KEY (`id`)\n) ENGINE=MyISAM AUTO_INCREMENT=5 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci\n\nHere is what is echoed out on the page:\n[{\"id\":\"4\",\"name\":\"Noter 2\",\"description\":null,\"icon\":\"http:\\/\\/images.apple.com\\/webapps\\/productivity\\/images\\/noter2_20091223182720-thumb.jpg\",\"date\":\"1262032317\",\"company\":\"dBelement, LLC\",\"companyurl\":\"http:\\/\\/dbelement.com\\/\",\"appurl\":\"http:\\/\\/noter2.dbelement.com\"},{\"id\":\"3\",\"name\":\"Noter 2\",\"description\":null,\"icon\":\"http:\\/\\/images.apple.com\\/webapps\\/productivity\\/images\\/noter2_20091223182720-thumb.jpg\",\"date\":\"1262032317\",\"company\":\"dBelement, LLC\",\"companyurl\":\"http:\\/\\/dbelement.com\\/\",\"appurl\":\"http:\\/\\/noter2.dbelement.com\"}]\n\nAny ideas?\n",
        "all_answers": [
            "\nAHHH!!! This looks so wrong it hurts my head. Try something more like this...\n<?php\ninclude('db.php');\n\n$result = mysql_query('SELECT `id`, `name`, `description`, `icon` FROM `staff` ORDER BY `id` DESC LIMIT 20') or die(mysql_error());\n$rows = array();\nwhile($row = mysql_fetch_assoc($result)){\n    $rows[] = $row;\n}\n\necho json_encode($rows);\n?>\n\n\nWhen iterating over mysql_num_rows you should use < not <=. You should also cache this value (save it to a variable) instead of having it re-count every loop. Who knows what it's doing under the hood... (might be efficient, I'm not really sure)\nYou don't need to copy out each value explicitly like that... you're just making this harder on yourself. If the query is returning more values than you've listed there, list only the ones you want in your SQL.\nmysql_fetch_array returns the values both by key and by int. You not using the indices, so don't fetch em.\n\nIf this really is a problem with json_encode, then might I suggest replacing the body of the loop with something like\n$rows[] = array_map('htmlentities',$row);\n\nPerhpas there are some special chars in there that are mucking things up...\n",
            "\nfunction isJson($string) {\n   json_decode($string);\n   return json_last_error() === JSON_ERROR_NONE;\n}\n\n",
            "\nI bet you are retrieving data in non-utf8 encoding: try to put mysql_query('SET CHARACTER SET utf8') before your SELECT query.\n"
        ],
        "answer": "A3",
        "tags": [
            "php",
            "null",
            "json"
        ]
    },
    {
        "question_id": "985272",
        "question": "\nI would like to have users click a link, then it selects the HTML text in another element (not an input).\nBy \"select\" I mean the same way you would select text by dragging your mouse over it. This has been a bear to research because everyone talks about \"select\" or \"highlight\" in other terms.\nIs this possible? My code so far:\nHTML:\n<a href=\"javascript:\" onclick=\"SelectText('xhtml-code')\">Select Code</a>\n<code id=\"xhtml-code\">Some Code here </code>\n\nJS:\nfunction SelectText(element) {\n    $(\"#\" + element).select();\n}\n\nAm I missing something blatantly obvious?\n",
        "all_answers": [
            "\nHave a look at the Selection object (Gecko engine) and the TextRange object (Trident engine.) I don't know about any JavaScript frameworks that have cross-browser support for this implemented, but I've never looked for it either, so it's possible that even jQuery has it.\n",
            "\nPlain Javascript\n\n\nfunction selectText(nodeId) {\n    const node = document.getElementById(nodeId);\n\n    if (document.body.createTextRange) {\n        const range = document.body.createTextRange();\n        range.moveToElementText(node);\n        range.select();\n    } else if (window.getSelection) {\n        const selection = window.getSelection();\n        const range = document.createRange();\n        range.selectNodeContents(node);\n        selection.removeAllRanges();\n        selection.addRange(range);\n    } else {\n        console.warn(\"Could not select text in node: Unsupported browser.\");\n    }\n}\n\nconst clickable = document.querySelector('.click-me');\nclickable.addEventListener('click', () => selectText('target'));\n<div id=\"target\"><p>Some text goes here!</p><p>Moar text!</p></div>\n<p class=\"click-me\">Click me!</p>\n\n\n\nHere is a working demo. For those of you looking for a jQuery plugin, I made one of those too.\n\njQuery (original answer)\nI have found a solution for this in this thread. I was able to modify the info given and mix it with a bit of jQuery to create a totally awesome function to select the text in any element, regardless of browser:\nfunction SelectText(element) {\n    var text = document.getElementById(element);\n    if ($.browser.msie) {\n        var range = document.body.createTextRange();\n        range.moveToElementText(text);\n        range.select();\n    } else if ($.browser.mozilla || $.browser.opera) {\n        var selection = window.getSelection();\n        var range = document.createRange();\n        range.selectNodeContents(text);\n        selection.removeAllRanges();\n        selection.addRange(range);\n    } else if ($.browser.safari) {\n        var selection = window.getSelection();\n        selection.setBaseAndExtent(text, 0, text, 1);\n    }\n}\n\n",
            "\nAccording to the jQuery documentation of select(): \n\nTrigger the select event of each matched element. This causes all of the functions that have been bound to that select event to be executed, and calls the browser's default select action on the matching element(s).\n\nThere is your explanation why the jQuery select() won't work in this case.\n",
            "\nThis thread (dead link) contains really wonderful stuff. But I'm not able to do it right on this page using FF 3.5b99 + FireBug due to \"Security Error\".\nYipee!! I was able to select whole right hand sidebar with this code hope it helps you:\n    var r = document.createRange();\n    var w=document.getElementById(\"sidebar\");  \n    r.selectNodeContents(w);  \n    var sel=window.getSelection(); \n    sel.removeAllRanges(); \n    sel.addRange(r); \n\nPS:- I was not able to use objects returned by jquery selectors like\n   var w=$(\"div.welovestackoverflow\",$(\"div.sidebar\"));\n   \n   //this throws **security exception**\n\n   r.selectNodeContents(w);\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "jquery"
        ]
    },
    {
        "question_id": "9047054",
        "question": "\nI have a project (myapp) in heroku but I can't get the static files to work properly. I was following this blog post.\nMy Procfile looks like this:\nweb: python myapp/manage.py collectstatic --noinput; bin/gunicorn_django --workers=4 --bind=0.0.0.0:$PORT myapp/settings.py\n\nsettings.py:\n...\n\nSTATIC_ROOT = os.path.join(PROJECT_PATH, 'staticfiles')\nSTATIC_URL = '/static/'\nADMIN_MEDIA_PREFIX = '/static/admin/'\n\nSTATICFILES_DIRS = (\n    # I have the static folder inside my app and not inside the project\n    os.path.join(PROJECT_PATH, 'cesar/static'),\n)\n\n...\n\nWhen restarting using heroku restart this is what the heroku logs shows:\n...\nCopying ...\n\n114 static files copied to '/app/myapp/staticfiles'.\n...\n\nBut when I do heroku run ls -l myapp/ I can't see the staticfiles folder:\n-rw------- 1 u5605 5605    0 Jan 28 16:53 __init__.py\ndrwx------ 4 u5605 5605 4096 Jan 28 16:53 cesar\n-rw------- 1 u5605 5605  503 Jan 28 16:53 manage.py\n-rw------- 1 u5605 5605 6292 Jan 28 16:53 settings.py\ndrwx------ 2 u5605 5605 4096 Jan 28 16:53 templates\n-rw------- 1 u5605 5605  257 Jan 28 16:53 urls.py\n-rw------- 1 u5605 5605  286 Jan 28 16:53 views.py\n\nWhat am I missing or doing wrong?\n",
        "all_answers": [
            "\nI found a solution. This was my initial myapp/urls.py:\nfrom django.conf.urls.defaults import patterns, include, url\nfrom django.contrib import admin\nfrom django.conf import settings\n\n\nadmin.autodiscover()\n\nurlpatterns = patterns('',\n    url(r'^$', include('myapp.cesar.urls')),\n    url(r'^admin/', include(admin.site.urls)),\n)\n\nI added these lines to the end of the original myapp/urls.py file:\nif not settings.DEBUG:\n    urlpatterns += patterns('',\n        (r'^static/(?P<path>.*)$', 'django.views.static.serve', {'document_root': settings.STATIC_ROOT}),\n    )\n\nNow it's working fine. I hope this helps someone else too\n",
            "\nProbably you should manually create empty STATIC_ROOT folder specified in you settings before running './manage.py collectstatic'.\n"
        ],
        "answer": "A1",
        "tags": [
            "django",
            "static",
            "heroku"
        ]
    },
    {
        "question_id": "8446218",
        "question": "\nOn http://github.com developer keep the HTML, CSS, JavaScript and images files of the project. How can I see the HTML output in browser?\nFor example this: https://github.com/necolas/css3-social-signin-buttons/blob/master/index.html\nWhen I open this it doesn't show the rendered HTML of the code of author. It shows the page as a source code.\nIs it possible to see it as rendered HTML directly? Otherwise I always need to download the whole ZIP just to see the result.\n",
        "all_answers": [
            "\nThe most comfortable way to preview HTML files on GitHub is to go to https://htmlpreview.github.io/ or just prepend it to the original URL, i.e.: https://htmlpreview.github.io/?https://github.com/bartaz/impress.js/blob/master/index.html\n",
            "\nI would suggest a more \"abstract\" classification. Add a new class \"img-center\" which can be used in combination with .img-responsive class:\n// Center responsive images\n.img-responsive.img-center {\n  margin: 0 auto;\n}\n\n",
            "\nThis should center the image and make it responsive.\n<img src=\"...\" class=\"img-responsive\" style=\"margin:0 auto;\"/>\n\n",
            "\nYou can use property of d-block here or you can use a parent div with property 'text-center' in bootstrap or 'text-align: center' in css.\nImage by default is displayed as inline-block, you need to display it as block in order to center it with .mx-auto. This can be done with built-in .d-block:\n<div>\n    <img class=\"mx-auto d-block\" src=\"...\">  \n</div>\n\nOr leave it as inline-block and wrapped it in a div with .text-center:\n<div class=\"text-center\">\n    <img src=\"...\">  \n</div>\n\n",
            "\nSimply put all the images thumbnails inside a row/col divs like this:\n<div class=\"row text-center\">\n <div class=\"col-12\">\n  # your images here...\n </div>\n</div>\n\nand everything will work fine!\n",
            "\nIf you're using Bootstrap v3.0.1 or greater, you should use this solution instead. It doesn't override Bootstrap's styles with custom CSS, but instead uses a Bootstrap feature.\nMy original answer is shown below for posterity\n\nThis is a pleasantly easy fix. Because .img-responsive from Bootstrap already sets display: block, you can use margin: 0 auto to center the image:\n.product .img-responsive {\n    margin: 0 auto;\n}\n\n",
            "\nIf you don't want to download an archive you can use GitHub Pages to render this.\n\nFork the repository to your account.\nClone it locally on your machine\nCreate a gh-pages branch (if one already exists, remove it and create a new one based off master).\nPush the branch back to GitHub.\nView the pages at http://username.github.io/repo`\n\nIn code:\ngit clone git@github.com:username/repo.git\ncd repo\ngit branch gh-pages\n# Might need to do this first: git branch -D gh-pages\ngit push -u origin gh-pages # Push the new branch back to github\nGo to http://username.github.io/repo\n\n",
            "\nAdd only the class center-block to an image, this works with Bootstrap 4 as well:\n<img src=\"...\" alt=\"...\" class=\"center-block\" />\n\nNote: center-block works even when img-responsive is used\n",
            "\nThere is .center-block class in Twitter Bootstrap 3 (Since v3.0.1), so use:\n<img src=\"...\" alt=\"...\" class=\"img-responsive center-block\" />\n\n",
            "\nJust use .text-center class if you're using Bootstrap 3.\n<div class=\"text-center\">\n    <img src=\"...\" alt=\"...\"/>\n</div>\n\nNote: This doesn't work with img-responsive\n"
        ],
        "answer": "A1",
        "tags": [
            "html",
            "css",
            "git",
            "github",
            "github-pages"
        ]
    },
    {
        "question_id": "14523348",
        "question": "\nAt some point in my app I have a highlighted UIButton (for example when a user has his finger on the button) and I need to change the background color while the button is highlighted (so while the finger of the user is still on the button).\nI tried the following:\n_button.backgroundColor = [UIColor redColor];\n\nBut it is not working. The color remains the same. I tried the same piece of code when the button is not highlighted and it works fine. I also tried calling -setNeedsDisplay after changing the color, it didn't have any effect.\nHow to force the button to change the background color?\n",
        "all_answers": [
            "\nNot sure if this sort of solves what you're after, or fits with your general development landscape  but the first thing I would try would be to change the background colour of the button on the touchDown event.\nOption 1:\nYou would need two events to be capture, UIControlEventTouchDown would be for when the user presses the button. UIControlEventTouchUpInside and UIControlEventTouchUpOutside will be for when they release the button to return it to the normal state\nUIButton *myButton =  [UIButton buttonWithType:UIButtonTypeCustom];\n[myButton setFrame:CGRectMake(10.0f, 10.0f, 100.0f, 20.f)];\n[myButton setBackgroundColor:[UIColor blueColor]];\n[myButton setTitle:@\"click me:\" forState:UIControlStateNormal];\n[myButton setTitle:@\"changed\" forState:UIControlStateHighlighted];\n[myButton addTarget:self action:@selector(buttonHighlight:) forControlEvents:UIControlEventTouchDown];\n[myButton addTarget:self action:@selector(buttonNormal:) forControlEvents:UIControlEventTouchUpInside];\n\nOption 2:\nReturn an image made from the highlight colour you want. This could also be a category.\n+ (UIImage *)imageWithColor:(UIColor *)color {\n   CGRect rect = CGRectMake(0.0f, 0.0f, 1.0f, 1.0f);\n   UIGraphicsBeginImageContext(rect.size);\n   CGContextRef context = UIGraphicsGetCurrentContext();\n\n   CGContextSetFillColorWithColor(context, [color CGColor]);\n   CGContextFillRect(context, rect);\n\n   UIImage *image = UIGraphicsGetImageFromCurrentImageContext();\n   UIGraphicsEndImageContext();\n\n   return image;\n}\n\nand then change the highlighted state of the button:\n[myButton setBackgroundImage:[self imageWithColor:[UIColor greenColor]] forState:UIControlStateHighlighted];\n\n",
            "\nYou can override UIButton's setHighlighted method.\nObjective-C\n- (void)setHighlighted:(BOOL)highlighted {\n    [super setHighlighted:highlighted];\n\n    if (highlighted) {\n        self.backgroundColor = UIColorFromRGB(0x387038);\n    } else {\n        self.backgroundColor = UIColorFromRGB(0x5bb75b);\n    }\n}\n\nSwift 3.0 and Swift 4.1\noverride open var isHighlighted: Bool {\n    didSet {\n        super.isHighlighted = isHighlighted\n        backgroundColor = isHighlighted ? UIColor.black : UIColor.white\n    }\n}\n\n",
            "\nTry tintColor:\n_button.tintColor = [UIColor redColor];\n\n",
            "\nTry this if you have an image:\n-(void)setBackgroundImage:(UIImage *)image forState:(UIControlState)state;\n\nor see if showsTouchWhenHighlighted is enough for you.\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "objective-c",
            "xcode",
            "uibutton"
        ]
    },
    {
        "question_id": "2411031",
        "question": "\nI have directory A with files matching directory B. Directory A may have other needed files. Directory B is a git repo.\nI want to clone directory B to directory A but git-clone won't allow me to since the directory is non-empty.\nI was hoping it would just clone .git and since all the files match I could go from there?\nI can't clone into an empty directory because I have files in directory A that are not in directory B and I want to keep them.\nCopying .git is not an option since I want refs to push/pull with and I don't want to set them up manually.\nIs there any way to do this?\nUpdate: I think this works, can anyone see any problems? -->\ncd a\ngit clone --no-hardlinks --no-checkout ../b a.tmp \nmv a.tmp/.git .\nrm -rf a.tmp\ngit unstage # apparently git thinks all the files are deleted if you don't do this\n\n",
        "all_answers": [
            "\nMaybe I misunderstood your question, but wouldn't it be simpler if you copy/move the files from A to the git repo B and add the needed ones with git add?\nUPDATE: From the git doc:\n\nCloning into an existing directory is only allowed if the directory is empty.\n\nSOURCE: http://git-scm.com/docs/git-clone\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nIn the following shell commands existing-dir is a directory whose contents match the tracked files in the repo-to-clone git repository.\n# Clone just the repository's .git folder (excluding files as they are already in\n# `existing-dir`) into an empty temporary directory\ngit clone --no-checkout repo-to-clone existing-dir/existing-dir.tmp # might want --no-hardlinks for cloning local repo\n\n# Move the .git folder to the directory with the files.\n# This makes `existing-dir` a git repo.\nmv existing-dir/existing-dir.tmp/.git existing-dir/\n\n# Delete the temporary directory\nrmdir existing-dir/existing-dir.tmp\ncd existing-dir\n\n# git thinks all files are deleted, this reverts the state of the repo to HEAD.\n# WARNING: any local changes to the files will be lost.\ngit reset --hard HEAD\n\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n"
        ],
        "answer": "A5",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "6514950",
        "question": "\nI know how to set the routes root of my rails app to a controller and an action.\nBut how to add an id?\n/pages/show/1 should be the root.\nHow do I set this?\n",
        "all_answers": [
            "\nI had a similar error and had to edit my manifest.js file in order to get it to work.\nEdit /assets/config.manifest.js and then\n// manifest.js\n//= link_tree ../images\n//= link_tree ../stylesheets .css\n\nThen do a bundle exec rake assets:precompile\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nTry:\n match 'pages/show/:id' => 'pages#show', :as => :root\n\nIn Rails console. rake routes | grep root, should show something like:\nroot     /pages/show/:id(.:format)      {:controller=>\"pages\", :action=>\"show\"}\n\nHope that helps.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nHad this same problem and this worked for me:\nroot :to => \"pages#show\", :id => '1'\n\n"
        ],
        "answer": "A6",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "ruby-on-rails-3",
            "routes",
            "url-routing"
        ]
    },
    {
        "question_id": "1306414",
        "question": "\nI've come across __stdcall a lot these days.\nMSDN doesn't explain very clearly what it really means, when and why should it be used, if at all.\nI would appreciate if someone would provide an explanation, preferably with an example or two.\n",
        "all_answers": [
            "\nIt specifies a calling convention for a function. A calling convention is a set of rules how parameters are passed to a function: in which order, per address or per copy, who is to clean up the parameters (caller or callee) etc. \n",
            "\nThat's a calling convention that WinAPI functions need to be called properly. A calling convention is a set of rules on how the parameters are passed into the function and how the return value is passed from the function.\nIf the caller and the called code use different conventions you run into undefined behaviour (like such a strange-looking crash).\nC++ compilers don't use __stdcall by default - they use other conventions. So in order to call WinAPI functions from C++ you need to specify that they use __stdcall - this is usually done in Windoes SDK header files and you also do it when declaring function pointers.\n",
            "\nI have done it earlier.\nHope this helps, if this is exactly what you are looking for.\n\nLoad your certificate (in PCCERT_CONTEXT structure) from Windows Cert store using Crypto APIs.\nGet encrypted content of it in binary format as it is. [PCCERT_CONTEXT->pbCertEncoded].\nParse this binary buffer into X509 certificate Object using OpenSSL's d2i_X509() method.\nGet handle to OpenSSL's trust store using SSL_CTX_get_cert_store() method.\nLoad above parsed X509 certificate into this trust store using X509_STORE_add_cert() method.\nYou are done!\n\n",
            "\nAll functions in C/C++ have a particular calling convention.  The point of a calling convention is to establish how data is passed between the caller and callee and who is responsible for operations such as cleaning out the call stack.  \nThe most popular calling conventions on windows are \n\n__stdcall, Pushes parameters on the stack, in reverse order (right to left)\n__cdecl,  Pushes parameters on the stack, in reverse order (right to left)\n__clrcall, Load parameters onto CLR expression stack in order (left to right).\n__fastcall, Stored in registers, then pushed on stack\n__thiscall, Pushed on stack; this pointer stored in ECX\n\nAdding this specifier to the function declaration essentially tells the compiler that you want this particular function to have this particular calling convention.  \nThe calling conventions are documented here\n\nhttps://learn.microsoft.com/en-us/cpp/cpp/calling-conventions\n\nRaymond Chen also did a long series on the history of the various calling conventions (5 parts) starting here.\n\nhttps://devblogs.microsoft.com/oldnewthing/20040102-00/?p=41213\n\n"
        ],
        "answer": "A4",
        "tags": [
            "c++",
            "windows",
            "calling-convention"
        ]
    },
    {
        "question_id": "3476646",
        "question": "\n\n\n\nI'm looking to set the left inset/margin of a UILabel and can't find a method to do so. The label has a background set so just changing its origin won't do the trick. It would be ideal to inset the text by 10px or so on the left hand side.\n",
        "all_answers": [
            "\n\nUse option-return when typing in the little box in Interface Builder to insert a line feed (\\n). In Interface Builder's Label attributes, set # Lines = 0.\nSelect the label and then change Lines property to 0 like in the above image, and then use \\n in your string for line break. \n",
            "\nUse \\n as you are using in your string.\nSet numberOfLines to 0 to allow for any number of lines.\nlabel.numberOfLines = 0;\nUpdate the label frame to match the size of the text using sizeWithFont:.  If you don't do this your text will be vertically centered or cut off.\nUILabel *label; // set frame to largest size you want\n...\nCGSize labelSize = [label.text sizeWithFont:label.font\n                          constrainedToSize:label.frame.size\n                              lineBreakMode:label.lineBreakMode];\nlabel.frame = CGRectMake(\n    label.frame.origin.x, label.frame.origin.y, \n    label.frame.size.width, labelSize.height);\n\nUpdate : Replacement for deprecatedsizeWithFont:constrainedToSize:lineBreakMode:\nReference, Replacement for deprecated sizeWithFont: in iOS 7?\nCGSize labelSize = [label.text sizeWithAttributes:@{NSFontAttributeName:label.font}];\n\nlabel.frame = CGRectMake(\n    label.frame.origin.x, label.frame.origin.y, \n    label.frame.size.width, labelSize.height);\n\n",
            "\nI solved this by subclassing UILabel and overriding drawTextInRect: like this:\n- (void)drawTextInRect:(CGRect)rect {\n    UIEdgeInsets insets = {0, 5, 0, 5};\n    [super drawTextInRect:UIEdgeInsetsInsetRect(rect, insets)];\n}\n\nSwift 3.1: \noverride func drawText(in rect: CGRect) {\n    let insets = UIEdgeInsets.init(top: 0, left: 5, bottom: 0, right: 5)\n    super.drawText(in: UIEdgeInsetsInsetRect(rect, insets))\n}\n\nSwift 4.2.1: \noverride func drawText(in rect: CGRect) {\n    let insets = UIEdgeInsets(top: 0, left: 5, bottom: 0, right: 5)\n    super.drawText(in: rect.inset(by: insets))\n}\n\nAs you might have gathered, this is an adaptation of tc.'s answer. It has two advantages over that one:\n\nthere's no need to trigger it by sending a sizeToFit message\nit leaves the label frame alone - handy if your label has a background and you don't want that to shrink\n\n",
            "\nI think UILabel class have no method for setting margin. Why you not set the position of Label at required place?\nSee below code:\nUILabel *label = [[UILabel alloc] init];\nlabel.text = @\"This is label\";\nlabel.frame = CGRectMake(0,0,100,100);\n\nif from interface builder then just position Label by following:\nyourLabel.frame = CGRectMake(0,0,100,100);\n\n",
            "\nIf you don't want to use an extra parent view to set the background, you can subclass UILabel and override textRectForBounds:limitedToNumberOfLines:. I'd add a textEdgeInsets property or similar and then do\n- (CGRect)textRectForBounds:(CGRect)bounds limitedToNumberOfLines:(NSInteger)numberOfLines\n{\n  return [super textRectForBounds:UIEdgeInsetsInsetRect(bounds,textEdgeInsets) limitedToNumberOfLines:numberOfLines];\n}\n\nFor robustness, you might also want to call [self setNeedsDisplay] in setTextEdgeInsets:, but I usually don't bother.\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "cocoa-touch",
            "uikit",
            "uilabel"
        ]
    },
    {
        "question_id": "2369673",
        "question": "\n\n\n\nIs there a short way to add List<> to List<> instead of looping in result and add new result one by one?\nvar list = GetViolations(VehicleID);\nvar list2 = GetViolations(VehicleID2);\n\nlist.Add(list2);\n\n",
        "all_answers": [
            "\nTry using list.AddRange(VTSWeb.GetDailyWorktimeViolations(VehicleID2));\n",
            "\n\nUse Concat or Union extension methods. You have to make sure that you have this declaration using System.Linq; in order to use LINQ extensions methods.\n\nUse the AddRange method.\n\n\n",
            "\nUse .AddRange to append any Enumrable collection to the list.\n",
            "\nUse List.AddRange(collection As IEnumerable(Of T)) method. \nIt allows you to append at the end of your list another collection/list.\nExample:\nList<string> initialList = new List<string>();\n// Put whatever you want in the initial list\nList<string> listToAdd = new List<string>();\n// Put whatever you want in the second list\ninitialList.AddRange(listToAdd);\n\n"
        ],
        "answer": "A4",
        "tags": [
            "c#",
            "asp.net",
            "list"
        ]
    },
    {
        "question_id": "9382245",
        "question": "\nI need to disable textarea horizontal resize. Sometimes I want to allow vertical resize on the textarea. \nWhenever I create a contact us page the textarea is making  my design ugly.\ncould any one give me a solution to disable it please?\n",
        "all_answers": [
            "\nWith some css like this\ntextarea\n{\n   resize: none;\n}\n\nOr if you want only vertical\ntextarea { resize:vertical; }\n\nOr horizontal\ntextarea { resize:horizontal; } \n\nor both ( not your case)\ntextarea { resize:both; } \n\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nYou can put this in the CSS file:\ntextarea {\n  resize: none;\n} \n\n",
            "\nYou can use css \ndisable all\ntextarea { resize: none; }\n\nonly vertical resize \ntextarea { resize: vertical; }\n\nonly horizontal resize \ntextarea { resize: horizontal; } \n\ndisable vertical and horizontal with limit\ntextarea { resize: horizontal; max-width: 400px; min-width: 200px; }\n\ndisable horizontal and vertical with limit\ntextarea { resize: vertical; max-height: 300px; min-height: 200px; }\n\nI think min-height should be useful for you\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n"
        ],
        "answer": "A5",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "807782",
        "question": "\n\n\n\nLet me start by telling you that I never used anything besides SVN and I'm also a Windows user.\nI have a couple of simple projects that are open-source, others are on their way when I'm happy enough to release their source code. Either way, I was thinking of using Google Code and SVN to share the source code of my projects instead of providing a link to the source on my website. This has always been a pain because I had to update the binaries and the code every time I released a new version. This would also help me to have a backup of my code some where instead of just my local machine (I used to have a local Subversion server running).\nWhat I want from a service like this is very simple... I just want a place to store my source code that people can download if they want, that allows me to control revisions and provide a simple and easy issue/bug system so people can submit bugs and stuff like that. I guess both of them have this.\nBut I don't want to host any binaries in their websites. I want this to be hosted on my website so I can control download statistics with my own scripts. I also don't have a need for wiki pages as I prefer to have all the documentation on my own website. Do any of these services provide a way to \"disable\" features like wiki and downloads and not show them at all for my project(s)?\nNow, I'm sure there are lots of pros and cons about using Google Code with SVN and GitHub with Git (of course) but here's what's important for me on each one, and why I like them:\nGoogle Code:\n\nAs with any Google page, the complexity is almost non-existent\nEveryone (or almost everyone) has a Google account, whcih is nice if people want to report problems using the issues system\n\nGitHub:\n\nMay (or may not) be a little more complex (not a problem for me though) than Google's pages but...\n...has a much prettier interface than Google's service\nIt needs people to be registered on GitHub to post about issues\nI like the fact that with Git, you have your own revisions locally (can I use TortoiseGit for this or?)\n\nBasically that's it. Not much, I know...\nWhat other common pros and cons can you tell me about each site/software? Keep in mind that my projects are simple, I'm probably the only one who will ever develop these projects on these repositories (or maybe not, but for now I am).\n",
        "all_answers": [
            "\nGoogle Code is supporting Mercurial now.  Mercurial should give you most of the benefits of Git, but you get the maturity of Google Code.  You also have the option to go with subversion there as well should you want to.\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nI haven't had particularly positive experiences with TortoiseGit myself.  I really like the git model, but everything about it feels weird to me when I'm trying to use it on Windows.  I often end up just using the cygwin version, but even that is far from perfect.\nHonestly, for small projects that you want to opensource, I'd probably just host on google code and deal with SVN for the moment.  It might be different if you were already a git expert, but I'm not sure that the learning curve is worth it for a small, windows-based project (esp. considering the # of windows developers who are likely to be turned off by it).\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n"
        ],
        "answer": "A3",
        "tags": [
            "svn",
            "git",
            "github",
            "google-code"
        ]
    },
    {
        "question_id": "10344197",
        "question": "\nI am using Django which allows people to add extra parameters to a class by using class Meta.\nclass FooModel(models.Model):\n    ...\n    class Meta:\n        ...\n\nThe only thing I found in Python's documentation was:\nclass FooMetaClass(type):\n    ...\n\nclass FooClass:\n    __metaclass__ = FooMetaClass\n\nHowever, I don't think this is the same thing.\n",
        "all_answers": [
            "\nYou are asking a question about two different things:\n\nMeta inner class in Django models:\nThis is just a class container with some options (metadata) attached to the model. It defines such things as available permissions, associated database table name, whether the model is abstract or not, singular and plural versions of the name etc.\nShort explanation is here: Django docs: Models: Meta options\nList of available meta options is here: Django docs: Model Meta options\nFor latest version of Django: Django docs: Model Meta options\n\nMetaclass in Python:\nThe best description is here: What are metaclasses in Python?\n\n\n",
            "\nDjango's Model class specifically handles having an attribute named Meta which is a class. It's not a general Python thing.\nPython metaclasses are completely different.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django"
        ]
    },
    {
        "question_id": "879",
        "question": "\nAre PHP variables passed by value or by reference?\n",
        "all_answers": [
            "\nNull OR an empty string?\nif (!empty($user)) {}\n\nUse empty().\n\nAfter realizing that $user ~= $_POST['user'] (thanks matt):\nvar uservariable='<?php \n    echo ((array_key_exists('user',$_POST)) || (!empty($_POST['user']))) ? $_POST['user'] : 'Empty Username Input';\n?>';\n\n",
            "\nIt's by value according to the PHP Documentation.\n\nBy default, function arguments are passed by value (so that if the value of the argument within the function is changed, it does not get changed outside of the function). To allow a function to modify its arguments, they must be passed by reference.\nTo have an argument to a function always passed by reference, prepend an ampersand (&) to the argument name in the function definition.\n\n<?php\nfunction add_some_extra(&$string)\n{\n    $string .= 'and something extra.';\n}\n\n$str = 'This is a string, ';\nadd_some_extra($str);\necho $str;    // outputs 'This is a string, and something extra.'\n?>\n\n",
            "\nPHP variables are assigned by value, passed to functions by value and when containing/representing objects are passed by reference. You can force variables to pass by reference using an '&'.\nAssigned by value/reference example:\n$var1 = \"test\";\n$var2 = $var1;\n$var2 = \"new test\";\n$var3 = &$var2;\n$var3 = \"final test\";\n\nprint (\"var1: $var1, var2: $var2, var3: $var3);\n\noutput:\n\nvar1: test, var2: final test, var3: final test\n\nPassed by value/reference example:\n$var1 = \"foo\";\n$var2 = \"bar\";\n\nchangeThem($var1, $var2);\n\nprint \"var1: $var1, var2: $var2\";\n\nfunction changeThem($var1, &$var2){\n    $var1 = \"FOO\";\n    $var2 = \"BAR\";\n}\n\noutput:\n\nvar1: foo, var2 BAR\n\nObject variables passed by reference example:\nclass Foo{\n    public $var1;\n\n    function __construct(){\n        $this->var1 = \"foo\";\n    }\n\n    public function printFoo(){\n        print $this->var1;\n    }\n}\n\n\n$foo = new Foo();\n\nchangeFoo($foo);\n\n$foo->printFoo();\n\nfunction changeFoo($foo){\n    $foo->var1 = \"FOO\";\n}\n\noutput:\n\nFOO\n\n(The last example could be better probably.)\n",
            "\nUse empty(). It checks for both empty strings and null.\nif (!empty($_POST['user'])) {\n  // do stuff\n}\n\nFrom the manual:\n\nThe following things are considered to be empty:\n\n\"\" (an empty string)  \n0 (0 as an integer)  \n0.0 (0 as a float)  \n\"0\" (0 as a string)    \nNULL  \nFALSE  \narray() (an empty array)  \nvar $var; (a variable declared, but without a value in a class)  \n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "variables",
            "pass-by-reference",
            "pass-by-value"
        ]
    },
    {
        "question_id": "27810380",
        "question": "\nI'm trying to sort the array that is being set before setting it but the argument of willSet is immutable and sort mutates the value. How can I overcome this limit?\nvar files:[File]! = [File]() {\n    willSet(newFiles) {\n        newFiles.sort { (a:File, b:File) -> Bool in\n            return a.created_at > b.created_at\n        }\n    }\n}\n\nTo put this question out of my own project context, I made this gist:\nclass Person {\n    var name:String!\n    var age:Int!\n\n    init(name:String, age:Int) {\n        self.name = name\n        self.age = age\n    }\n}\n\nlet scott = Person(name: \"Scott\", age: 28)\nlet will = Person(name: \"Will\", age: 27)\nlet john = Person(name: \"John\", age: 32)\nlet noah = Person(name: \"Noah\", age: 15)\n\nvar sample = [scott,will,john,noah]\n\n\n\nvar people:[Person] = [Person]() {\n    willSet(newPeople) {\n        newPeople.sort({ (a:Person, b:Person) -> Bool in\n            return a.age > b.age\n        })\n\n    }\n}\n\npeople = sample\n\npeople[0]\n\nI get the error stating that newPeople is not mutable and sort is trying to mutate it.\n",
        "all_answers": [
            "\nIt is not possible to change value types (including arrays) before they are set inside of willSet. You will need to instead use a computed property and backing storage like so:\nvar _people = [Person]()\n\nvar people: [Person] {\n    get {\n        return _people\n    }\n    set(newPeople) {\n        _people = newPeople.sorted { $0.age > $1.age }\n    }\n}\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nIt's not possible to mutate the value inside willSet. If you implement a willSet observer, it is passed the new property value as a constant parameter. \nWhat about modifying it to use didSet?\nvar people:[Person] = [Person]()\n{\n    didSet\n    {\n        people.sort({ (a:Person, b:Person) -> Bool in\n            return a.age > b.age\n        })\n    }\n}\n\nwillSet is called just before the value is stored.\ndidSet is called immediately after the new value is stored.\nYou can read more about property observers here\nhttps://developer.apple.com/library/ios/documentation/Swift/Conceptual/Swift_Programming_Language/Properties.html\nYou can also write a custom getter and setter like below. But didSet seems more convenient.\nvar _people = [Person]()\n\nvar people: [Person] {\n    get {\n        return _people\n    }\n    set(newPeople) {\n        _people = newPeople.sorted({ (a:Person, b:Person) -> Bool in\n            return a.age > b.age\n        })\n    }\n\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "1874592",
        "question": "\nAs PEP8 suggests keeping below the 80 column rule for your python program, how can I abide to that with long strings, i.e.\ns = \"this is my really, really, really, really, really, really, really long string that I'd like to shorten.\"\n\nHow would I go about expanding this to the following line, i.e.\ns = \"this is my really, really, really, really, really, really\" + \n    \"really long string that I'd like to shorten.\"\n\n",
        "all_answers": [
            "\nWith a \\ you can expand statements to multiple lines:\ns = \"this is my really, really, really, really, really, really\" + \\\n\"really long string that I'd like to shorten.\"\n\nshould work.\n",
            "\nI think the most important word in your question was \"suggests\".  \nCoding standards are funny things.  Often the guidance they provide has a really good basis when it was written (e.g. most terminals being unable to show > 80 characters on a line), but over time they become functionally obsolete, but still rigidly adhered to.  I guess what you need to do here is weigh up the relative merits of \"breaking\" that particular suggestion against the readability and mainatinability of your code.\nSorry this doesn't directly answer your question.\n",
            "\nImplicit concatenation might be the cleanest solution:\ns = \"this is my really, really, really, really, really, really,\" \\\n    \" really long string that I'd like to shorten.\"\n\nEdit On reflection I agree that Todd's suggestion to use brackets rather than line continuation is better for all the reasons he gives. The only hesitation I have is that it's relatively easy to confuse bracketed strings with tuples.\n",
            "\nYou lost a space, and you probably need a line continuation character, ie. a \\.\ns = \"this is my really, really, really, really, really, really\" +  \\\n    \" really long string that I'd like to shorten.\"\n\nor even:\ns = \"this is my really, really, really, really, really, really\"  \\\n    \" really long string that I'd like to shorten.\"\n\nParens would also work instead of the line continuation, but you risk someone thinking you intended to have a tuple and had just forgotten a comma.  Take for instance:\ns = (\"this is my really, really, really, really, really, really\"\n    \" really long string that I'd like to shorten.\")\n\nversus:\ns = (\"this is my really, really, really, really, really, really\",\n    \" really long string that I'd like to shorten.\")\n\nWith Python's dynamic typing, the code may run either way, but produce incorrect results with the one you didn't intend.\n",
            "\nBackslash:\ns = \"this is my really, really, really, really, really, really\" +  \\\n    \"really long string that I'd like to shorten.\"\n\nor wrap in parens:\ns = (\"this is my really, really, really, really, really, really\" + \n    \"really long string that I'd like to shorten.\")\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "string",
            "pep8"
        ]
    },
    {
        "question_id": "2918362",
        "question": "\nI want to append a newline to my string every time I call file.write(). What's the easiest way to do this in Python?\n",
        "all_answers": [
            "\nYou can do this in two ways:\nf.write(\"text to write\\n\")\n\nor, depending on your Python version (2 or 3):\nprint >>f, \"text to write\"         # Python 2.x\nprint(\"text to write\", file=f)     # Python 3.x\n\n",
            "\nUse \"\\n\":\nfile.write(\"My String\\n\")\n\nSee the Python manual for reference.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "newline"
        ]
    },
    {
        "question_id": "24022763",
        "question": "\nI'm struggling to figure out what's wrong with this code snippet. This is currently working in Objective-C, but in Swift this just crashes on the first line of the method. It shows an error message in console log: Bad_Instruction.\nfunc tableView(tableView: UITableView!, cellForRowAtIndexPath indexPath: NSIndexPath!) -> UITableViewCell!  {\n        var cell : UITableViewCell = tableView.dequeueReusableCellWithIdentifier(\"Cell\") as UITableViewCell\n\n        if (cell == nil) {\n            cell = UITableViewCell(style: UITableViewCellStyle.Value1, reuseIdentifier: \"Cell\")\n        }\n\n        cell.textLabel.text = \"TEXT\"\n        cell.detailTextLabel.text = \"DETAIL TEXT\"\n\n        return cell\n    }\n\n",
        "all_answers": [
            "\nAlso see matt's answer which contains the second half of the solution\nLet's find a solution without creating custom subclasses or nibs\nThe real problem is in the fact that Swift distinguishes between objects that can be empty (nil) and objects that can't be empty. If you don't register a nib for your identifier, then dequeueReusableCellWithIdentifier can return nil.\nThat means we have to declare the variable as optional:\nvar cell : UITableViewCell?\n\nand we have to cast using as? not as\n//variable type is inferred\nvar cell = tableView.dequeueReusableCellWithIdentifier(\"CELL\") as? UITableViewCell\n\nif cell == nil {\n    cell = UITableViewCell(style: UITableViewCellStyle.Value1, reuseIdentifier: \"CELL\")\n}\n\n// we know that cell is not empty now so we use ! to force unwrapping but you could also define cell as\n// let cell = (tableView.dequeue... as? UITableViewCell) ?? UITableViewCell(style: ...)\n\ncell!.textLabel.text = \"Baking Soda\"\ncell!.detailTextLabel.text = \"1/2 cup\"\n\ncell!.textLabel.text = \"Hello World\"\n\nreturn cell\n\n",
            "\nTry this:\nfunc tableView(tableView: UITableView!, cellForRowAtIndexPath indexPath: NSIndexPath!) -> UITableViewCell! {\n    let cell = tableView.dequeueReusableCellWithIdentifier(\"Cell\", forIndexPath: indexPath) as UITableViewCell\n    cell.textLabel.text = \"\\(indexPath.row)\"\n\n    return cell\n}\n\nNote that you should register you UITableViewCell and ID when creating instantiating your UITableView:\ntableView.delegate = self\ntableView.dataSource = self\ntableView.registerClass(UITableViewCell.classForCoder(), forCellReuseIdentifier: \"Cell\")\n\n",
            "\nTry This:\nfunc tableView(tableView: UITableView, heightForRowAtIndexPath indexPath: NSIndexPath) -> CGFloat {\n    return UITableViewAutomaticDimension\n}\n\nEDIT\nfunc tableView(tableView: UITableView, estimatedHeightForRowAtIndexPath indexPath: NSIndexPath) -> CGFloat {\n    return UITableViewAutomaticDimension\n}\n\nSwift 4\nfunc tableView(_ tableView: UITableView, estimatedHeightForRowAt indexPath: IndexPath) -> CGFloat {\n    return UITableViewAutomaticDimension\n}\n\nSwift 4.2\nfunc tableView(_ tableView: UITableView, estimatedHeightForRowAt indexPath: IndexPath) -> CGFloat {\n    return UITableView.automaticDimension\n}\n\nDefine above Both Methods.\nIt solves the problem.\nPS: Top and bottom constraints is required for this to work.\nHere is example\n",
            "\nHere is what I wrote to get it working...\nFirst Register the table view cell with the table view\nself.tableView.registerClass(MyTableViewCell.self, forCellReuseIdentifier: \"Cell\")\n\nThen configure cellForRowAtIndexPath\nfunc tableView(tableView: UITableView!, cellForRowAtIndexPath indexPath: NSIndexPath!) -> UITableViewCell!  {\n    var cell = tableView.dequeueReusableCellWithIdentifier(\"Cell\", forIndexPath: indexPath) as MyTableViewCell\n\n    cell.textLabel.text = \"Cell Text\"\n    cell.detailTextLabel.text = \"Cell Detail Text in Value 1 Style\"\n\n    return cell\n}\n\nI then defined a custom cell subclass write at the bottom of the file (since its so much easier now)\nclass MyTableViewCell : UITableViewCell {\n\n    init(style: UITableViewCellStyle, reuseIdentifier: String!) {\n        super.init(style: UITableViewCellStyle.Value1, reuseIdentifier: reuseIdentifier)\n    }\n\n}\n\n",
            "\nFor cell template: \nfunc tableView(tableView: UITableView!, cellForRowAtIndexPath indexPath: NSIndexPath!) -> UITableViewCell! {\n        let myCell : youCell =  youCell(style: UITableViewCellStyle.Subtitle, reuseIdentifier: \"cell\")\n        return myCell\n    }\n\n"
        ],
        "answer": "A1",
        "tags": [
            "uitableview",
            "swift",
            "ios8"
        ]
    },
    {
        "question_id": "34647591",
        "question": "\nI'm trying to run the following from my bash script. (bash installed via msysgit)\ntaskkill /IM ssh-agent.exe\n\nThe output I get on the screen from taskkill is:\nERROR: Invalid argument/option - 'C:/Program Files/Git/IM'.\nType \"TASKKILL /?\" for usage.\n\nThe executible is running, but the /IM is being expanded regardless of what I try to do to escape it...\n\nI've tried using \\/IM but then it sends \\/IM without escaping the slash, I've tried a few different ways of running it through eval, cmd /c start, etc... but they all seem to have issues.  I've also tried set -o noglob, which also didn't work.  neither did $'\\057/'IM or similar attempts...\n",
        "all_answers": [
            "\nThis is the new icon being used with Git for Windows 2.x. The website needs an update for that I guess but there are not many volunteers typically. \nThe MINGW64 is the value from the MSYSTEM environment variable. This has been included in the bash prompt by setting PS1 in the /etc/bash.bashrc file. You can either override this in your own $HOME/.profile or edit the distributed one to remove that if you prefer.\n",
            "\nAfter hours of looking for various searches like \"disable bash file expansion\" and the like, I found it by searching specifically for \"bash\" \"windows\" taskkill the executable I was trying to run, I came across this answer, which finally worked for me.\ncmd \" /c taskkill /F /IM ssh-agent.exe\"\n\n",
            "\nSince my comment actually provided the answer, I'll post it.\nHow about escaping a forward slash to another forward slash like //. It works for me when I execute this command where I escaped the /r parameter:\nstart C:/folder/beep 2000 250 100 //r 3\nSource: http://oldwiki.mingw.org/index.php/switches%20with%20forward%20slashes\n\nMinimalist GNU for Windows\nPassing switches with forward slashes under MSYS\nIn MSYS a command line argument of \"/c\" is interpreted as the C:\n  drive, so to pass any argument beginning with a forward slash you need\n  to use two forward slashes. For example, to use this command in MSYS:\ncmd /c echo foo\nUse:\ncmd //c echo foo\nIf you need to have the windows-style of a path in a shell script, you\n  can do\nx=$(cd /unix/path && cmd //c cd)\nThe x var now contains the windows equivalent path to /unix/path\n\n",
            "\nEasiest way to remove 'MINGW64' is to comment two lines in file:\n\\Git\\etc\\profile.d\\git-prompt.sh\n...\n# PS1=\"$PS1\"'\\[\\033[35m\\]'       # change to purple\n# PS1=\"$PS1\"'$MSYSTEM '          # show MSYSTEM\n\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "bash",
            "msysgit"
        ]
    },
    {
        "question_id": "19406242",
        "question": "\n\n\n\nI have a class list of class\npublic class LinqTest\n{\npublic int id { get; set; }\npublic string value { get; set; }\n}\n\n\nList<LinqTest> myList = new List<LinqTest>();\nmyList.Add(new LinqTest() { id = 1, value = \"a\" });\nmyList.Add(new LinqTest() { id = 1, value = \"b\" });\nmyList.Add(new LinqTest() { id = 2, value = \"c\" });\n\nI need to select only the distinct id's from that list.\nie, my resultant list should only contain\n[{id=1,value=\"a\"},{ id = 2, value = \"c\" }]\n\nHow can I do this with linq?\nEdit\nInput,\nid      value\n1        a\n1        b\n2        c\n3        d\n3        e\n\nOut put should be,\nid      value\n1        a\n2        c\n3        d\n\nie, if there is a repetition of id, result should take the first occurrence only.\n",
        "all_answers": [
            "\nmyList.GroupBy(i => i.id).Select(group => group.First())\n\n",
            "\nI don't understand where the first \"result with sample data\" is coming from, but the problem in the console app is that you're using SelectMany to look at each item in each group.\nI think you just want:\nList<ResultLine> result = Lines\n    .GroupBy(l => l.ProductCode)\n    .Select(cl => new ResultLine\n            {\n                ProductName = cl.First().Name,\n                Quantity = cl.Count().ToString(),\n                Price = cl.Sum(c => c.Price).ToString(),\n            }).ToList();\n\nThe use of First() here to get the product name assumes that every product with the same product code has the same product name. As noted in comments, you could group by product name as well as product code, which will give the same results if the name is always the same for any given code, but apparently generates better SQL in EF.\nI'd also suggest that you should change the Quantity and Price properties to be int and decimal types respectively - why use a string property for data which is clearly not textual?\n",
            "\nmyList.GroupBy(test => test.id)\n      .Select(grp => grp.First());\n\nEdit: as getting this IEnumerable<> into a List<> seems to be a mystery to many people, you can simply write:\nvar result = myList.GroupBy(test => test.id)\n                   .Select(grp => grp.First())\n                   .ToList();\n\nBut one is often better off working with the IEnumerable rather than IList as the Linq above is lazily evaluated: it doesn't actually do all of the work until the enumerable is iterated. When you call ToList it actually walks the entire enumerable forcing all of the work to be done up front. (And may take a little while if your enumerable is infinitely long.)\nThe flipside to this advice is that each time you enumerate such an IEnumerable the work to evaluate it has to be done afresh. So you need to decide for each case whether it is better to work with the lazily evaluated IEnumerable or to realize it into a List, Set, Dictionary or whatnot.\n",
            "\nUsing morelinq you can use DistinctBy:\nmyList.DistinctBy(x => x.id);\n\nOtherwise, you can use a group:\nmyList.GroupBy(x => x.id)\n      .Select(g => g.First());\n\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "linq",
            "list",
            "class"
        ]
    },
    {
        "question_id": "1210026",
        "question": "\nI'm doing a small multi-threaded app that uses asynchronous TCP sockets, but I will get to the point: I'm using a custom event to read a value from a form and the delegate used by the event returns a string when finished.\nMy question here is: is that correct? is it OK to return values from the events? or is there a better way to do this? (like using a simple delegate to the form to read the values)\n",
        "all_answers": [
            "\nIt's often awkward to return values from events. In practice, I've found it much easier to include a writable property on a set of custom EventArgs that is passed to the event, and then checked after the event fires -- similar to Cancel property of the WinForms FormClosing event.\n",
            "\nThe closest example I can think of is the FormClosing event in WinForms. It lets the form cancel the event by setting the eventArgs.Cancel property to true. For you to do something similar, you would define your own event args class with the return value as a property on that class. Then pass an event args object whenever you raise the event. Whoever raised the event can inspect the event args object for the return value. Others who are receiving the event can also inspect or change the event args object.\nUpdate: I just ran across the AppDomain.AssemblyResolve event, and it appears to be an event that returns a value. It seems you just need to declare a delegate type that returns a value, and then define your event with that delegate type. I haven't tried creating my own event like this, though. One advantage to using a property on the event argument is that all subscribers to the event can see what previous subscribers have returned.\n",
            "\nHere is a good write up about .NET events and race conditions with threads.  It covers some common scenarios and has some good references in it.\nHope this helps.\n",
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "multithreading",
            "events",
            "delegates"
        ]
    },
    {
        "question_id": "22328882",
        "question": "\nAfter updating to Xcode 5.1, I can no longer build my project for the 64-bit simulator, receiving this error:\n No architectures to compile for (ONLY_ACTIVE_ARCH=YES, active arch=x86_64, VALID_ARCHS=i386).\n\nThese are my target build settings:\n\nI tried changing \"Build Active Architecture\" to No, as well as adding \"i386\" to the \"Valid Architectures\", unfortunately neither worked.\nThanks for any suggestions!\n",
        "all_answers": [
            "\nAdd:\nArchitectures: $(ARCHS_STANDARD_INCLUDING_64_BIT)\nValid architectures: arm64 armv7 armv7s\n",
            "\nI had the same error message after upgrading to XCode 5.1.  Are you using CocoaPods?  If so, this should fix the problem:\n\nDelete the \"Pods\" project from the workspace in the left pane of Xcode and close Xcode.\nRun \"pod install\" from the command line to recreate the \"Pods\" project.\nRe-open Xcode and make sure \"Build Active Architecture Only\" is set to \"No\" in the build settings of both the \"Pods\" project and your own project.\nClean and build.\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "xcode",
            "xcode5.1"
        ]
    },
    {
        "question_id": "6173400",
        "question": "\nI have a RelativeLayout which contains two buttons. Which are overlapped on each other.\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    android:orientation=\"vertical\"\n    android:layout_width=\"fill_parent\"\n    android:layout_height=\"fill_parent\"\n    android:background=\"#FFFFFF\">\n\n\n<Button android:text=\"Play\"  \n    android:id=\"@+id/play\"\n    android:layout_width=\"fill_parent\" \n    android:layout_height=\"wrap_content\" \n    android:layout_alignParentBottom = \"true\">\n</Button>\n\n<Button android:text=\"Stop \"\n    android:id=\"@+id/stop\" \n    android:layout_width=\"fill_parent\" \n    android:layout_height=\"wrap_content\"\n    android:layout_alignParentBottom = \"true\">\n</Button>\n\n\n</RelativeLayout>\n\nI want to programmatically show only one button at a time when its click event is called.\nI tried it with :\nplayButton.setVisibility(1);\n\nbut it does not worked. Following is an example what I am trying to do.\nplayButton = (Button) findViewById(R.id.play);\nplayButton.setVisibility(1);\nplayButton.setOnClickListener(new OnClickListener() {\n    @Override\n    public void onClick(View v) {\n        //when play is clicked show stop button and hide play button\n\n    }\n});\n\n",
        "all_answers": [
            "\nPlease try this: playButton = (Button) findViewById(R.id.play);\nplayButton.setVisibility(View.INVISIBLE); I think this will do it.\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nTry the below code -\nplayButton.setVisibility(View.INVISIBLE);\n\nor -\nplayButton.setVisibility(View.GONE);\n\nshow it again with -\nplayButton.setVisibility(View.VISIBLE);\n\n",
            "\nTry View.INVISIBLE.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nYou can use the following code:\nplayButton = (Button) findViewById(R.id.play);\nplayButton.setVisibility(View.VISIBLE);\nplayButton.setOnClickListener(new OnClickListener() {\n    @Override\n    public void onClick(View v) {\n        //when play is clicked show stop button and hide play button\n        playButton.setVisibility(View.GONE);\n        stopButton.setVisibility(View.VISIBLE);\n    }\n});\n\n",
            "\nPlease used below\nView.GONE and View.VISIBLE\n\n",
            "\nI would suggest you only use one button an change the text and the behavior on the button on demand. That's easier and cleaner than handling two buttons which are overlapping. \n@Override\npublic void onClick(View v) {\n    String curText = ((TextView)v).getText();                 \n\n    if(curText.equals(\"Play\")){\n        ((TextView)v).setText(\"Stop\");\n    }\n\n    if(curText.equals(\"Stop\")){\n        ((TextView)v).setText(\"Play\");\n    }\n }\n\n"
        ],
        "answer": "A6",
        "tags": [
            "android"
        ]
    },
    {
        "question_id": "51300121",
        "question": "\nI have an enum of associated values which I would like to make equatable for testing purposes, but do not know how this pattern would work with an enum case with more than one argument.\nFor example, summarised below I know the syntax for making heading equatable. How would this work for options, which contains multiple values of different types?\nenum ViewModel {\n    case heading(String)\n    case options(id: String, title: String, enabled: Bool)\n}\n\nfunc ==(lhs: ViewModel, rhs: ViewModel) -> Bool {\n    switch (lhs, rhs) {\n    case (let .heading(lhsString), let .heading(rhsString)):\n        return lhsString == rhsString\n    case options...\n    default:\n        return false\n    }\n}\n\nI know Swift 4.1 can synthesize conformance for Equatable for us, but at present I am not able to update to this version.\n",
        "all_answers": [
            "\nSE-0185 Synthesizing Equatable and Hashable conformance has been implemented in Swift 4.1, so that it suffices do declare conformance to the protocol (if all members are Equatable):\nenum ViewModel: Equatable {\n    case heading(String)\n    case options(id: String, title: String, enabled: Bool)\n}\n\nFor earlier Swift versions, a convenient way is to use that tuples can be compared with ==.\nYou many also want to enclose the compatibility code in a Swift version check, so that the automatic synthesis is used once the project is updated to Swift 4.1:\nenum ViewModel: Equatable {\n    case heading(String)\n    case options(id: String, title: String, enabled: Bool)\n    \n    #if swift(>=4.1)\n    #else\n    static func ==(lhs: ViewModel, rhs: ViewModel) -> Bool {\n        switch (lhs, rhs) {\n        case (let .heading(lhsString), let .heading(rhsString)):\n            return lhsString == rhsString\n        case (let .options(lhsId, lhsTitle, lhsEnabled), let .options(rhsId, rhsTitle, rhsEnabled)):\n            return (lhsId, lhsTitle, lhsEnabled) == (rhsId, rhsTitle, rhsEnabled)\n        default:\n            return false\n        }\n    }\n    #endif\n}\n\n",
            "\nYou can add something like below, check this link for more information.\nReturn statement for options depend on your needs.\n#if swift(>=4.1)\n#else\nfunc ==(lhs: ViewModel, rhs: ViewModel) -> Bool {\n    switch (lhs, rhs) {\n    case (let .heading(lhsString), let .heading(rhsString)):\n        return lhsString == rhsString\n\n    case (let .options(id1, title1, enabled1),let .options(id2, title2, enabled2)):\n        return id1 == id2 && title1 == title2 && enabled1 == enabled2\n    default:\n        return false\n    }\n}\n#endif\n\n",
            "\nInfo on Enumerations as dictionary keys:\nFrom the Swift book:\n\nEnumeration member values without associated values (as described in\nEnumerations) are also hashable by default.\n\nHowever, your Enumeration does have a member value with an associated value, so Hashable conformance has to be added manually by you.\nSolution\nThe problem with your implementation, is that operator declarations in Swift must be at a global scope.\nJust move:\nfunc == (lhs: StationSelector, rhs: StationSelector) -> Bool {\n    return lhs.toInt() == rhs.toInt()\n}\n\noutside the enum definition and it will work.\nCheck the docs for more on that.\n"
        ],
        "answer": "A1",
        "tags": [
            "swift",
            "enums",
            "equatable",
            "associated-value"
        ]
    },
    {
        "question_id": "28471164",
        "question": "\nHow do you remove the back button text.\nCurrent back button:\n\n< Back\n\nDesired back button:\n\n< AnythingElse\n\nNone of these have worked:\nself.navigationItem.backBarButtonItem?.title = \"Back\"\nself.backItem?.title = \"\"\nself.navigationController?.navigationBar.backItem?.title = \"\"\nself.navigationItem.backBarButtonItem?.title = \"\"\nself.navigationController?.navigationItem.backBarButtonItem?.title=\"Back\"\nself.navigationController?.navigationBar.backItem?.title = \"\"\nself.navigationController?.navigationItem.backBarButtonItem?.title\n\n",
        "all_answers": [
            "\nThis should work:\noverride func viewDidLoad() {\n    super.viewDidLoad()\n\n    var button = UIBarButtonItem(title: \"YourTitle\", style: UIBarButtonItemStyle.Bordered, target: self, action: \"goBack\")\n    self.navigationItem.backBarButtonItem = button\n\n}\n\nfunc goBack()\n{\n    self.navigationController?.popViewControllerAnimated(true)\n}\n\nAlthough it is not recommended since this actually replaces the backButton and it also removed the back arrow and the swipe gesture.\n",
            "\nDuring startup in (-viewDidLoad or in storyboard) do:\nself.tableView.allowsMultipleSelectionDuringEditing = false\n\nOverride to support conditional editing of the table view. This only needs to be implemented if you are going to be returning NO for some items. By default, all items are editable.\n- (BOOL)tableView:(UITableView *)tableView canEditRowAtIndexPath:(NSIndexPath *)indexPath {\n    // Return YES if you want the specified item to be editable.\n    return YES;\n}\n\n// Override to support editing the table view.\n- (void)tableView:(UITableView *)tableView commitEditingStyle:(UITableViewCellEditingStyle)editingStyle forRowAtIndexPath:(NSIndexPath *)indexPath {\n    if (editingStyle == UITableViewCellEditingStyleDelete) {\n        //add code here for when you hit delete\n    }    \n}\n\n",
            "\nThe back button belongs to the previous view controller, not the one currently presented on screen.\nTo modify the back button you should update it before pushing, on the view controller that initiated the segue:\noverride func prepareForSegue(segue: UIStoryboardSegue, sender: AnyObject?) {\n    let backItem = UIBarButtonItem()\n    backItem.title = \"Something Else\"\n    navigationItem.backBarButtonItem = backItem // This will show in the next view controller being pushed\n}\n\nSwift 3, 4 & 5:\noverride func prepare(for segue: UIStoryboardSegue, sender: Any?) {\n    let backItem = UIBarButtonItem()\n    backItem.title = \"Something Else\"\n    navigationItem.backBarButtonItem = backItem // This will show in the next view controller being pushed\n}\n\nOR\n// in your viewDidLoad or viewWillAppear\nnavigationItem.backBarButtonItem = UIBarButtonItem(\n    title: \"Something Else\", style: .plain, target: nil, action: nil)\n\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "uikit",
            "uinavigationcontroller",
            "uinavigationitem"
        ]
    },
    {
        "question_id": "24327544",
        "question": "\n\n\n\nWhen PHP script run from command line (windows) , how can clear the console screen from script .  \nfor example :  \nwhile(true){\n    // sleep for 10 seconds , then clear the console\n    sleep(10);\n\n    // below command execute to clear the console windows\n    **COMMAND**\n}\n\n",
        "all_answers": [
            "\nYou can do this by using:\nncurses_clear();\n\nSource: http://www.php.net/manual/en/function.ncurses-clear.php\nEdit: As trejder says this solution is only for supported platforms, it seems windows is not one of them.\n",
            "\nFound a solution, that works in both cmd and GitBash. However, this is the ugliest implementation of clearing console-screen I can think of. Pity, that there isn't any working alternative.\nThe \"magic\" is to... poke console with fifty new-lines, like that:\npublic function clearStdin()\n{\n    for ($i = 0; $i < 50; $i++) echo \"\\r\\n\";\n}\n\nThis is a modified (fixed?) version of this non-working (for me) post from 2006.\n",
            "\nFor Windows users : \nsystem('cls');\n\nFor Linux users : \nsystem('clear');\n\n",
            "\nIf you did not have any luck with the solutions above, consider the following\necho chr(27).chr(91).'H'.chr(27).chr(91).'J';   //^[H^[J  \n\nHope it will help.\nSource : http://pank.org/blog/2011/02/php-clear-terminal-screen.html\n"
        ],
        "answer": "A4",
        "tags": [
            "php",
            "windows"
        ]
    },
    {
        "question_id": "7522781",
        "question": "\nAfter I added Sprockets, Rails is loading very slow in development mode, what should I do to speed it up?\n",
        "all_answers": [
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nTake a look at https://github.com/wavii/rails-dev-tweaks.  \nRails is running all of the to_prepare hooks on every Sprockets asset request in development mode.  This includes things like auto-(re)loading your code, and various gems sneak work in there too.\nrails-dev-tweaks disables to_prepare & reloading on any asset request (and a few others - read the first part of its README).  Speeds up your dev environment by a huge amount for any decently sized project.  It's also configurable to do this for any additional requests you like\n",
            "\nHave you looked at how quickly it runs in production? The development environment behaves differently than testing and production, and takes more performance hits because of it. Without more information, we can't provide you with a better answer.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "ruby-on-rails-3.1",
            "sprockets"
        ]
    },
    {
        "question_id": "6154539",
        "question": "\nI just want my main thread to wait for any and all my (p)threads to complete before exiting. \nThe threads come and go a lot for different reasons, and I really don't want to keep track of all of them - I just want to know when they're all gone.\nwait() does this for child processes, returning ECHILD when there are no children left, however wait does not (appear to work with) (p)threads.\nI really don't want to go through the trouble of keeping a list of every single outstanding thread (as they come and go), then having to call pthread_join on each.\nAs there a quick-and-dirty way to do this?\n",
        "all_answers": [
            "\nGCC Atomic Built-ins\n",
            "\nThe proper way is to keep track of all of your pthread_id's, but you asked for a quick and dirty way so here it is.  Basically:\n\njust keep a total count of running threads, \nincrement it in the main loop before calling pthread_create, \ndecrement the thread count as each thread finishes.  \nThen sleep at the end of the main process until the count returns to 0.\n\n.\nvolatile int running_threads = 0;\npthread_mutex_t running_mutex = PTHREAD_MUTEX_INITIALIZER;\n\nvoid * threadStart()\n{\n   // do the thread work\n   pthread_mutex_lock(&running_mutex);\n   running_threads--;\n   pthread_mutex_unlock(&running_mutex);\n}\n\nint main()\n{\n  for (i = 0; i < num_threads;i++)\n  {\n     pthread_mutex_lock(&running_mutex);\n     running_threads++;\n     pthread_mutex_unlock(&running_mutex);\n     // launch thread\n\n  }\n\n  while (running_threads > 0)\n  {\n     sleep(1);\n  }\n}\n\n",
            "\nIf you don't want to keep track of your threads then you can detach the threads so you don't have to care about them, but in order to tell when they are finished you will have to go a bit further.\nOne trick would be to keep a list (linked list, array, whatever) of the threads' statuses.   When a thread starts it sets its status in the array to something like THREAD_STATUS_RUNNING and just before it ends it updates its status to something like THREAD_STATUS_STOPPED.   Then when you want to check if all threads have stopped you can just iterate over this array and check all the statuses.\nDon't forget though that if you do something like this, you will need to control access to the array so that only one thread can access (read and write) it at a time, so you'll need to use a mutex on it.\n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "linux",
            "multithreading",
            "pthreads",
            "posix-api"
        ]
    },
    {
        "question_id": "32106155",
        "question": "\nJust a quick question. \nCan you force Vue.js to reload/recalculate everything? If so, how?\n",
        "all_answers": [
            "\nAs per the other answers, add the following to someFile.js\nmodule.exports.someFunction = function () {\n  console.log('hi');\n};\n\nYou can then add the following to package.json\n\"scripts\": {\n   \"myScript\": \"node -e 'require(\\\"./someFile\\\").someFunction()'\"\n}\n\nFrom the terminal, you can then call\nnpm run myScript\n\nI find this a much easier way to remember the commands and use them\n",
            "\nUpdate 2020 - CLI\nAs @mix3d pointed out you can just run a command where file.js is your file and someFunction is your function optionally followed by parameters separated with spaces\nnpx run-func file.js someFunction \"just some parameter\"\n\nThat's it.\nfile.js called in the example above\nconst someFunction = (param) => console.log('Welcome, your param is', param)\n\n// exporting is crucial\nmodule.exports = { someFunction }\n\nMore detailed description\nRun directly from CLI (global)\nInstall\nnpm i -g run-func\n\nUsage i.e. run function \"init\", it must be exported, see the bottom\nrun-func db.js init\n\nor\nRun from package.json script (local)\nInstall\nnpm i -S run-func\n\nSetup\n\"scripts\": {\n   \"init\": \"run-func db.js init\"\n}\n\nUsage\nnpm run init\n\nParams\nAny following arguments will be passed as function parameters init(param1, param2)\nrun-func db.js init param1 param2\n\nImportant\nthe function (in this example init) must be exported in the file containing it\nmodule.exports = { init };\n\nor ES6 export\nexport { init };\n\n",
            "\nTry this magic spell:\nvm.$forceUpdate();\n//or in file components\nthis.$forceUpdate();\n\nNo need to create any hanging vars :)\nUpdate: I found this solution when I only started working with VueJS. However further exploration proved this approach as a crutch. As far as I recall, in a while I got rid of it simply putting all the properties that failed to refresh automatically (mostly nested ones) into computed properties.\nMore info here: https://v2.vuejs.org/v2/guide/computed.html\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nUse vm.$set('varName', value).\nLook for details into Change_Detection_Caveats\n",
            "\nI found a way. It's a bit hacky but works.\nvm.$set(\"x\",0);\nvm.$delete(\"x\");\n\nWhere vm is your view-model object, and x is a non-existent variable. \nVue.js will complain about this in the console log but it does trigger a refresh for all data. Tested with version 1.0.26.\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "node.js",
            "vue.js",
            "reload",
            "rerender"
        ]
    },
    {
        "question_id": "10054653",
        "question": "\n\n\n\nI want to learn how to be able to use the Win32 API, since recently I've got a lot of tasks I need to do which requires functions from user32.dll, so I'm trying to learn and I Googled but the thing is: every tutorial there is about it, just tells you how to do a certain thing. like show a MessageBox through the Win32 API, but you can't actually learn Win32 framework.\nSo how do you actually learn it? How do you know all the functions? with managed libraries it's quite easy, especially with Visual Studio which provides IntelliSense, the Object Browser etc. but the Win32 API is so messy (at least from a C# developer standpoint).\nThe way I've been using it until now is just searching on Google for a task and seeing that it can be done with the Win32 API (I had no idea) and just copy the function and use it (and it's horrible for me, I feel I'm missing a lot of \"power\").\nSo, how can I learn it?\nTo be clear: I'm not interested in a book. as bad as it sounds I need this knowledge for a project and I just don't have the time to invest in a book. I did get my answer although.\nThank you all.\n",
        "all_answers": [
            "\nFrom MSDN you can find the WinAPI list:\nThe following is a list of the reference content for the Windows application programming interface (API).\nhttp://msdn.microsoft.com/en-us/library/ff818516(v=vs.85).aspx\nYou can learn some stuff via Visual Basic Win API functions. Examples are very easy to follow and understand. Then you can translate the code to C#.\nThere Are 598 Visual Basic Windows API Functions in 55 Category\nhttp://www.ex-designz.net/api.asp\n",
            "\nFirst, Win32 is a set of subsystems. You possibly can't learn them all easily. You just have to prioritize.\nBut then, to be able to say what you'd like to learn, you probably need a big picture. I believe the best way to approach Win32 is through \"Programming Windows\" by Charles Petzold. It's very clear to read and easy to understand. There are a lot of examples you can pick up and experiment on your own.\nAfter you learn the basic stuff, I recommend \"Microsoft Windows Internals\" by Mark Russinovich. It's rather advanced but lets you understand what's inside Windows core.\n",
            "\nWin32 API - help documents and samples should be in Windows SDK download.\nhttp://www.microsoft.com/download/en/details.aspx?id=8279\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "windows",
            "winapi"
        ]
    },
    {
        "question_id": "1602904",
        "question": "\nI'm looking to be able to run a single query on a remote server in a scripted task.\nFor example, intuitively, I would imagine it would go something like:\nmysql -uroot -p -hslavedb.mydomain.com mydb_production \"select * from users;\"\n\n",
        "all_answers": [
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\necho \"select * from users;\" | mysql -uroot -p -hslavedb.mydomain.com mydb_production\n\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nmysql -u <user> -p -e 'select * from schema.table'\n\n(Note the use of single quotes rather than double quotes, to avoid the shell expanding the * into filenames)\n"
        ],
        "answer": "A9",
        "tags": [
            "sql",
            "mysql",
            "unix",
            "command-line"
        ]
    },
    {
        "question_id": "3167494",
        "question": "\n\nHow often does Python flush to a file?\nHow often does Python flush to stdout?\n\nI'm unsure about (1).\nAs for (2), I believe Python flushes to stdout after every new line.  But, if you overload stdout to be to a file, does it flush as often?\n",
        "all_answers": [
            "\nAfter Python 3.4, you can also use pathlib's class Path to move file.\nfrom pathlib import Path\n\nPath(\"path/to/current/file.foo\").rename(\"path/to/new/destination/for/file.foo\")\n\nhttps://docs.python.org/3.4/library/pathlib.html#pathlib.Path.rename\n",
            "\nAlthough os.rename() and shutil.move() will both rename files, the command that is closest to the Unix mv command is shutil.move().  The difference is that os.rename() doesn't work if the source and destination are on different disks, while shutil.move() is files disk agnostic.\n",
            "\nI don't know if this applies to python as well, but I think it depends on the operating system that you are running.\nOn Linux for example, output to terminal flushes the buffer on a newline, whereas for output to files it only flushes when the buffer is full (by default).  This is because it is more efficient to flush the buffer fewer times, and the user is less likely to notice if the output is not flushed on a newline in a file.  \nYou might be able to auto-flush the output if that is what you need.\nEDIT:  I think you would auto-flush in python this way (based \nfrom here)\n#0 means there is no buffer, so all output\n#will be auto-flushed\nfsock = open('out.log', 'w', 0)\nsys.stdout = fsock\n#do whatever\nfsock.close()\n\n",
            "\nFor file operations, Python uses the operating system's default buffering unless you configure it do otherwise.  You can specify a buffer size, unbuffered, or line buffered.\nFor example, the open function takes a buffer size argument.\nhttp://docs.python.org/library/functions.html#open\n\"The optional buffering argument specifies the file’s desired buffer size:\" \n\n0 means unbuffered, \n1 means line buffered, \nany other positive value means use a buffer of (approximately) that size. \nA negative buffering means to use the system default, which is usually line buffered for tty devices and fully buffered for other files. \nIf omitted, the system default is used. \n\ncode:\nbufsize = 0\nf = open('file.txt', 'w', buffering=bufsize)\n\n",
            "\nos.rename(), os.replace(), or shutil.move()\nAll employ the same syntax:\nimport os\nimport shutil\n\nos.rename(\"path/to/current/file.foo\", \"path/to/new/destination/for/file.foo\")\nos.replace(\"path/to/current/file.foo\", \"path/to/new/destination/for/file.foo\")\nshutil.move(\"path/to/current/file.foo\", \"path/to/new/destination/for/file.foo\")\n\n\nThe filename (\"file.foo\") must be included in both the source and destination arguments. If it differs between the two, the file will be renamed as well as moved.\nThe directory within which the new file is being created must already exist.\nOn Windows, a file with that name must not exist or an exception will be raised, but os.replace() will silently replace a file even in that occurrence.\nshutil.move simply calls os.rename in most cases. However, if the destination is on a different disk than the source, it will instead copy and then delete the source file.\n\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "file",
            "flush"
        ]
    },
    {
        "question_id": "9332718",
        "question": "\n\n\n\nI need to see all of the POST results that are submitted to the server for testing.\nWhat would be an example of how I can create a new file to submit to that will echo out all of the fields which were submitted with that form?\nIt's dynamic, so some fields may have a name/ID of field1, field2, field3, etc.\n",
        "all_answers": [
            "\nYou need to set a few extra flags so that curl sends the data as JSON.\ncommand\n$ curl -H \"Content-Type: application/json\" \\\n       -X POST \\\n       -d '{\"JSON\": \"HERE\"}' \\\n       http://localhost:3000/api/url\n\nflags\n\n-H: custom header, next argument is expected to be header\n-X: custom HTTP verb, next argument is expected to be verb\n-d: sends the next argument as data in an HTTP POST request\n\nresources\n\ncURL manpage\ncURL examples\n\n",
            "\nJordans analysis of why the $_POST-array isn't populated is correct. However, you can use\n$data = file_get_contents(\"php://input\");\n\nto just retrieve the http body and handle it yourself. See PHP input/output streams.\nFrom a protocol perspective this is actually more correct, since you're not really processing http multipart form data anyway. Also, use application/json as content-type when posting your request.\n",
            "\nYou could try var_dump:\nvar_dump($_POST)\n\n",
            "\nYou could use something as simple as this\n<?php\n   print_r($_POST);\n?>\n\nThis would make it a bit more viewable:\n<?php\n   echo str_replace('  ', '&nbsp; ', nl2br(print_r($_POST, true)));\n?>\n\n",
            "\nI believe you are getting an empty array because PHP is expecting the posted data to be in a Querystring format (key=value&key1=value1).\nTry changing your curl request to:\ncurl -i -X POST -d 'json={\"screencast\":{\"subject\":\"tools\"}}'  \\\n      http://localhost:3570/index.php/trainingServer/screencast.json\n\nand see if that helps any.\n",
            "\nNormally the parameter -d is interpreted as form-encoded.  You need the -H parameter: \ncurl -v -H \"Content-Type: application/json\" -X POST -d '{\"screencast\":{\"subject\":\"tools\"}}' \\\nhttp://localhost:3570/index.php/trainingServer/screencast.json\n\n",
            "\nSimply:\n<?php\n    print_r($_POST);\n\n    //Or:\n    foreach ($_POST as $key => $value)\n        echo $key.'='.$value.'<br />';\n?>\n\n",
            "\nYou may mean something like this:\n<?php\n    $output = var_export($_POST, true);\n    error_log($output, 0, \"/path/to/file.log\");\n?>\n\n",
            "\nAll the values are stored in the $_POST collection\n<?php print_r($_POST); ?>\n\nor if you want something fancier that is easier to read use a foreach loop to loop through the $_POST collection and print the values.\n<table>\n<?php \n\n\n    foreach ($_POST as $key => $value) {\n        echo \"<tr>\";\n        echo \"<td>\";\n        echo $key;\n        echo \"</td>\";\n        echo \"<td>\";\n        echo $value;\n        echo \"</td>\";\n        echo \"</tr>\";\n    }\n\n\n?>\n</table>\n\n",
            "\nYou should escape the quotes like this:\ncurl -i -X POST -d '{\\\"screencast\\\":{\\\"subject\\\":\\\"tools\\\"}}'  \\\n  http://localhost:3570/index.php/trainingServer/screencast.json\n\n"
        ],
        "answer": "A9",
        "tags": [
            "php",
            "post",
            "echo"
        ]
    },
    {
        "question_id": "18673860",
        "question": "\nI have got an array which I am looping through. Every time a condition is true, I want to append a copy of the HTML code below to a container element with some values.\nWhere can I put this HTML to re-use in a smart way?\n<a href=\"#\" class=\"list-group-item\">\n    <div class=\"image\">\n         <img src=\"\" />\n    </div>\n    <p class=\"list-group-item-text\"></p>\n</a>\n\nJQuery \n$('.search').keyup(function() {\n    $('.list-items').html(null);\n\n    $.each(items, function(index) {\n        // APPENDING CODE HERE\n    });\n});\n\n",
        "all_answers": [
            "\nIn order to solve this problem, I recognize two solutions:\n\nThe first one goes with AJAX, with which you'll have to load the template from another file and just add everytime you want with .clone().\n$.get('url/to/template', function(data) {\n    temp = data\n    $('.search').keyup(function() {\n        $('.list-items').html(null);\n\n        $.each(items, function(index) {\n             $(this).append(temp.clone())\n        });\n\n    });\n});\n\nTake into account that the event should be added once the ajax has completed to be sure the data is available!\nThe second one would be to directly add it anywhere in the original html, select it and hide it in jQuery:\ntemp = $('.list_group_item').hide()\n\nYou can after add a new instance of the template with \n$('.search').keyup(function() {\n    $('.list-items').html(null);\n\n    $.each(items, function(index) {\n        $(this).append(temp.clone())\n    });\n});\n\nSame as the previous one, but if you don't want the template to remain there, but just in the javascript, I think you can use (have not tested it!) .detach() instead of hide.\ntemp = $('.list_group_item').detach()\n\n.detach() removes elements from the DOM while keeping the data and events alive (.remove() does not!).\n\n",
            "\nYou could decide to make use of a templating engine in your project, such as:\n\nmustache\nunderscore.js\nhandlebars\n\nIf you don't want to include another library, John Resig offers a jQuery solution, similar to the one below.\n\nBrowsers and screen readers ignore unrecognized script types:\n<script id=\"hidden-template\" type=\"text/x-custom-template\">\n    <tr>\n        <td>Foo</td>\n        <td>Bar</td>\n    <tr>\n</script>\n\nUsing jQuery, adding rows based on the template would resemble:\nvar template = $('#hidden-template').html();\n\n$('button.addRow').click(function() {\n    $('#targetTable').append(template);\n});\n\n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n",
            "\nAdd somewhere in body\n<div class=\"hide\">\n<a href=\"#\" class=\"list-group-item\">\n    <table>\n        <tr>\n            <td><img src=\"\"></td>\n            <td><p class=\"list-group-item-text\"></p></td>\n        </tr>\n    </table>\n</a>\n</div>\n\nthen create css\n.hide { display: none; }\n\nand add to your js\n$('#output').append( $('.hide').html() );\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "jquery",
            "json"
        ]
    },
    {
        "question_id": "25579962",
        "question": "\nIm making a Tcp client and therefore using the CFStreamCreatePairWithSocketToHost which is expecting an UInt32 for the second parameter.\nHere is a sample of what I'm trying to do.:\nfunc initNetwork(IP: String, Port: Int) {\n    // relevant stuff\n\n    //Convert Port:Int to UInt32 to make this shit work!\n\n    CFStreamCreatePairWithSocketToHost(kCFAllocatorDefault, IP as NSString , Port , &readStream, &writeStream)\n\n    // Irelevant stuff\n}\n\nI have been looking around for a solution for some time now, and i can't seem to find one!\n",
        "all_answers": [
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nIt's very simple:\nlet int: Int = 40\nlet uint = UInt32(i)\n\nin your case, just pass \nUInt32(Port)\n\nFor a port is not a problem, but in other cases be sure to take care of overflow\nSide note: in swift it's good practice to name variables using lower camel case, so with the first letter in lowercase\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nYou can do it easily:\nvar x = UInt32(yourInt)\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n"
        ],
        "answer": "A4",
        "tags": [
            "swift",
            "type-conversion"
        ]
    },
    {
        "question_id": "24245916",
        "question": "\nIm trying to read a text file using a Swift playground with the following\nlet dirs : String[]? =    NSSearchPathForDirectoriesInDomains(NSSearchPathDirectory.DocumentDirectory, NSSearchPathDomainMask.UserDomainMask, true) as? String[]\n\nif (dirs != nil) {\n    let directories:String[] = dirs!;\n    let dir = directories[0]; //documents directory\n    let path = dir.stringByAppendingPathComponent(file);\n\n    //read\n    let content = String.stringWithContentsOfFile(path, encoding: NSUTF8StringEncoding, error: nil)\n}\n\nHowever this fails with no error. It seems the first line stops the playground from outputting anything below\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nThis works for me. The only thing I changed was to be explicit about the file name (which is implied in your example) - perhaps you have a typo in the off-screen definition of the \"file\" variable?\nlet dirs = NSSearchPathForDirectoriesInDomains(NSSearchPathDirectory.DocumentDirectory, NSSearchPathDomainMask.UserDomainMask, true) as? [String]\n\nlet file = \"trial.txt\" // My change to your code - yours is presumably set off-screen\nif let directories = dirs {\n  let dir = directories[0]; //documents directory\n  let path = dir.stringByAppendingPathComponent(file);\n\n  //read\n  let content = NSString(contentsOfFile: path, usedEncoding: nil, error: nil)\n  // works...\n}\n\nUpdate Swift 4.2\nAs @raistlin points out, this would now be\nlet dirs = NSSearchPathForDirectoriesInDomains(\n              FileManager.SearchPathDirectory.documentDirectory,\n              FileManager.SearchPathDomainMask.userDomainMask,\n              true)\n\nor, more tersely:\nlet dirs = NSSearchPathForDirectoriesInDomains(.documentDirectory,\n                                .userDomainMask, true)\n\n",
            "\n\nSelect the .playground file.\nOpen Utility inspector, In the playground press opt-cmd-1 to open the File Inspector.      You should see the playground on the right. If you don't have it selected, press cmd-1 to open the Project Navigator and click on the playground file.\nUnder 'Resource Path' in Playground Settings choose 'Relative To Playground' and platform as OSX.\n\n"
        ],
        "answer": "A2",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "26328034",
        "question": "\nI have a project that was started in Objective-C, and I am trying to import some Swift code into the same class files that I have previously written Objective-C in.\nI have consulted the Apple docs on using Swift and Objective-C in the same project, as well as SO question like this, but still no avail: I continue to get the file not found error after putting in #import \"NewTestApp-Swift.h\" (NewTestApp is the name of the Product and module).\nHere is what I have done so far:\n\nIn Define Modules, selected YES for the app.\nEnsured that the Product Module name did not have any space in it (see screenshot below question)\n\nI have tried using #import \"NewTestApp-Swift.h\" inside ViewController.m, ViewController.h and AppDelegate.m but none of them has worked. \nWhat else am I doing incorrectly? Thanks for your help.\n\nScreenshot of settings:\n\n\nErrors that I am presently encountering:\n\n",
        "all_answers": [
            "\nIf the Swift code is inside a Module (like in your case):\n#import <ProductName/ProductModuleName-Swift.h>\n\nIf the Swift code is inside the project (mixed Swift and ObjC):\n#import <ProductModuleName-Swift.h>\n\nIn your case, you have to add this line in the *.m file:\n#import <NewTestApp/NewTestApp-Swift.h>\n\nIMPORTANT: look at the \"<\" in the import statement\nhttps://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nI was running into the same issue and couldn't get my project to import Swift into Objective-C classes.  Using Xcode 6, (should work for Xcode 6+) and was able to do it in this way:\n\nAny class that you need to access in the .h file needs to be a forward declaration like this:\n\n@class MySwiftClass;\n\n\nIn the .m file ONLY, if the code is in the same project (module) then you need to import it with:\n\n#import \"ProductModuleName-Swift.h\"\n\nLink to the Apple documentation about it.\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "objective-c",
            "xcode",
            "swift",
            "xcode6"
        ]
    },
    {
        "question_id": "1531800",
        "question": "\nThe subject says it all. A normal antivirus has to intercept all file accesses, scan the files and then optionally deny access to the file (possibly even displaying a prompt to the user). How can this be done?\nI'm aware of a method called API hooking, but that's a really dirty undocumented hack - and as such isn't really reliable. What's the \"official\" way of doing this?\nAlternatively, I would be interested in intercepting the loading of executable modules (.DLL, .EXE, etc.), not just arbitrary file reads.\n",
        "all_answers": [
            "\nThrough File System Filter Drivers. However, implementing such drivers is quite complicated and \"fragile\".\n",
            "\nIn the recent versions of windows (at least XP onwards) there is the concept 'filters' which can be viewed using MS Filter Manager, (fltmc.exe from a command prompt)\nThis provides a low level I/O hook that AV programs can access and automatically register to be passed all I/O requests to the file system. It is a kit you can get the drivers for an develop your own filters for.\nhttp://www.microsoft.com/whdc/driver/filterdrv/default.mspx is a starting place to get in depth info.\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "antivirus"
        ]
    },
    {
        "question_id": "2463822",
        "question": "\nMSDN says that public static members of System.Windows.Application are thread safe. But when I try to run my app with multiple threads I get the following exception:\nArgumentException: An entry with the same key already exists.\n\n   at System.ThrowHelper.ThrowArgumentException(ExceptionResource resource)\n   at System.Collections.Generic.SortedList`2.Add(TKey key, TValue value)\n   at System.IO.Packaging.Package.AddIfNoPrefixCollisionDetected(ValidatedPartUri partUri,\n        PackagePart part)\n   at System.IO.Packaging.Package.GetPartHelper(Uri partUri)\n   at System.IO.Packaging.Package.GetPart(Uri partUri)\n   at System.Windows.Application.GetResourceOrContentPart(Uri uri)\n   at System.Windows.Application.LoadComponent(Uri resourceLocator, Boolean \nbSkipJournaledProperties)\n       at System.Windows.Application.LoadComponent(Uri resourceLocator)\n\nThe exception occurs on the following call:\ngenericResources = (ResourceDictionary)Application.LoadComponent(new Uri(\"/Themes/Generic.xaml\", UriKind.Relative));\n\nThe application works fine on a single thread and even on two or three. When I get up past 5 then I get the error every time. Am I doing something wrong? What can I do to fix this?\n",
        "all_answers": [
            "\nIt looks like an item with the same key has already been added in the map. It's not a threading issue, it's an issue with the program you have. One thread has added a key/value pair to the map and a second thread is attempting to add a value with an identical key, how did you end up having identical keys on two separate threads? How are you generating the keys?\n\nThe elements of a SortedList  object\nare sorted by the keys either\naccording to a specific IComparer\nimplementation specified when the\nSortedList  is created or according to\nthe IComparable  implementation\nprovided by the keys themselves. In\neither case, a SortedList does not\nallow duplicate keys.\n\n(from the msdn documentation)\nUpdate:\nTry synchronizing when you're calling LoadComponent and see if the issue still persists.\nI simply don't know what they mean when they say the following:\n\nThe public static (Shared in Visual\nBasic) members of this type are thread\nsafe. In addition, the FindResource\nand TryFindResource  methods and the\nProperties  and Resources  properties\nare thread safe.\n\nIt sure does say thread safe, but if it's duplicating identical keys, then they must be referring to some other type of thread safety.\n",
            "\nYou are not doing something wrong.  MSDN is wrong.  Application.LoadComponent is not actually thread safe.  This is a bug in WPF, in my opinion.\nThe problem is that whenever Application.LoadComponent loads a \"Part\" from a \"Package\" it:\n\nChecks its internal cache for the package to see if the part is already loaded & returns it if found\nLoads the part from the file\nAdds it to the internal cache\nReturns it\n\nYou have two threads calling Application.LoadComponent to load the same part at the same time.  The MSDN documentation says this is ok, but what is happening is:\n\nThread #1 checks the cache and starts loading from the file\nThread #2 checks the cache and starts loading from the file\nThread #1 finishes loading from the file and adds to the cache\nThread #2 finishes loading from the file and tries to add to the cache, resulting in a duplicate key exception\n\nThe workaround for the bug is to wrap all calls to Application.LoadComponent inside a lock().\nYour lock object can be created thusly in your App.cs or elsewhere (your choice):\n public static object MyLoadComponentLock = new Object();\n\nThen your LoadComponent call looks like this:\n lock(App.MyLoadComponentLock)\n   genericDictionary = (ResourceDictionary)Application.LoadComponent(...\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "wpf",
            "multithreading",
            "thread-safety"
        ]
    },
    {
        "question_id": "8114657",
        "question": "\nI know that there does not exist a CSS parent selector, but is it possible to style a parenting element when hovering a child element without such a selector?\nTo give an example: consider a delete button that when hovered will highlight the element that is about to become deleted:\n<div>\n    <p>Lorem ipsum ...</p>\n    <button>Delete</button>\n</div>\n\nBy means of pure CSS, how to change the background color of this section when the mouse is over the button?\n",
        "all_answers": [
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nI know it is an old question, but I just managed to do so without a pseudo child (but a pseudo wrapper). \nIf you set the parent to be with no pointer-events, and then a child div with pointer-events set to auto, it works:)\nNote that <img> tag (for example) doesn't do the trick.\nAlso remember to set pointer-events to auto for other children which have their own event listener, or otherwise they will lose their click functionality.\n\n\ndiv.parent {  \r\n    pointer-events: none;\r\n}\r\n\r\ndiv.child {\r\n    pointer-events: auto;\r\n}\r\n\r\ndiv.parent:hover {\r\n    background: yellow;\r\n}    \n<div class=\"parent\">\r\n  parent - you can hover over here and it won't trigger\r\n  <div class=\"child\">hover over the child instead!</div>\r\n</div>\n\n\n\nEdit:\nAs Shadow Wizard kindly noted: it's worth to mention this won't work for IE10 and below. (Old versions of FF and Chrome too, see here)\n",
            "\nthere is no CSS selector for selecting a parent of a selected child.\nyou could do it with JavaScript\n",
            "\nWell, this question is asked many times before, and the short typical answer is: It cannot be done by pure CSS. It's in the name: Cascading Style Sheets only supports styling in cascading direction, not up.\nBut in most circumstances where this effect is wished, like in the given example, there still is the possibility to use these cascading characteristics to reach the desired effect. Consider this pseudo markup:\n<parent>\n    <sibling></sibling>\n    <child></child>\n</parent>\n\nThe trick is to give the sibling the same size and position as the parent and to style the sibling instead of the parent. This will look like the parent is styled!\nNow, how to style the sibling?\nWhen the child is hovered, the parent is too, but the sibling is not. The same goes for the sibling. This concludes in three possible CSS selector paths for styling the sibling:\nparent sibling { }\nparent sibling:hover { }\nparent:hover sibling { }\n\nThese different paths allow for some nice possibilities. For instance, unleashing this trick on the example in the question results in this fiddle:\ndiv {position: relative}\ndiv:hover {background: salmon}\ndiv p:hover {background: white}\ndiv p {padding-bottom: 26px}\ndiv button {position: absolute; bottom: 0}\n\n\nObviously, in most cases this trick depends on the use of absolute positioning to give the sibling the same size as the parent, ánd still let the child appear within the parent.\nSometimes it is necessary to use a more qualified selector path in order to select a specific element, as shown in this fiddle which implements the trick multiple times in a tree menu. Quite nice really.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n"
        ],
        "answer": "A2",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "12188027",
        "question": "\nLet's say I have columns a, b c, d in a table in a MySQL database. What I'm trying to do is to select the distinct values of ALL of these 4 columns in my table (only the distinct values). I tried stuff like:\nSELECT DISTINCT a,b,c,d FROM my_table;\nSELECT DISTINCT a,b,c,d FROM my_table GROUP BY a,b,c,d;\n\nNone of those worked. Can anybody help out here?\nThank you\nNOTE I want the distinct values of the columns a, b, c d separately. Not the distinct combination of values\n",
        "all_answers": [
            "\nTaking a guess at the results you want so maybe this is the query you want then\nSELECT DISTINCT a FROM my_table\nUNION \nSELECT DISTINCT b FROM my_table\nUNION\nSELECT DISTINCT c FROM my_table\nUNION\nSELECT DISTINCT d FROM my_table\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nBoth your queries are correct and should give you the right answer.\nI would suggest the following query to troubleshoot your problem.\nSELECT DISTINCT a,b,c,d,count(*) Count FROM my_table GROUP BY a,b,c,d\norder by count(*) desc\n\nThat is add count(*) field. This will give you idea how many rows were eliminated using the group command.\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\ncan this help?\nselect \n(SELECT group_concat(DISTINCT a) FROM my_table) as a,\n(SELECT group_concat(DISTINCT b) FROM my_table) as b,\n(SELECT group_concat(DISTINCT c) FROM my_table) as c,\n(SELECT group_concat(DISTINCT d) FROM my_table) as d\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n"
        ],
        "answer": "A5",
        "tags": [
            "mysql",
            "sql",
            "distinct"
        ]
    },
    {
        "question_id": "4559925",
        "question": "\nIs there a difference between isset and !empty. If I do this double boolean check, is it correct this way or redundant? and is there a shorter way to do the same thing?\nisset($vars[1]) AND !empty($vars[1])\n\n",
        "all_answers": [
            "\nEmpty just check is the refered variable/array has an value if you check the php doc(empty) you'll see this things are considered emtpy \n\n* \"\" (an empty string)\n* 0 (0 as an integer)\n* \"0\" (0 as a string)\n* NULL\n* FALSE\n* array() (an empty array)\n* var $var; (a variable declared, but without a value in a class)\n\n\nwhile isset check if the variable isset and not null which can also be found in the php doc(isset) \n",
            "\n\"Empty\": only works on variables. Empty can mean different things for different variable types\n(check manual: http://php.net/manual/en/function.empty.php).\n\"isset\": checks if the variable exists and checks for a true NULL or false value.\nCan be unset by calling \"unset\". Once again, check the manual.\nUse of either one depends of the variable type you are using. \nI would say, it's safer to check for both, because you are checking first of all if the variable exists, and if it isn't really NULL or empty.\n",
            "\nThis is completely redundant. empty is more or less shorthand for !isset($foo) || !$foo, and !empty is analogous to isset($foo) && $foo. I.e. empty does the reverse thing of isset plus an additional check for the truthiness of a value.  \nOr in other words, empty is the same as !$foo, but doesn't throw warnings if the variable doesn't exist. That's the main point of this function: do a boolean comparison without worrying about the variable being set.\nThe manual puts it like this:\n\nempty() is the opposite of (boolean) var, except that no warning is generated when the variable is not set.\n\nYou can simply use !empty($vars[1]) here.\n",
            "\nisset() tests if a variable is set and not null:\nhttp://us.php.net/manual/en/function.isset.php\nempty() can return true when the variable is set to certain values:\nhttp://us.php.net/manual/en/function.empty.php\nTo demonstrate this, try the following code with $the_var unassigned, set to 0, and set to 1.\n<?php\n\n#$the_var = 0;\n\nif (isset($the_var)) {\n  echo \"set\";\n} else {\n  echo \"not set\";\n}\n\necho \"\\n\";\n\nif (empty($the_var)) {\n  echo \"empty\";\n} else {\n  echo \"not empty\";\n}\n?>\n\n"
        ],
        "answer": "A3",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "517589",
        "question": "\n\n\n\nI have a large work space which has many source files of C code. Although I can see the functions called from a function in MS VS2005 using the Object browser, and in MSVC 6.0 also, this only shows functions called from a particular function in a non-graphical kind of display. Additionally, it does not show the function called starting from say main(), and then the functions called from it, and so on, deeper inside to the leaf level function.\nI need a tool which will give me a function call graph pictorially with functions callee and caller connected by arrows or something like that, starting from main() to the last level of function, or at least showing a call graph of all functions in one C source file pictorially. It would be great if I could print this graph.\nAny good tools to do that (need not be free tools)?\n",
        "all_answers": [
            "\nThere is a big difference between static functions in C and static member functions in C++.  In C, a static function is not visible outside of its translation unit, which is the object file it is compiled into.  In other words, making a function static limits its scope.  You can think of a static function as being \"private\" to its *.c file (although that is not strictly correct).\nIn C++, \"static\" can also apply to member functions and data members of classes.  A static data member is also called a \"class variable\", while a non-static data member is an \"instance variable\". This is Smalltalk terminology.  This means that there is only one copy of a static data member shared by all objects of a class, while each object has its own copy of a non-static data member.  So a static data member is essentially a global variable, that is a member of a class.\nNon-static member functions can access all data members of the class: static and non-static.  Static member functions can only operate on the static data members.\nOne way to think about this is that in C++ static data members and static member functions do not belong to any object, but to the entire class.\n",
            "\n\nEgypt (free software)\nncc\nKcacheGrind (GPL)\nGraphviz (CPL)\nCodeViz (GPL)\n\n",
            "\nstatic functions are functions that are only visible to other functions in the same file (more precisely the same translation unit).\nEDIT: For those who thought, that the author of the questions meant a 'class method': As the question is tagged C he means a plain old C function. For (C++/Java/...) class methods, static means that this method can be called on the class itself, no instance of that class necessary.\n",
            "\nUnderstand does a very good job of creating call graphs.\n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "function",
            "call-graph"
        ]
    },
    {
        "question_id": "31228368",
        "question": "\nI'm really confused as I'm trying to use Telegram's APIs after reading a lot of the documentation on http://core.telegram.org.\nI have registered my app and got a hash_id and all of that stuff. But I'm not sure where to begin with.\nI had worked with Spotify's API before, and was able to interact with it using http://api.spotify.com/v1/method?params:values form.\nI can't find the URL for Telegram's API. I also searched a lot on the internet but couldn't find any useful examples.\nDoes anyone know anything about getting started to work with Telegram's API?\nAny help would be appreciated.\n",
        "all_answers": [
            "\nThe Telegram API is not as easy to use as a normal HTTP/Rest API, you have to interact with their MTProto protocol. You also have to do all sorts of encryption and decryption. Telegram recently released a new Bot API which abstracts all the complications behind a decent HTTP API. Usage example in NodeJS using https://github.com/arcturial/telegrambot:\nvar TelegramBot = require('telegrambot');\nvar api = new TelegramBot('<YOUR TOKEN HERE>');\n\napi.getUpdates({ offset: 0 }, function (err, updates) {\n    // array of message updates since last poll\n    console.log(updates);\n});\n\napi.sendMessage({ chat_id: 0, text: 'test' }, function (err, message) {\n    // the chat_id is the id received in the getUpdates() call\n});\n\nThe token can be generated using their BotFather application. You can also use their deep-linking feature to add a link to your website to initiate a conversation with the bot, like so:\nhttps://telegram.me/triviabot?start=payload\nThe payload value can be anything you want, like a cache key you might use for validating a real person etc.\nI know it doesn't directly answer your question, but from personal experience I found it's better to interact with the Bot API than trying to implement all the intricacies required for the normal API. If you are adamant about using their normal API, the IPs are 149.154.167.40:443 (test) and 149.154.167.50:443 (production). They provide the IP details under https://my.telegram.org/apps.\n",
            "\nIf you really want to understand Telegram API development from scratch. My advice would be to follow the steps here \nhttps://core.telegram.org/mtproto/auth_key \nand here \nhttps://core.telegram.org/mtproto/samples-auth_key\nTry to successfully generate an AuthKey.\nThis exercise will get you familiar with enough of the basics as well as help you build up routines you will need to do further work on Telegram API.\nI have outlined the basics for you to get started in this SO post.\nAlso i think the API documentation online is not so well-written, but following the above step by step while reading the API documentation, for just AuthKey generation, would get you familiar with the language and writing style of the authors of the API\nGood Luck.\n"
        ],
        "answer": "A2",
        "tags": [
            "json",
            "http-post",
            "asp.net-web-api",
            "telegram"
        ]
    },
    {
        "question_id": "10666163",
        "question": "\nI have a list consisting of like 20000 lists. I use each list's 3rd element as a flag. I want to do some operations on this list as long as at least one element's flag is 0, it's like:\nmy_list = [[\"a\", \"b\", 0], [\"c\", \"d\", 0], [\"e\", \"f\", 0], .....]\n\nIn the beginning, all flags are 0. I use a while loop to check if at least one element's flag is 0:\ndef check(list_):\n    for item in list_:\n        if item[2] == 0:\n            return True\n    return False\n\nIf check(my_list) returns True, then I continue working on my list:\nwhile check(my_list):\n    for item in my_list:\n        if condition:\n            item[2] = 1\n        else:\n            do_sth()\n\nActually, I wanted to remove an element in my_list as I iterated over it, but I'm not allowed to remove items as I iterate over it.\nOriginal my_list didn't have flags:\nmy_list = [[\"a\", \"b\"], [\"c\", \"d\"], [\"e\", \"f\"], .....]\n\nSince I couldn't remove elements as I iterated over it, I invented these flags. But the my_list contains many items, and while loop reads all of them at each for loop, and it consumes lots of time! Do you have any suggestions?\n",
        "all_answers": [
            "\nIf you want to check if any item in the list violates a condition use all:\nif all([x[2] == 0 for x in lista]):\n    # Will run if all elements in the list has x[2] = 0 (use not to invert if necessary)\n\nTo remove all elements not matching, use filter\n# Will remove all elements where x[2] is 0\nlistb = filter(lambda x: x[2] != 0, listb)\n\n",
            "\nThe best answer here is to use all(), which is the builtin for this situation. We combine this with a generator expression to produce the result you want cleanly and efficiently. For example:\n>>> items = [[1, 2, 0], [1, 2, 0], [1, 2, 0]]\n>>> all(flag == 0 for (_, _, flag) in items)\nTrue\n>>> items = [[1, 2, 0], [1, 2, 1], [1, 2, 0]]\n>>> all(flag == 0 for (_, _, flag) in items)\nFalse\n\nNote that all(flag == 0 for (_, _, flag) in items) is directly equivalent to all(item[2] == 0 for item in items), it's just a little nicer to read in this case.\nAnd, for the filter example, a list comprehension (of course, you could use a generator expression where appropriate):\n>>> [x for x in items if x[2] == 0]\n[[1, 2, 0], [1, 2, 0]]\n\nIf you want to check at least one element is 0, the better option is to use any() which is more readable:\n>>> any(flag == 0 for (_, _, flag) in items)\nTrue\n\n",
            "\nYou could use itertools's takewhile like this, it will stop once a condition is met that fails your statement. The opposite method would be dropwhile\nfor x in itertools.takewhile(lambda x: x[2] == 0, list)\n    print x\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "list",
            "for-loop",
            "while-loop"
        ]
    },
    {
        "question_id": "13073281",
        "question": "\nI'm trying to write tests for a class that has methods like:\nimport datetime\nimport pytz\n\nclass MyClass:\n    def get_now(self, timezone):\n        return datetime.datetime.now(timezone)\n\n    def do_many_things(self, tz_string='Europe/London'):\n        tz = pytz.timezone(tz_string)\n        localtime_now = self.get_now(tz)\n        ...\n        return things\n\nI want to test it, and to do so I need to make sure that the datetime.datetime.now() call returns something predictable.\nI've been reading lots of examples of using Mock in tests, but haven't found anything quite like what I need, and I can't work out how to use it in my tests.\nI separated the get_now() method out in case it's easier to mock that, instead of datetime.datetime.now(), but I'm still stumped. Any thoughts on how to write UnitTests for this using Mock? (This is all in Django, fwiw; I'm not sure if this makes a difference in this case.)\n",
        "all_answers": [
            "\nYou'd create a function that returns a specific datetime, localized to the timezone passed in:\nimport mock\n\ndef mocked_get_now(timezone):\n    dt = datetime.datetime(2012, 1, 1, 10, 10, 10)\n    return timezone.localize(dt)\n\n@mock.patch('path.to.your.models.MyClass.get_now', side_effect=mocked_get_now)\ndef your_test(self, mock_obj):\n    # Within this test, `MyClass.get_now()` is a mock that'll return a predictable\n    # timezone-aware datetime object, set to 2012-01-01 10:10:10.\n\nThat way you can test if the resulting timezone-aware datetime is correctly being handled;  results elsewhere should show the correct timezone but will have a predictable date and time.\nYou use the mocked_get_now function as a side-effect when mocking get_now; whenever code calls get_now the call is recorded by mock, and mocked_get_now is called, and it's return value used as the value returned to the caller of get_now.\n",
            "\nYou could use freezegun :\nfrom freezegun import freeze_time\n\ndef test():\n    assert datetime.datetime.now() != datetime.datetime(2012, 1, 14)\n    with freeze_time(\"2012-01-14\"):\n        assert datetime.datetime.now() == datetime.datetime(2012, 1, 14)\n    assert datetime.datetime.now() != datetime.datetime(2012, 1, 14)\n\nIt basically mocks datetime module calls.\n",
            "\nI'm using date, but the same idea should work for datetime: \nclass SpoofDate(date):\n    def __new__(cls, *args, **kwargs):\n        return date.__new__(date, *args, **kwargs)\n\n...\nfrom mock import patch\n\n@patch('some.module.date', SpoofDate)\ndef testSomething(self):\n    SpoofDate.today = classmethod(lambda cls : date(2012, 9, 24))\n\nWhere some.module imports date.  Patch is replacing the imported date with SpoofDate, which you can then redefine to do whatever you want.\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI would use the helpers from the 'testfixtures' package to mock out the datetime class you're calling now() on:\nhttp://packages.python.org/testfixtures/datetime.html#datetimes\nThat way, you can test all the cases you have, all the time.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django",
            "unit-testing",
            "testing",
            "mocking"
        ]
    },
    {
        "question_id": "8434518",
        "question": "\nI have two tables, table1 is the parent table with a column ID and table2 with a column IDFromTable1 (not the actual name) when I put a FK on IDFromTable1 to ID in table1 I get the error Foreign key constraint is incorrectly formed error. I would like to delete table 2 record if table1 record gets deleted. Thanks for any help\nALTER TABLE `table2`  \n   ADD CONSTRAINT `FK1` \n      FOREIGN KEY (`IDFromTable1`) REFERENCES `table1` (`ID`) \n      ON UPDATE CASCADE \n      ON DELETE CASCADE;\n\nLet me know if any other information is needed. I am new to mysql\n",
        "all_answers": [
            "\nI ran into this same problem with HeidiSQL. The error you receive is very cryptic. My problem ended up being that the foreign key column and the referencing column were not of the same type or length.\nThe foreign key column was SMALLINT(5) UNSIGNED and the referenced column was INT(10) UNSIGNED. Once I made them both the same exact type, the foreign key creation worked perfectly.\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nTry running following:\n\nshow create table Parent\n\n//and check if type for both tables are the same, like myISAM or innoDB, etc\n//Other aspects to check with this error message: the columns used as foreign \nkeys must be indexed, they must be of the same type \n(if i.e one is of type smallint(5) and the other of type smallint(6), \nit won't work), and, if they are integers, they should be unsigned.\n\n//or check for charsets\nshow variables like \"character_set_database\";\nshow variables like \"collation_database\";\n\n//edited: try something like this\nALTER TABLE table2\nADD CONSTRAINT fk_IdTable2\nFOREIGN KEY (Table1_Id)\nREFERENCES Table1(Table1_Id)\nON UPDATE CASCADE \nON DELETE CASCADE;\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n"
        ],
        "answer": "A1",
        "tags": [
            "mysql",
            "sql",
            "heidisql"
        ]
    },
    {
        "question_id": "420741",
        "question": "\nI'm looking at creating a basic ORM (purely for fun), and was wondering, is there a way to return the list of tables in a database and also the fields for every table?\nUsing this, I want to be able to loop through the result set (in C#) and then say for each table in the result set, do this (e.g. use reflection to make a class that will do or contain xyz).\nFurther to this, what are some good online blogs for SQL Server? I know this question is really about using system SPs and databases in Sql Server, and I am ok with general queries, so I'm interested in some blogs which cover this sort of functionality.\nThanks\n",
        "all_answers": [
            "\nSELECT * FROM INFORMATION_SCHEMA.COLUMNS\n\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nThis will get you all the user created tables:\nselect * from sysobjects where xtype='U'\n\nTo get the cols:\nSelect * from Information_Schema.Columns Where Table_Name = 'Insert Table Name Here'\n\nAlso, I find http://www.sqlservercentral.com/ to be a pretty good db resource.\n",
            "\nTables ::\nSELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE='BASE TABLE'\n\ncolumns ::\nSELECT * FROM INFORMATION_SCHEMA.COLUMNS \n\nor \nSELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME='your_table_name'\n\n",
            "\nYour other inbuilt friend here is the system sproc SP_HELP.\nsample usage :: \nsp_help <MyTableName>\n\nIt returns a lot more info than you will really need, but at least 90% of your possible requirements will be catered for.\n",
            "\nIs this what you are looking for:\nUsing OBJECT CATALOG VIEWS\n SELECT T.name AS Table_Name ,\n       C.name AS Column_Name ,\n       P.name AS Data_Type ,\n       C.max_length AS Size ,\n       CAST(P.precision AS VARCHAR) + '/' + CAST(P.scale AS VARCHAR) AS Precision_Scale\nFROM   sys.objects AS T\n       JOIN sys.columns AS C ON T.object_id = C.object_id\n       JOIN sys.types AS P ON C.system_type_id = P.system_type_id\nWHERE  T.type_desc = 'USER_TABLE';\n\nUsing INFORMATION SCHEMA VIEWS\n  SELECT TABLE_SCHEMA ,\n       TABLE_NAME ,\n       COLUMN_NAME ,\n       ORDINAL_POSITION ,\n       COLUMN_DEFAULT ,\n       DATA_TYPE ,\n       CHARACTER_MAXIMUM_LENGTH ,\n       NUMERIC_PRECISION ,\n       NUMERIC_PRECISION_RADIX ,\n       NUMERIC_SCALE ,\n       DATETIME_PRECISION\nFROM   INFORMATION_SCHEMA.COLUMNS;\n\nReference : My Blog - http://dbalink.wordpress.com/2008/10/24/querying-the-object-catalog-and-information-schema-views/\n"
        ],
        "answer": "A6",
        "tags": [
            "sql",
            "t-sql"
        ]
    },
    {
        "question_id": "5393085",
        "question": "\n\n\n\nHere is the code for pulling the data for my array\n<?php\n    $link = mysqli_connect('localhost', 'root', '', 'mutli_page_form');\n\n    $query = \"SELECT * FROM wills_children WHERE will=73\";\n\n    $result = mysqli_query($link, $query) or die(mysqli_error($link));\n\n    if ($result = mysqli_query($link, $query)) {\n\n    /* fetch associative array */\n    if($row = mysqli_fetch_assoc($result)) {\n        $data = unserialize($row['children']);\n    }\n\n    /* free result set */\n    mysqli_free_result($result);\n    }\n?>\n\nWhen I use print_r($data) it reads as:\nArray ( [0] => Array ( [0] => Natural Chlid 1 [1] => Natural Chlid 2 [2] => Natural Chlid 3 ) ) \n\nI would like it to read as:\nNatural Child 1\nNatural Child 2\nNatural Child 3\n",
        "all_answers": [
            "\nTry this:\nforeach($data[0] as $child) {\n   echo $child . \"\\n\";\n}\n\nin place of print_r($data)\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nforeach($array as $v) echo $v, PHP_EOL;\n\nUPDATE: A more sophisticated solution would be:\n $test = [\n    'key1' => 'val1',\n    'key2' => 'val2',\n    'key3' => [\n        'subkey1' => 'subval1',\n        'subkey2' => 'subval2',\n        'subkey3' => [\n            'subsubkey1' => 'subsubval1',\n            'subsubkey2' => 'subsubval2',\n        ],\n    ],\n];\nfunction printArray($arr, $pad = 0, $padStr = \"\\t\") {\n    $outerPad = $pad;\n    $innerPad = $pad + 1;\n    $out = '[' . PHP_EOL;\n    foreach ($arr as $k => $v) {\n        if (is_array($v)) {\n            $out .= str_repeat($padStr, $innerPad) . $k . ' => ' . printArray($v, $innerPad) . PHP_EOL;\n        } else {\n            $out .= str_repeat($padStr, $innerPad) . $k . ' => ' . $v;\n            $out .= PHP_EOL;\n        }\n    }\n    $out .= str_repeat($padStr, $outerPad) . ']';\n    return $out;\n}\n\necho printArray($test);\n\nThis prints out:\n    [\n        key1 => val1\n        key2 => val2\n        key3 => [\n            subkey1 => subval1\n            subkey2 => subval2\n            subkey3 => [\n                subsubkey1 => subsubval1\n                subsubkey2 => subsubval2\n            ]\n        ]\n    ]\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "sql"
        ]
    },
    {
        "question_id": "4503550",
        "question": "\nI have a model stories in Rails 3.\nI want to make an alias \"books\" for \"stories\" so I can have routes /books/192 instead of /stories/192, and also that all my generated links (e.g. link_to) point to books' routes instead of stories' routes.\nHow can I do that?\nThanks\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nI had a similar error and had to edit my manifest.js file in order to get it to work.\nEdit /assets/config.manifest.js and then\n// manifest.js\n//= link_tree ../images\n//= link_tree ../stylesheets .css\n\nThen do a bundle exec rake assets:precompile\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nThat's why they made the path option on match which is also available on resources:\nresources :stories, :path => \"books\"\n\n",
            "\nTry something like this:\nmatch 'books/:id' => 'books#show'\nmatch 'books' => 'books#index'\n\n"
        ],
        "answer": "A5",
        "tags": [
            "ruby-on-rails"
        ]
    },
    {
        "question_id": "10757851",
        "question": "\nIs there a way on Windows to run a JAR file using a JRE located in a specific folder?  Similar to the way Eclipse looks for its JRE in some path you give to it.  Either some windows executable code (C or C++) or a Batch file will do the job.  Thanks!\n",
        "all_answers": [
            "\nI had the same error in my case was when I needed to update jdk 7 to jdk 8, and my bad was just I installed jdk8 and I never installed jre8, only that, the error was solved immediately when I installed jre8.\n",
            "\nNot able to run Appium {“message”:”A new session could not be created. (Original error: ‘java -version’ failed\nI used Jdk 1.8 and JRE 1.8, Classpath is also set properly but I observed that Java command gives Error to initialization of VM (java/lang/NoClassDefFoundError: java/lang/Object)\nSolution:\nUninstalled JRE and JDK completely \nInstalled JRE 1.8 then\nInstalled JDK 1.8 \nSet Classpath\ncheck Java command works or not and its working \nalso able to execute the Appium program thru Eclipse Kepler Service Release 2 with JDK1.8 support\n\n",
            "\nI faced the same problem,Eclipse splash screen for a second and it disappears.Then i noticed due to auto update of java there are two java version installed in my system. when i uninstalled one eclipse started working.\nThanks you..\n",
            "\nGo to Eclipse folder, locate eclipse.ini file, add following entry (before -vmargs if present):\n-vm\nC:\\Program Files\\Java\\jdk1.7.0_10\\bin\\javaw.exe\n\nSave file and execute eclipse.exe.\n",
            "\nI had the same issue on Windows 7 and I had to install both JDK and JRE and it's a success. \n",
            "\nCheck that downloaded eclipse/JDK/JRE is compatible with your processor/OS architecture that is are they 32bit or 64bit?\n",
            "\nA JRE directory has a bin/java.exe.\nYou can run a jar from that JRE simply with\n<path_to_jre>/bin/java.exe -jar Executable.jar\n\nIf you don't want to have to open a console each time, simply put the above line in a .bat file and double click on that.\n",
            "\nTry placing the desired java directory in PATH before  not needed java directories in your PATH.\n",
            "\nYou could change the Windows Environment Variable for JAVA_HOME (see here). Point it to the JRE you want it to run with. I'm sure there's no programmatic way to do it (because the right JRE is loaded at run-time).\n",
            "\nplease try to execute java from \n\nC:\\Program Files\\Java\\jdk1.7.0_10\\bin\n\ni.e from the location where java is installed.\nIf it is successful, it means that the error lies somewhere in the classpath.\nAlso, this guy seems to have had the same problem as yours, check it out\n"
        ],
        "answer": "A7",
        "tags": [
            "windows",
            "batch-file",
            "jar",
            "java"
        ]
    },
    {
        "question_id": "673233",
        "question": "\nTrying to use WMI to obtain a list of installed programs for Windows XP. Using wmic, I tried:\nwmic /output:c:\\ProgramList.txt product get name,version\n\nand I get a listing of many of the installed programs, but after scrubbing this list against what \"Add/Remove Programs\" displays, I see many more programs listed in the GUI of Add/Remove Programs than with the WMI query. Is there another WMI query I need to use to get the rest of the programs installed? Or is there some other place I need to look for the rest?\nAlso, there are two installed programs that are listed in the WMI query that aren't in Add/Remove programs. Any idea why?\n",
        "all_answers": [
            "\nFYI, this post explains the root problem  https://superuser.com/q/293542/245923\nYou can uninstall it using the product code:\nmsiexec.exe /x {your-product-code-guid}\n\nYou would obtain this code from the MSI itself, or whatever tool you are using to build the MSI.\nNote that when you uninstall a product, it uses a cached MSI, since only the original MSI knows how to uninstall itself. When you use the product code, it uses the cached MSI from C:\\WINDOWS\\Installer.\n",
            "\nI believe your syntax is using the Win32_Product Class in WMI.  One cause is that this class only displays products installed using Windows Installer (See Here).  The Uninstall Registry Key is your best bet.\nHKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\nHKEY_LOCAL_MACHINE\\SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\nUPDATE FOR COMMENTS:\nThe Uninstall Registry Key is the standard place to list what is installed and what isn't installed.  It is the location that the Add/Remove Programs list will use to populate the list of applications.  I'm sure that there are applications that don't list themselves in this location.  In that case you'd have to resort to another cruder method such as searching the Program Files directory or looking in the Start Menu Programs List.  Both of those ways are definitely not ideal.  \nIn my opinion, looking at the registry key is the best method.\n",
            "\nAll that Add/Remove Programs is really doing is reading this Registry key:\nHKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\n\n",
            "\nPlease note that Microsoft has now released an official tool to resolve these issues, without the problems that previously existed with MSIZAP.\n\nMicrosoft Fixit: Fix problems with programs that can't be installed or uninstalled\n\n",
            "\nTake a look at a tool called MSIZap released by Microsoft.\n\nUPDATE:\nMsiZap.exe has been deprecated for quite some time. Its use is unsupported on all recent versions of Windows, and it is considered a very unsafe tool to use.\nI added a link to a newer Microsoft support tool designed to clean out installations, but this tool also appears deprecated at this point. I have removed the link from the comments section.\nPerhaps try the tool linked to in saschabeaumont's answer below.\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "windows-installer",
            "wmi"
        ]
    },
    {
        "question_id": "4654653",
        "question": "\nI am working on catching errors in my app, and I am looking into using NSError.  I am slightly confused about how to use it, and how to populate it.\nCould someone provide an example on how I populate then use NSError?\n",
        "all_answers": [
            "\nPlease refer following tutorial \ni hope it will helpful for you but prior you have to read documentation of NSError\nThis is very interesting link i found recently ErrorHandling\n",
            "\nWell, what I usually do is have my methods that could error-out at runtime take a reference to a NSError pointer. If something does indeed go wrong in that method, I can populate the NSError reference with error data and return nil from the method.\nExample:\n- (id) endWorldHunger:(id)largeAmountsOfMonies error:(NSError**)error {\n    // begin feeding the world's children...\n    // it's all going well until....\n    if (ohNoImOutOfMonies) {\n        // sad, we can't solve world hunger, but we can let people know what went wrong!\n        // init dictionary to be used to populate error object\n        NSMutableDictionary* details = [NSMutableDictionary dictionary];\n        [details setValue:@\"ran out of money\" forKey:NSLocalizedDescriptionKey];\n        // populate the error object with the details\n        *error = [NSError errorWithDomain:@\"world\" code:200 userInfo:details];\n        // we couldn't feed the world's children...return nil..sniffle...sniffle\n        return nil;\n    }\n    // wohoo! We fed the world's children. The world is now in lots of debt. But who cares? \n    return YES;\n}\n\nWe can then use the method like this. Don't even bother to inspect the error object unless the method returns nil:\n// initialize NSError object\nNSError* error = nil;\n// try to feed the world\nid yayOrNay = [self endWorldHunger:smallAmountsOfMonies error:&error];\nif (!yayOrNay) {\n   // inspect error\n   NSLog(@\"%@\", [error localizedDescription]);\n}\n// otherwise the world has been fed. Wow, your code must rock.\n\nWe were able to access the error's localizedDescription because we set a value for NSLocalizedDescriptionKey. \nThe best place for more information is Apple's documentation. It really is good.\nThere is also a nice, simple tutorial on Cocoa Is My Girlfriend. \n"
        ],
        "answer": "A2",
        "tags": [
            "iphone",
            "ios",
            "objective-c",
            "ios4",
            "nserror"
        ]
    },
    {
        "question_id": "47538857",
        "question": "\nI know I can't use DELETE in a query (that is a shame by the way), I will get the following error:\n<i>Error:error: Observable query return type (LiveData, Flowable etc) can only be used with SELECT queries that directly or indirectly (via @Relation, for example) access at least one table.</i>\n\nBut I can't use @Delete(WHERE... xxx)\nSo how do I delete a specific row by a parameter?\n",
        "all_answers": [
            "\nActually, you can use @Query to perform a delete.\n@Query(\"DELETE FROM users WHERE user_id = :userId\")\nabstract void deleteByUserId(long userId);\n\nExtracted from Query javadoc:\n\nUPDATE or DELETE queries can return void or int. If it is an int, the\n  value is the number of rows affected by this query.\n\n",
            "\npublic class NetworkChangeReceiver extends BroadcastReceiver {\n\n    @Override\n    public void onReceive(final Context context, final Intent intent) {\n        if (checkInternet(context)) {\n            Toast.makeText(context, \"Network Available Do operations\", Toast.LENGTH_LONG).show();\n        }\n    }\n\n    boolean checkInternet(Context context) {\n        ServiceManager serviceManager = new ServiceManager(context);\n        return serviceManager.isNetworkAvailable()\n    }\n}\n\nServiceManager.java\npublic class ServiceManager {\n\n    Context context;\n\n    public ServiceManager(Context base) {\n        context = base;\n    }\n\n    public boolean isNetworkAvailable() {\n        ConnectivityManager cm = (ConnectivityManager) context.getSystemService(Context.CONNECTIVITY_SERVICE);\n        NetworkInfo networkInfo = cm.getActiveNetworkInfo();\n        return networkInfo != null && networkInfo.isConnected();\n    }\n}\n\npermissions:\n <uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" />\n <uses-permission android:name=\"android.permission.INTERNET\" />\n\n",
            "\nAnswer to your first question: Your broadcast receiver is being called two times because\nYou have added two <intent-filter>\n\nChange in network connection :\n<action android:name=\"android.net.conn.CONNECTIVITY_CHANGE\" />\n\nChange in WiFi state:\n<action android:name=\"android.net.wifi.WIFI_STATE_CHANGED\" />\n\n\nJust use one:\n<action android:name=\"android.net.conn.CONNECTIVITY_CHANGE\" />.\nIt will respond to only one action instead of two. See here for more information.\nAnswer to your second question (you want the receiver to call only one time if an internet connection is available):\nYour code is perfect; you notify only when the internet is available.\nUPDATE\nYou can use this method to check your connectivity if you want just to check whether your mobile is connected to the internet or not.\npublic boolean isOnline(Context context) {\n  \n    ConnectivityManager cm = (ConnectivityManager) context.getSystemService(Context.CONNECTIVITY_SERVICE);\n    NetworkInfo netInfo = cm.getActiveNetworkInfo();\n    //should check null because in airplane mode it will be a null\n    return (netInfo != null && netInfo.isConnected());\n}\n\n",
            "\nThe beauty of room is, we play with the objects. As per requirement you can use \nfor kotlin:\n@Delete\nfun delete(model: LanguageModel)\n\nfor Java:\n@Delete\nvoid delete(LanguageModel model)\n\nit will delete the exact object which is stored in the db with the same values. LanguageModel is my model class and it works perfectly.\n"
        ],
        "answer": "A4",
        "tags": [
            "java",
            "android",
            "sql",
            "android-room"
        ]
    },
    {
        "question_id": "19761766",
        "question": "\nNew to rails and I'm following the Depot project found in the Agile web development with rails 3.1. Everything was fine until I got lost when the book used the \"build\" method.\n@cart = current_cart\nproduct = Product.find(params[:product_id])\n@line_item = @cart.line_items.build(product: product)\n\nMy google searches led me to understand that the .build method is just a cleaner way to create a row in the table (with association between tables). But on the code above, I was expecting the code would look like something like this: \n@line_item = @cart.line_items.build(product_id => params[:product_id])\n\nI don't understand why the author had to store the whole row of products( product = Product.find(params[:product_id])) instead of just getting the product_id...\nIs there more to it than what I can understand?\n",
        "all_answers": [
            "\nYou misunderstood build. It's just an alias of new, nothing special. https://github.com/rails/rails/blob/959fb8ea651fa6638aaa7caced20d921ca2ea5c1/activerecord/lib/active_record/relation.rb#L84\nbuild won't \"create\" a record in database, just create a new object in memory so that the view can take this object and display something, especially for a form.\nFor your second question, yes, your way of composing by id will work as well. But a better approach is not to trust param. Instead, verify it by finding in db at first.  \n",
            "\nI definitely prefer sass to scss too - have you considered just using the compass gem for all your CSS, and adding preferred_syntax = :sass to config/compass.rb\nI haven't tested this out yet on rails 3.1 yet but it works in 3.0.7\nEDIT\nAs a troubleshooting step, what happens when you remove just the first line of code from sass_config.rb so that it just has the second one? Do both these lines cause the error?\n",
            "\nI'm going to go ahead and say you are entirely correct.  Either method works and will do the same thing, but your version using just :product_id is more efficient and requires one less database query.  That said, it might make sense if you need that product variable later in the code or that specific line item calls product.{something} later so it doesn't have to fetch it by id at that point.\nHowever, I personally would prefer to just set the :product_id, I see no reason to find the object first.\n",
            "\nDo require 'sass/plugin' and make sure it's at the bottom after your Application.initialize! call. \n",
            "\nI added the following to config/environments/development.rb:\nconfig.sass.preferred_syntax = :sass\n\nThat did the trick.\n",
            "\nFor rails 3.1.rc4, you could set the config:\nconfig.sass.preferred_syntax = :sass\n\nin the application.rb file\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby-on-rails-3.1",
            "associations"
        ]
    },
    {
        "question_id": "30812057",
        "question": "\nI'm attempting to create a UIImage (like a thumbnail or something) from a PHAsset so that I can pass it into something that takes a UIImage. I've tried adapting solutions I found on SO (since they all just directly pass it into say a tableview or something), but I have no success (likely because I'm not doing it right).\nfunc getAssetThumbnail(asset: PHAsset) -> UIImage {\n    var retimage = UIImage()\n    println(retimage)\n    let manager = PHImageManager.defaultManager()\n    manager.requestImageForAsset(asset, targetSize: CGSize(width: 100.0, height: 100.0), contentMode: .AspectFit, options: nil, resultHandler: {(result, info)->Void in\n            retimage = result\n    })\n    println(retimage)\n    return retimage\n}\n\nThe printlns are telling me that the manager.request line isn't doing anything right now. How do I get it to give me the asset as a UIImage.\nThanks.\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nThis did what I needed it to do, in case anyone also needs this.\nfunc getAssetThumbnail(asset: PHAsset) -> UIImage {\n    let manager = PHImageManager.defaultManager()\n    let option = PHImageRequestOptions()\n    var thumbnail = UIImage()\n    option.synchronous = true\n    manager.requestImageForAsset(asset, targetSize: CGSize(width: 100.0, height: 100.0), contentMode: .AspectFit, options: option, resultHandler: {(result, info)->Void in\n            thumbnail = result!\n    })\n    return thumbnail\n}\n\nEdit: Swift 3 update\nfunc getAssetThumbnail(asset: PHAsset) -> UIImage {\n    let manager = PHImageManager.default()\n    let option = PHImageRequestOptions()\n    var thumbnail = UIImage()\n    option.isSynchronous = true\n    manager.requestImage(for: asset, targetSize: CGSize(width: 100, height: 100), contentMode: .aspectFit, options: option, resultHandler: {(result, info)->Void in\n        thumbnail = result!\n    })\n    return thumbnail\n}\n\n",
            "\nThe problem is that requestImageForAsset is a resultHandler and this block of code happens in the future after your functions has already printed and returned the value you was expecting. I did come changes to show you this happening and also suggest some simple solutions. \nfunc getAssetThumbnail(asset: PHAsset) {\n    var retimage = UIImage()\n    println(retimage)\n    let manager = PHImageManager.defaultManager()\n    manager.requestImageForAsset(asset, targetSize: CGSize(width: 100.0, height: 100.0), contentMode: .AspectFit, options: nil, resultHandler: {\n    (result, info)->Void in\n            retimage = result\n      println(\"This happens after\")\n      println(retimage)\n      callReturnImage(retimage) // <- create this method\n    })\n    println(\"This happens before\")\n}\n\nLearn more about closures and completion handle and async funcs at Apple documentation\nI hope that helps you!\n"
        ],
        "answer": "A2",
        "tags": [
            "swift",
            "phasset"
        ]
    },
    {
        "question_id": "37956720",
        "question": "\nFacing issue \"Value of type 'AppDelegate' has no member 'managedObjectContext' In new Xcode 8 (using Swift 3, iOS 10) when trying to create new context in View Controller \nlet context = (UIApplication.shared().delegate as! AppDelegate).managedObjectContext\n\nIn Xcode 8 there is no code for managedObjectContext inside AppDelegate.swift file. Core Data stack code inside AppDelegate.swift presented only with: lazy var persistentContainer: NSPersistentContainer property and func saveContext () . There is no managedObjectContext property.\nHow to create managedObjectContext using Swift 3 in Xcode 8) or maybe there is no need to do it using Swift 3 ? \n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nNSPersistentContainer has a viewContext property that is an NSManagedObjectContext type.\nAs a side note, if you create a Master-Detail application in Xcode 8, Apple's sample code puts the managedObjectContext property in the MasterViewController.swift file and sets it by using said viewContext property in AppDelegate.\n",
            "\nIn Swift3, you can access the managedObjectContext via the viewContext as\nlet context = (UIApplication.shared.delegate as! AppDelegate).persistentContainer.viewContext\n\nThis option is available if Core data was enabled when creating the project. However, for existing project that you want to include core data, go through the normal process of adding the core data and add the following code which will allow you to get the \nlazy var persistentContainer: NSPersistentContainer = {\n\n    let container = NSPersistentContainer(name: \"you_model_file_name\")\n    container.loadPersistentStores(completionHandler: { (storeDescription, error) in\n        if let error = error {\n\n            fatalError(\"Unresolved error \\(error), \\(error.userInfo)\")\n        }\n    })\n    return container\n}()\n\nYou will need to import the CoreData.\nNote: For Swift3, the ManagedObject Subclass are generated automatically. \nSee more from  WWDC 2016\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "xcode",
            "swift",
            "core-data",
            "swift3"
        ]
    },
    {
        "question_id": "2740003",
        "question": "\nI am using Django for a project and is already in production.\nIn the production environment 500.html is rendered whenever a server error occurs.\nHow do I test the rendering of 500.html in dev environment? Or how do I render 500.html in dev, if I turn-off debug I still get the errors and not 500.html\nbackground: I include some page elements based on a page and some are missing when 500.html is called and want to debug it in dev environment. \n",
        "all_answers": [
            "\nAre both debug settings false?\nsettings.DEBUG = False\nsettings.TEMPLATE_DEBUG = False\n\n",
            "\nI prefer not to turn DEBUG off. Instead I put the following snippet in the urls.py:\nif settings.DEBUG:\n    urlpatterns += patterns('',\n        (r'^500/$', 'your_custom_view_if_you_wrote_one'),\n        (r'^404/$', 'django.views.generic.simple.direct_to_template', {'template': '404.html'}),\n    )\n\nIn the snippet above, the error page uses a custom view, you can easily replace it with Django's direct_to_template view though.\nNow you can test 500 and 404 pages by calling their urls: http://example.com/500 and http://example.com/404\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A2",
        "tags": [
            "django",
            "development-environment"
        ]
    },
    {
        "question_id": "4910905",
        "question": "\nAssume we have class Employee. I want to have a field which references a different instance of the same class. \nHow to write this? How about the following code?\nref_employee= models.ForeignKey('self',null=True,blank=True)\n\n",
        "all_answers": [
            "\nAnother way to avoid the SerializerMethodField solution and therefore still allow writing to the serializer as well would be to subclass the RelatedField and do the filtering there.\nTo only allow active users as values for the field, the example would look like:\nclass ActiveUsersPrimaryKeyField(serializers.PrimaryKeyRelatedField):\n    def get_queryset(self):\n        return super().get_queryset().filter(active=True)\n\nclass MySerializer(serializers.ModelSerializer):\n    users = ActiveUsersPrimaryKeyField(many=True)\n    class Meta:\n        model = MyModel\n        fields = ('users',)\n\nAlso see this response.\nNote that this only restricts the set of input values to active users, though, i.e. only when creating or updating model instances, inactive users will be disallowed.\n\nIf you also use your serializer for reading and MyModel already has a relation to a user that has become inactive in the meantime, it will still be serialized. To prevent this, one way is to filter the relation using django's Prefetch objects. Basically, you'll filter out inactive users before they even get into the serializer:\nfrom django.db.models import Prefetch\n\n# Fetch a model instance, eagerly prefetching only those users that are active\nmodel_with_active_users = MyModel.objects.prefetch_related(\n    Prefetch(\"users\", queryset=User.objects.filter(active=True))\n).first()\n\n# serialize the data with the serializer defined above and see that only active users are returned\ndata = MyModelSerializer(model_with_active_users).data\n\n\n",
            "\nYou can reference other models by name (using a string, including\npackage), instead of by the class directly:\nSo, if your Employee class is in the hr app:\nclass Employee(models.model):\n   other_employee = models.ForeignKey('hr.models.Employee', null=True, blank=True)\n\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nhttp://docs.djangoproject.com/en/dev/ref/models/fields/#foreignkey\n\nTo create a recursive relationship --\n  an object that has a many-to-one\n  relationship with itself -- use\n  models.ForeignKey('self').\n\nSo you have it right. It's usually faster to determine if code will do what you want by running it :)\n"
        ],
        "answer": "A5",
        "tags": [
            "django",
            "django-models",
            "django-orm"
        ]
    },
    {
        "question_id": "1580805",
        "question": "\nConsider the table creation script below:\ncreate_table :foo do |t|\n  t.datetime :starts_at, :null => false\nend\n\nIs it's possible to set the default value as the current time?\nI am trying to find a DB independent equivalent in rails for the SQL column definitions given below:\nOracle Syntax\nstart_at DATE DEFAULT SYSDATE() \n\nMySQL Syntax\nstart_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n\nOR\nstart_at DATETIME DEFAULT NOW()\n\n",
        "all_answers": [
            "\nI usually do:\ndef change\n  execute(\"\n    ALTER TABLE your_table\n    ALTER COLUMN your_column\n    SET DEFAULT CURRENT_TIMESTAMP\n  \")\nend\n\nSo, your schema.rb is going to have something like:\ncreate_table \"your_table\", force: :cascade do |t|\n  t.datetime \"your_column\", default: \"now()\"\nend\n\n",
            "\n\nActive Record automatically timestamps create and update operations if the table has fields named created_at/created_on or updated_at/updated_on. Source - api.rubyonrails.org\n\nYou don't need to do anything else except to have that column.\n",
            "\nIn the answer given by @szymon-lipiński (Szymon Lipiński), the execute method didn't work for me. It was throwing a MySQL syntax error.\nThe MySQL syntax which worked for me is this.\nexecute \"ALTER TABLE mytable CHANGE `column_name` `column_name` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\"\n\nSo to set the default value for a datetime column in migration script can be done as follows:\ndef up\n  create_table :foo do |t|\n    t.datetime :starts_at, :null => false\n  end\n\n  execute \"ALTER TABLE `foo` CHANGE `starts_at` `starts_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\"\nend\n\n",
            "\nYou can add a function in a model like this:\n  before_create :set_foo_to_now\n  def set_foo_to_now\n    self.foo = Time.now\n  end\n\nSo that the model will set the current time in the model.\nYou can also place some sql code in the migration for setting the default value at the database level, something like:\nexecute 'alter table foo alter column starts_at set default now()'\n\nSetting something like this:\ncreate_table :foo do |t|\n  t.datetime :starts_at, :null => false, :default => Time.now\nend\n\ncauses executing the Time.now function during migrating so then the table in database is created like this:\ncreate table foo ( starts_at timestamp not null default '2009-01-01 00:00:00');\n\nbut I think that it is not what you want.\n",
            "\nI was searching for a similar solutions but I ended using https://github.com/FooBarWidget/default_value_for.\nThe default_value_for plugin allows one to define default values for ActiveRecord models in a declarative manner. For example:\nclass User < ActiveRecord::Base\n  default_value_for :name, \"(no name)\"\n  default_value_for :last_seen do\n    Time.now\n  end\nend\n\nu = User.new\nu.name       # => \"(no name)\"\nu.last_seen  # => Mon Sep 22 17:28:38 +0200 2008\n\n",
            "\nThis is supported now in Rails 5. \nHere is a sample migration:\nclass CreatePosts < ActiveRecord::Migration[5.0]\n  def change\n    create_table :posts do |t|\n      t.datetime :modified_at, default: -> { 'CURRENT_TIMESTAMP' }\n      t.timestamps\n    end\n  end \nend\n\nSee discussion at https://github.com/rails/rails/issues/27077 and answer there by prathamesh-sonpatki \n"
        ],
        "answer": "A6",
        "tags": [
            "ruby-on-rails"
        ]
    },
    {
        "question_id": "171205",
        "question": "\nI've always been able to allocate 1400 megabytes for Java SE running on 32-bit Windows XP (Java 1.4, 1.5 and 1.6).\njava -Xmx1400m ...\n\nToday I tried the same option on a new Windows XP machine using Java 1.5_16 and 1.6.0_07 and got the error:\nError occurred during initialization of VM\nCould not reserve enough space for object heap\nCould not create the Java virtual machine.\n\nThrough trial and error it seems 1200 megabytes is the most I can allocate on this machine.\nAny ideas why one machine would allow 1400 and another only 1200?\nEdit: The machine has 4GB of RAM with about 3.5GB that Windows can recognize.\n",
        "all_answers": [
            "\nKeep in mind that Windows has virtual memory management and the JVM only needs memory that is contiguous in its address space. So, other programs running on the system shouldn't necessarily impact your heap size. What will get in your way are DLL's that get loaded in to your address space. Unfortunately optimizations in Windows that minimize the relocation of DLL's during linking make it more likely you'll have a fragmented address space. Things that are likely to cut in to your address space aside from the usual stuff include security software, CBT software, spyware and other forms of malware. Likely causes of the variances are different security patches, C runtime versions, etc. Device drivers and other kernel bits have their own address space (the other 2GB of the 4GB 32-bit space).\nYou could try going through your DLL bindings in your JVM process and look at trying to rebase your DLL's in to a more compact address space. Not fun, but if you are desperate...\nAlternatively, you can just switch to 64-bit Windows and a 64-bit JVM. Despite what others have suggested, while it will chew up more RAM, you will have much more contiguous virtual address space, and allocating 2GB contiguously would be trivial.\n",
            "\nThe JVM needs contiguous memory and depending on what else is running, what was running before, and how windows has managed memory you may be able to get up to 1.4GB of contiguous memory.  I think 64bit Windows will allow larger heaps.\n",
            "\nsun's JDK/JRE needs a contiguous amount of memory if you allocate a huge block.\nThe OS and initial apps tend to allocate bits and pieces during loading which fragments the available RAM. If a contiguous block is NOT available, the SUN JDK cannot use it. JRockit from Bea(acquired by Oracle) can allocate memory from pieces.\n",
            "\nSun's JVM needs contiguous memory. So the maximal amount of available memory is dictated by memory fragmentation. Especially driver's dlls tend to fragment the memory, when loading into some predefined base address. So your hardware and its drivers determine how much memory you can get. \nTwo sources for this with statements from Sun engineers: forum blog\nMaybe another JVM? Have you tried Harmony? I think they planned to allow non-continuous memory.\n",
            "\nI think it has more to do with how Windows is configured as hinted by this response:\nJava -Xmx Option\nSome more testing: I was able to allocate 1300MB on an old Windows XP machine with only 768MB physical RAM (plus virtual memory). On my 2GB RAM machine I can only get 1220MB. On various other corporate machines (with older Windows XP) I was able to get 1400MB. The machine with a 1220MB limit is pretty new (just purchased from Dell), so maybe it has newer (and more bloated) Windows and DLLs (it's running Window XP Pro Version 2002 SP2).\n"
        ],
        "answer": "A1",
        "tags": [
            "java",
            "windows",
            "memory"
        ]
    },
    {
        "question_id": "821692",
        "question": "\nWhat does \"nonatomic\" mean in this code?\n@property(nonatomic, retain) UITextField *theUsersName;\n\nWhat is the difference between atomic and nonatomic?\nThanks\n",
        "all_answers": [
            "\nUsually atomic means that writes/reads to the property happen as a single operation.\nAtomic_operation\n",
            "\nIf you specify \"atomic\", the generated access functions have some extra code to guard against simultaneous updates.\n",
            "\nIn a multi-threaded program, an atomic operation cannot be interrupted partially through, whereas nonatomic operations can.\nTherefore, you should use mutexes (or something like that) if you have a critical operation that is nonatomic that you don't want interrupted.\n",
            "\nTake a look at the Apple Docs.\nBasically, if you say nonatomic, and you generate the accessors using @synthesize, then if multiple threads try to change/read the property at once, badness can happen. You can get partially-written values or over-released/retained objects, which can easily lead to crashes. (This is potentially a lot faster than an atomic accessor, though.)\nIf you use the default (which is atomic; there used to be no keyword for this, but there is now), then the @synthesized methods use an object-level lock to ensure that multiple reads/writes to a single property are serialized. As the Apple docs point out, this doesn't mean the whole object is thread-safe, but the individual property reads/writes are.\nOf course, if you implement your own accessors rather than using @synthesize, I think these declarations do nothing except express your intent as to whether the property is implemented in a threadsafe manner.\n"
        ],
        "answer": "A4",
        "tags": [
            "ios",
            "objective-c",
            "iphone",
            "cocoa",
            "properties"
        ]
    },
    {
        "question_id": "2118090",
        "question": "\nI'm currently working on a wireless networking application in C++ and it's coming to a point where I'm going to want to multi-thread pieces of software under one process, rather than have them all in separate processes.  Theoretically, I understand multi-threading, but I've yet to dive in practically.  \nWhat should every programmer know when writing multi-threaded code in C++?\n",
        "all_answers": [
            "\nYou should read about locks, mutexes, semaphores and condition variables. \nOne word of advice, if your app has any form of UI make sure you always change it from the UI thread. Most UI toolkits/frameworks will crash (or behave unexpectedly) if you access them from a background thread. Usually they provide some form of dispatching method to execute some function in the UI thread.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nI am no expert at all in this subject. Just some rule of thumb:\n\nDesign for simplicity, bugs really are hard to find in concurrent code even in the simplest examples.\nC++ offers you a very elegant paradigm to manage resources(mutex, semaphore,...): RAII. I observed that it is much easier to work with boost::thread than to work with POSIX threads.\nBuild your code as thread-safe. If you don't do so, your program could behave strangely\n\n",
            "\nI would focus on design the thing as much as partitioned as possible so you have the minimal amount of shared things across threads. If you make sure you don't have statics and other resources shared among threads (other than those that you would be sharing if you designed this with processes instead of threads) you would be fine.\nTherefore, while yes, you have to have in mind concepts like locks, semaphores, etc, the best way to tackle this is to try to avoid them.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n"
        ],
        "answer": "A4",
        "tags": [
            "c++",
            "multithreading"
        ]
    },
    {
        "question_id": "8220801",
        "question": "\nHow do I use timeit to compare the performance of my own functions such as \"insertion_sort\" and \"tim_sort\"?\n",
        "all_answers": [
            "\nThe way timeit works is to run setup code once and then make repeated calls to a series of statements.  So, if you want to test sorting, some care is required so that one pass at an in-place sort doesn't affect the next pass with already sorted data (that, of course, would make the Timsort really shine because it performs best when the data already partially ordered).\nHere is an example of how to set up a test for sorting:\n>>> import timeit\n\n>>> setup = '''\nimport random\n\nrandom.seed('slartibartfast')\ns = [random.random() for i in range(1000)]\ntimsort = list.sort\n'''\n\n>>> print min(timeit.Timer('a=s[:]; timsort(a)', setup=setup).repeat(7, 1000))\n0.334147930145\n\nNote that the series of statements makes a fresh copy of the unsorted data on every pass.\nAlso, note the timing technique of running the measurement suite seven times and keeping only the best time -- this can really help reduce measurement distortions due to other processes running on your system.\nThose are my tips for using timeit correctly.\n",
            "\nPython 3 only:\nSince time.clock() is deprecated as of Python 3.3, you will want to use time.perf_counter() for system-wide timing, or time.process_time() for process-wide timing, just the way you used to use time.clock():\nimport time\n\nt = time.process_time()\n#do some stuff\nelapsed_time = time.process_time() - t\n\nThe new function process_time will not include time elapsed during sleep.\n",
            "\nI find the easiest way to use timeit is from the command line:\nGiven test.py:\ndef InsertionSort(): ...\ndef TimSort(): ...\n\nrun timeit like this:\n% python -mtimeit -s'import test' 'test.InsertionSort()'\n% python -mtimeit -s'import test' 'test.TimSort()'\n\n",
            "\nUse time.time() to measure the elapsed wall-clock time between two points:\nimport time\n\nstart = time.time()\nprint(\"hello\")\nend = time.time()\nprint(end - start)\n\nThis gives the execution time in seconds.\n\nAnother option since Python 3.3 might be to use perf_counter or process_time, depending on your requirements. Before 3.3 it was recommended to use time.clock (thanks Amber). However, it is currently deprecated:\n\nOn Unix, return the current processor time as a floating point number\nexpressed in seconds. The precision, and in fact the very definition\nof the meaning of “processor time”, depends on that of the C function\nof the same name.\nOn Windows, this function returns wall-clock seconds elapsed since the\nfirst call to this function, as a floating point number, based on the\nWin32 function QueryPerformanceCounter(). The resolution is typically\nbetter than one microsecond.\nDeprecated since version 3.3: The behaviour of this function depends\non the platform: use perf_counter() or process_time() instead,\ndepending on your requirements, to have a well defined behaviour.\n\n",
            "\nUse timeit.default_timer instead of timeit.timeit. The former provides the best clock available on your platform and version of Python automatically:\nfrom timeit import default_timer as timer\n\nstart = timer()\n# ...\nend = timer()\nprint(end - start) # Time in seconds, e.g. 5.38091952400282\n\ntimeit.default_timer is assigned to time.time() or time.clock() depending on OS. On Python 3.3+ default_timer is time.perf_counter() on all platforms. See Python - time.clock() vs. time.time() - accuracy?\nSee also:\n\nOptimizing code\nHow to optimize for speed\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "time",
            "timeit"
        ]
    },
    {
        "question_id": "4380879",
        "question": "\nI have a model that I would like to contain a subjects name and their initials (he data is somewhat anonymized and tracked by initials).\nRight now, I wrote\nclass Subject(models.Model):\n\n    name = models.CharField(\"Name\", max_length=30)\n    def subject_initials(self):\n        return ''.join(map(lambda x: '' if len(x)==0 else x[0],\n                           self.name.split(' ')))\n    # Next line is what I want to do (or something equivalent), but doesn't work with\n    # NameError: name 'self' is not defined\n    subject_init = models.CharField(\"Subject Initials\", max_length=5, default=self.subject_initials)\n\nAs indicated by the last line, I would prefer to be able to have the initials actually get stored in the database as a field (independent of name), but that is initialized with a default value based on the name field.  However, I am having issues as django models don't seem to have a 'self'.\nIf I change the line to subject_init = models.CharField(\"Subject initials\", max_length=2, default=subject_initials), I can do the syncdb, but can't create new subjects.\nIs this possible in Django, having a callable function give a default to some field based on the value of another field?\n(For the curious, the reason I want to separate my store initials separately is in rare cases where weird last names may have different than the ones I am tracking.  E.g., someone else decided that Subject 1 Named \"John O'Mallory\" initials are \"JM\" rather than \"JO\" and wants to fix edit it as an administrator.)\n",
        "all_answers": [
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nI don't know if there is a better way of doing this, but you can use a signal handler for the pre_save signal:\nfrom django.db.models.signals import pre_save\n\ndef default_subject(sender, instance, using):\n    if not instance.subject_init:\n        instance.subject_init = instance.subject_initials()\n\npre_save.connect(default_subject, sender=Subject)\n\n",
            "\nModels certainly do have a \"self\"!  It's just that you're trying to define an attribute of a model class as being dependent upon a model instance; that's not possible, as the instance does not (and cannot) exist before your define the class and its attributes.\nTo get the effect you want, override the save() method of the model class.  Make any changes you want to the instance necessary, then call the superclass's method to do the actual saving.  Here's a quick example.\ndef save(self, *args, **kwargs):\n    if not self.subject_init:\n        self.subject_init = self.subject_initials()\n    super(Subject, self).save(*args, **kwargs)\n\nThis is covered in Overriding Model Methods in the documentation.\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "django",
            "django-models"
        ]
    },
    {
        "question_id": "2852748",
        "question": "\nI have just installed Debian Lenny with Apache, MySQL, and PHP and I am receiving a PDOException could not find driver.\nThis is the specific line of code it is referring to:\n$dbh = new PDO('mysql:host=' . DB_HOST . ';dbname=' . DB_NAME, DB_USER, DB_PASS)\nDB_HOST, DB_NAME, DB_USER, and DB_PASS are constants that I have defined. It works fine on the production server (and on my previous Ubuntu Server setup).\nIs this something to do with my PHP installation?\nSearching the internet has not helped, all I get is experts-exchange and examples, but no solutions.\n",
        "all_answers": [
            "\nI assume you mean that you want the final SQL query, with parameter values interpolated into it.  I understand that this would be useful for debugging, but it is not the way prepared statements work.  Parameters are not combined with a prepared statement on the client-side, so PDO should never have access to the query string combined with its parameters.\nThe SQL statement is sent to the database server when you do prepare(), and the parameters are sent separately when you do execute().  MySQL's general query log does show the final SQL with values interpolated after you execute().  Below is an excerpt from my general query log.  I ran the queries from the mysql CLI, not from PDO, but the principle is the same.\n081016 16:51:28 2 Query       prepare s1 from 'select * from foo where i = ?'\n                2 Prepare     [2] select * from foo where i = ?\n081016 16:51:39 2 Query       set @a =1\n081016 16:51:47 2 Query       execute s1 using @a\n                2 Execute     [2] select * from foo where i = 1\n\nYou can also get what you want if you set the PDO attribute PDO::ATTR_EMULATE_PREPARES.  In this mode, PDO interpolate parameters into the SQL query and sends the whole query when you execute().  This is not a true prepared query.  You will circumvent the benefits of prepared queries by interpolating variables into the SQL string before execute().\n\nRe comment from @afilina:\nNo, the textual SQL query is not combined with the parameters during execution. So there's nothing for PDO to show you.\nInternally, if you use PDO::ATTR_EMULATE_PREPARES, PDO makes a copy of the SQL query and interpolates parameter values into it before doing the prepare and execute. But PDO does not expose this modified SQL query. \nThe PDOStatement object has a property $queryString, but this is set only in the constructor for the PDOStatement, and it's not updated when the query is rewritten with parameters.\nIt would be a reasonable feature request for PDO to ask them to expose the rewritten query. But even that wouldn't give you the \"complete\" query unless you use PDO::ATTR_EMULATE_PREPARES.\nThis is why I show the workaround above of using the MySQL server's general query log, because in this case even a prepared query with parameter placeholders is rewritten on the server, with parameter values backfilled into the query string. But this is only done during logging, not during query execution.\n",
            "\nYou need to have a module called pdo_mysql. Looking for following in phpinfo(),\npdo_mysql\n\nPDO Driver for MySQL, client library version => 5.1.44\n\n",
            "\nDid you check your php.ini (check for the correct location with phpinfo()) if MySQL and the driver is installed correctly?\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "mysql",
            "pdo",
            "lamp"
        ]
    },
    {
        "question_id": "3896537",
        "question": "\nEvery time I develop a new form that includes a textarea I have the following dilemma when I need to specify its dimensions:\nUse CSS or use the textarea's attributes cols and rows?\nWhat are the pros and cons of each method?\nWhat are the semantics of using these attributes?\nHow is it usually done?\n",
        "all_answers": [
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nAccording to the w3c, cols and rows are both required attributes for textareas.  Rows and Cols are the number of characters that are going to fit in the textarea rather than pixels or some other potentially arbitrary value.  Go with the rows/cols.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nI recommend to use both. Rows and cols are required and useful if the client does not support CSS. But as a designer I overwrite them to get exactly the size I wish. \nThe recommended way to do it is via an external stylesheet e.g.\n\n\ntextarea {\r\n  width: 300px;\r\n  height: 150px;\r\n}\n<textarea> </textarea>\n\n\n\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n"
        ],
        "answer": "A4",
        "tags": [
            "html",
            "css",
            "textarea"
        ]
    },
    {
        "question_id": "3167824",
        "question": "\nI have a form in my Django app (not in admin) that allows staff members to select a user from a dropdown.\nforms.ModelChoiceField(queryset = User.objects.filter(is_staff=False), required = False)\n\nThe problem is that the dropdown shows users by usernames whereas I'd rather it show their full name from user.get_full_name() and use username only if that is not available. I only really need this change on this page, in other places like admin, I don't care if it uses username.\nIs there a way I can do this?\nThanks!\n",
        "all_answers": [
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nYou can override the field with a custom ModelChoiceField and change the label_from_instance function to return get_full_name instead.  See the docs for ModelChoiceField: http://docs.djangoproject.com/en/1.2/ref/forms/fields/#modelchoicefield\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n",
            "\nYou can setup a custom ModelChoiceField that will return whatever label you'd like.\nPlace something like this within a fields.py or wherever applicable.\nclass UserModelChoiceField(ModelChoiceField):\n    def label_from_instance(self, obj):\n         return obj.get_full_name()\n\nThen when creating your form, simply use that field\n UserModelChoiceField(queryset=User.objects.filter(is_staff=False), required = False)\n\nMore info can be found here\n",
            "\nsettings.py\nALLOWED_HOSTS = ['*'] // if you are in dev or docker\n\nEdited\nOk guys, dont do this in production if you are not using docker, just put the IP addr.\nGrettings\n",
            "\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['62.63.141.41', 'namjoosadr.com']\n\nand then restart your apache. in ubuntu:\n/etc/init.d/apache2 restart\n\n"
        ],
        "answer": "A6",
        "tags": [
            "python",
            "django",
            "django-forms",
            "django-authentication"
        ]
    },
    {
        "question_id": "2717590",
        "question": "\nMySQL has something like this:\nINSERT INTO visits (ip, hits)\nVALUES ('127.0.0.1', 1)\nON DUPLICATE KEY UPDATE hits = hits + 1;\n\nAs far as I know this feature doesn't exist in SQLite, what I want to know is if there is any way to achive the same effect without having to execute two queries. Also, if this is not possible, what do you prefer:\n\nSELECT + (INSERT or UPDATE) or\nUPDATE (+ INSERT if UPDATE fails)\n\n",
        "all_answers": [
            "\nI'd prefer UPDATE (+ INSERT if UPDATE fails). Less code = fewer bugs.\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nThe current answer will only work in sqlite OR mysql (depending on if you use OR or not).  So, if you want cross dbms compatibility, the following will do...\nREPLACE INTO `visits` (ip, value) VALUES ($ip, 0);\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nINSERT OR IGNORE INTO visits VALUES ($ip, 0);\nUPDATE visits SET hits = hits + 1 WHERE ip LIKE $ip;\n\nThis requires the \"ip\" column to have a UNIQUE (or PRIMARY KEY) constraint.\n\nEDIT: Another great solution: https://stackoverflow.com/a/4330694/89771.\n",
            "\nSince 3.24.0 SQLite also supports upsert, so now you can simply write the following\nINSERT INTO visits (ip, hits)\nVALUES ('127.0.0.1', 1)\nON CONFLICT(ip) DO UPDATE SET hits = hits + 1;\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n"
        ],
        "answer": "A8",
        "tags": [
            "sql",
            "mysql",
            "database",
            "sqlite",
            "upsert"
        ]
    },
    {
        "question_id": "5180382",
        "question": "\n\n\n\nIs there any jQuery or javascript library that generates a dynamic table given json data?\nI don't want to define the columns, the library should read the keys in the json hash and generate columns.\nOf course, I can myself iterate through the json data and generate the html table. I just want to know if any such library exists which I can simply reuse.\n",
        "all_answers": [
            "\nCheck out JSON2HTML http://json2html.com/ plugin for jQuery. It allows you to specify a transform that would convert your JSON object to HTML template. Use builder on http://json2html.com/ to get json transform object for any desired html template. In your case, it would be a table with row having following transform.\nExample: \nvar transform = {\"tag\":\"table\", \"children\":[\n    {\"tag\":\"tbody\",\"children\":[\n        {\"tag\":\"tr\",\"children\":[\n            {\"tag\":\"td\",\"html\":\"${name}\"},\n            {\"tag\":\"td\",\"html\":\"${age}\"}\n        ]}\n    ]}\n]};\n\nvar data = [\n    {'name':'Bob','age':40},\n    {'name':'Frank','age':15},\n    {'name':'Bill','age':65},\n    {'name':'Robert','age':24}\n];\n\n$('#target_div').html(json2html.transform(data,transform));\n\n",
            "\nThanks all for your replies. I wrote one myself. Please note that this uses jQuery.\nCode snippet:\n\n\nvar myList = [\r\n  { \"name\": \"abc\", \"age\": 50 },\r\n  { \"age\": \"25\", \"hobby\": \"swimming\" },\r\n  { \"name\": \"xyz\", \"hobby\": \"programming\" }\r\n];\r\n\r\n// Builds the HTML Table out of myList.\r\nfunction buildHtmlTable(selector) {\r\n  var columns = addAllColumnHeaders(myList, selector);\r\n\r\n  for (var i = 0; i < myList.length; i++) {\r\n    var row$ = $('<tr/>');\r\n    for (var colIndex = 0; colIndex < columns.length; colIndex++) {\r\n      var cellValue = myList[i][columns[colIndex]];\r\n      if (cellValue == null) cellValue = \"\";\r\n      row$.append($('<td/>').html(cellValue));\r\n    }\r\n    $(selector).append(row$);\r\n  }\r\n}\r\n\r\n// Adds a header row to the table and returns the set of columns.\r\n// Need to do union of keys from all records as some records may not contain\r\n// all records.\r\nfunction addAllColumnHeaders(myList, selector) {\r\n  var columnSet = [];\r\n  var headerTr$ = $('<tr/>');\r\n\r\n  for (var i = 0; i < myList.length; i++) {\r\n    var rowHash = myList[i];\r\n    for (var key in rowHash) {\r\n      if ($.inArray(key, columnSet) == -1) {\r\n        columnSet.push(key);\r\n        headerTr$.append($('<th/>').html(key));\r\n      }\r\n    }\r\n  }\r\n  $(selector).append(headerTr$);\r\n\r\n  return columnSet;\r\n}\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\r\n\r\n<body onLoad=\"buildHtmlTable('#excelDataTable')\">\r\n  <table id=\"excelDataTable\" border=\"1\">\r\n  </table>\r\n</body>\n\n\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "html",
            "json",
            "html-table"
        ]
    },
    {
        "question_id": "4386168",
        "question": "\nI want to concatenate a string in a Django template tag, like:\n{% extend shop/shop_name/base.html %}\n\nHere shop_name is my variable and I want to concatenate this with rest of path.\nSuppose I have shop_name=example.com and I want result to extend shop/example.com/base.html.\n",
        "all_answers": [
            "\nUse with:\n{% with \"shop/\"|add:shop_name|add:\"/base.html\" as template %}\n{% include template %}\n{% endwith %}\n\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nHave a look at the add filter.\nEdit: You can chain filters, so you could do \"shop/\"|add:shop_name|add:\"/base.html\". But that won't work because it is up to the template tag to evaluate filters in arguments, and extends doesn't.\nI guess you can't do this within templates.\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nYou can't do variable manipulation in django templates. \nYou have two options, either write your own template tag or do this in view,    \n",
            "\nextends has no facility for this. Either put the entire template path in a context variable and use that, or copy the exist template tag and modify it appropriately.\n",
            "\nI have changed the folder hierarchy \n\n/shop/shop_name/base.html To /shop_name/shop/base.html\n\nand then below would work.\n{% extends shop_name|add:\"/shop/base.html\"%} \n\nNow its able to extend the base.html page.\n",
            "\nFrom the docs:\nThis tag can be used in two ways:\n\n{% extends \"base.html\" %} (with quotes) uses the literal value \"base.html\" as the name of the parent template to extend.\n{% extends variable %} uses the value of variable. If the variable evaluates to a string, Django will use that string as the name of the parent template. If the variable evaluates to a Template object, Django will use that object as the parent template.\n\nSo seems like you can't use a filter to manipulate the argument. In the calling view you have to either instantiate the ancestor template or create an string variable with the correct path and pass it with the context.\n"
        ],
        "answer": "A1",
        "tags": [
            "django",
            "django-templates"
        ]
    },
    {
        "question_id": "26189409",
        "question": "\nHow do I do this in Swift ?\n(someboolexpression ? \"Return value 1\" : \"Return value 2\")\n\n(no I have not read the whole manual yet... I probably missed it on page 2!)\nOK so its on page 91 and the above appears to be correct.  However I am trying to use this in a string like so:\nprintln(\" some string \\(some expression ? \"Return value 1\" : \"Return value 2\")\"\n\nbut the compiler is not happy.  Any idea if this if possible?\nThis is as close as I have been able to get\nlet exists = \"exists\"\nlet doesnotexist= \"does not exist\"\n\nprintln(\"  something \\(fileExists ? exists : doesnotexist)\")\n\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nYou were oh so close. Just needed to assign it to a variable:\nself.automaticOption = (automaticOptionOfCar ? \"Automatic\" : \"Manual\")\n\nEdit:\n\nAny idea why that same expression can't be embedded in a string?\n\nYou can do that:\nlet a = true\nlet b = 1\nlet c = 2\n\nprintln(\"\\(a ? 1: 2)\")\n\n",
            "\nIf you're looking for a one-liner to do that, you can pull the ?: operation out of the string interpolation and concatenate with + instead:\nlet fileExists = false // for example\nprintln(\"something \" + (fileExists ? \"exists\" : \"does not exist\"))\n\nOutputs:\n\nsomething does not exist\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n"
        ],
        "answer": "A4",
        "tags": [
            "swift",
            "conditional-statements"
        ]
    },
    {
        "question_id": "1285911",
        "question": "\nI want to do something like:\nfoo = {\n    'foo': 1,\n    'zip': 2,\n    'zam': 3,\n    'bar': 4\n}\n\nif (\"foo\", \"bar\") in foo:\n    #do stuff\n\nHow do I check whether both foo and bar are in dict foo?\n",
        "all_answers": [
            "\nThis should work:\nif all(key in foo for key in [\"foo\",\"bar\"]):\n    # do stuff\n    pass\n\n\nHint:\nUsing square brackets inside all() to make a list comprehension:\nif all([key in foo for key in [\"foo\",\"bar\"]]):\n\nIs not only unnecessary, but it is positively harmful, as they impede the normal short-circuiting behavior of all().\n",
            "\nWell, you could do this:\n>>> if all(k in foo for k in (\"foo\",\"bar\")):\n...     print \"They're there!\"\n...\nThey're there!\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "dictionary"
        ]
    },
    {
        "question_id": "28795166",
        "question": "\nI got this error this morning and can't find a reasonable explanation:\nCommunications error: <OS_xpc_error: <error: 0x3b3c2614> { count = 1, contents =\n    \"XPCErrorDescription\" => <string: 0x3b3c286c> { length = 22, contents = \"Connection interrupted\" }\n}>\n\nI think this happen when I am taking a photo. I can show the complete snippet upon request. However, it's example code from a tutorial. It only showed up once, and there is not much explanation online either.\nI have turned on breakpoint at all exception and symbolic breakpoint at UIViewAlertForUnsatisfiableConstraints. But this error showed too without these breakpoints set.\nNeither of the breakpoint invoked when this error showed up.\nWhat is this?\n",
        "all_answers": [
            "\nI encountered the same Error.\nMy mistake was to load an URL of a specific gif (http://whyd.com/uCoverImg/bd1833e6afe5a8ae9c9aff4177d3f80d_960x.gif) with SDWebImage in a imageView\nNSURL *url = NSURL urlFromString:@\"image.gif\"];\n[myImageView sd_setImageWithURL:imageCoverUrl];\n\nThis crash isn't exist for all GIF pictures, I have to find the right rule\n",
            "\nXPC is Apple's inter-process communication (IPC) system. Some functionality (such as h.264 encoding/decoding, or interacting with camera hardware) is handled by a separate app - a daemon - that runs all the time in the background.\nConnection interrupted means that the IPC connection was interrupted for some reason. Perhaps it took too long, perhaps the timing was just bad and the daemon or your app needed to urgently do something else.\nIt's probably not an error per se. When dealing with IPC, the daemon should be considered a black box, and your connection to it, somewhat flimsy. In this case you're talking to the daemon indirectly (via Apple's libraries), and it's likely they've designed it to work asynchronously and automatically recover from errors. \n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "xcode",
            "swift"
        ]
    },
    {
        "question_id": "559363",
        "question": "\nHow can I match a space character in a PHP regular expression?\nI mean like \"gavin schulz\", the space in between the two words. I am using a regular expression to make sure that I only allow letters, number and a space. But I'm not sure how to find the space. This is what I have right now:\n$newtag = preg_replace(\"/[^a-zA-Z0-9s|]/\", \"\", $tag);\n\n",
        "all_answers": [
            "\nIt seems to me like using a REGEX in this case would just be overkill.  Why not just just strpos to find the space character.  Also, there's nothing special about the space character in regular expressions, you should be able to search for it the same as you would search for any other character.  That is, unless you disabled pattern whitespace, which would hardly be necessary in this case.\n",
            "\nIn Perl the switch is \\s (whitespace).\n",
            "\nIf you're looking for a space, that would be \" \" (one space).\nIf you're looking for one or more, it's \"  *\" (that's two spaces and an asterisk) or \" +\" (one space and a plus).\nIf you're looking for common spacing, use \"[ X]\" or \"[ X][ X]*\" or \"[ X]+\" where X is the physical tab character (and each is preceded by a single space in all those examples).\nThese will work in every* regex engine I've ever seen (some of which don't even have the one-or-more \"+\" character, ugh).\nIf you know you'll be using one of the more modern regex engines, \"\\s\" and its variations are the way to go. In addition, I believe word boundaries match start and end of lines as well, important when you're looking for words that may appear without preceding or following spaces.\nFor PHP specifically, this page may help.\nFrom your edit, it appears you want to remove all non valid characters The start of this is (note the space inside the regex):\n$newtag = preg_replace (\"/[^a-zA-Z0-9 ]/\", \"\", $tag);\n#                                    ^ space here\n\nIf you also want trickery to ensure there's only one space between each word and none at the start or end, that's a little more complicated (and probably another question) but the basic idea would be:\n$newtag = preg_replace (\"/ +/\", \" \", $tag); # convert all multispaces to space\n$newtag = preg_replace (\"/^ /\", \"\", $tag);  # remove space from start\n$newtag = preg_replace (\"/ $/\", \"\", $tag);  # and end\n\n",
            "\nYou can also use the \\b for a word boundary.  For the name I would use something like this:\n[^\\b]+\\b[^\\b]+(\\b|$)\n\nEDIT Modifying this to be a regex in Perl example\nif( $fullname =~ /([^\\b]+)\\b[^\\b]+([^\\b]+)(\\b|$)/ ) {\n $first_name = $1;\n $last_name = $2;\n}\n\nEDIT AGAIN Based on what you want:\n$new_tag = preg_replace(\"/[\\s\\t]/\",\"\",$tag);\n\n",
            "\nTo match exactly the space character, you can use the octal value \\040 (Unicode characters displayed as octal) or the hexadecimal value \\x20 (Unicode characters displayed as hex).\nHere is the regex syntax reference: https://www.regular-expressions.info/nonprint.html.\n"
        ],
        "answer": "A3",
        "tags": [
            "php",
            "regex"
        ]
    },
    {
        "question_id": "8563535",
        "question": "\nI have a variable called $final_time_saving which is just a number of minutes, 250 for example. \nHow can I convert that number of minutes into hours and minutes using PHP in this format: \n4 hours 10 minutes\n",
        "all_answers": [
            "\n$hours = floor($final_time_saving / 60);\n$minutes = $final_time_saving % 60;\n\n",
            "\n<?php\n\nfunction convertToHoursMins($time, $format = '%02d:%02d') {\n    if ($time < 1) {\n        return;\n    }\n    $hours = floor($time / 60);\n    $minutes = ($time % 60);\n    return sprintf($format, $hours, $minutes);\n}\n\necho convertToHoursMins(250, '%02d hours %02d minutes'); // should output 4 hours 17 minutes\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "time"
        ]
    },
    {
        "question_id": "1508572",
        "question": "\nIt's a very simple problem that I have. I use XDocument to generate an XML file. I then want to return it as a XmlDocument class.\nAnd I have an XmlDocument variable which I need to convert back to XDocument to append more nodes.\nSo, what is the most efficient method to convert XML between XDocument and XmlDocument? (Without using any temporary storage in a file.)\n",
        "all_answers": [
            "\nYou could try writing the XDocument to an XmlWriter piped to an XmlReader for an XmlDocument.\nIf I understand the concepts properly, a direct conversion is not possible (the internal structure is different / simplified with XDocument). But then, I might be wrong...\n",
            "\nYou can use the built in xDocument.CreateReader() and an XmlNodeReader to convert back and forth.\nPutting that into an Extension method to make it easier to work with.\nusing System;\nusing System.Xml;\nusing System.Xml.Linq;\n\nnamespace MyTest\n{\n    internal class Program\n    {\n        private static void Main(string[] args)\n        {\n\n            var xmlDocument = new XmlDocument();\n            xmlDocument.LoadXml(\"<Root><Child>Test</Child></Root>\");\n\n            var xDocument = xmlDocument.ToXDocument();\n            var newXmlDocument = xDocument.ToXmlDocument();\n            Console.ReadLine();\n        }\n    }\n\n    public static class DocumentExtensions\n    {\n        public static XmlDocument ToXmlDocument(this XDocument xDocument)\n        {\n            var xmlDocument = new XmlDocument();\n            using(var xmlReader = xDocument.CreateReader())\n            {\n                xmlDocument.Load(xmlReader);\n            }\n            return xmlDocument;\n        }\n\n        public static XDocument ToXDocument(this XmlDocument xmlDocument)\n        {\n            using (var nodeReader = new XmlNodeReader(xmlDocument))\n            {\n                nodeReader.MoveToContent();\n                return XDocument.Load(nodeReader);\n            }\n        }\n    }\n}\n\nSources:\n\nhttp://msdn.microsoft.com/en-us/library/bb356384.aspx\nLink\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "xml",
            "linq-to-xml"
        ]
    },
    {
        "question_id": "12258399",
        "question": "\nI want to create a folder in a GitHub repository and want to add files in that folder. How do I achieve this?\n",
        "all_answers": [
            "\nGit doesn't store empty folders. Just make sure there's a file in the folder like doc/foo.txt and run git add doc or git add doc/foo.txt, and the folder will be added to your local repository once you've committed (and appear on GitHub once you've pushed it).\n",
            "\nTL;DR Use / in the file name field to create folder(s), e.g. typing folder1/file1 in the file name field will create a folder folder1 and a file file1.\nOriginal answer\nYou cannot create an empty folder and then add files to that folder, but rather creation of a folder must happen together with adding of at least a single file. This is because git doesn't track empty folders.\nOn GitHub you can do it this way:\n\nGo to the folder inside which you want to create another folder\nClick on New file\nOn the text field for the file name, first write the folder name you want to create\nThen type /. This creates a folder\nYou can add more folders similarly\nFinally, give the new file a name (for example, .gitkeep which is conventionally used to make Git track otherwise empty folders; it is not a Git feature though)\nFinally, click Commit new file.\n\n",
            "\nYou just create the required folders in your local repository. For example, you created the app and config directories.\nYou may create new files under these folders.\nFor Git rules:\n\nFirst we need to add files to the directory.\nThen commit those added files.\n\nGit command to do commit:\n\ngit add app/ config/\ngit commit\n\nThen give the commit message and save the commit.\nThen push to your remote repository,\ngit push origin remote\n\n",
            "\nFirst you have to clone the repository to you local machine\ngit clone github_url local_directory\n\nThen you can create local folders and files inside your local_directory, and add them to the repository using:\ngit add file_path\n\nYou can also add everything using:\ngit add .\n\nNote that Git does not track empty folders. A workaround is to create a file inside the empty folder you want to track. I usually name that file empty, but it can be whatever name you choose.\nFinally, you commit and push back to GitHub:\ngit commit\ngit push\n\nFor more information on Git, check out the Pro Git book.\n"
        ],
        "answer": "A2",
        "tags": [
            "github",
            "github-services"
        ]
    },
    {
        "question_id": "2109756",
        "question": "\nHow can I get a color from a hexadecimal color code (e.g. #FFDFD991)?\nI am reading a file and am getting a hexadecimal color code. I need to create the corresponding System.Windows.Media.Color instance for the hexadecimal color code. Is there an inbuilt method in the framework to do this?\n",
        "all_answers": [
            "\nAssuming you mean the HTML type RGB codes (called Hex codes, such as #FFCC66), use the ColorTranslator class:\nSystem.Drawing.Color col = System.Drawing.ColorTranslator.FromHtml(\"#FFCC66\");\n\nIf, however you are using an ARGB hex code, you can use the ColorConverter class from the System.Windows.Media namespace:\nColor col = ColorConverter.ConvertFromString(\"#FFDFD991\") as Color;\n//or      = (Color) ColorConverter.ConvertFromString(\"#FFCC66\") ;\n\n",
            "\nFor desktop versions of .NET:\nSystem.Diagnostics.Process.Start(\"http://www.webpage.com\");\n\nFor .NET Core, the default for ProcessStartInfo.UseShellExecute has changed from true to false, and so you have to explicitly set it to true for this to work:\nSystem.Diagnostics.Process.Start(new ProcessStartInfo\n    {\n        FileName = \"http://www.webpage.com\",\n        UseShellExecute = true\n    });\n\nTo further complicate matters, this property cannot be set to true for UWP apps (so none of these solutions are usable for UWP).\n",
            "\nI'm assuming that's an ARGB code... Are you referring to System.Drawing.Color or System.Windows.Media.Color? The latter is used in WPF for example. I haven't seen anyone mention it yet, so just in case you were looking for it:\nusing System.Windows.Media;\n\nColor color = (Color)ColorConverter.ConvertFromString(\"#FFDFD991\");\n\n",
            "\nIf you don't want to use the ColorTranslator, you can do it in easily:\nstring colorcode = \"#FFFFFF00\";\nint argb = Int32.Parse(colorcode.Replace(\"#\", \"\"), NumberStyles.HexNumber);\nColor clr = Color.FromArgb(argb);\n\nThe colorcode is just the hexadecimal representation of the ARGB value.\nEDIT\nIf you need to use 4 values instead of a single integer, you can use this (combining several comments):\nstring colorcode = \"#FFFFFF00\";    \ncolorcode = colorcode.TrimStart('#');\n\nColor col; // from System.Drawing or System.Windows.Media\nif (colorcode.Length == 6)\n    col = Color.FromArgb(255, // hardcoded opaque\n                int.Parse(colorcode.Substring(0,2), NumberStyles.HexNumber),\n                int.Parse(colorcode.Substring(2,2), NumberStyles.HexNumber),\n                int.Parse(colorcode.Substring(4,2), NumberStyles.HexNumber));\nelse // assuming length of 8\n    col = Color.FromArgb(\n                int.Parse(colorcode.Substring(0, 2), NumberStyles.HexNumber),\n                int.Parse(colorcode.Substring(2, 2), NumberStyles.HexNumber),\n                int.Parse(colorcode.Substring(4, 2), NumberStyles.HexNumber),\n                int.Parse(colorcode.Substring(6, 2), NumberStyles.HexNumber));\n\nNote 1: NumberStyles is in System.Globalization.\nNote 2: please provide your own error checking (colorcode should be a hexadecimal value of either 6 or 8 characters)\n",
            "\nUse\nSystem.Drawing.Color.FromArgb(myHashCode);\n\n",
            "\nIf you mean HashCode as in .GetHashCode(), I'm afraid you can't go back. Hash functions are not bi-directional, you can go 'forward' only, not back.\nFollow Oded's suggestion if you need to get the color based on the hexadecimal value of the color.\n",
            "\nAccepted answer no longer works on .NET Core 3. To make it work, use the following method:\nvar psi = new ProcessStartInfo\n{\n    FileName = url,\n    UseShellExecute = true\n};\nProcess.Start (psi);\n\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "wpf",
            "colors",
            "hex"
        ]
    },
    {
        "question_id": "13687334",
        "question": "\n\n\n\n\nPossible Duplicate:\nMove existing, uncommited work to a new branch in Git \n\nI have some code in branch ABC. \nAfter making some changes to it, i'd like to move all those uncommitted changes into a commit on a new branch ABC_1.\nHow can this be done please?\n",
        "all_answers": [
            "\nJust create a new branch:\ngit checkout -b newBranch\n\nAnd if you do git status you'll see that the state of the code hasn't changed and you can commit it to the new branch.\n",
            "\nI have experienced the same situation I did the below as this much easier.\nBy passing commit-Id you can reach to the particular commit you want to go:\ngit reset --hard {commit-id}\n\nAs you want to remove your last commit so you need to pass the commit-Id where you need to move your pointer:\ngit reset --hard db0c078d5286b837532ff5e276dcf91885df2296\n\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nJust move to the new branch. The uncommited changes get carried over.\ngit checkout -b ABC_1\n\ngit commit -m <message>\n\n",
            "\nJust create a new branch with git checkout -b ABC_1; your uncommitted changes will be kept, and you then commit them to that branch.\n",
            "\nRemove the last commit before push\ngit reset --soft HEAD~1\n1 means the last commit, if you want to remove two last use 2, and so forth*\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n"
        ],
        "answer": "A1",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "2590850",
        "question": "\nFrom what I understand, the entire client side of a GWT application is converted to Javascript when you build, therefore I suppose this question is related to both Javascript and the possibilities that GWT offers.\nI have a couple of dozen processes that will need to be initiated in my GWT application, each process will then continuously make calls to a server. Does GWT support threading? Does the GWT client side support threading?\nEDIT:\nThis link states:\nNo JavaScript knowledge required If you’re just a user of the framework, \nwhich I am for the matter of discussion, you do not need to know JavaScript \nin order to write dynamic content, be it client-side such as rolling frames, \ndocking panels or scheduled “multi-threading” tasks, or server-side calls \nusing XMLHttpRequests (aka AJAX). \n\nor scheduled “multi-threading” tasks, what does this mean?\n",
        "all_answers": [
            "\nJavaScript doesn't support multithreading. However, GWT has a class to 'simulate' threading, which is not real multithreading, but in most cases does what you need: com.google.gwt.core.client.Scheduler.ScheduledCommand. The technique is based on the timer class, which executes a method after the given time elapses.\nFor example, when placing the following code in you own code, the scheduleDeferred method will return directly and your code continues after the command, while the execute() method is executed using the timer:\nScheduler.get().scheduleDeferred(new ScheduledCommand() {\n   public void execute() {\n      .. code here is executed using the timer technique.\n   }\n});\n\nYou can create a repeating command RepeatingCommand, which can be used to run the command more than once. Start it with Scheduler.get().scheduleIncremental() that will execute the command until the execute method returns false. You can use this to split tasks into sub tasks to get better 'threading' behavior. The Scheduler supports some additional methods to start a scheduled command differently. See the JavaDoc for more details.\nEdited and updated with new GWT class instead of the deprecated DeferredCommand.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nThere is work on Web Workers as part of HTML5 that is implemented in a number of browsers, but not on all (most notably internet explorer). You could use these features where available, but what you should do is look at the javascript programming model.\nJavascript generally works asynchronously. Requests are fired off and at some point their answers are received as an event. You can have a large number of pending requests at the same time. This will require a bit of a redesign of your system though.\n",
            "\nJavaScript doesn't support multithreading, so whatever GWT does, multithreading has to be done solely on the server side, because GWT can only use features that are already available on the client side.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n"
        ],
        "answer": "A1",
        "tags": [
            "gwt",
            "multithreading"
        ]
    },
    {
        "question_id": "8668174",
        "question": "\nHow can I simply and directly find the index within an array of objects meeting some condition?\nFor example, given this input:\nvar hello = { hello: 'world', foo: 'bar'};\nvar qaz = { hello: 'stevie', foo: 'baz'}\n\nvar myArray = [];\nmyArray.push(hello, qaz);\n\nHow can I search myArray to find the index of the element whose hello property equals 'stevie' (in this case, the result should be 1)?\n",
        "all_answers": [
            "\nI think you can solve it in one line using the map function:\nconst pos = myArray.map(e => e.hello).indexOf('stevie');\n\n",
            "\nSee this example: http://jsfiddle.net/89C54/\nfor (i = 0; i < myArray.length; i++) {\n    if (myArray[i].hello === 'stevie') {\n        alert('position: ' + i);\n        return;\n    }\n}\n\nIt starts to count with zero.\n",
            "\nvar idx = myArray.reduce( function( cur, val, index ){\n\n    if( val.hello === \"stevie\" && cur === -1 ) {\n        return index;\n    }\n    return cur;\n\n}, -1 );\n\n",
            "\nOr prototype it :\nArray.prototype.indexOfObject = function arrayObjectIndexOf(property, value) {\n    for (var i = 0, len = this.length; i < len; i++) {\n        if (this[i][property] === value) return i;\n    }\n    return -1;\n}\n\nmyArr.indexOfObject(\"name\", \"stevie\");\n\n",
            "\nArray.prototype.findIndex is supported in all browsers other than IE (non-edge). But the polyfill provided is nice.\nvar indexOfStevie = myArray.findIndex(i => i.hello === \"stevie\");\n\nThe solution with map is okay. But you are iterating over the entire array every search. That is only the worst case for findIndex which stops iterating once a match is found.\n\nThere's not really a concise way (when devs had to worry about IE8), but here's a common solution:\nvar searchTerm = \"stevie\",\n    index = -1;\nfor(var i = 0, len = myArray.length; i < len; i++) {\n    if (myArray[i].hello === searchTerm) {\n        index = i;\n        break;\n    }\n}\n\nor as a function:\nfunction arrayObjectIndexOf(myArray, searchTerm, property) {\n    for(var i = 0, len = myArray.length; i < len; i++) {\n        if (myArray[i][property] === searchTerm) return i;\n    }\n    return -1;\n}\narrayObjectIndexOf(arr, \"stevie\", \"hello\"); // 1\n\nJust some notes:\n\nDon't use for...in loops on arrays\nBe sure to break out of the loop or return out of the function once you've found your \"needle\"\nBe careful with object equality\n\nFor example,\nvar a = {obj: 0};\nvar b = [a];\nb.indexOf({obj: 0}); // -1 not found\n\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript"
        ]
    },
    {
        "question_id": "4696229",
        "question": "\nIn config/routes.rb, I tried both:\nroot :to => 'things#index', :as => 'things'\n\nand\nroot :to => 'things#index'\n\nWhen I hit http://localhost:3000/, both approaches work, and nothing seems to be different.\nWhat is the :as option used for?\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThe :as option creates a named path. You can then call this path in your controllers and views (e.g. redirect_to things_path). This isn't very useful for the root path (as it already named root), but is very useful for new routes you add.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nThe :as option forms a named route.\nUsually it's used in a non-root route.  For example:\nmatch '/search' => 'search#search', :as => 'search' # SearchController#search\nYou could then do something like:\n<%= link_to search_path, 'Click Here to Search!' %>\nsearch_path and search_url are defined because of the :as\nFor a root route, you don't really need :as because the the URL helpers root_path and root_url are defined for you by Rails.\n"
        ],
        "answer": "A4",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "ruby-on-rails-3",
            "routes"
        ]
    },
    {
        "question_id": "4547672",
        "question": "\nI am writing a SP, using PL/pgSQL.\nI want to return a record, comprised of fields from several different tables. Could look something like this:\nCREATE OR REPLACE FUNCTION get_object_fields(name text)\n  RETURNS RECORD AS $$\nBEGIN\n  -- fetch fields f1, f2 and f3 from table t1\n  -- fetch fields f4, f5 from table t2\n  -- fetch fields f6, f7 and f8 from table t3\n  -- return fields f1 ... f8 as a record\nEND\n$$ language plpgsql; \n\nHow may I return the fields from different tables as fields in a single record?\n[Edit]\nI have realized that the example I gave above was slightly too simplistic. Some of the fields I need to be retrieving, will be saved as separate rows in the database table being queried, but I want to return them in the 'flattened' record structure.\nThe code below should help illustrate further:\nCREATE TABLE user (id int, school_id int, name varchar(32));\n\nCREATE TYPE my_type AS (\n  user1_id   int,\n  user1_name varchar(32),\n  user2_id   int,\n  user2_name varchar(32)\n);\n\nCREATE OR REPLACE FUNCTION get_two_users_from_school(schoolid int)\n  RETURNS my_type AS $$\nDECLARE\n  result my_type;\n  temp_result user;\nBEGIN\n  -- for purpose of this question assume 2 rows returned\n  SELECT id, name INTO temp_result FROM user where school_id = schoolid LIMIT 2;\n  -- Will the (pseudo)code below work?:\n  result.user1_id := temp_result[0].id ;\n  result.user1_name := temp_result[0].name ;\n  result.user2_id := temp_result[1].id ;\n  result.user2_name := temp_result[1].name ;\n  return result ;\nEND\n$$ language plpgsql\n\n",
        "all_answers": [
            "\nYou need to define a new type and define your function to return that type.\nCREATE TYPE my_type AS (f1 varchar(10), f2 varchar(10) /* , ... */ );\n\nCREATE OR REPLACE FUNCTION get_object_fields(name text) \nRETURNS my_type \nAS \n$$\n\nDECLARE\n  result_record my_type;\n\nBEGIN\n  SELECT f1, f2, f3\n  INTO result_record.f1, result_record.f2, result_record.f3\n  FROM table1\n  WHERE pk_col = 42;\n\n  SELECT f3 \n  INTO result_record.f3\n  FROM table2\n  WHERE pk_col = 24;\n\n  RETURN result_record;\n\nEND\n$$ LANGUAGE plpgsql; \n\nIf you want to return more than one record you need to define the function as returns setof my_type\n\nUpdate \nAnother option is to use RETURNS TABLE() instead of creating a TYPE which was introduced in Postgres 8.4\nCREATE OR REPLACE FUNCTION get_object_fields(name text) \n  RETURNS TABLE (f1 varchar(10), f2 varchar(10) /* , ... */ )\n...\n\n",
            "\nIf you have a table with this exact record layout, use its name as a type, otherwise you will have to declare the type explicitly:\nCREATE OR REPLACE FUNCTION get_object_fields\n        (\n        name text\n        )\nRETURNS mytable\nAS\n$$\n        DECLARE f1 INT;\n        DECLARE f2 INT;\n        …\n        DECLARE f8 INT;\n        DECLARE retval mytable;\n        BEGIN\n        -- fetch fields f1, f2 and f3 from table t1\n        -- fetch fields f4, f5 from table t2\n        -- fetch fields f6, f7 and f8 from table t3\n                retval := (f1, f2, …, f8);\n                RETURN retval;\n        END\n$$ language plpgsql; \n\n"
        ],
        "answer": "A1",
        "tags": [
            "sql",
            "postgresql",
            "stored-procedures",
            "types",
            "plpgsql"
        ]
    },
    {
        "question_id": "8620547",
        "question": "\nI have the following scope:\nscope :comments, :conditions => ['text_value IS NOT NULL']\n\nBut I also want the conditions to say \"OR text_value IS NOT EMPTY\" (or something to that effect).\nI don't want to select any rows where text_value is empty/blank.\n",
        "all_answers": [
            "\nAs Erwin points out, a simple text_value <> '' comparison will work in this case.\nscope :comments, where(\"text_value <> ''\")\n\n(Rails 3 prefers this query syntax for scope—as well as find, all, etc.—rather than an options hash e.g. :conditions => .... The latter is deprecated in Rails 3.1.)\nIn Rails 4, the second argument should be a lambda instead:\nscope :comments, ->{ where(\"text_value <> ''\") }\n\n",
            "\nUse text_value <> '' to efficiently cover both cases.\nWill only be TRUE for a text_value that is neither NULL nor empty.\n",
            "\nI assume you don't care about the data:\ndef self.truncate!\n  connection.execute(\"truncate table #{quoted_table_name}\")\nend\n\nOr if you do, but not too much (there is a slice of time where the data only exists in memory):\ndef self.truncate_preserving_data!\n  data = all.map(&:clone).each{|r| raise \"Record would not be able to be saved\" unless r.valid? }\n  connection.execute(\"truncate table #{quoted_table_name}\")\n  data.each(&:save)\nend\n\nThis will give new records, with the same attributes, but id's starting at 1.\nAnything belongs_toing this table could get screwy.\n",
            "\nI came out with a solution based on hgimenez's answer and this other one. \nSince I usually work with either Sqlite or PostgreSQL, I've only developed for those; but extending it to, say MySQL, shouldn't be too troublesome.\nPut this inside lib/ and require it on an initializer:\n# lib/active_record/add_reset_pk_sequence_to_base.rb\nmodule ActiveRecord\n  class Base\n    def self.reset_pk_sequence\n      case ActiveRecord::Base.connection.adapter_name\n      when 'SQLite'\n        new_max = maximum(primary_key) || 0\n        update_seq_sql = \"update sqlite_sequence set seq = #{new_max} where name = '#{table_name}';\"\n        ActiveRecord::Base.connection.execute(update_seq_sql)\n      when 'PostgreSQL'\n        ActiveRecord::Base.connection.reset_pk_sequence!(table_name)\n      else\n        raise \"Task not implemented for this DB adapter\"\n      end\n    end     \n  end\nend\n\nUsage:\nClient.count # 10\nClient.destroy_all\nClient.reset_pk_sequence\nClient.create(:name => 'Peter') # this client will have id=1\n\nEDIT: Since the most usual case in which you will want to do this is after clearing a database table, I recommend giving a look to database_cleaner. It handles the ID resetting automatically. You can tell it to delete just selected tables like this:\nDatabaseCleaner.clean_with(:truncation, :only => %w[clients employees])\n\n",
            "\nYou never mentioned what DBMS you're using. If this is postgreSQL, the ActiveRecord postgres adapter has a reset_pk_sequences! method that you could use:\nActiveRecord::Base.connection.reset_pk_sequence!('table_name')\n\n"
        ],
        "answer": "A1",
        "tags": [
            "sql",
            "ruby-on-rails",
            "postgresql",
            "scope"
        ]
    },
    {
        "question_id": "15253954",
        "question": "\nof course I could replace specific arguments like this:\n    mydata=c(\"á\",\"é\",\"ó\")\n    mydata=gsub(\"á\",\"a\",mydata)\n    mydata=gsub(\"é\",\"e\",mydata)\n    mydata=gsub(\"ó\",\"o\",mydata)\n    mydata\n\nbut surely there is a easier way to do this all in onle line, right?\nI dont find the gsub help to be very comprehensive on this. \n",
        "all_answers": [
            "\nAn interesting question! I think the simplest option is to devise a special function, something like a \"multi\" gsub():\nmgsub <- function(pattern, replacement, x, ...) {\n  if (length(pattern)!=length(replacement)) {\n    stop(\"pattern and replacement do not have the same length.\")\n  }\n  result <- x\n  for (i in 1:length(pattern)) {\n    result <- gsub(pattern[i], replacement[i], result, ...)\n  }\n  result\n}\n\nWhich gives me:\n> mydata <- c(\"á\",\"é\",\"ó\")\n> mgsub(c(\"á\",\"é\",\"ó\"), c(\"a\",\"e\",\"o\"), mydata)\n[1] \"a\" \"e\" \"o\"\n\n",
            "\nMy R-Fu is weak to the point of being non-existent but I think I know what's up.\nThe string handling part of the R processor has to peek inside the strings to convert \\n and related escape sequences into their character equivalents. R doesn't know what \\. means so it complains. You want to get the escaped dot down into the regex engine so you need to get a single \\ past the string mangler. The usual way of doing that sort of thing is to escape the escape:\ngrepl(\"Processor\\\\.[0-9]+\\\\..*Processor\\\\.Time\", names(web02))\n\nEmbedding one language (regular expressions) inside another language (R) is usually a bit messy and more so when both languages use the same escaping syntax.\n",
            "\nYou can use gsubfn\nlibrary(gsubfn)\ngsubfn(\".\", list(\"'\" = \"\", \" \" = \"_\"), x)\n# [1] \"ab_c\"\n\nSimilarly, we can also use mgsub which allows multiple replacement with multiple pattern to search\nmgsub::mgsub(x, c(\"'\", \" \"), c(\"\", \"_\"))\n#[1] \"ab_c\"\n\n",
            "\nThe R-centric way of doing this is using the [::] notation, for example:\ngrepl(\"[:.:]\", \".\")\n# [1] TRUE\ngrepl(\"[:.:]\", \"a\")\n# [1] FALSE\n\nFrom the docs (?regex):\n\nThe metacharacters in extended regular expressions are . \\ | ( ) [ { ^ $ * + ?, but note that whether these have a special meaning depends on the context.\n\n\n[:punct:]\nPunctuation characters:\n! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ ` { | } ~.\n\n",
            "\nInstead of \n\\.\n\nTry\n\\\\.\n\nYou need to escape the backspace first.\n",
            "\nUse the character translation function\nchartr(\"áéó\", \"aeo\", mydata)\n\n",
            "\nI am a fan of the syntax that the %<>% and %>% opperators from the magrittr package provide.\nlibrary(magrittr)\n\nx <- \"a'b c\"\n\nx %<>%\n  gsub(\"'\", \"\", .) %>%\n  gsub(\" \", \"_\", .) \nx\n##[1] \"ab_c\"\n\ngusbfn is wonderful, but I like the chaining %>% allows.\n"
        ],
        "answer": "A6",
        "tags": [
            "r",
            "regex",
            "gsub"
        ]
    },
    {
        "question_id": "4664724",
        "question": "\nI have a Django project that I'd like to distribute on a public repository like bitbucket or github.  I'd like it to be as easy to install as possible, so I'm including the full project, not just the pluggable apps.  This means that the settings.py file will be included as well.\nHow can I avoid the problem of settings.SECRET_KEY being the same for every installation?\nIs the only simple solution to have the user manually modify settings.py?\nShould I store the key in the default database and have settings.py initialize it if it doesn't exist?  That would solve the problem, but I'm wondering if there is already a standard way of doing this.\nThanks!\n",
        "all_answers": [
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nGenerally speaking, you can divide Django configuration into things that are app-specific and things that are server-specific.  This falls into the latter category.\nThere are a number of ways you can tackle the problem of server-specific configuration, it is discussed more in this question.\nFor this particular instance, using the approach I outline in my answer to the other question, I'd put a placeholder in settings_local.py.sample for distribution, and during installation, I'd copy that over to settings_local.py and edit to suit.\n",
            "\nI'd go about it this way:\nHave the secret key in a separate file \"secret_key.py\". This file does not exist for a pristine installation. In your settings.py include something like:\ntry:\n    from .secret_key import SECRET_KEY\nexcept ImportError:\n    SETTINGS_DIR = os.path.abspath(os.path.dirname(__file__))\n    generate_secret_key(os.path.join(SETTINGS_DIR, 'secret_key.py'))\n    from .secret_key import SECRET_KEY\n\nThe function generate_secret_key(filename) that you will write generates a file called filename (which, as we call it, will be secret_key.py in the same dir as settings.py) with the contents:\nSECRET_KEY = '....random string....'\n\nWhere random string is the generated key based on a random number.\nFor key generation you can use Umang's suggestion https://stackoverflow.com/a/16630719/166761.\n"
        ],
        "answer": "A4",
        "tags": [
            "django"
        ]
    },
    {
        "question_id": "39321421",
        "question": "\nI am trying to convert my project to Swift 3.0 however I am having two error messages when working with NSNumber and Integers. \n\nCannot assign type int to type NSNumber\n\nfor \n//item is a NSManaged object with a property called index of type NSNumber \n\nvar currentIndex = 0\n for item in self.selectedObject.arrayOfItems {\n   item.index = currentIndex\n   currentIndex += 1\n }\n\nand even when I change currentIndex to a type NSNumber then I get the error \n\nBinary operator '+=' cannot be applied to type 'NSNumber' and 'Int'\n\nso then I create a property called one of type NSNumber to add to currentIndex but then get the following error; \n\nBinary operator '+=' cannot be applied to two NSNumber operands\n\n&& the second error I get is \n\nNo '+' candidates produce the expected contextual result type NSNumber\n\n let num: Int = 210\n let num2: Int = item.points.intValue\n item.points = num + num2\n\nHere I am just trying to add 210 to the points property value, item is a NSManagedObject. \nSo basically I am having issues getting my head around adding numbers to properties of type NSNumber. I am working with NSNumber because they are properties of NSManagedObject's. \nCan anyone help me out ? I have over 80 errors which are all either one of the above errors mentioned. \nThanks            \n",
        "all_answers": [
            "\nYou should stay with or original code and just change the assignment, so that it works:\nvar currentIndex = 0\nfor item in self.selectedFolder.arrayOfTasks {\n    item.index = NSNumber(integer: currentIndex)\n    currentIndex += 1\n}\n\nAs your code works fine in Swift 2, I'd expect that this is behaviour that might change in the next update.\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nBefore Swift 3, many types were automatically \"bridged\" to an \ninstance of some NSObject subclass where necessary, such as String to\nNSString, or Int, Float, ... to NSNumber.\nAs of Swift 3 you have to make that conversion explicit:\nvar currentIndex = 0\nfor item in self.selectedFolder.arrayOfTasks {\n   item.index = currentIndex as NSNumber // <--\n   currentIndex += 1\n}\n\nAlternatively, use the option \"Use scalar properties for primitive data types\" when creating the NSManagedObject subclass,\nthen the property has some integer type instead of NSNumber,\nso that you can get and set it without conversion.\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "swift",
            "int",
            "swift3",
            "nsnumber"
        ]
    },
    {
        "question_id": "5373780",
        "question": "\nI want to catch this error:\n$a[1] = 'jfksjfks';\ntry {\n      $b = $a[0];\n} catch (\\Exception $e) {\n      echo \"jsdlkjflsjfkjl\";\n}\n\nEdit: in fact, I got this error on the following line:\n$parse = $xml->children[0]->children[0]->toArray();\n",
        "all_answers": [
            "\nfunction isJson($string) {\n   json_decode($string);\n   return json_last_error() === JSON_ERROR_NONE;\n}\n\n",
            "\nYou can't with a try/catch block, as this is an error, not an exception.\nAlways tries offsets before using them:\nif( isset( $a[ 0 ] ) { $b = $a[ 0 ]; }\n\n",
            "\nYou need to define your custom error handler like:\n<?php\n\nset_error_handler('exceptions_error_handler');\n\nfunction exceptions_error_handler($severity, $message, $filename, $lineno) {\n  if (error_reporting() == 0) {\n    return;\n  }\n  if (error_reporting() & $severity) {\n    throw new ErrorException($message, 0, $severity, $filename, $lineno);\n  }\n}\n\n$a[1] = 'jfksjfks';\ntry {\n      $b = $a[0];\n} catch (Exception $e) {\n      echo \"jsdlkjflsjfkjl\";\n}\n\n",
            "\n$a[1] = 'jfksjfks';\ntry {\n  $offset = 0;\n  if(isset($a[$offset]))\n    $b = $a[$offset];\n  else\n    throw new Exception(\"Notice: Undefined offset: \".$offset);\n} catch (Exception $e) {\n  echo $e->getMessage();\n}\n\nOr, without the inefficiency of creating a very temporary exception:\n$a[1] = 'jfksjfks';\n$offset = 0;\nif(isset($a[$offset]))\n  $b = $a[$offset];\nelse\n  echo \"Notice: Undefined offset: \".$offset;\n\n"
        ],
        "answer": "A3",
        "tags": [
            "php",
            "error-handling",
            "try-catch"
        ]
    },
    {
        "question_id": "3024168",
        "question": "\nWhen processing a POST request in the Django views.py file, I sometimes need to redirect it to another url. This url I'm redirecting to is handled by another function in the same Django views.py file. Is there a way of doing this and maintaining the original POST data? \nUPDATE: More explanation of why I want to do this.\nI have two web apps (let's call them AppA and AppB) which accept data entered into a text field by the user. When the the user clicks submit, the data is processed and detailed results are displayed. AppA and AppB expect different types of data. Sometimes a user mistakenly posts AppB type data to AppA. When this happens I want to redirect them to AppB and show the AppB results or at least have it populated with the data they entered into AppA. \nAlso:\n\nThe client wants two separate apps rather than combining them into just one.\nI can't show the code as it belongs to a client.\n\nUPDATE 2:\nI've decided that KISS is the best principle here. I have combined the two apps into one which  makes things simpler and more robust; I should be able to convince the client it's the best way to go too. Thanks for all the great feedback. If I was going to maintain two apps as described then I think sessions would be the way to do this - thanks to  Matthew J Morrison for suggesting that. Thanks to Dzida as his comments got me thinking about the design and simplification.\n",
        "all_answers": [
            "\nIf you faced such problem there's a slight chance that you might need to revise your designs.\nThis is a restriction of HTTP that POST data cannot go with redirects.\nCan you describe what are you trying to accomplish and maybe then we can think about some neat solution.\nIf you do not want use sessions as Matthew suggested you can pass POST params in GET to the new page (consider some limitations such as security and max length of GET params in query string).\nUPDATE to your update:)\nIt sounds strange to me that you have 2 web apps and those apps use one views.py (am I right?). Anyway consider passing your data from POST in GET to the proper view (in case data is not sensitive of course).\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI think how I would probably handle this situation would be to save the post data in session, then remove it when I no longer need it.  That way I can access the original post data after a redirect even though that post is gone.\nWill that work for what you're trying to do?\nHere is a code sample of what I'm suggesting: (keep in mind this is untested code)\ndef some_view(request):\n    #do some stuff\n    request.session['_old_post'] = request.POST\n    return HttpResponseRedirect('next_view')\n\ndef next_view(request):\n    old_post = request.session.get('_old_post')\n    #do some stuff using old_post\n\nOne other thing to keep in mind... if you're doing this and also uploading files, i would not do it this way.\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "python-3.x",
            "django",
            "http-post",
            "http-redirect"
        ]
    },
    {
        "question_id": "3861353",
        "question": "\nIs there something like struct data type in PHP?\nCan anyone give me example for struct data type to understand this better?\nIf there's no such data type, how can I get a data type that behaves like a struct?\n",
        "all_answers": [
            "\nClosest you'd get to a struct is an object with all members public.\nclass MyStruct {\n    public $foo;\n    public $bar;\n}\n\n$obj = new MyStruct();\n$obj->foo = 'Hello';\n$obj->bar = 'World';\n\nI'd say looking at the PHP Class Documentation would be worth it.\nIf you need a one-off struct, use the StdObject as mentioned in alex's answer.\n",
            "\nI recommend 2 things. First is associative array.\n$person = Array();\n$person['name'] = \"Joe\";\n$person['age'] = 22;\n\nSecond is classes.\nDetailed documentation here: http://php.net/manual/en/language.oop5.php\n",
            "\nYou can use an array\n$something = array(\n   'key' => 'value',\n   'key2' => 'value2'\n);\n\nor with standard object.\n$something = new StdClass();\n\n$something->key = 'value';\n$something->key2 = 'value2';\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "9610277",
        "question": "\nI have the following 2 models\nclass Sport < ActiveRecord::Base\n  has_many :charts, order: \"sortWeight ASC\"\n  has_one :product, :as => :productable\n  accepts_nested_attributes_for :product, :allow_destroy => true\nend\n\nclass Product < ActiveRecord::Base\n  belongs_to :category\n  belongs_to :productable, :polymorphic => true\nend\n\nA sport can't exist without the product, so in my sports_controller.rb I had:\ndef new\n  @sport = Sport.new\n  @sport.product = Product.new\n...\nend\n\nI tried to move the creation of the product to the sport model, using after_initialize:\nafter_initialize :create_product\n\ndef create_product\n self.product = Product.new\nend\n\nI quickly learned that after_initialize is called whenever a model is instantiated (i.e., from a find call).  So that wasn't the behavior I was looking for.\nWhats the way I should be modeling the requirement that all sport have a product?\nThanks\n",
        "all_answers": [
            "\nPutting the logic in the controller could be the best answer as you stated, but you could get the after_initialize to work by doing the following:\nafter_initialize :add_product\n\ndef add_product\n  self.product ||= Product.new\nend\n\nThat way, it only sets product if no product exists. It may not be worth the overhead and/or be less clear than having the logic in the controller.\nEdit: Per Ryan's answer, performance-wise the following would likely be better:\nafter_initialize :add_product\n\ndef add_product\n  self.product ||= Product.new if self.new_record?\nend\n\n",
            "\nJust figured out that rails does not supports this kind of behavior so I came up with the following workaround:\nclass Job <ActiveRecord::Base\n  belongs_to :client, :polymorphic=>:true, :autosave=>true\n  accepts_nested_attributes_for :client\n\n  def attributes=(attributes = {})\n    self.client_type = attributes[:client_type]\n    super\n  end\n\n  def client_attributes=(attributes)\n    self.client = type.constantize.find_or_initialize_by_id(attributes.delete(:client_id)) if client_type.valid?\n  end\nend\n\nThis gives me to set up my form like this:\n<%= f.select :client_type %>\n<%= f.fields_for :client do |client|%>\n  <%= client.text_field :name %>\n<% end %>\n\nNot the exact solution but the idea is important.\n",
            "\nInstead of using after_initialize, how about after_create?\nafter_create :create_product\n\ndef create_product\n  self.product = Product.new\n  save\nend\n\nDoes that look like it would solve your issue?\n",
            "\nIt looks like you are very close. You should be able to do away with the after_initialize call altogether, but first I believe if your Sport model has a \"has_one\" relationship with :product as you've indicated, then your Product model should also \"belong_to\" sport. Add this to your Product model\nbelongs_to: :sport\n\nNext step, you should now be able to instantiate a Sport model like so\n@sport = @product.sport.create( ... )\n\nThis is based off the information from Association Basics from Ruby on Rails Guides, which you could have a read through if I am not exactly correct\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "model",
            "nested-attributes"
        ]
    },
    {
        "question_id": "12941083",
        "question": "\nIn a node.js, I'd like to find a way to obtain the output of a Unix terminal command. Is there any way to do this?\nfunction getCommandOutput(commandString){\n    // now how can I implement this function?\n    // getCommandOutput(\"ls\") should print the terminal output of the shell command \"ls\"\n}\n\n",
        "all_answers": [
            "\nYou're looking for child_process\nvar exec = require('child_process').exec;\nvar child;\n\nchild = exec(command,\n   function (error, stdout, stderr) {\n      console.log('stdout: ' + stdout);\n      console.log('stderr: ' + stderr);\n      if (error !== null) {\n          console.log('exec error: ' + error);\n      }\n   });\n\n\nAs pointed out by Renato, there are some synchronous exec packages out there now too, see sync-exec that might be more what yo're looking for. Keep in mind though, node.js is designed to be a single threaded high performance network server, so if that's what you're looking to use it for, stay away from sync-exec kinda stuff unless you're only using it during startup or something.\n",
            "\nIf you don't want to bother with giving permissions and the env you execute the script has for example sh, you could just do\n\"scripts\": {\n   \"build\": \"sh ./build.sh\"\n}\n\n\n",
            "\nIn case someone sees this and is using Docker for creating an image of this application.\nRegarding:\n\nbut I'm not clear on exactly where I'm supposed to drop my build.sh file\n\nWherever you do decide to drop your build.sh file, make sure it is included in the Dockerfile image output, i.e. the file's path is in one of the COPY commands in the Dockerfile.\nFor example, if you have something like\nscripts {\n  \"build\": \"./scripts/build.sh\"\n}\n\nThen your Dockerfile should have a COPY command similar to:\nCOPY scripts/build.sh scripts/\n\n",
            "\nIf you can use node's built in child_process.spawn, you're able to send a SIGINT signal to the child process:\nvar proc = require('child_process').spawn('mongod');\nproc.kill('SIGINT');\n\nAn upside to this is that the main process should hang around until all of the child processes have terminated.\n",
            "\nThis is the method I'm using in a project I am currently working on.\nvar exec = require('child_process').exec;\nfunction execute(command, callback){\n    exec(command, function(error, stdout, stderr){ callback(stdout); });\n};\n\nExample of retrieving a git user:\nmodule.exports.getGitUser = function(callback){\n    execute(\"git config --global user.name\", function(name){\n        execute(\"git config --global user.email\", function(email){\n            callback({ name: name.replace(\"\\n\", \"\"), email: email.replace(\"\\n\", \"\") });\n        });\n    });\n};\n\n",
            "\nEven Simpler:\nI routinely do this for one-offs and PoC's not involving a VCS\n\npackage.json\n\n{\n    \"scripts\": {\n        \"ship\": \"rsync -avz deployable/* <some-server>:/var/www/some-site/sub-dir/\"\n    },\n}\n...\n\n",
            "\nIts totally possible... \n\"scripts\": {\n   \"build\": \"./build.sh\"\n},\n\nalso, make sure you put a hash bang at the top of your bash file #!/usr/bin/env bash\nalso make sure you have permissions to execute the file \nchmod +x ./build.sh\n\nFinally, the command to run build in npm would be \nnpm run build\n\n",
            "\n\nJust add 'bash' keyword before the file_name.sh\n\"scripts\": { \"build\": \"bash ./file_name.sh\" }\n\nthen run \"npm run build\" on terminal\n\n\n"
        ],
        "answer": "A5",
        "tags": [
            "node.js",
            "shell",
            "command-line-interface"
        ]
    },
    {
        "question_id": "148968",
        "question": "\nAs I understand it, .bat is the old 16-bit naming convention, and .cmd is for 32-bit Windows, i.e., starting with NT. But I continue to see .bat files everywhere, and they seem to work exactly the same using either suffix. Assuming that my code will never need to run on anything older than NT, does it really matter which way I name my batch files, or is there some gotcha awaiting me by using the wrong suffix?\n",
        "all_answers": [
            "\nNo - it doesn't matter in the slightest.  On NT the .bat and .cmd extension both cause the cmd.exe processor to process the file in exactly the same way.\nAdditional interesting information about command.com vs. cmd.exe on WinNT-class systems from MS TechNet (http://technet.microsoft.com/en-us/library/cc723564.aspx):\n\nThis behavior reveals a quite subtle\n  feature of Windows NT that is very\n  important. The 16-bit MS-DOS shell\n  (COMMAND.COM) that ships with Windows\n  NT is specially designed for Windows\n  NT. When a command is entered for\n  execution by this shell, it does not\n  actually execute it. Instead, it\n  packages the command text and sends it\n  to a 32-bit CMD.EXE command shell for\n  execution. Because all commands are\n  actually executed by CMD.EXE (the\n  Windows NT command shell), the 16-bit\n  shell inherits all the features and\n  facilities of the full Windows NT\n  shell.\n\n",
            "\nFrom this news group posting by Mark Zbikowski himself:\n\nThe differences between .CMD and .BAT as far as CMD.EXE is concerned\n  are:  With extensions enabled, PATH/APPEND/PROMPT/SET/ASSOC in .CMD \n  files will set ERRORLEVEL regardless of error. .BAT sets ERRORLEVEL \n  only on errors.\n\nIn other words, if ERRORLEVEL is set to non-0 and then you run one of those commands, the resulting ERRORLEVEL will be:\n\nleft alone at its non-0 value in a .bat file \nreset to 0 in a .cmd file. \n\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "batch-file",
            "cmd"
        ]
    },
    {
        "question_id": "13811922",
        "question": "\nTake for instance the following code:\nphpinfo(INFO_MODULES | INFO_ENVIRONMENT | INFO_VARIABLES);\n\nA single argument is being used, but I am providing a list of options separated by a single pipe symbol.\n\nWhat exactly is happening with the argument value in the function? \nCan I use the same thing in my own functions?\nIs so how, and are there benefits to this over say passing an array instead?\n\n",
        "all_answers": [
            "\nBitwise operators\nBitwise operators modify the bits of the values involved. A bitwise OR basically ORs together each bit of both the left and right argument. For example:\n5 | 2\n\nWould translate to bits/binary as:\n101 | 10\n\nWhich would result in:\n111\n\nBecause:\n1 || 0 = 1\n0 || 1 = 1\n1 || 0 = 1\n\nAnd as an Integer that is the representation of 7 which is exactly what you get if you:\necho 5 | 2;\n\n\nIn the words of Eddie Izzard... Flag!\nAs Ignacio states, this is most often used in PHP (and other langauges) as a way to combine multiple flags. Each flag is usually defined as a constant whose value is normally set to an integer that represents just one bit at a different offset:\ndefine('FLAG_A', 1); /// 0001\ndefine('FLAG_B', 2); /// 0010\ndefine('FLAG_C', 4); /// 0100\ndefine('FLAG_D', 8); /// 1000\n\nThen when you OR these together they operate each on their own bit offset and will never collide:\nFLAG_A | FLAG_C\n\nTranslates to:\n1 | 100\n\nSo you end up turning on:\n101\n\nWhich represents the integer 5.\nThen all the code has to do—the code that will be reacting to the different flags being set—is the following (using a bitwise AND):\n$combined_flags = FLAG_A | FLAG_C;\n\nif ( $combined_flags & FLAG_A ) {\n  /// do something when FLAG_A is set\n}\n\nif ( $combined_flags & FLAG_B ) {\n  /// this wont be reached with the current value of $combined_flags\n}\n\nif ( $combined_flags & FLAG_C ) {\n  /// do something when FLAG_C is set\n}\n\nAt the end of the day it just makes things easier to read by having named constants, and generally more optimal by relying on integer values rather than strings or arrays. Another benefit of using constants is that if they are ever mistyped when used, the compiler is in a better situation to tell and to throw a warning... if a string value is used it has no way of knowing that anything is wrong.\ndefine('MY_FLAG_WITH_EASY_TYPO', 1);\n\nmy_function_that_expects_a_flag( MY_FLAG_WITH_EASY_TPYO );\n\n/// if you have strict errors on the above will trigger an error\n\nmy_function_that_expects_a_flag( 'my_string_with_easy_tpyo' );\n\n/// the above is just a string, the compiler knows nowt with \n/// regard to it's correctness, so instead you'd have to\n/// code your own checks.\n\n",
            "\nYou're passing an argument which is the bitwise OR of multiple flags. You can use the operator anywhere you like.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "function",
            "arguments",
            "bitwise-operators"
        ]
    },
    {
        "question_id": "14626636",
        "question": "\nI have a Node.js application that contains an http(s) server.\nIn a specific case, I need to shutdown this server programmatically. What I am currently doing is calling its close() function, but this does not help, as it waits for any kept alive connections to finish first.\nSo, basically, this shutdowns the server, but only after a minimum wait time of 120 seconds. But I want the server to shutdown immediately - even if this means breaking up with currently handled requests.\nWhat I can not do is a simple\nprocess.exit();\n\nas the server is only part of the application, and the rest of the application should remain running. What I am looking for is conceptually something such as server.destroy(); or something like that.\nHow could I achieve this?\nPS: The keep-alive timeout for connections is usually required, hence it is not a viable option to decrease this time.\n",
        "all_answers": [
            "\nAs a side note to anyone looking for a solution from Google... make sure you are not using an http.Agent with an https request or you will get this error.\n",
            "\nMy best guess would be to kill the connections manually (i.e. to forcibly close it's sockets).\nIdeally, this should be done by digging into the server's internals and closing it's sockets by hand. Alternatively, one could run a shell-command that does the same (provided the server has proper privileges &c.)\n",
            "\nWhen you want to request an https resource, you need to use https.get, not http.get. \nhttps://nodejs.org/api/https.html\n",
            "\nThe trick is that you need to subscribe to the server's connection event which gives you the socket of the new connection. You need to remember this socket and later on, directly after having called server.close(), destroy that socket using socket.destroy().\nAdditionally, you need to listen to the socket's close event to remove it from the array if it leaves naturally because its keep-alive timeout does run out.\nI have written a small sample application you can use to demonstrate this behavior:\n// Create a new server on port 4000\nvar http = require('http');\nvar server = http.createServer(function (req, res) {\n  res.end('Hello world!');\n}).listen(4000);\n\n// Maintain a hash of all connected sockets\nvar sockets = {}, nextSocketId = 0;\nserver.on('connection', function (socket) {\n  // Add a newly connected socket\n  var socketId = nextSocketId++;\n  sockets[socketId] = socket;\n  console.log('socket', socketId, 'opened');\n\n  // Remove the socket when it closes\n  socket.on('close', function () {\n    console.log('socket', socketId, 'closed');\n    delete sockets[socketId];\n  });\n\n  // Extend socket lifetime for demo purposes\n  socket.setTimeout(4000);\n});\n\n// Count down from 10 seconds\n(function countDown (counter) {\n  console.log(counter);\n  if (counter > 0)\n    return setTimeout(countDown, 1000, counter - 1);\n\n  // Close the server\n  server.close(function () { console.log('Server closed!'); });\n  // Destroy all open sockets\n  for (var socketId in sockets) {\n    console.log('socket', socketId, 'destroyed');\n    sockets[socketId].destroy();\n  }\n})(10);\n\nBasically, what it does is to start a new HTTP server, count from 10 to 0, and close the server after 10 seconds. If no connection has been established, the server shuts down immediately.\nIf a connection has been established and it is still open, it is destroyed.\nIf it had already died naturally, only a message is printed out at that point in time.\n"
        ],
        "answer": "A4",
        "tags": [
            "node.js",
            "http",
            "connection",
            "keep-alive"
        ]
    },
    {
        "question_id": "4877931",
        "question": "\nIf I have a scope with a lambda and it takes an argument, depending on the value of the argument, I might know that there will not be any matches, but I still want to return a relation, not an empty array:\nscope :for_users, lambda { |users| users.any? ? where(\"user_id IN (?)\", users.map(&:id).join(',')) : [] }\n\nWhat I really want is a \"none\" method, the opposite of \"all\", that returns a relation that can still be chained, but results in the query being short-circuited.\n",
        "all_answers": [
            "\nadd_index :subscriptions, [:user_id, :content_id], unique: true\n\n",
            "\nYou can add a scope called \"none\":\nscope :none, where(:id => nil).where(\"id IS NOT ?\", nil)\n\nThat will give you an empty ActiveRecord::Relation\nYou could also add it to ActiveRecord::Base in an initializer (if you want):\nclass ActiveRecord::Base\n def self.none\n   where(arel_table[:id].eq(nil).and(arel_table[:id].not_eq(nil)))\n end\nend\n\nPlenty of ways to get something like this, but certainly not the best thing to keep in a code base.  I have used the scope :none when refactoring and finding that I need to guarantee an empty ActiveRecord::Relation for a short time.\n",
            "\nUse scoped:\n\nscope :for_users, lambda { |users| users.any? ? where(\"user_id IN (?)\", users.map(&:id).join(',')) : scoped }\n\nBut, you can also simplify your code with:\n\nscope :for_users, lambda { |users| where(:user_id => users.map(&:id)) if users.any? }\n\nIf you want an empty result, use this (remove the if condition):\n\nscope :for_users, lambda { |users| where(:user_id => users.map(&:id)) }\n\n",
            "\nRails 5 has a left_outer_joins method. So you can do\nUser.left_outer_joins(:user_points)\n\nor use the alias\nUser.left_joins(:user_points)\n\n",
            "\nYou can try this\nUser.find(:all, limit: 10,\n            joins:  \"LEFT JOIN `user_points` ON user_points.user_id = users.id\" ,\n            select: \"users.*, count(user_points.id)\", \n            group:  \"user_points.user_id\")\n\n",
            "\nJust for future reference, adding :all gives a deprecated message. In later versions of rails you can simply chain the methods like this:\nUser.joins(\"LEFT JOIN `user_points` ON user_points.user_id = users.id\").select(\"users.*, count(user_points.id)\").group(\"user_points.user_id\")\n\nOR use a scope like this:\nscope :my_scope_name_here, -> { \n        joins(\"LEFT JOIN `user_points` ON user_points.user_id = users.id\")\n        .select(\"users.*, count(user_points.id)\")\n        .group(\"user_points.user_id\")\n}\n\nYou can also chain .where between the .join and the .select.\nHope this helps someone in the future.\n",
            "\nA more portable solution that doesn't require an \"id\" column and doesn't assume there won't be a row with an id of 0:\nscope :none, where(\"1 = 0\")\n\nI'm still looking for a more \"correct\" way.\n",
            "\nThere is a now a \"correct\" mechanism in Rails 4:\n>> Model.none \n=> #<ActiveRecord::Relation []>\n\n",
            "\nI think I prefer the way this looks to the other options:\nscope :none, limit(0)\n\nLeading to something like this:\nscope :users, lambda { |ids| ids.present? ? where(\"user_id IN (?)\", ids) : limit(0) }\n\n"
        ],
        "answer": "A8",
        "tags": [
            "ruby-on-rails",
            "activerecord",
            "relation"
        ]
    },
    {
        "question_id": "1133770",
        "question": "\nHow do I convert a string to an integer in JavaScript?\n",
        "all_answers": [
            "\nTry parseInt function:\nvar number = parseInt(\"10\");\n\nBut there is a problem. If you try to convert \"010\" using parseInt function, it detects as octal number, and will return number 8. So, you need to specify a radix (from 2 to 36). In this case base 10.\nparseInt(string, radix)\n\nExample:\nvar result = parseInt(\"010\", 10) == 10; // Returns true\n\nvar result = parseInt(\"010\") == 10; // Returns false\n\nNote that parseInt ignores bad data after parsing anything valid.\nThis guid will parse as 51:\nvar result = parseInt('51e3daf6-b521-446a-9f5b-a1bb4d8bac36', 10) == 51; // Returns true\n\n",
            "\nThe simplest way would be to use the native Number function:\nvar x = Number(\"1000\")\n\nIf that doesn't work for you, then there are the parseInt, unary plus, parseFloat with floor, and Math.round methods.\nparseInt()\nvar x = parseInt(\"1000\", 10); // You want to use radix 10\n    // So you get a decimal number even with a leading 0 and an old browser ([IE8, Firefox 20, Chrome 22 and older][1])\n\nUnary plus\nIf your string is already in the form of an integer:\nvar x = +\"1000\";\n\nfloor()\nIf your string is or might be a float and you want an integer:\nvar x = Math.floor(\"1000.01\"); // floor() automatically converts string to number\n\nOr, if you're going to be using Math.floor several times:\nvar floor = Math.floor;\nvar x = floor(\"1000.01\");\n\nparseFloat()\nIf you're the type who forgets to put the radix in when you call parseInt, you can use parseFloat and round it however you like. Here I use floor.\nvar floor = Math.floor;\nvar x = floor(parseFloat(\"1000.01\"));\n\nround()\nInterestingly, Math.round (like Math.floor) will do a string to number conversion, so if you want the number rounded (or if you have an integer in the string), this is a great way, maybe my favorite:\nvar round = Math.round;\nvar x = round(\"1000\"); // Equivalent to round(\"1000\", 0)\n\n",
            "\n\nNote: This is not unicode compliant. \"I💖U\".split('') results in the\n  4 character array [\"I\", \"�\", \"�\", \"u\"] which can lead to dangerous\n  bugs. See answers below for safe alternatives.\n\nJust split it by an empty string. \n\n\nvar output = \"Hello world!\".split('');\r\nconsole.log(output);\n\n\n\nSee the String.prototype.split() MDN docs.\n",
            "\nTry parseInt.\nvar number = parseInt(\"10\", 10); //number will have value of 10.\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "string",
            "integer",
            "data-conversion"
        ]
    },
    {
        "question_id": "1411577",
        "question": "\nI have a POCO class that is being sent to the browser as a JSON string in .NET 3.5 sp1.  I am just using the default JSON serialization and I have some fields that I want to ignore.  I want to put an attribute similar to [System.Xml.Serialization.XmlIgnore] on them so that they are not serialized.\n",
        "all_answers": [
            "\nYou should also try my ServiceStack JsonSerializer - it's the fastest .NET JSON serializer at the moment based on the benchmarks of the leading JSON serializers and supports serializing any POCO Type, DataContracts, Lists/Dictionaries, Interfaces, Inheritance, Late-bound objects including anonymous types, etc.\nBasic Example\nvar customer = new Customer { Name=\"Joe Bloggs\", Age=31 };\nvar json = customer.ToJson();\nvar fromJson = json.FromJson<Customer>(); \n\nNote: Only use Microsofts JavaScriptSerializer if performance is not important to you as I've had to leave it out of my benchmarks since its up to 40x-100x slower than the other JSON serializers.\n",
            "\nIf you look here, you will see several different libraries for JSON on C#.\nhttp://json.org/\nYou will find a version for LINQ as well as some others. There are about 7 libraries for C# and JSON.\n",
            "\n[ScriptIgnore] \n\nis your huckaberry.\n",
            "\nJSON.Net\n",
            "\nThe .net framework supports JSON through JavaScriptSerializer. Here is a good example to get you started.\nusing System.Collections.Generic;\nusing System.Web.Script.Serialization;\n\nnamespace GoogleTranslator.GoogleJSON\n{\n    public class FooTest\n    {\n        public void Test()\n        {\n            const string json = @\"{\n              \"\"DisplayFieldName\"\" : \"\"ObjectName\"\", \n              \"\"FieldAliases\"\" : {\n                \"\"ObjectName\"\" : \"\"ObjectName\"\", \n                \"\"ObjectType\"\" : \"\"ObjectType\"\"\n              }, \n              \"\"PositionType\"\" : \"\"Point\"\", \n              \"\"Reference\"\" : {\n                \"\"Id\"\" : 1111\n              }, \n              \"\"Objects\"\" : [\n                {\n                  \"\"Attributes\"\" : {\n                    \"\"ObjectName\"\" : \"\"test name\"\", \n                    \"\"ObjectType\"\" : \"\"test type\"\"\n                  }, \n                  \"\"Position\"\" : \n                  {\n                    \"\"X\"\" : 5, \n                    \"\"Y\"\" : 7\n                  }\n                }\n              ]\n            }\";\n\n            var ser = new JavaScriptSerializer();\n            ser.Deserialize<Foo>(json);\n        }\n    }\n\n    public class Foo\n    {\n        public Foo() { Objects = new List<SubObject>(); }\n        public string DisplayFieldName { get; set; }\n        public NameTypePair FieldAliases { get; set; }\n        public PositionType PositionType { get; set; }\n        public Ref Reference { get; set; }\n        public List<SubObject> Objects { get; set; }\n    }\n\n    public class NameTypePair\n    {\n        public string ObjectName { get; set; }\n        public string ObjectType { get; set; }\n    }\n\n    public enum PositionType { None, Point }\n    public class Ref\n    {\n        public int Id { get; set; }\n    }\n\n    public class SubObject\n    {\n        public NameTypePair Attributes { get; set; }\n        public Position Position { get; set; }\n    }\n\n    public class Position\n    {\n        public int X { get; set; }\n        public int Y { get; set; }\n    }\n}\n\n",
            "\nI use the ScriptIgnore attribute on my model like so:\npublic class Item\n{\n    [ScriptIgnore]\n    public Item ParentItem { get; set; }\n}\n\nIn this particular scenario I was getting a circular reference error from the Json serializer, so I simply ignored it.  I was asking a similar question here on SO when I was turned on to the difference between a Model and ViewModel.\n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            ".net",
            "asp.net-mvc",
            "json",
            "serialization"
        ]
    },
    {
        "question_id": "10373561",
        "question": "\n\n\n\n\nPossible Duplicate:\nHow to convert a column number (eg. 127) into an excel column (eg. AA) \n\nOk so I am writing a method which accepts a 2d array as a parameter. I want to put this 2d array onto an Excel worksheet but I need to work out the final cell location. I can get the height easily enough like so:\nvar height = data.GetLength(1); //`data` is the name of my 2d array\n\nThis gives me my Y axis but it's not so easy to get my X axis. Obviously I can get the number like so:\nvar width = data.GetLength(0);\n\nThis gives me a number, which I want to convert to a letter. So, for example, 0 is A, 1 is B and so on until we get to 26 which goes back to A again. I am sure that there is a simple way to do this but I have a total mental block.\nWhat would you do?\nThanks\n",
        "all_answers": [
            "\nHere's a version that also handles two-letter columns (after column Z):\nstatic string GetColumnName(int index)\n{\n    const string letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\";\n\n    var value = \"\";\n\n    if (index >= letters.Length)\n        value += letters[index / letters.Length - 1];\n\n    value += letters[index % letters.Length];\n\n    return value;\n}\n\n",
            "\nJust cast it to a char and do \"ToString()\".\nusing System;\nusing System.Collections.Generic;\n\npublic class MyClass\n{\n    public static void RunSnippet()\n    {\n        int myNumber = 65;\n        string myLetter = ((char) myNumber).ToString();\n        WL(myLetter);\n    }\n\n    #region Helper methods\n\n    public static void Main()\n    {\n        try\n        {\n            RunSnippet();\n        }\n        catch (Exception e)\n        {\n            string error = string.Format(\"---\\nThe following error occurred while executing the snippet:\\n{0}\\n---\", e.ToString());\n            Console.WriteLine(error);\n        }\n        finally\n        {\n            Console.Write(\"Press any key to continue...\");\n            Console.ReadKey();\n        }\n    }\n\n    private static void WL(object text, params object[] args)\n    {\n        Console.WriteLine(text.ToString(), args);   \n    }\n\n    private static void RL()\n    {\n        Console.ReadLine(); \n    }\n\n    private static void Break() \n    {\n        System.Diagnostics.Debugger.Break();\n    }\n\n    #endregion\n}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "algorithm",
            "excel"
        ]
    },
    {
        "question_id": "1532618",
        "question": "\nIs there a function to make a copy of a PHP array to another?\nI have been burned a few times trying to copy PHP arrays. I want to copy an array defined inside an object to a global outside it.\n",
        "all_answers": [
            "\nIn PHP, all variables except objects are assigned by the mechanism called copy-on-write, while objects are assigned by reference. Which means that for the arrays with scalar values simply $b = $a already will give you a copy:\n$a = array();\n$b = $a;\n$b['foo'] = 42;\nvar_dump($a);\n\nWill yield:\narray(0) {\n}\n\nWhereas with objects,\n$a = new StdClass();\n$b = $a;\n$b->foo = 42;\nvar_dump($a);\n\nYields:\nobject(stdClass)#1 (1) {\n  [\"foo\"]=>\n  int(42)\n}\n\nAn edge case when array elements could be objects that need to be cloned as well, is explained in another answer\nYou could get confused by intricacies such as ArrayObject, which is an object that acts exactly like an array. Being an object however, it has reference semantics.\nEdit: @AndrewLarsson raises a point in the comments below. PHP has a special feature called \"references\". They are somewhat similar to pointers in languages like C/C++, but not quite the same. If your array contains references, then while the array itself is passed by copy, the references will still resolve to the original target. That's of course usually the desired behaviour, but I thought it was worth mentioning.\n",
            "\n$arraysAreEqual = ($a == $b); // TRUE if $a and $b have the same key/value pairs.\n$arraysAreEqual = ($a === $b); // TRUE if $a and $b have the same key/value pairs in the same order and of the same types.\n\nSee Array Operators.\nEDIT\nThe inequality operator is != while the non-identity operator is !== to match the equality \noperator == and the identity operator ===.\n",
            "\nWhen you do\n$array_x = $array_y;\n\nPHP copies the array, so I'm not sure how you would have gotten burned.  For your case,\nglobal $foo;\n$foo = $obj->bar;\n\nshould work fine.\nIn order to get burned, I would think you'd either have to have been using references or expecting objects inside the arrays to be cloned.\n",
            "\nPHP will copy the array by default. References in PHP have to be explicit. \n$a = array(1,2);\n$b = $a; // $b will be a different array\n$c = &$a; // $c will be a reference to $a\n\n",
            "\nAccording to this page.\nNOTE: The accepted answer works for associative arrays, but it will not work as expected with indexed arrays (explained below). If you want to compare either of them, then use this solution. Also, this function may not works with multidimensional arrays (due to the nature of array_diff function).\nTesting two indexed arrays, which elements are in different order, using $a == $b or $a === $b fails, for example:\n<?php\n    (array(\"x\",\"y\") == array(\"y\",\"x\")) === false;\n?>\n\nThat is because the above means:\narray(0 => \"x\", 1 => \"y\") vs. array(0 => \"y\", 1 => \"x\").\nTo solve that issue, use:\n<?php\nfunction array_equal($a, $b) {\n    return (\n         is_array($a) \n         && is_array($b) \n         && count($a) == count($b) \n         && array_diff($a, $b) === array_diff($b, $a)\n    );\n}\n?>\n\nComparing array sizes was added (suggested by super_ton) as it may improve speed.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "arrays",
            "copy"
        ]
    },
    {
        "question_id": "4870531",
        "question": "\nI was wondering if there is a way to find the newest record in a table in rails3?\n",
        "all_answers": [
            "\nTry, for a model named ModelName:\nrecord = ModelName.last\n\n",
            "\nGiven a Post model, you could do @post = Post.order(\"created_at\").last\n(The reason I didn't just do a @post = Post.last is because that always defaults to sort by your primary key (usually id). Most of the time this is fine, but I'm sure there's a scenario where that could cause problems (e.g. setting custom IDs on records, database changes which affect the primary key sequencing/autonumbering, etc.). Sorting by the created_at timestamp ensures you are really getting the most recent record).\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "ruby-on-rails-3"
        ]
    },
    {
        "question_id": "4686945",
        "question": "\nDumb question but I have some lingering confusion of what, exactly, a \"resource\" is in Rails. The term is used everywhere but I get a funny feeling it might be being used rather loosely. It's referenced in the model, the controller and, quite literally, in routes.rb. \nIs it the specific route? For example, map.resources maps the 7 RESTful \"resources\". So an example of one resource would be the call to, say, the index action of a particular class's controller?!?\nIs it a reference to the whole page/object being retrieved? or perhaps, more narrowly, a database table? or the row being retreived?\nIs it something else? \nAnyway, hopefully someone can set me straight...\n",
        "all_answers": [
            "\nAny object that you want users to be able to access via URI and perform CRUD (or some subset thereof) operations on can be thought of as a resource. In the Rails sense, it is generally a database table which is represented by a model, and acted on through a controller.\nFor example, you might have a User resource (with a users table in your DB). This is represented by a User model, is mapped to users_controller with map.resources :users (which then generates routes like /users (a collection of User resources) and /users/1 (a specific User resource).\nYou act upon those resources by using the appropriate HTTP method when making calls to those resources. POST to the resource collection (/users) creates a new record; GET retrieves a list of resources (/users) or a specific user (/users/1). PUT updates a specific user (/users/1/), and DELETE destroys that user. The URLs are the same, but the result (and controller action) may be different based on the HTTP verb. The idea, though is that /users/1 always means \"I'm interacting with the User that has ID #1\", regardless of the action.\n",
            "\nI think they probably mean it in the general web sense, i.e., Resource (Web):\n\nthe referent of any Uniform Resource Identifier\n\nI don't think it has anything to do with database tables.\n",
            "\nHere's a good article discussing how most developers think that \"Resource\" is synonomous with the database table, the argument, I guess, being that mapping to the resource is mapping the controller to that database table (or, with ActiveResource, to another REST url).\nBasically, I think a \"resource\" is \"persisted data.\" map.resources maps the 7 RESTful actions to a particular suite of persisted data.\nBut I haven't thought about it too much in depth. Good question!\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails"
        ]
    },
    {
        "question_id": "3506208",
        "question": "\nHere are two pages, test.php and testserver.php.\ntest.php\n<script src=\"scripts/jq.js\" type=\"text/javascript\"></script>\n<script>\n    $(function() {\n        $.ajax({url:\"testserver.php\",\n            success:function() {\n                alert(\"Success\");\n            },\n            error:function() {\n                alert(\"Error\");\n            },\n            dataType:\"json\",\n            type:\"get\"\n        }\n    )})\n</script>\n\ntestserver.php\n<?php\n$arr = array(\"element1\",\n             \"element2\",\n             array(\"element31\",\"element32\"));\n$arr['name'] = \"response\";\necho json_encode($arr);\n?>\n\nNow my problem: when both of these files are on the same server (either localhost or web server), it works and alert(\"Success\") is called; If it is on different servers, meaning testserver.php on web server and test.php on localhost, its not working, and alert(\"Error\") is executing. Even if the URL inside AJAX is changed to http://domain.example/path/to/file/testserver.php\n",
        "all_answers": [
            "\nYou need to have a look at Same Origin Policy:\n\nIn computing, the same origin policy\n  is an important security concept for a\n  number of browser-side programming\n  languages, such as JavaScript. The\n  policy permits scripts running on\n  pages originating from the same site\n  to access each other's methods and\n  properties with no specific\n  restrictions, but prevents access to\n  most methods and properties across\n  pages on different sites.\n\nFor you to be able to get data, it has to be:\nSame protocol and host\nYou need to implement JSONP to workaround it.\n",
            "\nIt means that the object you pass in the request (I guess it is pagedoc) has a circular reference, something like:\nvar a = {};\na.b = a;\n\nJSON.stringify cannot convert structures like this.\nN.B.: This would be the case with DOM nodes, which have circular references, even if they are not attached to the DOM tree. Each node has an ownerDocument which refers to document in most cases. document has a reference to the DOM tree at least through document.body and document.body.ownerDocument refers back to document again, which is only one of multiple circular references in the DOM tree.\n",
            "\nUse JSONP.\njQuery:\n$.ajax({\n     url:\"testserver.php\",\n     dataType: 'jsonp', // Notice! JSONP <-- P (lowercase)\n     success:function(json){\n         // do stuff with json (in this case an array)\n         alert(\"Success\");\n     },\n     error:function(){\n         alert(\"Error\");\n     }      \n});\n\nPHP:\n<?php\n$arr = array(\"element1\",\"element2\",array(\"element31\",\"element32\"));\n$arr['name'] = \"response\";\necho $_GET['callback'].\"(\".json_encode($arr).\");\";\n?>\n\nThe echo might be wrong, it's been a while since I've used php. In any case you need to output callbackName('jsonString') notice the quotes. jQuery will pass its own callback name, so you need to get that from the GET params.\nAnd as Stefan Kendall posted, $.getJSON() is a shorthand method, but then you need to append 'callback=?' to the url as GET parameter (yes, value is ?, jQuery replaces this with its own generated callback method).\n",
            "\nBrowser security prevents making an ajax call from a page hosted on one domain to a page hosted on a different domain; this is called the \"same-origin policy\".\n",
            "\nFrom the Jquery docs (link):\n\nDue to browser security restrictions, most \"Ajax\" requests are subject to the same origin policy; the request can not successfully retrieve data from a different domain, subdomain, or protocol.\nScript and JSONP requests are not subject to the same origin policy restrictions.\n\nSo I would take it that you need to use jsonp for the request. But haven't tried this myself.\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "jquery",
            "ajax",
            "json",
            "cross-domain"
        ]
    },
    {
        "question_id": "25962958",
        "question": "\nI wanted to call a function defined in a first.js file in second.js file. Both files are defined in an HTML file like:\n<script type=\"text/javascript\" src=\"first.js\"></script>\n<script type=\"text/javascript\" src=\"second.js\"></script>\n\nI want to call fn1() defined in first.js in second.js. From my searches answers were if first.js is defined first it is possible, but from my tests I haven't found any way to do that.\nHere is my code:\nsecond.js\ndocument.getElementById(\"btn\").onclick = function() {\n    fn1();\n}\n\nfirst.js\nfunction fn1() {\n    alert(\"external fn clicked\");\n}\n\n",
        "all_answers": [
            "\nA function cannot be called unless it was defined in the same file or one loaded before the attempt to call it.\nA function cannot be called unless it is in the same or greater scope then the one trying to call it.\nYou declare function fn1 in first.js, and then in second you can just have fn1();\n1.js: \nfunction fn1 () {\n    alert();\n}\n\n2.js: \nfn1();\n\nindex.html : \n<script type=\"text/javascript\" src=\"1.js\"></script>\n<script type=\"text/javascript\" src=\"2.js\"></script>\n\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYou can make the function a global variable in first.js\nand have a look at closure  and do not put it in document.ready put it outside\nyou can use ajax too\n    $.ajax({\n      url: \"url to script\",\n      dataType: \"script\",\n      success: success\n    });\n\nsame way you can use jquery getScript\n$.getScript( \"ajax/test.js\" )\n  .done(function( script, textStatus ) {\n    console.log( textStatus );\n  })\n  .fail(function( jqxhr, settings, exception ) {\n    $( \"div.log\" ).text( \"Triggered ajaxError handler.\" );\n});\n\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "html"
        ]
    },
    {
        "question_id": "8225125",
        "question": "\nHow can I remove the last commit from a remote Git repository such as I don't see it any more in the log?\nIf for example git log gives me the following commit history\nA->B->C->D[HEAD, ORIGIN]\n\nhow can I go to\nA->B->C[HEAD,ORIGIN]\n\n",
        "all_answers": [
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nRemove the last commit before push\ngit reset --soft HEAD~1\n1 means the last commit, if you want to remove two last use 2, and so forth*\n",
            "\nIf nobody has pulled it, you can probably do something like\ngit push remote +branch^1:remotebranch\n\nwhich will forcibly update the remote branch to the last but one commit of your branch.\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nBe aware that this will create an \"alternate reality\" for people who have already fetch/pulled/cloned from the remote repository. But in fact, it's quite simple:\ngit reset HEAD^ # remove commit locally\ngit push origin +HEAD # force-push the new HEAD commit\n\nIf you want to still have it in your local repository and only remove it from the remote, then you can use:\ngit push origin +HEAD^:$name_of_your_branch # e.g. +HEAD^:master\n\nSome shells interpret the ^ character. For those shells, either quote/escape or use ~:\nHEAD\\^\n'HEAD^'\nHEAD~\n\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n"
        ],
        "answer": "A7",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "671876",
        "question": "\nI'm developing some desktop software for a client to resell.  The client wants to restrict the software so that the registration code will be specific to one and only one computer.\nBesides using the MAC from the network card, does anyone have any other techniques (that work on both Windows and Mac OS X) for uniquely identifying a computer?\n",
        "all_answers": [
            "\nThere used to be a serial number imprinted into the CPU's, as far as I have seen though; this information (PSN, Pentium Serial Number) has been deprecated.  The information may possibly still exist, but at least in the P3 world it was gone.  Also, I think the obvious choice of MAC address on the NIC for the main interface used for the host should be considered as a real possibility.  Unless your client is not expecting ethernet interfaces to be present on the hosts that they sell to.\n",
            "\nHere's one for Mac: GitX\nScreenshot:\n\n",
            "\nAnother solution is to use a licensing technology with a dongle.  This is a small device that plugs into USB or another I/O port on the host, and serves as a unique, physical key to activate the software.\nA third solution is to provide a license manager.  That is, when the software starts up, it queries a server on the network (either on the customer's LAN or else accessed at your company via the internet) that validates that the customer's usage of the software is legitimate.  This is a good solution for \"concurrent licenses\" so customers can install your software on many hosts, but you license it for simultaneous use on a limited number of hosts.  FLEXnet Publisher is an example of a license management solution.\nThe MAC address of the network card is the solution I used last time I worked for a company that licensed software to run on a specific host.\nHowever, I want to offer a caution:  if you do this type of licensing, you have to anticipate that it'll become an ongoing administrative chore to track  your customers' licenses.  Once you have a few hundred customers, you'll be amazed at how frequently you get phone calls with requests to change keys\n\n\"We upgraded our server to a gigabit\n  network adapter, and now the license\n  won't work because the new adapter has\n  a different MAC address.\"\n\nOr else the customers may replace their whole machine, and need an updated license to run your software on the new machine.  We got these calls practically every day at the company I worked for.  \nYou also need to trust the customer to stop using your software on the old computer (or network adapter) if you give them a new key.  If you couldn't trust them to obey the license in the first place, how can you trust that they'll throw away the old key?\nIf you don't plan how you're going to support this administrative activity,  don't license your product in this way.  You'll only inconvenience your good customers, who would have cooperated anyway.\n",
            "\nWindows has TortoiseGit. It is not as mature as TortoiseSVN, but I've been using it and it works well enough for my purposes.\nScreenshot:\n\nEDIT [Dec 2014]: I'd also recommend looking at Dan's answer. Github's UI is probably the most mature/supported tool out there now (even if you don't use Github!)\n",
            "\nTry Git Extensions.\nScreenshot:\n\n",
            "\nIn the vein of teaching how to fish: take a look at https://git.wiki.kernel.org/index.php/InterfacesFrontendsAndTools page on Git Wiki, which has section about GUIs.\nGit Homepage also has section about GUIs: http://git-scm.com/downloads/guis\n",
            "\nI'm surprised nobody has mentioned Tower for Mac OSX.\nHere is a screenshot:\n\n",
            "\nSource Tree (for MAC)\nScreenshot:\n\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "macos",
            "uniqueidentifier"
        ]
    },
    {
        "question_id": "314636",
        "question": "\nIf you know the Index, Value or Text. also if you don't have an ID for a direct reference.\nThis, this and this are all helpful answers.\nExample markup\n<div class=\"selDiv\">\n  <select class=\"opts\">\n    <option selected value=\"DEFAULT\">Default</option>\n    <option value=\"SEL1\">Selection 1</option>\n    <option value=\"SEL2\">Selection 2</option>\n  </select>\n</div>\n\n",
        "all_answers": [
            "\nAnswering my own question for documentation. I'm sure there are other ways to accomplish this, but this works and this code is tested.\n<html>\n<head>\n<script language=\"Javascript\" src=\"javascript/jquery-1.2.6.min.js\"></script>\n<script type=\"text/JavaScript\">\n\n$(function() {\n    $(\".update\").bind(\"click\",      // bind the click event to a div\n        function() {\n            var selectOption = $('.selDiv').children('.opts') ;\n            var _this = $(this).next().children(\".opts\") ;\n\n            $(selectOption).find(\"option[index='0']\").attr(\"selected\",\"selected\");\n//          $(selectOption).find(\"option[value='DEFAULT']\").attr(\"selected\",\"selected\");\n//          $(selectOption).find(\"option[text='Default']\").attr(\"selected\",\"selected\");\n\n\n//          $(_this).find(\"option[value='DEFAULT']\").attr(\"selected\",\"selected\");\n//          $(_this).find(\"option[text='Default']\").attr(\"selected\",\"selected\");\n//          $(_this).find(\"option[index='0']\").attr(\"selected\",\"selected\");\n\n    }); // END Bind\n}); // End eventlistener\n\n</script>\n</head>\n<body>\n<div class=\"update\" style=\"height:50px; color:blue; cursor:pointer;\">Update</div>\n<div class=\"selDiv\">\n        <select class=\"opts\">\n            <option selected value=\"DEFAULT\">Default</option>\n            <option value=\"SEL1\">Selection 1</option>\n            <option value=\"SEL2\">Selection 2</option>\n        </select>\n    </div>\n</body>\n</html>\n\n",
            "\nYou can just use val() method:\n$('select').val('the_value');\n\n",
            "\nA selector to get the middle option-element by value is\n$('.selDiv option[value=\"SEL1\"]')\n\nFor an index:\n$('.selDiv option:eq(1)')\n\nFor a known text:\n$('.selDiv option:contains(\"Selection 1\")')\n\nEDIT: As commented above the OP might have been after changing the selected item of the dropdown. In version 1.6 and higher the prop() method is recommended:\n$('.selDiv option:eq(1)').prop('selected', true)\n\nIn older versions:\n$('.selDiv option:eq(1)').attr('selected', 'selected')\n\nEDIT2: after Ryan's comment. A match on \"Selection 10\" might be unwanted. I found no selector to match the full text, but a filter works:\n $('.selDiv option')\n    .filter(function(i, e) { return $(e).text() == \"Selection 1\"})\n\nEDIT3: Use caution with $(e).text() as it can contain a newline making the comparison fail.  This happens when the options are implicitly closed (no </option> tag):\n<select ...>\n<option value=\"1\">Selection 1\n<option value=\"2\">Selection 2\n   :\n</select>\n\nIf you simply use e.text any extra whitespace like the trailing newline will be removed, making the comparison more robust.\n"
        ],
        "answer": "A3",
        "tags": [
            "jquery"
        ]
    },
    {
        "question_id": "15536872",
        "question": "\nI can't find at all where npm has its global settings stored.\nnpm config get userconfig\nC:\\Users\\Jack\\.npmrc\n\nnpm config get globalconfig\nC:\\Users\\Jack\\AppData\\Roaming\\npm\\etc\\npmrc\n\nThere's no files at either of these paths and yet \nnpm config get proxy\n-> returns my proxy url for work. which I want to delete.\nnpm config -g delete proxy\nnpm ERR! Error: ENOENT, unlink 'C:\\Users\\Jack\\AppData\\Roaming\\npm\\etc\\npmrc'\n\nnpm ERR! System Windows_NT 6.2.9200\nnpm ERR! command \"C:\\\\Program Files\\\\nodejs\\\\\\\\node.exe\" \"C:\\\\Program Files\\\\nodejs\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\" \"config\" \"-g\" \"delete\" \"proxy\"\nnpm ERR! cwd C:\\f\\Dropbox\\apps\nnpm ERR! node -v v0.8.22\nnpm ERR! npm -v 1.2.14\nnpm ERR! path C:\\Users\\Jack\\AppData\\Roaming\\npm\\etc\\npmrc\nnpm ERR! code ENOENT\nnpm ERR! errno 34\nnpm ERR!\nnpm ERR! Additional logging details can be found in:\nnpm ERR!     C:\\f\\Dropbox\\apps\\npm-debug.log\nnpm ERR! not ok code 0\n\n",
        "all_answers": [
            "\nIsn't this the path you are looking for?\nC:\\Program Files\\nodejs\\node_modules\\npm\\npmrc\nI know that npm outputs that , but the global folder is the folder where node.js is installed and all the modules are.\n",
            "\nIt looks like the files npm uses to edit its config files are not created on a clean install, as npm has a default option for each one. This is why you can still get options with npm config get <option>: having those files only overrides the defaults, it doesn't create the options from scratch.\nI had never touched my npm config stuff before today, even though I had had it for months now. None of the files were there yet, such as ~/.npmrc (on a Windows 8.1 machine with Git Bash), yet I could run npm config get <something> and, if it was a correct npm option, it returned a value. When I ran npm config set <option> <value>, the file ~/.npmrc seemed to be created automatically, with the option & its value as the only non-commented-out line.\nAs for deleting options, it looks like this just sets the value back to the default value, or does nothing if that option was never set or was unset & never reset. Additionally, if that option is the only explicitly set option, it looks like ~/.npmrc is deleted, too, and recreated if you set anything else later.\nIn your case (assuming it is still the same over a year later), it looks like you never set the proxy option in npm. Therefore, as npm's config help page says, it is set to whatever your http_proxy (case-insensitive) environment variable is. This means there is nothing to delete, unless you want to \"delete\" your HTTP proxy, although you could set the option or environment variable to something else and hope neither breaks your set-up somehow.\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "node.js",
            "npm"
        ]
    },
    {
        "question_id": "6081617",
        "question": "\nAFAIK maven does not have an installer for Windows, you simply unzip it wherever you like, as explained here.\nHowever in many places there are references to a .m2 folder under the user folder (in Win7 I would guess it to be by default at C:\\Users\\.m2. Alas I do not have that folder. Is there some command to create this folder? Am I missing something basic?\n",
        "all_answers": [
            "\nYou can use the Rscript front end to run code as if it were in a running R session. Say the package you want to install is foo.zip in the current working directory. I'm probably abusing Rscript here, but it works for me:\nRscript -e \"install.packages('foo.zip', repos = NULL)\"\n\nYou need to supply the path to the binary package if it is not in the directory where there script is running. repos = NULL is the trick to get install.packages() to work from a local file. Read ?install.packages for more info on other arguments you might want to specify, especially lib. Note that you don't benefit from automatic dependency resolution when doing this - you need a repo for that and if you supply one, R will try to download packages.\nYou are right about R CMD INSTALL; the R Installation and Administration manual has the following in Section 6.3:\n\nTo install packages from source in a Unix-alike use\n    R CMD INSTALL -l /path/to/library pkg1 pkg2 ...\n\n\n",
            "\nAn alternative for newbies like me that is hassle free would be:\n install.packages(file.choose(), repos=NULL)\n\nThe file.choose() command will show a window allowing you to choose the .zip file or the tar.gz file where you downloaded it. \nThis command is very useful when you don't have enough rights on a Windows machine and run R from a flash drive like myself. \nIt is also useful before running this command to RENAME the zip file you are going to install into the package name that you intend to use.\n",
            "\nDo you have the file system display config set up to show hidden files and folders?  If I remember correctly, by default it's hidden.  Should be under c:\\users\\username\\.m2.\n",
            "\nOn a Windows machine, the .m2 folder is expected to be located under ${user.home}. On Windows 7 and Vista this resolves to <root>\\Users\\<username> and on XP it is <root>\\Documents and Settings\\<username>\\.m2. So you'd normally see it under c:\\Users\\Jonathan\\.m2.\nIf you want to create a folder with a . prefix on Windows, you can simply do this on the command line.\n\nGo to Start->Run\nType cmd and press Enter\nAt the command prompt type md c:\\Users\\Jonathan\\.m2 (or equivalent for your ${user.home} value).\n\nNote that you don't actually need the .m2 location unless you want to create a distinct user settings file, which is optional (see the Settings reference for more details).\nIf you don't need a separate user settings file and don't really want the local repository under your user home you can simply set the location of your repository to a different folder by modifying the global settings file (located in \\conf\\settings.xml).\nThe following snippet would set the local repository to c:\\Maven\\repository for example:\n<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                  http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  <localRepository>c:\\Maven\\repository</localRepository>\n  ...\n\n"
        ],
        "answer": "A4",
        "tags": [
            "windows",
            "maven",
            "installation"
        ]
    },
    {
        "question_id": "1024847",
        "question": "\nHow do I add a new key to an existing dictionary? It doesn't have an .add() method.\n",
        "all_answers": [
            "\nUse a dict comprehension (Python 2.7 and later):\n{key: value for key, value in zip(keys, values)}\n\n\nAlternatively, use the dict constructor (for str keys only):\npairs = [('a', 1), ('b', 2)]\ndict(pairs)                          # → {'a': 1, 'b': 2}\ndict((k, v + 10) for k, v in pairs)  # → {'a': 11, 'b': 12}\n\nGiven separate lists of keys and values, use the dict constructor with zip:\nkeys = ['a', 'b']\nvalues = [1, 2]\ndict(zip(keys, values))              # → {'a': 1, 'b': 2}\n\n",
            "\ndictionary[key] = value\n\n",
            "\nIn Python 3 and Python 2.7+, dictionary comprehensions look like the below:\nd = {k:v for k, v in iterable}\n\nFor Python 2.6 or earlier, see fortran's answer.\n",
            "\nIn fact, you don't even need to iterate over the iterable if it already comprehends some kind of mapping, the dict constructor doing it graciously for you:\n>>> ts = [(1, 2), (3, 4), (5, 6)]\n>>> dict(ts)\n{1: 2, 3: 4, 5: 6}\n>>> gen = ((i, i+1) for i in range(1, 6, 2))\n>>> gen\n<generator object <genexpr> at 0xb7201c5c>\n>>> dict(gen)\n{1: 2, 3: 4, 5: 6}\n\n",
            "\nYou create a new key/value pair on a dictionary by assigning a value to that key\nd = {'key': 'value'}\nprint(d)  # {'key': 'value'}\n\nd['mynewkey'] = 'mynewvalue'\n\nprint(d)  # {'key': 'value', 'mynewkey': 'mynewvalue'}\n\nIf the key doesn't exist, it's added and points to that value. If it exists, the current value it points to is overwritten.\n"
        ],
        "answer": "A5",
        "tags": [
            "python",
            "dictionary",
            "lookup"
        ]
    },
    {
        "question_id": "3724242",
        "question": "\nI know about int and long (32-bit and 64-bit numbers), but what are uint and ulong?\n",
        "all_answers": [
            "\nTry:\nType type = Type.GetType(inputString); //target type\nobject o = Activator.CreateInstance(type); // an instance of target type\nYourType your = (YourType)o;\n\nJon Skeet is right as usually :)\nUpdate: You can specify assembly containing target type in various ways, as Jon mentioned, or:\nYourType your = (YourType)Activator.CreateInstance(\"AssemblyName\", \"NameSpace.MyClass\");\n\n",
            "\nThe primitive data types prefixed with \"u\" are unsigned versions with the same bit sizes. Effectively, this means they cannot store negative numbers, but on the other hand they can store positive numbers twice as large as their signed counterparts. The signed counterparts do not have \"u\" prefixed.\nThe limits for int (32 bit) are:\nint: –2147483648 to 2147483647 \nuint: 0 to 4294967295 \n\nAnd for long (64 bit):\nlong: -9223372036854775808 to 9223372036854775807\nulong: 0 to 18446744073709551615\n\n",
            "\nIf you really want to get the type by name you may use the following:\nSystem.AppDomain.CurrentDomain.GetAssemblies().SelectMany(x => x.GetTypes()).First(x => x.Name == \"theassembly\");\n\nNote that you can improve the performance of this drastically the more information you have about the type you're trying to load.\n",
            "\nuint and ulong are the unsigned versions of int and long. That means they can't be negative. Instead they have a larger maximum value.\n\nType    Min                           Max                           CLS-compliant\nint     -2,147,483,648                2,147,483,647                 Yes\nuint    0                             4,294,967,295                 No\nlong    –9,223,372,036,854,775,808    9,223,372,036,854,775,807     Yes\nulong   0                             18,446,744,073,709,551,615    No\n\nTo write a literal unsigned int in your source code you can use the suffix u or U for example 123U.\nYou should not use uint and ulong in your public interface if you wish to be CLS-Compliant.\nRead the documentation for more information:\n\nint\nuint\nlong\nulong\n\nBy the way, there is also short and ushort and byte and sbyte.\n",
            "\nYou can only use just the name of the type (with its namespace, of course) if the type is in mscorlib or the calling assembly. Otherwise, you've got to include the assembly name as well:\nType type = Type.GetType(\"Namespace.MyClass, MyAssembly\");\n\nIf the assembly is strongly named, you've got to include all that information too. See the documentation for Type.GetType(string) for more information.\nAlternatively, if you have a reference to the assembly already (e.g. through a well-known type) you can use Assembly.GetType:\nAssembly asm = typeof(SomeKnownType).Assembly;\nType type = asm.GetType(namespaceQualifiedTypeName);\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "types",
            "integer",
            "unsigned",
            "signed"
        ]
    },
    {
        "question_id": "12412167",
        "question": "\nI need to stop a thread until another thread sets a boolean value and I don't want to share between them an event.\nWhat I currently have is the following code using a Sleep (and that's the code I want to change):\nwhile (!_engine.IsReadyToStop())\n{\n    System.Threading.Thread.Sleep(Properties.Settings.Default.IntervalForCheckingEngine); \n}\n\nAny ideas?\nEDIT TO CLARIFY THINGS:\nThere is an object called _engine of a class that I don't own. I cannot modify it, that's why I don't want to share an event between them. I need to wait until a method of that class returns true.\n",
        "all_answers": [
            "\nHere is a good write up about .NET events and race conditions with threads.  It covers some common scenarios and has some good references in it.\nHope this helps.\n",
            "\nSpinWait.SpinUntil is the right answer, regardless where you're gonna place this code. SpinUntil offers \"a nice mix of spinning, yielding, and sleeping in between invocations\".\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\ndeclare as\n AutoResetEvent _ReadyToStop = new AutoResetEvent(false);\n\nand use as\n _ReadyToStop.WaitOne();\n\nand \n _ReadyToStop.Set();\n\nFor more info see the Synchronization Primitives in .Net\n",
            "\nIf you are using C# 4.0, you can use:\nTask t = Task.Factory.StartNew (() => SomeCall(..));\nt.Wait();\n\nBy using Task.Wait method.\nIf you have more than one task run one after another, you can use Task.ContinueWith:\n Task t = Task.Factory.StartNew (() =>SomeCall(..)).\n                                ContinueWith(ExecuteAfterThisTaskFinishes(...);\n t.Wait();\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            ".net",
            "multithreading",
            "mutex",
            "semaphore"
        ]
    },
    {
        "question_id": "5365055",
        "question": "\nI just started developing PHP projects on my mac (using PDT) and was wondering where localhost is located? How does Mac OS X serve websites, I haven't changed any settings during the installation of PDT.\n",
        "all_answers": [
            "\nThere's no such thing as a \"localhost\" folder; the word \"localhost\" is an alias for your local computer. The document root for your apache server, by default, is \"Sites\" in your home directory.\n",
            "\nbrew install autoconf\n\nMuch easier solution\n",
            "\nXCODE 4.3 doesn't put all the autoconf etc. tools in the Developer folder. It doesn't even create that folder in MACINTOSH HD. I had to downgrade to XCODE 4.2.1 which installs everything you need in the Developer folder and now I see no errors.\nAlso here is a useful reference.\n",
            "\nThere are actually two place where mac os x serves websites by default:\n\n/Library/WebServer/Documents --> http://localhost\n~/Sites --> http://localhost/~user/\n\n",
            "\nYou have to make your Apache use the PHP that you just downloaded.\n\nOpen your httpd.conf (mine is at /etc/apache2/httpd.conf) and look for the line that loads the PHP module, something like:\nLoadModule php5_module path/to/php\nThen, make it point to the PHP that brew installed for you with mcrypt support. Mine was at this path. Yours can vary depending on the PHP version that you installed.\n/usr/local/Cellar/php54/5.4.21/libexec/apache2/libphp5.so\nFinally you will need to restart your Apache server to load the new configuration:\nsudo apachectl restart\n\n",
            "\nor\nsudo port install autoconf\n\nif you use macports\n",
            "\nThe default Apache root folder (localhost/) is /Library/WebServer/Documents\nAlso, make sure you have the PHP5 module loaded in /etc/apache2/httpd.conf\nLoadModule php5_module libexec/apache2/libphp5.so\n\n",
            "\nYou need to install autoconfig. I usually like to install libraries from source. So you can do the following:\ncurl -OL http://ftpmirror.gnu.org/autoconf/autoconf-latest.tar.gz\ntar xzf autoconf-latest.tar.gz\ncd autoconf-*\n./configure --prefix=/usr/local\nmake\nsudo make install\n\nI just went through this with Mountain Lion.\n",
            "\nOn Mac OS X 10.8 situation is slightly different. Highly voted solution from Bob Spryn doesn't work, because it doesn't create symlinks, so after installing autoconf you should make them:\nsudo ln -s /usr/local/Cellar/autoconf/2.69/bin/autoconf /usr/bin/autoconf\nsudo ln -s /usr/local/Cellar/autoconf/2.69/bin/autoheader /usr/bin/autoheader\n\nI know that this question was for 10.7, but I hope my answer is useful for someone on 10.8. :)\nUpdated: Also works on 10.10 Yosemite.\n",
            "\nmaybe you need link autoconf with brew link autoconf.\n"
        ],
        "answer": "A4",
        "tags": [
            "php",
            "macos",
            "eclipse-pdt"
        ]
    },
    {
        "question_id": "3053761",
        "question": "\nIs it a good practice to reload an Activity in Android?\nWhat would be the best way to do it? this.finish and then this.startActivity with the activity Intent?\n",
        "all_answers": [
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nI don't think that's a good idea... it'd be better to implement a cleaner method. For instance, if your activity holds a form, the cleaner method could just clear each widget in the form and delete all temporary data. I guess that's what you want: restore the activity to its initial state.\n",
            "\nYou can Simply use \nfinish();\nstartActivity(getIntent());\n\nto refresh an Activity from within itself.\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nAndroid includes a process management system which handles the creation and destruction of activities which largely negates any benefit you'd see from manually restarting an activity. You can see more information about it at Application Fundamentals\nWhat is good practice though is to ensure that your onPause and onStop methods release any resources which you don't need to hold on to and use onLowMemory to reduce your activities needs to the absolute minimum.\n",
            "\nin some cases it's the best practice in other it's not a good idea it's context driven\nif you chose to do so using the following is the best way to pass from an activity to her sons :\n    Intent i = new Intent(myCurrentActivityName.this,activityIWishToRun.class);    \n    startActivityForResult(i, GlobalDataStore.STATIC_INTEGER_VALUE);\n\nthe thing is whenever you finish() from activityIWishToRun you return to your a living  activity\n",
            "\nI needed to update a message list in one of my applications in a hurry, so I just performed a refresh of my main UI activity before I closed the dialog I was in. I'm sure there are better ways to accomplish this as well. \n// Refresh main activity upon close of dialog box\nIntent refresh = new Intent(this, clsMainUIActivity.class);\nstartActivity(refresh);\nthis.finish(); //\n\n",
            "\nAfter experimenting with this for a while I've found no unexpected consequences of restarting an activity. Also, I believe this is very similar to what Android does by default when the orientation changes, so I don't see a reason not to do it in a similar circumstance.\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "android-activity"
        ]
    },
    {
        "question_id": "5396498",
        "question": "\nmyCol\n------\n true\n true\n true\n false\n false\n null\n\nIn the above table, if I do :\nselect count(*), count(myCol);\n\nI get 6, 5\nI get 5 as it doesn't count the null entry.\nHow do I also count the number of true values (3 in the example)?\n(This is a simplification and I'm actually using a much more complicated expression within the count function)\nEdit summary: I also want to include a plain count(*) in the query, so can't use a where clause\n",
        "all_answers": [
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nSELECT count(*)         -- or count(myCol)\nFROM   <table name>     -- replace <table name> with your table\nWHERE  myCol = true;\n\nHere's a way with Windowing Function:\nSELECT DISTINCT *, count(*) over(partition by myCol)\nFROM   <table name>;\n\n-- Outputs:\n-- --------------\n-- myCol | count\n-- ------+-------\n--  f    |  2\n--  t    |  3\n--       |  1\n\n",
            "\nselect f1,\n       CASE WHEN f1 = 't' THEN COUNT(*) \n            WHEN f1 = 'f' THEN COUNT(*) \n            END AS counts,\n       (SELECT COUNT(*) FROM mytable) AS total_counts\nfrom mytable\ngroup by f1\n\nOr Maybe this\nSELECT SUM(CASE WHEN f1 = 't' THEN 1 END) AS t,\n       SUM(CASE WHEN f1 = 'f' THEN 1 END) AS f,\n       SUM(CASE WHEN f1 NOT IN ('t','f') OR f1 IS NULL THEN 1 END) AS others,\n       SUM(CASE WHEN f1 IS NOT NULL OR f1 IS NULL THEN 1 ELSE 0 END) AS total_count\nFROM mytable;\n\n",
            "\nSELECT COALESCE(sum(CASE WHEN myCol THEN 1 ELSE 0 END),0) FROM <table name>\n\nor, as you found out for yourself:\nSELECT count(CASE WHEN myCol THEN 1 END) FROM <table name>\n\n"
        ],
        "answer": "A4",
        "tags": [
            "sql",
            "postgresql"
        ]
    },
    {
        "question_id": "24007050",
        "question": "\n\n\n\nWhat is the minimum deployment target for Xcode 6 and the new Swift language?  Specifically, can I still support iOS 5.0?\n",
        "all_answers": [
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nSwift is supported on devices running iOS 7 or later.\n",
            "\nYou actually don't need to use a web and app URL anymore. The web URL will automatically open in the app if the user has it. Instagram or other apps implement this on their end as a Universal Link\nSwift 4\nfunc openInstagram(instagramHandle: String) {\n    guard let url = URL(string: \"https://instagram.com/\\(instagramHandle)\")  else { return }\n    if UIApplication.shared.canOpenURL(url) {\n        if #available(iOS 10.0, *) {\n            UIApplication.shared.open(url, options: [:], completionHandler: nil)\n        } else {\n            UIApplication.shared.openURL(url)\n        }\n    }\n}\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nFrom one of the engineers working on Swift, iOS 7, Mavericks and later:\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nIn swift 3;\nFirst you should add this on your Info.plist\n\nThan you can use this code;\n    let instagramUrl = URL(string: \"instagram://app\")\n    UIApplication.shared.canOpenURL(instagramUrl!)\n    UIApplication.shared.open(instagramUrl!, options: [:], completionHandler: nil)\n\n"
        ],
        "answer": "A5",
        "tags": [
            "ios",
            "swift"
        ]
    },
    {
        "question_id": "4316940",
        "question": "\nAny idea on how to create and save a new User object with devise from the ruby console?\nWhen I tried to save it, I'm getting always false. I guess I'm missing something but I'm unable to find any related info.\n",
        "all_answers": [
            "\nYou should be able to do this using\nu = User.new(:email => \"[email protected]\", :password => 'password', :password_confirmation => 'password')\nu.save\n\nif this returns false, you can call\nu.errors\n\nto see what's gone wrong.\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nYou can add false to the save method to skip the validations if you want.\nUser.new({:email => \"[email protected]\", :roles => [\"admin\"], :password => \"111111\", :password_confirmation => \"111111\" }).save(false)\n\nOtherwise I'd do this\nUser.create!({:email => \"[email protected]\", :roles => [\"admin\"], :password => \"111111\", :password_confirmation => \"111111\" })\n\nIf you have confirmable module enabled for devise, make sure you are setting the confirmed_at value to something like Time.now while creating.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "devise"
        ]
    },
    {
        "question_id": "21615431",
        "question": "\nI have an issue with git and my terminal. Here's a gallery to show you my issue.\nWhen I push commits from my terminal, git says I push them with another username, that's a user from my organization (my company) with no commit at all and it seems it belongs to no one : (check gallery first pic)\nBut this doesn't happen when I use Github for mac, in the feed I see the commits pushed by myself.\nThe problem also affects my personal repositories, my terminal says that I don't have the permission to push commits on those repositories (which is obviously wrong) since it tries to push it with this user : (check gallery second pic)\nGuess what ? This doesn't happen with Github for mac too.\nI changed my computer to a brand new one few days ago, so I reset'ed all my ssh key of github and left only a new one generated by Github for Mac so I don't think that there's some ghost user/ssh key hidden somewhere, this hdd is brand new : (check gallery third pic)\nMy .gitconfig file is all clear, there's only my credentials : (check gallery fourth pic)\nI really don't get it, help, StackOverflow, you're my only hope.\n(My apologies for my poor Gimp skills and the Star Wars reference)\nEDIT : ssh-add -l only shows the good ssh key created by github for mac and I have only one github account\nEDIT2 : ssh -T git@github.com recognize me as the good user.\nEDIT3 : After a few tests it looks like my terminal does the commits with my username, but pushes them with the other one, Github for mac commits and pushes with the good username.This situation happen with every repo I have/make (even new ones).\nEDIT4 : In a personal repository git log --pretty=\"%h %an %ae\" shows my good username\nEDIT5 : No sign of environment variables that would override my credentials in my env. Even if I try to set those variables with the good credentials problem persists.\nEDIT6 : Things work back normally if I force the user in the path of /.git/config of a repository but I don't think that's the good option : http://USER@github.com/USER/REPO.git\nEDIT7 : We deleted the git user that pushed the commits for me and this brings another error : remote: Invalid username or password. fatal: Authentication failed for 'https://github.com/USER/REPO.git/'\nFINAL EDIT : I installed git with homebrew, typed git config --global push.default simple and now it takes my credentials even without forceing the user. That's strange. Thanks everybody for your help, you're great guys !\n",
        "all_answers": [
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nDespite all the great options given by other users, the only way to fix this was to reinstall git completely and type git config --global push.default simple to rewrite good credentials.\n",
            "\n\nit looks like my terminal does the commits with my username, but pushes them with the other one\n\nAuthor and committer name and email (which are important for GitHub) are derived from:\ngit config user.name\ngit config user.email\n\nHowever, as mentioned in git config and git commit-tree, those values can be overridden by environment variables:\nGIT_AUTHOR_NAME\nGIT_AUTHOR_EMAIL\nGIT_COMMITTER_NAME\nGIT_COMMITTER_EMAIL\n\nSo double-check those variables.\n\nThings work back normally if I force the user in the .git/config of a repository but I don't think that's the good option.\n\nBut it should be a good solution.\nWhen using an https url, I always specify the user in it to make sure the authentication is done with the right user.\nhttp://USER@github.com/USER/REPO.git\n\n"
        ],
        "answer": "A2",
        "tags": [
            "git",
            "github",
            "ssh",
            "git-push"
        ]
    },
    {
        "question_id": "31638582",
        "question": "\nConfiguration:\n\nWindows 8.1\nADB version: 1.0.32\nSmartphone: Oneplus One\n\nProblem\nI installed the Samsung drivers as it is said to do. When I run the ADB devices command, it said unauthorized.\nAlready tried:\n\nI've done everything that'd been said on this post: https://stackoverflow.com/a/25546300/1848376\nBut the problem is that I don't get a prompt on the phone to tell me I must accept the connection.\nWhen I run the command adb shell, here is the answer:\nerror: device unauthorized.\nThis adbd's $ADB_VENDOR_KEYS is not set; try 'adb kill-server' if that seems wrong.\nOtherwise check for a confirmation dialog on your device.\n\n\nI did \"adb kill-server\", but it didn't change anything. Why?\n",
        "all_answers": [
            "\nI had this problem and it wasnt solved by the deleting of any keys (at least deleting them didnt fix it, maybe had an effect after i did fix it though)\nI actually had a discrepancy between my sdk-tools version and my Android Studio version. After updating my tools it still didnt work, but after updating AS (to 1.4) everything worked fine again.\nAlways update both sdk-tools and AS version together ;)\n",
            "\nI removed the following files from the ~/.android folder:\n\nadbkey\nadbkey.pub\n\nI disabled and enabled ADB within device and now it works...\n",
            "\n\nTry Revoke USB DEBUGGING Authorization.\nEnable USB debugging again.\n\nIt worked. \n",
            "\nI had the same problem after reinstalled my android studio. Here's what I did to make my adb work again:\n-path to C:\\Users\\User\\AppData\\Local\\Android\\sdk\\platform-tools\n-Shift+r.click and start command from here instead.\n\n",
            "\nI was hit by this problem, too. I'm using my custom build of AOSP on Nexus 5X. I've added a single line in build/core/main.mk:\ndiff --git a/core/main.mk b/core/main.mk\nindex a6f829ab6..555657539 100644\n--- a/core/main.mk\n+++ b/core/main.mk\n@@ -362,6 +362,8 @@ else # !enable_target_debugging\n   ADDITIONAL_DEFAULT_PROPERTIES += ro.debuggable=0\n endif # !enable_target_debugging\n\n+ADDITIONAL_DEFAULT_PROPERTIES += ro.adb.secure=1\n+\n ## eng ##\n\n ifeq ($(TARGET_BUILD_VARIANT),eng)\n\nNow adb shell works fine\nThose materials are useful (Chinese articles): http://www.voidcn.com/blog/kc58236582/article/p-6335996.html, http://blog.csdn.net/fanmengke_im/article/details/28389439\n",
            "\nThankgod xda developers exist : http://forum.xda-developers.com/verizon-lg-g3/help/unable-to-access-adb-t2830087\nJust had to delete adbkey file in C:Users/$Name/.android adbkey.pub was missing.\nRestart after this and both files are there.\nIf this does not work : \n- Try Revoke USB DEBUGGING Authorization.\n- Enable USB debugging again.\n",
            "\nI suppose you have enabled On-device Developer Options in your smartphone? If not you can take a look at the steps provided by Android, http://developer.android.com/tools/device.html#developer-device-options \n",
            "\nAll you need is to authorize debug mode.\n1. make sure your Device is connected to your PC. \n2. Allow authorized for debug mode via Android-Studio by going to  \nRun -> Attach debugger to Android process \nthan you will see the pop up window for allow debug mode in your Device, press OK. done.\ni hope it help to someone.\n"
        ],
        "answer": "A6",
        "tags": [
            "android",
            "adb",
            "unauthorized",
            "oneplusone"
        ]
    },
    {
        "question_id": "3209807",
        "question": "\nI want error logging in PHP CodeIgniter. How do I enable error logging?  \nI have some questions:\n\nWhat are all the steps to log an error?\nHow is an error log file created?\nHow to push the error message into log file (whenever an error occurs)?\nHow do you e-mail that error to an email address?\n\n",
        "all_answers": [
            "\nCodeIgniter has some error logging functions built in.\n\nMake your /application/logs folder writable \nIn /application/config/config.php set $config['log_threshold'] = 1; or use a higher number, depending on how much detail you want in your logs\nUse log_message('error', 'Some variable did not contain a value.');\nTo send an email you need to extend the core CI_Exceptions class method log_exceptions(). You can do this yourself or use this. More info on extending the core here\n\nSee http://www.codeigniter.com/user_guide/general/errors.html\n",
            "\nTo simply put a line in the server's error log, use PHP's error_log() function. However, that method will not send an e-mail.\nFirst, to trigger an error:\ntrigger_error(\"Error message here\", E_USER_ERROR);\n\nBy default, this will go in the server's error log file. See the ErrorLog directive for Apache. To set your own log file:\nini_set('error_log', 'path/to/log/file');\n\nNote that the log file you choose must already exist and be writable by the server process. The simplest way to make the file writable is to make the server user the owner of the file. (The server user may be nobody, _www, apache, or something else, depending on your OS distribution.)\nTo e-mail the error, you need to set up a custom error handler:\nfunction mail_error($errno, $errstr, $errfile, $errline) {\n  $message = \"[Error $errno] $errstr - Error on line $errline in file $errfile\";\n  error_log($message); // writes the error to the log file\n  mail('[email protected]', 'I have an error', $message);\n}\nset_error_handler('mail_error', E_ALL^E_NOTICE);\n\nPlease see the relevant PHP documentation for more info.\n",
            "\nfunction isJson($string) {\n   json_decode($string);\n   return json_last_error() === JSON_ERROR_NONE;\n}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "codeigniter",
            "logging",
            "error-handling"
        ]
    },
    {
        "question_id": "2988017",
        "question": "\n\n\n\nI noticed a Python script I was writing was acting squirrelly, and traced it to an infinite loop, where the loop condition was while line is not ''. Running through it in the debugger, it turned out that line was in fact ''. When I changed it to !='' rather than is not '', it worked fine. \nAlso, is it generally considered better to just use '==' by default, even when comparing int or Boolean values? I've always liked to use 'is' because I find it more aesthetically pleasing and pythonic (which is how I fell into this trap...), but I wonder if it's intended to just be reserved for when you care about finding two objects with the same id.\n",
        "all_answers": [
            "\nSee This question\nYour logic in reading \n\nFor all built-in Python objects (like\n  strings, lists, dicts, functions,\n  etc.), if x is y, then x==y is also\n  True.\n\nis slightly flawed.\nIf is applies then == will be True, but it does NOT apply in reverse. == may yield True while is yields False.\n",
            "\n\nFor all built-in Python objects (like\n  strings, lists, dicts, functions,\n  etc.), if x is y, then x==y is also\n  True.\n\nNot always.  NaN is a counterexample.  But usually, identity (is) implies equality (==).  The converse is not true: Two distinct objects can have the same value.\n\nAlso, is it generally considered better to just use '==' by default, even\n  when comparing int or Boolean values?\n\nYou use == when comparing values and is when comparing identities.\nWhen comparing ints (or immutable types in general), you pretty much always want the former.  There's an optimization that allows small integers to be compared with is, but don't rely on it.\nFor boolean values, you shouldn't be doing comparisons at all.   Instead of:\nif x == True:\n    # do something\n\nwrite:\nif x:\n    # do something\n\nFor comparing against None, is None is preferred over == None.\n\nI've always liked to use 'is' because\n  I find it more aesthetically pleasing\n  and pythonic (which is how I fell into\n  this trap...), but I wonder if it's\n  intended to just be reserved for when\n  you care about finding two objects\n  with the same id.\n\nYes, that's exactly what it's for.\n",
            "\nThere are two string methods for this, find() and index().  The difference between the two is what happens when the search string isn't found.  find() returns -1  and index() raises a ValueError.\nUsing find()\n>>> myString = 'Position of a character'\n>>> myString.find('s')\n2\n>>> myString.find('x')\n-1\n\n\nUsing index()\n>>> myString = 'Position of a character'\n>>> myString.index('s')\n2\n>>> myString.index('x')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: substring not found\n\n\nFrom the Python manual\n\nstring.find(s, sub[, start[, end]])\nReturn the lowest index in s where the substring sub is found such that sub is wholly contained in s[start:end]. Return -1 on failure. Defaults for start and end and interpretation of negative values is the same as for slices.\n\nAnd:\n\nstring.index(s, sub[, start[, end]])\nLike find() but raise ValueError when the substring is not found.\n\n",
            "\nJust for a sake of completeness, if you need to find all positions of a character in a string, you can do the following:\ns = 'shak#spea#e'\nc = '#'\nprint([pos for pos, char in enumerate(s) if char == c])\n\nwhich will print: [4, 9]\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "string",
            "comparison",
            "equality"
        ]
    },
    {
        "question_id": "15208711",
        "question": "\nI'm curious as to the pros and cons of using subdocuments vs a deeper layer in my main schema:\nvar subDoc = new Schema({\n  name: String\n});\n\nvar mainDoc = new Schema({\n  names: [subDoc]\n});\n\nor \nvar mainDoc = new Schema({\n  names: [{\n    name: String\n }]\n});\n\nI'm currently using subdocs everywhere but I am wondering primarily about performance or querying issues I might encounter.\n",
        "all_answers": [
            "\nI think this is handled elsewhere by multiple post on SO.\nJust a few:\n\nMongoDB relationships: embed or reference?\nHow should I implement this schema in MongoDB?\nMongoDB Schema Design - Many small documents or fewer large documents?\n\nThe big key is that there is no single answer here, only a set of rather complex trade-offs.\n",
            "\nYou will get an error if you try to close/disconnect outside of the method. The best solution is to close the connection in both callbacks in the method. The dummy code is here.\nconst newTodo = new Todo({text:'cook dinner'});\n\nnewTodo.save().then((docs) => {\n  console.log('todo saved',docs);\n  mongoose.connection.close();\n},(e) => {\n  console.log('unable to save');\n});\n\n",
            "\nJust as Jake Wilson said: You can set the connection to a variable then disconnect it when you are done:\nlet db;\nmongoose.connect('mongodb://localhost:27017/somedb').then((dbConnection)=>{\n    db = dbConnection;\n    afterwards();\n});\n\n\nfunction afterwards(){\n\n    //do stuff\n\n    db.disconnect();\n}\n\nor if inside Async function:\n(async ()=>{\n    const db = await mongoose.connect('mongodb://localhost:27017/somedb', { useMongoClient: \n                  true })\n\n    //do stuff\n\n    db.disconnect()\n})\n\notherwise when i was checking it in my environment it has an error.\n",
            "\nYou can close the connection with\nmongoose.connection.close()\n\n",
            "\nYou can set the connection to a variable then disconnect it when you are done:\nvar db = mongoose.connect('mongodb://localhost:27017/somedb');\n\n// Do some stuff\n\ndb.disconnect();\n\n",
            "\nmongoose.connection.close()\n\nno longer supports a callback only accepting a boolean value.\n",
            "\nThe other answer didn't work for me. I had to use mongoose.disconnect(); as stated in this answer. \n",
            "\nProbably you have this:\nconst db = mongoose.connect('mongodb://localhost:27017/db');\n\n// Do some stuff\n\ndb.disconnect();\n\nbut you can also have something like this:\nmongoose.connect('mongodb://localhost:27017/db');\n\nconst model = mongoose.model('Model', ModelSchema);\n\nmodel.find().then(doc => {\n  console.log(doc);\n}\n\nyou cannot call db.disconnect() but you can close the connection after you use it.\nmodel.find().then(doc => {\n  console.log(doc);\n}).then(() => {\n  mongoose.connection.close();\n});\n\n",
            "\nAccording to the docs, it's exactly the same.\nHowever, using a Schema would add an _id field as well (as long as you don't have that disabled),  and presumably uses some more resources for tracking subdocs.\n\nAlternate declaration syntax\nNew in v3 If you don't need access to the sub-document schema instance, you may also declare sub-docs by simply passing an object literal [...]\n\n",
            "\nmongoose.connection.close(function(){\nconsole.log('Mongoose default connection disconnected through app termination');\nprocess.exit(0);\n});\n\nThis will close the mongoose connection and will also notify you by message in your console.\n",
            "\nI'm using version 4.4.2 and none of the other answers worked for me. But adding useMongoClient to the options and putting it into a variable that you call close on seemed to work. \nvar db = mongoose.connect('mongodb://localhost:27017/somedb', { useMongoClient: true })\n\n//do stuff\n\ndb.close()\n\n"
        ],
        "answer": "A9",
        "tags": [
            "javascript",
            "node.js",
            "mongodb",
            "mongoose"
        ]
    },
    {
        "question_id": "8807836",
        "question": "\nThe title is my question. I googled and try something like\nmysql> !\\ clear\nmysql> !\\ cls\nmysql> system cls\nmysql> system clear \n\nblah blah ...\n\nbut none of them works.\nAnyone show me how to clear screen, just like cls command in Windows?\n",
        "all_answers": [
            "\nI don't think Any of the commands will work.\nIn Linux Ctrl+L will do the job. In Windows there is no equivalent. You can only exit MySQL console by executing quit, execute cls and then re-enter MySQL console.\n",
            "\nThis is not possible on Windows.\nThere is an open bug for this issue: Bug #58680: Windows Clear Screen Command\n"
        ],
        "answer": "A2",
        "tags": [
            "mysql",
            "windows",
            "command-line",
            "sqlcommand"
        ]
    },
    {
        "question_id": "5074803",
        "question": "\nGiven a URL like the following, how can I parse the value of the query parameters? For example, in this case I want the value of some_key .\n/some_path?some_key=some_value'\n\nI am using Django in my environment; is there a method on the request object that could help me?\nI tried using self.request.get('some_key') but it is not returning the value some_value as I had hoped.\n",
        "all_answers": [
            "\nThe urlparse module provides everything you need:\nurlparse.parse_qs()\n",
            "\nI usually use a dictionary, not a list to return JSON content. \nimport json\n\nfrom django.http import HttpResponse\n\nresponse_data = {}\nresponse_data['result'] = 'error'\nresponse_data['message'] = 'Some error message'\n\nPre-Django 1.7 you'd return it like this:\nreturn HttpResponse(json.dumps(response_data), content_type=\"application/json\")\n\nFor Django 1.7+, use JsonResponse as shown in this SO answer like so : \nfrom django.http import JsonResponse\nreturn JsonResponse({'foo':'bar'})\n\n",
            "\nThis is not specific to Django, but for Python in general. For a Django specific answer, see this one from @jball037\nPython 2:\nimport urlparse\n\nurl = 'https://www.example.com/some_path?some_key=some_value'\nparsed = urlparse.urlparse(url)\ncaptured_value = urlparse.parse_qs(parsed.query)['some_key'][0]\n\nprint captured_value\n\nPython 3:\nfrom urllib.parse import urlparse\nfrom urllib.parse import parse_qs\n\nurl = 'https://www.example.com/some_path?some_key=some_value'\nparsed_url = urlparse(url)\ncaptured_value = parse_qs(parsed_url.query)['some_key'][0]\n\nprint(captured_value)\n\nparse_qs returns a list. The [0] gets the first item of the list so the output of each script is some_value\nHere's the 'parse_qs' documentation for Python 3\n",
            "\nI use this, it works fine.\nfrom django.utils import simplejson\nfrom django.http import HttpResponse\n\ndef some_view(request):\n    to_json = {\n        \"key1\": \"value1\",\n        \"key2\": \"value2\"\n    }\n    return HttpResponse(simplejson.dumps(to_json), mimetype='application/json')\n\nAlternative:\nfrom django.utils import simplejson\n\nclass JsonResponse(HttpResponse):\n    \"\"\"\n        JSON response\n    \"\"\"\n    def __init__(self, content, mimetype='application/json', status=None, content_type=None):\n        super(JsonResponse, self).__init__(\n            content=simplejson.dumps(content),\n            mimetype=mimetype,\n            status=status,\n            content_type=content_type,\n        )\n\nIn Django 1.7 JsonResponse objects have been added to the Django framework itself which makes this task even easier:\nfrom django.http import JsonResponse\ndef some_view(request):\n    return JsonResponse({\"key\": \"value\"})\n\n",
            "\nNew in django 1.7\nyou could use JsonResponse objects. \nfrom the docs:\nfrom django.http import JsonResponse\nreturn JsonResponse({'foo':'bar'})\n\n",
            "\nThe url you are referring is a query type and I see that the request object supports a method called arguments to get the query arguments. You may also want try self.request.get('def') directly to get your value from the object..\n",
            "\ndef getParams(url):\n    params = url.split(\"?\")[1]\n    params = params.split('=')\n    pairs = zip(params[0::2], params[1::2])\n    answer = dict((k,v) for k,v in pairs)\n\nHope this helps\n",
            "\nSince Django 1.7 you have a standard JsonResponse that's exactly what you need:\nfrom django.http import JsonResponse\n...\nreturn JsonResponse(array_to_js, safe=False)\n\nYou don't even need to json.dump your array.\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "django",
            "parsing",
            "url"
        ]
    },
    {
        "question_id": "11384292",
        "question": "\nI have a problem when data is null and the warning has appear when the result is display.\nHow to solve this problem?. How to change the null data to 0 when no data in the table?.\nThis is my code:-\nSELECT DISTINCT c.username             AS assigner_officer,\n                d.description          AS ticketcategory,\n                (SELECT Count(closed)\n                 FROM   ticket\n                 WHERE  assigned_to = c.user_id\n                        AND closed IS NOT NULL\n                 GROUP  BY assigned_to)closedcases,\n                (SELECT Count(closed)\n                 FROM   ticket\n                 WHERE  assigned_to = c.user_id\n                        AND closed IS NULL\n                 GROUP  BY assigned_to)opencases\nFROM   ticket a\n       JOIN ticketlog b\n         ON a.ticketid = b.ticketid\n       JOIN access c\n         ON a.assigned_to = c.user_id\n       JOIN ticket_category d\n         ON a.cat_code = d.id\n       JOIN lookup_department e\n         ON a.department_code = e.code \n\nThe result appear like this:-\n Warnings: ---> \n   W (1): Warning: Null value is eliminated by an aggregate or other SET operation.\n          <--- \n assigner_officer     ticketcategory     closedcases     opencases    \n -------------------  -----------------  --------------  ------------ \n abdulhafiz           Enquiry            (null)          0            \n affan                Enquiry            12              (null)       \n amirul               Enquiry            1               (null)       \n azrul_fahmi          Enquiry            45              0            \n Azwani               Enquiry            (null)          0            \n chai                 Enquiry            4               (null)       \n dalinawati           Enquiry            1               0            \n Emmy                 Complaints         (null)          0            \n Fadhlia              Enquiry            38              0            \n fairulhalif          Others             1               (null)       \n farikh               Enquiry            (null)          0            \n ismailh              Enquiry            28              0            \n izzahanna            Enquiry            (null)          0            \n Kamsuzilawati        Enquiry            1               (null)     \n\n",
        "all_answers": [
            "\nUse ISNULL(field, 0) It can also be used with aggregates:\nISNULL(count(field), 0)\n\nHowever, you might consider changing count(field) to count(*)\nEdit:\ntry:\nclosedcases = ISNULL(\n   (select count(closed) from ticket       \n    where assigned_to = c.user_id and closed is not null       \n    group by assigned_to), 0), \n\nopencases = ISNULL(\n    (select count(closed) from ticket \n     where assigned_to = c.user_id and closed is null \n     group by assigned_to), 0),\n\n",
            "\nYou would mostly be using COUNT to summarize over a UID.  Therefore\nCOUNT([uid]) will produce the warning:\n\nWarning: Null value is eliminated by an aggregate or other SET operation.\n\nwhilst being used with a left join, where the counted object does not exist.\nUsing COUNT(*) in this case would also render incorrect results, as you would then be counting the total number of results (ie parents) that exist.\nUsing COUNT([uid]) IS a valid way of counting, and the warning is nothing more than a warning.  However if you are concerned, and you want to get a true count of uids in this case then you could use:\nSUM(CASE WHEN [uid] IS NULL THEN 0 ELSE 1 END) AS [new_count]\n\nThis would not add a lot of overheads to your query.\n(tested mssql 2008)\n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "sql-server-2005"
        ]
    },
    {
        "question_id": "11584489",
        "question": "\nWhat is the simplest way to get translated name of ActiveRecord model class when I have an instance of it?\nFor example - I have model class like this:\nclass Category < ActiveRecord::Base\n  ...\nend\n\nI have an instance of the class:\ncategory = Category.first\n\nAnd I have YAML file config/locales/cs.yml:\ncs:\n  activerecord:\n    models:\n      category: Kategorie\n\nAnd I need to do this dynamicaly, even when I don't previously know with what model class' instance I will be dealing. So I don't want to explicitly specify \"activerecord.models.category\".\nIs there an easy way to do this? I know, that I can do something like this\n\"activerecord.models.#{category.class.name.underscore}\"\n\nBut there has to be a better way to do this.\n",
        "all_answers": [
            "\nTry this in your Today model:\nhas_many :tasks, :order => 'priority DESC'\n\nEDIT: As mentioned in comment below, in Rails 4+, this is now:\nhas_many :tasks, -> { order(:priority => :desc) }\n\n(more info here)\n",
            "\nJust for future reference, adding :all gives a deprecated message. In later versions of rails you can simply chain the methods like this:\nUser.joins(\"LEFT JOIN `user_points` ON user_points.user_id = users.id\").select(\"users.*, count(user_points.id)\").group(\"user_points.user_id\")\n\nOR use a scope like this:\nscope :my_scope_name_here, -> { \n        joins(\"LEFT JOIN `user_points` ON user_points.user_id = users.id\")\n        .select(\"users.*, count(user_points.id)\")\n        .group(\"user_points.user_id\")\n}\n\nYou can also chain .where between the .join and the .select.\nHope this helps someone in the future.\n",
            "\nadd_index :subscriptions, [:user_id, :content_id], unique: true\n\n",
            "\nCheck out constantize and classify. \n",
            "\nYou can try this\nUser.find(:all, limit: 10,\n            joins:  \"LEFT JOIN `user_points` ON user_points.user_id = users.id\" ,\n            select: \"users.*, count(user_points.id)\", \n            group:  \"user_points.user_id\")\n\n",
            "\nDirect solution would be to include the tasks table name before priority:\nToday.where(:user_id => current_user.id).includes(:tasks).order('tasks.priority').first\n# joins(:tasks) is not required\n\nOr, if you don't want to have the table name hardcoded, you can merge with scope from Task model:\nToday.where(:user_id => current_user.id).joins(:tasks).includes(:tasks).merge(Task.order(:priority)).first\n# joins(:tasks) here is required\n\nAlso, you can add has_many: todays to User model to ditch the where clause and do:\ncurrent_user.todays.includes(:tasks).order('tasks.priority').first\n# or\ncurrent_user.todays.joins(:tasks).includes(:tasks).merge(Task.order(:priority)).first\n\nBut if you need only/always to order by priority, and do not need other different orderings, adding order to has_many :tasks is easier.\n",
            "\nRails 5 has a left_outer_joins method. So you can do\nUser.left_outer_joins(:user_points)\n\nor use the alias\nUser.left_joins(:user_points)\n\n",
            "\nSee:\nhttp://api.rubyonrails.org/classes/ActiveModel/Naming.html\nhttp://guides.rubyonrails.org/i18n.html#translations-for-active-record-models\nSo, for example, on an AR class use:\nPerson.model_name.human\n\nor from an AR instance:\nperson.class.model_name.human\n\n"
        ],
        "answer": "A8",
        "tags": [
            "ruby-on-rails",
            "activerecord",
            "internationalization"
        ]
    },
    {
        "question_id": "27439220",
        "question": "\nI have a UIView with a UILabel in it. I want the UIView to have white background color, but with an opacity of 50%. The problem whith setting view.alpha = 0.5 is that the label will have an opacity of 50% as well, so I figured out that it maybe would be possible to have a UIView with white background color and opacity (white_view), and then have another UIView with the label (label_view). Then add the \"white_view\" to \"label_view\" by doing this: label_view.addSubview(white_view). This apparently doesn't work. I'd like to do like: label_view.backgroundView(white_view) but you can't set a background view on a UIView like you can do in a UICollectionView for instance.\nDoes anyone have any clue of how to solve this?\nEDIT\nBecause several answers are approx the same I'll type it here.\nNow I've tried even these:\nlabel_view1.backgroundColor = UIColor.whiteColor().colorWithAlphaComponent(0.5)\nlabel_view1.addSubview(firstPlacelbl)\nendGameView.addSubview(label_view1)\n\nand\nlabel_view1.backgroundColor = UIColor(white: 1, alpha: 0.5)\nlabel_view1.addSubview(firstPlacelbl)\nendGameView.addSubview(label_view1)\n\nAnd still the label is also affected by the alpha, and it gets an opacity of 50%. I don't get it what I do wrong because I only set the colors alpha to 0.5 and not the labels. Any ideas?\n",
        "all_answers": [
            "\nThe problem you have found is that view is different from your UIView. 'view' refers to the entire view. For example your home screen is a view.\nYou need to clearly separate the entire 'view' your 'UIView' and your 'UILabel'\nYou can accomplish this by going to your storyboard, clicking on the item, Identity Inspector, and changing the Restoration ID.\nNow to access each item in your code using the restoration ID\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nYou can set background color of view to the UIColor with alpha, and not affect view.alpha:\nview.backgroundColor = UIColor(white: 1, alpha: 0.5)\nor\nview.backgroundColor = UIColor.red.withAlphaComponent(0.5)\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "swift",
            "uiview",
            "alpha"
        ]
    },
    {
        "question_id": "72634225",
        "question": "\nI have upgraded targetSdkVersion and compileSdkVersion to 33.\nI am now getting a warning telling me that onBackPressed is deprecated.\nI see suggestions to use android.window.OnBackInvokedCallback or androidx.activity.OnBackPressedCallback to handle back navigation instead. Can anyone can help me use the updated method?\nExample\n\nUse Case\nI use if (isTaskRoot) {} inside the onBackPressed() method to check whether the activity is the last one on the activity stack.\noverride fun onBackPressed() {\n    if (isTaskRoot) { // Check whether this activity is last on the activity stack. (Check whether this activity opened from a Push Notification.)\n        startActivity(Intent(mContext, Dashboard::class.java))\n        finish()\n    } else {\n        finishWithResultOK()\n    }\n}\n\n",
        "all_answers": [
            "\nAccording your API level register:\n\nonBackInvokedDispatcher.registerOnBackInvokedCallback for API level 33+\nonBackPressedDispatcher callback for backword compatibility \"API level 13+\"\n\nThis requires to at least use appcompat:1.6.0-alpha03; the current is 1.6.0-alpha04:\n implementation 'androidx.appcompat:appcompat:1.6.0-alpha04'\n\n// kotlin\nimport androidx.activity.addCallback\n\nif (BuildCompat.isAtLeastT()) {\n    onBackInvokedDispatcher.registerOnBackInvokedCallback(\n        OnBackInvokedDispatcher.PRIORITY_DEFAULT\n    ) {\n        // Back is pressed... Finishing the activity\n        finish()\n    }\n} else {\n    onBackPressedDispatcher.addCallback(this /* lifecycle owner */, object : OnBackPressedCallback(true) {\n        override fun handleOnBackPressed() {\n            // Back is pressed... Finishing the activity\n            finish()\n        }\n    })\n}\n\n// ====================================================\n/* Or for lambda simplicity: */\n// ====================================================\nif (BuildCompat.isAtLeastT()) {\n    onBackInvokedDispatcher.registerOnBackInvokedCallback(\n        OnBackInvokedDispatcher.PRIORITY_DEFAULT\n    ) {\n        // Back is pressed... Finishing the activity\n        finish()\n    }\n} else {\n    onBackPressedDispatcher.addCallback(this /* lifecycle owner */) {\n        // Back is pressed... Finishing the activity\n        finish()\n    }\n}\n\n\n\nUPDATE:\nThanks to @ianhanniballake comment; you can just use OnBackPressedDispatcher even in API level 33+\n\nThe OnBackPressedDispatcher is already going to be using the Android T specific API internally when using Activity 1.6+,\n\nSo, you can just do:\n// kotlin\nimport androidx.activity.addCallback\n\nonBackPressedDispatcher.addCallback(this /* lifecycle owner */, object : OnBackPressedCallback(true) {\n    override fun handleOnBackPressed() {\n        // Back is pressed... Finishing the activity\n        finish()\n    }\n})\n\n// ====================================================\n/* Or for lambda simplicity: */\n// ====================================================\nonBackPressedDispatcher.addCallback(this /* lifecycle owner */) {\n    // Back is pressed... Finishing the activity\n    finish()\n}\n\n\n// java\nimport androidx.activity.OnBackPressedCallback;\n\ngetOnBackPressedDispatcher().addCallback(this, new OnBackPressedCallback(true) {\n    @Override\n    public void handleOnBackPressed() {\n        // Back is pressed... Finishing the activity\n        finish();\n    }\n});\n\nNote that you shouldn't override the onBackPressed() as that will make the onBackPressedDispatcher callback not to fire; check this answer for clarifying that.\n",
            "\nIf you get a compiler error that observeAsState or getValue are not defined make sure you have the following imports:\nimport androidx.compose.runtime.getValue\n\nimport androidx.compose.runtime.livedata.observeAsState\n\nThis information is from Step #4 in the \"Using State in Jetpack Compose\" codelab.\n",
            "\nYou can use the OnBackInvokedCallback\n as described in the documentation and follow this guide here to update your code\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "kotlin",
            "navigation",
            "deprecation-warning",
            "android-tiramisu"
        ]
    },
    {
        "question_id": "464902",
        "question": "\nI am trying to convert some VBA code to C#. I am new to C#. Currently I am trying to open an Excel file from a folder and if it does not exist then create it. I am trying something like the following. How can I make it work?\nExcel.Application objexcel;\nExcel.Workbook wbexcel;\nbool wbexists;\nExcel.Worksheet objsht;\nExcel.Range objrange;\n\nobjexcel = new Excel.Application();\nif (Directory(\"C:\\\\csharp\\\\error report1.xls\") = \"\")\n{\n    wbexcel.NewSheet();\n}\n\nelse\n{\n    wbexcel.Open(\"C:\\\\csharp\\\\error report1.xls\");\n    objsht = (\"sheet1\");\n}\nobjsht.Activate();\n\n",
        "all_answers": [
            "\nIt's easier to help you if you say what's wrong as well, or what fails when you run it.\nBut from a quick glance you've confused a few things.\nThe following doesn't work because of a couple of issues.\nif (Directory(\"C:\\\\csharp\\\\error report1.xls\") = \"\")\n\nWhat you are trying to do is creating a new Directory object that should point to a file and then check if there was any errors. \nWhat you are actually doing is trying to call a function named Directory() and then assign a string to the result. This won't work since 1/ you don't have a function named Directory(string str) and you cannot assign to the result from a function (you can only assign a value to a variable).\nWhat you should do (for this line at least) is the following\nFileInfo fi = new FileInfo(\"C:\\\\csharp\\\\error report1.xls\");\nif(!fi.Exists)\n{\n    // Create the xl file here\n}\nelse\n{\n    // Open file here\n}\n\nAs to why the Excel code doesn't work, you have to check the documentation for the Excel library which google should be able to provide for you.\n",
            "\nYou need to have installed Microsoft Visual Studio Tools for Office (VSTO).\nVSTO can be selected in the Visual Studio installer under Workloads > Web & Cloud > Office/SharePoint Development.\nAfter that create a generic .NET project and add a reference to  Microsoft.Office.Interop.Excel via 'Add Reference... > Assemblies' dialog.\nApplication excel = new Application();\nWorkbook wb = excel.Workbooks.Open(path);\n\nMissing.Value is a special reflection struct for unnecessary parameters replacement\n\nIn newer versions, the assembly reference required is called Microsoft Excel 16.0 Object Library. If you do not have the latest version installed you might have Microsoft Excel 15.0 Object Library, or an older version, but it is the same process to include.\n\n",
            "\nFor opening a file, try this:\nobjexcel.Workbooks.Open(@\"C:\\YourPath\\YourExcelFile.xls\",\n    missing, missing, missing, missing, missing, missing, missing,\n    missing, missing, missing, missing, missing,missing, missing);\n\nYou must supply those stupid looking 'missing' arguments. If you were writing the same code in VB.Net you wouldn't have needed them, but you can't avoid them in C#.\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            ".net",
            "excel",
            "vsto"
        ]
    },
    {
        "question_id": "8446218",
        "question": "\nOn http://github.com developer keep the HTML, CSS, JavaScript and images files of the project. How can I see the HTML output in browser?\nFor example this: https://github.com/necolas/css3-social-signin-buttons/blob/master/index.html\nWhen I open this it doesn't show the rendered HTML of the code of author. It shows the page as a source code.\nIs it possible to see it as rendered HTML directly? Otherwise I always need to download the whole ZIP just to see the result.\n",
        "all_answers": [
            "\nI got the same problem while using a github repository, and connecting to it via https, while using the OS X Keychain Credential helper.\nMy problem was that I had the wrong credentials stored in OS X's Keychain (I was using the email address that I used to sign up for github.com rather than the [username]@github.com address it provides you). I deleted the old account in the keychain and only left the @github.com one and it fixed the problem.\nNot sure if it is related, but when I checked the user.email local config:\ngit config -l\n\nit showed the incorrect email address as well, so I updated the local git user.email to use the correct account too:\ngit config user.email <username>@github.com\n\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nMake sure that your user account is added to the repository as a collaborator.\nSetting --> Collaborators\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nThe most comfortable way to preview HTML files on GitHub is to go to https://htmlpreview.github.io/ or just prepend it to the original URL, i.e.: https://htmlpreview.github.io/?https://github.com/bartaz/impress.js/blob/master/index.html\n",
            "\nIf you don't want to download an archive you can use GitHub Pages to render this.\n\nFork the repository to your account.\nClone it locally on your machine\nCreate a gh-pages branch (if one already exists, remove it and create a new one based off master).\nPush the branch back to GitHub.\nView the pages at http://username.github.io/repo`\n\nIn code:\ngit clone git@github.com:username/repo.git\ncd repo\ngit branch gh-pages\n# Might need to do this first: git branch -D gh-pages\ngit push -u origin gh-pages # Push the new branch back to github\nGo to http://username.github.io/repo\n\n",
            "\nMy issue was that I used the clone https url widget provided by github. That URL doesn't work for private repositories as you need to add a username to the front of it.  \nExample: a private repo owned by john and named widget with collaborator sam the correct url would be: \nhttps://sam@github.com/john/widget.git\nThe github provided url: \nhttps://github.com/john/widget.git\nThe error message leaves much to be desired.\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n"
        ],
        "answer": "A8",
        "tags": [
            "html",
            "css",
            "git",
            "github",
            "github-pages"
        ]
    },
    {
        "question_id": "1176136",
        "question": "\nGiven a string as user input to a Python function, I'd like to get a class object out of it if there's a class with that name in the currently defined namespace. Essentially, I want the implementation for a function which will produce this kind of result:\nclass Foo:\n    pass\n\nstr_to_class(\"Foo\")\n==> <class __main__.Foo at 0x69ba0>\n\nIs this, at all, possible?\n",
        "all_answers": [
            "\nYou could do something like:\nglobals()[class_name]\n\n",
            "\n\nWarning: eval() can be used to execute arbitrary Python code. You should never use eval() with untrusted strings. (See Security of Python's eval() on untrusted strings?)\n\nThis seems simplest.\n>>> class Foo(object):\n...     pass\n... \n>>> eval(\"Foo\")\n<class '__main__.Foo'>\n\n",
            "\nYes, you can do this. Assuming your classes exist in the global namespace, something like this will do it:\nimport types\n\nclass Foo:\n    pass\n\ndef str_to_class(s):\n    if s in globals() and isinstance(globals()[s], types.ClassType):\n            return globals()[s]\n    return None\n\nstr_to_class('Foo')\n\n==> <class __main__.Foo at 0x340808cc>\n\n",
            "\nimport sys\nimport types\n\ndef str_to_class(field):\n    try:\n        identifier = getattr(sys.modules[__name__], field)\n    except AttributeError:\n        raise NameError(\"%s doesn't exist.\" % field)\n    if isinstance(identifier, (types.ClassType, types.TypeType)):\n        return identifier\n    raise TypeError(\"%s is not a class.\" % field)\n\nThis accurately handles both old-style and new-style classes.\n",
            "\nThis could work:\nimport sys\n\ndef str_to_class(classname):\n    return getattr(sys.modules[__name__], classname)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python"
        ]
    },
    {
        "question_id": "41974883",
        "question": "\nHere is an example of what I want to do: \nfunc application(application: UIApplication, didFailToRegisterForRemoteNotificationsWithError error: NSError)\n{\n    let  nm =  NetworkModel()\n    nm.sendlog(\"file name :AppDelegate , line number : 288\", info: \" Failed to register: \\(error)\")\n}\n\ncurrent scenario i done that hard coded value line number and file name . but is it possible to programatically pick line number and file name . \n",
        "all_answers": [
            "\nYou can use #function, #file, #line\nHere is the implementation of log method in swift : https://github.com/InderKumarRathore/SwiftLog\nBelow is the snippet\npublic func debugLog(object: Any, functionName: String = #function, fileName: String = #file, lineNumber: Int = #line) {\n  #if DEBUG\n    let className = (fileName as NSString).lastPathComponent\n    print(\"<\\(className)> \\(functionName) [#\\(lineNumber)]| \\(object)\\n\")\n  #endif\n}\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nstatic func DLog(message: String, file: String = #file, function: String = #function, line: Int = #line, column: Int = #column) {\n    print(\"\\(file) : \\(function) : \\(line) : \\(column) - \\(message)\")\n}\n\n",
            "\nLiteral        Type     Value\n\n#file          String   The name of the file in which it appears.\n#line          Int      The line number on which it appears.\n#column        Int      The column number in which it begins.\n#function      String   The name of the declaration in which it appears.\n#dsohandle     UnsafeMutablePointer   The dso handle.\n\nExample\nprint(\"Function: \\(#function), line: \\(#line)\") \n\nWith default values in parameters you can also create a function\npublic func track(_ message: String, file: String = #file, function: String = #function, line: Int = #line ) { \n    print(\"\\(message) called from \\(function) \\(file):\\(line)\") \n}\n\nwhich can be used like this\ntrack(\"enters app\")\n\nIn Swift 2.1\n Literal        Type     Value\n\n__FILE__       String   The name of the file in which it appears.\n__LINE__       Int      The line number on which it appears.\n__COLUMN__     Int      The column number in which it begins.\n__FUNCTION__   String   The name of the declaration in which it appears.\n\nfor more info see the documentation\n"
        ],
        "answer": "A4",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "9756567",
        "question": "\nas everyone knows Windows does paths with backslashes where Unix does paths with forward slashes. node.js provides path.join() to always use the correct slash. So for example instead of writing the Unix only 'a/b/c' you would do path.join('a','b','c') instead.\nHowever, it seems that despite this difference if you do not normalize your paths (e.g. using path.join) and just write paths like a/b/c node.js has no problem with running your scripts on Windows.\nSo is there any benefit over writing path.join('a','b','c') over 'a/b/c'? Both appear to work regardless of platform...\n",
        "all_answers": [
            "\nI use path.join to ensure folder separators are in the correct places, not necessarily to ensure that it uses forward versus back slashes. For example:\npath.join(\"/var/www\", \"test\")\n\nWill correctly insert the separator between www and test /var/www/test\n",
            "\nDo a import os and then use os.sep\n",
            "\nDon't build directory and file names your self, use python's included libraries. \nIn this case the relevant one is os.path. Especially join which creates a new pathname from a directory and a file name or directory and split that gets the filename from a full path.\nYour example would be \npathfile=os.path.dirname(templateFile)\np = os.path.join(pathfile, 'output')\np = os.path.join( p, 'log.txt')\nrootTree.write(p)\n\n",
            "\nSome useful links that will help you:\n\nos.sep\nos.path\nos.pathsep\n\n",
            "\nos.path.normpath(pathname) should also be mentioned as it converts / path separators into \\ separators on Windows. It also collapses redundant uplevel references... i.e., A/B and A/foo/../B and A/./B all become A/B.  And if you are Windows, these all become A\\B.\n",
            "\nIf you are fortunate enough to be running Python 3.4+, you can use pathlib:\nfrom pathlib import Path\n\npath = Path(dir, subdir, filename)  # returns a path of the system's path flavour\n\nor, equivalently,\npath = Path(dir) / subdir / filename\n\n",
            "\nYou can use os.sep:\n>>> import os\n>>> os.sep\n'/'\n\n",
            "\nWindows filesystems have no problem using either forward or backward slashes as path separators (this has been the case since back in the DOS days). The only real issue is that Windows command-line processors (or, more specifically, Windows-native command-line utilities) tend to interpret forward slashes as option specifiers rather than path components. Therefore, you need a backslashed path if you need to pass a path to a Windows command run as a subprocess. Also, Windows API calls (and methods from higher-level languages that call the Windows API) that return paths will use backslashes, so even if you aren't passing them to subprocesses, you'll need to normalize them.\n",
            "\nUse:\nimport os\nprint os.sep\n\nto see how separator looks on a current OS.\nIn your code you can use:\nimport os\npath = os.path.join('folder_name', 'file_name')\n\n",
            "\n\n\nYou can use \"os.sep \"\n\n\n import os\n pathfile=os.path.dirname(templateFile)\n directory = str(pathfile)+os.sep+'output'+os.sep+'log.txt'\n rootTree.write(directory)\n\n",
            "\nUse os.path.join().\nExample: os.path.join(pathfile,\"output\",\"log.txt\").\nIn your code that would be: rootTree.write(os.path.join(pathfile,\"output\",\"log.txt\"))\n"
        ],
        "answer": "A8",
        "tags": [
            "node.js",
            "windows",
            "unix",
            "path"
        ]
    },
    {
        "question_id": "53428",
        "question": "\n\n\n\nI'm evaluating and looking at using CherryPy for a project that's basically a JavaScript front-end from the client-side (browser) that talks to a Python web service on the back-end. So, I really need something fast and lightweight on the back-end that I can implement using Python that then speaks to the PostgreSQL DB via an ORM (JSON to the browser).\nI'm also looking at Django, which I like, since its ORM is built-in. However, I think Django might be a little more than I really need (i.e. more features than I really need == slower?).\nAnyone have any experience with different Python ORM solutions that can compare and contrast their features and functionality, speed, efficiency, etc.?\n",
        "all_answers": [
            "\nI think you might look at:\nAutumn\nStorm\n",
            "\nSQLAlchemy is more full-featured and powerful (uses the DataMapper pattern).  Django ORM has a cleaner syntax and is easier to write for (ActiveRecord pattern).  I don't know about performance differences.\nSQLAlchemy also has a declarative layer that hides some complexity and gives it a ActiveRecord-style syntax more similar to the Django ORM.\nI wouldn't worry about Django being \"too heavy.\"  It's decoupled enough that you can use the ORM if you want without having to import the rest.\nThat said, if I were already using CherryPy for the web layer and just needed an ORM, I'd probably opt for SQLAlchemy.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "orm"
        ]
    },
    {
        "question_id": "6333738",
        "question": "\nI have this model I'm showing in the admin page:\nclass Dog(models.Model):\n    bark_volume = models.DecimalField(...\n    unladen_speed = models.DecimalField(...\n\n    def clean(self):\n        if self.bark_volume < 5:\n            raise ValidationError(\"must be louder!\")\n\nAs you can see I put a validation on the model.  But what I want to happen is for the admin page to show the error next to the bark_volume field instead of a general error like it is now.  Is there a way to specify which field the validation is failing on?\nMuch thanks in advance.\n",
        "all_answers": [
            "\nUse a clean_ method that is specific to the field:\nclass DogForm(forms.ModelForm):\n    class Meta:\n        model = Dog\n\n    def clean_bark_volume(self):\n        if self.cleaned_data['bark_volume'] < 5:\n            raise ValidationError(\"must be louder!\")\n\nSee the clean<fieldname> part of the Form Validation page. Also, make sure to use cleaned_data instead of the form field itself; the latter may have old data. Finally, do this on the form and not the model.\n",
            "\nclass Dog(models.Model):\n    bark_volume = models.DecimalField(...\n    unladen_speed = models.DecimalField(...\n\n    def clean(self):\n        if self.bark_volume < 5:\n            if not self._errors.has_key('bark_volume'):\n                from django.forms.util import ErrorList\n                self._errors['bark_volume'] = ErrorList()\n            self._errors['bark_volume'].append('must be louder!')\n\nThat works on forms, at least. Never tried it on the model itself, but the methodology should be the same. However, from the Django docs:\n\nWhen you use a ModelForm, the call to is_valid() will perform these validation steps for all the fields that are included on the form. (See the ModelForm documentation for more information.) You should only need to call a model’s full_clean() method if you plan to handle validation errors yourself, or if you have excluded fields from the ModelForm that require validation.\n\nAnd...\n\nNote that full_clean() will not be called automatically when you call your model’s save() method, nor as a result of ModelForm validation. You’ll need to call it manually when you want to run model validation outside of a ModelForm.\n\nSo, basically, unless you have a really good reason to do field cleaning on the model, you should do it on the form instead. The code for that would look like:\nclass DogForm(forms.ModelForm):\n\n    def clean(self):\n        bark_volume = self.cleaned_data.get('bark_volume')\n        if bark_volume < 5:\n            if not self._errors.has_key('bark_volume'):\n                from django.forms.util import ErrorList\n                self._errors['bark_volume'] = ErrorList()\n            self._errors['bark_volume'].append('must be louder!')\n\n        return self.cleaned_data\n\nAnd that will work, for sure.\n",
            "\nOK, I figured it out from this answer.\nYou have to do something like this:\nclass Dog(models.Model):\n    bark_volume = models.DecimalField(...\n    unladen_speed = models.DecimalField(...\n\n    def clean_fields(self):\n        if self.bark_volume < 5:\n            raise ValidationError({'bark_volume': [\"Must be louder!\",]})\n\n"
        ],
        "answer": "A3",
        "tags": [
            "django",
            "django-models",
            "django-admin"
        ]
    },
    {
        "question_id": "6459080",
        "question": "\nI have performed git commit followed by a git push.  How can I revert that change on both local and remote repositories?\n$ git log\ncommit 364705c23011b0fc6a7ca2d80c86cef4a7c4db7ac8\nAuthor: Michael Silver <Michael Silver@gmail.com>\nDate:   Tue Jun 11 12:24:23 2011 -0700\n\n",
        "all_answers": [
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\ngit reset --hard HEAD~1\ngit push -f <remote> <branch>\n\n(Example push: git push -f origin bugfix/bug123)\nThis will undo the last commit and push the updated history to the remote. You need to pass the -f because you're replacing upstream history in the remote.\nEdit:\nPlease note that --hard will make your commit unreachable (i.e. it will appear to be deleted, but you can still git show <hash> or git log <hash> it if you remember its hash). If you want to keep your changes, run:\ngit reset [--mixed] HEAD~1\n\nAt this point you have unstaged changes because you used --mixed, which is the default.\nYou may first want to update the remote tree first (i.e. remove the commit): git push -f <remote> <branch>\nSince you still have your changes locally you can create another branch and  commit them there (and push as you see fit).\n",
            "\nYou can do an interactive rebase:\ngit rebase -i <commit>\n\nThis will bring up your default editor.  Just delete the line containing the commit you want to remove to delete that commit.\nYou will, of course, need access to the remote repository to apply this change there too.\nSee this question: Git: removing selected commits from repository\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nGenerally, make an \"inverse\" commit, using:\ngit revert 364705c\n\nthen send it to the remote as usual:\ngit push\n\nThis won't delete the commit: it makes an additional commit that undoes whatever the first commit did. Anything else, not really safe, especially when the changes have already been propagated.\n"
        ],
        "answer": "A3",
        "tags": [
            "git",
            "git-push",
            "git-commit"
        ]
    },
    {
        "question_id": "2292662",
        "question": "\nI've heard that you should put columns that will be the most selective at the beginning of the index declaration.  Example:\nCREATE NONCLUSTERED INDEX MyINDX on Table1\n(\n   MostSelective,\n   SecondMost,\n   Least\n)\n\nFirst off, is what I'm saying correct?  If so, am i likely to see large differences in performance by rearranging the order of the columns in my index or is it more of a \"nice to do\" practice?\nThe reason I'm asking is because after putting a query through the DTA it recommended that I create an index that had almost all of the same columns in it as an existing index, just in a different order.  I was considering just adding the missing columns to the existing index and calling it good.  Thoughts?\n",
        "all_answers": [
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\n\nyou should put columns that will be the most selective at the beginning of the index declaration.\n\nCorrect.\nIndexes can be composites - composed of multiple columns - and the order is important because of the leftmost principle.  Reason is, that the database checks the list from left to right, and has to find a corresponding column reference matching the order defined.  For example, having an index on an address table with columns:\n\nAddress\nCity\nState\n\nAny query using the address column can utilize the index, but if the query only has either city and/or state references - the index can not be used.  This is because the leftmost column isn't referenced.  Query performance should tell you which is optimal - individual indexes, or multiple composites with different orders.  Good read: The Tipping Point, by Kimberley Tripp\n",
            "\nLook at an index like this:\nCols\n  1   2   3\n-------------\n|   | 1 |   |\n| A |---|   |\n|   | 2 |   |\n|---|---|   |\n|   |   |   |\n|   | 1 | 9 |\n| B |   |   |\n|   |---|   |\n|   | 2 |   |\n|   |---|   |\n|   | 3 |   |\n|---|---|   |\n\nSee how restricting on A first, as your first column eliminates more results than restricting on your second column first?  It's easier if you picture how the index must be traversed across, column 1, then column 2, etc...you see that lopping off most of the results in the fist pass makes the 2nd step that much faster.  \nAnother case, if you queried on column 3, the optimizer wouldn't even use the index, because it's not helpful at all in narrowing down the result sets.  Anytime you're in a query, narrowing down the number of results to deal with before the next step means better performance.\nSince the index is also stored this way, there's no backtracking across the index to find the first column when you're querying on it.  \nIn short: No, it's not for show, there are real performance benefits.\n"
        ],
        "answer": "A3",
        "tags": [
            "sql",
            "sql-server",
            "sql-server-2005",
            "t-sql",
            "indexing"
        ]
    },
    {
        "question_id": "40730",
        "question": "\nHow do you give a C# auto-property an initial value?\nI either use the constructor, or revert to the old syntax. \n Using the Constructor:\nclass Person \n{\n    public Person()\n    {\n        Name = \"Initial Name\";\n    }\n    public string Name { get; set; }\n}\n\nUsing normal property syntax  (with an initial value)\nprivate string name = \"Initial Name\";\npublic string Name \n{\n    get \n    {\n        return name;\n    }\n    set\n    {\n        name = value;\n    }\n}\n\nIs there a better way?\n",
        "all_answers": [
            "\nHave you tried using the DefaultValueAttribute or ShouldSerialize and Reset methods in conjunction with the constructor?  I feel like one of these two methods is necessary if you're making a class that might show up on the designer surface or in a property grid.\n",
            "\nIf you want to see the list of all available snippets: \nPress Ctrl + K and then X.\n",
            "\nIn Visual Studio 2010, if you type \"ctor\" (without the quotes), IntelliSense should load, showing you \"ctor\" in the list. Now press TAB twice, and you should have generated an empty constructor.\n",
            "\nIf you use ReSharper, you can quickly generate constructors by typing:\n\n'ctor' + Tab + Tab (without parameters),\n'ctorf' + Tab + Tab (with parameters that initialize all fields) or\n'ctorp' + Tab + Tab (with parameters that initialize all properties).\n\n",
            "\nIn case you want a constructor with properties, you need to do the following:\n\nPlace your cursor in any empty line in a class;\n\nPress Ctrl + . to trigger the Quick Actions and Refactorings menu;\n\n\nSelect Generate constructor from the drop-down menu;\n\nPick the members you want to include as constructor parameters. You can order them using the up and down arrows. Choose OK.\n\n\nThe constructor is created with the specified parameters.\nGenerate a constructor in Visual Studio\n",
            "\nType \"ctor\" + TAB + TAB (hit the Tab key twice). This will create the default constructor for the class you are in:\npublic MyClass()\n{\n\n}\n\nIt seems that in some cases you will have to press TAB twice.\n",
            "\nType ctor, and then press TAB twice.\n",
            "\nAs mentioned by many, \"ctor\" and double TAB works in Visual Studio 2017, but it only creates the constructor with none of the attributes.\nTo auto-generate with attributes (if there are any), just click on an empty line below them and press Ctrl + .. It'll display a small pop-up from which you can select the \"Generate Constructor...\" option.\n",
            "\nSimply type ctor then press TAB.\n",
            "\nFor the full list of snippets (little bits of prefabricated code) press Ctrl+K and then Ctrl+X.\nSource from MSDN.\nWorks in Visual Studio 2013 with a C# project.\nSo how to make a constructor\n\nPress Ctrl+K and then Ctrl+X\nSelect Visual C#\nSelect ctor\nPress Tab\n\nUpdate: You can also right-click in your code where you want the snippet, and select Insert Snippet from the right-click menu\n",
            "\nIn C# 5 and earlier, to give auto implemented properties an initial value, you have to do it in a constructor.\nSince C# 6.0, you can specify initial value in-line. The syntax is:\npublic int X { get; set; } = x; // C# 6 or higher\n\nDefaultValueAttribute is intended to be used by the VS designer (or any other consumer) to specify a default value, not an initial value. (Even if in designed object, initial value is the default value).\nAt compile time DefaultValueAttribute will not impact the generated IL and it will not be read to initialize the property to that value (see DefaultValue attribute is not working with my Auto Property).\nExample of attributes that impact the IL are ThreadStaticAttribute, CallerMemberNameAttribute, ...\n"
        ],
        "answer": "A11",
        "tags": [
            "c#",
            "constructor",
            "getter",
            "setter",
            "automatic-properties"
        ]
    },
    {
        "question_id": "2701192",
        "question": "\nI'm looking for a HTML or ASCII character which is a triangle pointing up or down so that I can use it as a toggle switch.\nI found ↑ (&uarr;), and ↓ (&darr;) - but those have a narrow stem. I'm looking just for the HTML arrow \"head\".\n",
        "all_answers": [
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nThis one seems to imply that 030 and 031 are up and down triangles.\n(As bobince pointed out, this doesn't seem to be an ASCII standard)\n",
            "\nUnicode arrows heads:\n\n▲ - U+25B2 BLACK UP-POINTING TRIANGLE\n▼ - U+25BC BLACK DOWN-POINTING TRIANGLE\n▴ - U+25B4 SMALL BLACK UP-POINTING TRIANGLE\n▾ - U+25BE SMALL BLACK DOWN-POINTING TRIANGLE\n\nFor ▲ and ▼ use &#x25B2; and &#x25BC; respectively if you cannot include Unicode characters directly (use UTF-8!).\nNote that the font support for the smaller versions is not as good. Better to use the large versions in smaller font.\nMore Unicode arrows are at:\n\nhttp://en.wikipedia.org/wiki/Arrow_%28symbol%29#Arrows_in_Unicode\nhttp://en.wikipedia.org/wiki/Geometric_Shapes\n\nLastly, these arrows are not ASCII, including ↑ and ↓: they are Unicode.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n"
        ],
        "answer": "A4",
        "tags": [
            "html",
            "css",
            "unicode",
            "icons",
            "symbols"
        ]
    },
    {
        "question_id": "2010747",
        "question": "\nTrying to use a very simple form to upload a file into a new class instance. I am expecting to have both files in request.FILES but it's empty. I am on the bundled dev server.\nBeen stuck here and went through all related questions.\nwayfinder_map.media_file = request.FILES['media_file'] \n\ngenerates\n\nMultiValueDictKeyError: \"Key 'media_file' not found in MultiValueDict:\n  {}>\"\n\nmodel\nclass WayfinderMap(models.Model):\n    \"\"\" Way-finding Map Config\"\"\"\n\n\n    media_file = models.FileField(upload_to=\"maps\", null=True, blank=True) \n    wall_file = models.FileField(upload_to=\"maps_data\", null=True, blank=True) \n\nview\n@login_required\ndef create_map(request, form_class=WayfinderMapForm, template_name=\"wayfinder/map/create.html\"):\nwayfinder_map_form = form_class(request.user, request.POST or None, request.FILES)\n\n    if wayfinder_map_form.is_valid():\n        wayfinder_map = wayfinder_map_form.save(commit=False)\n        wayfinder_map.media_file = request.FILES['media_file']\n        wayfinder_map.data_file = request.FILES['data_file']\n        wayfinder_map.creator = request.user\n        wayfinder_map.save()\n    return HttpResponseRedirect(wayfinder_map.get_absolute_url())\n\nreturn render_to_response(template_name, {\n    \"wayfinder_map_form\": wayfinder_map_form,\n}, context_instance=RequestContext(request))\n\ntemplate\n<form enctype=\"multipart/form-data\" class=\"uniForm\" id=\"wayfinder_map_form\" method=\"POST\" action=\"\">\n        <fieldset class=\"inlineLabels\">\n            {{ wayfinder_map_form|as_uni_form }}\n            <div class=\"form_block\">\n                <input type=\"hidden\" name=\"action\" value=\"create\" />\n                <input type=\"submit\" value=\"{% trans 'create' %}\"/>\n            </div>\n        </fieldset>\n    </form>\n\n",
        "all_answers": [
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nIt seems as request.FILES is not necessary in this case (good thing cause it's empty ...)\nI modified this line \nwayfinder_map.media_file = request.FILES['media_file'] \n\nfor \nwayfinder_map.media_file = wayfinder_map_form.cleaned_data['media_file'] \n\nand it works. Not sure what the right way to do thing though... –\n",
            "\nI think your troubles may lie in assigning data to a form without first verifying the the request is POST\n@login_required\ndef create_map(request, form_class=WayfinderMapForm, template_name=\"wayfinder/map create.html\"):\n  if request.method=='POST':\n    wayfinder_map_form = form_class(request.user, data=request.POST, files=request.FILES)\n\n    if wayfinder_map_form.is_valid():\n      #save your data\n      return HttpResponseRedirect(wayfinder_map.get_absolute_url())\n\n  else:\n    wayfinder_map_form=form_class(request.user)\n\n return render_to_response(template_name, {\"wayfinder_map_form\": wayfinder_map_form,}, context_instance=RequestContext(request))\n\n"
        ],
        "answer": "A2",
        "tags": [
            "django",
            "django-forms"
        ]
    },
    {
        "question_id": "40112279",
        "question": "\nWhen running npm install -g ionic I get the following error:\n\nFATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory\n\nIs there a way to globally increase the node.js memory limit?\n",
        "all_answers": [
            "\nI was able to resolve this from the comments section; outlining the process below.\nFrom the comments\nAndreFigueiredo stated :\n\nI installed modules here in less than 1 min with your package.json with npm v3.5.2 and node v4.2.6. I suggest you update node and npm.\n\n\n\nv1.3.0 didn't even have flattened dependencies introduced on v3 that resolved a lot of annoying issues\n\nLINKIWI stated :\n\nGenerally speaking, don't rely on package managers like apt to maintain up-to-date software. I would strongly recommend purging the node/npm combo you installed from apt and following the instructions on nodejs.org to install the latest release.\n\nObservations\nFollowing their advice, I noticed that CentOS, Ubuntu, and Debian all use very outdated versions of nodejs and npm when retrieving the current version using apt or yum (depending on operating systems primary package manager).\nGet rid of the outdated nodejs and npm\nTo resolve this with as minimal headache as possible, I ran the following command (on Ubuntu) :\napt-get purge --auto-remove nodejs npm\n\nThis purged the system of the archaic nodejs and npm as well as all dependencies which were no longer required\nInstall current nodejs and compatible npm\nThe next objective was to get a current version of both nodejs and npm which I can snag nodejs directly from here and either compile or use the binary, however this would not make it easy to swap versions as I need to (depending on age of project).\nI came across a great package called nvm which (so far) seems to manage this task quite well. To install the current stable latest build of version 7 of nodejs :\nInstall nvm\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.0/install.sh | bash\n\nSource .bashrc\nsource ~/.bashrc\n\nUse nvm to install nodejs 7.x\nnvm install 7\n\nAfter installation I was pleasantly surprised by much faster performance of npm, that it also now showed a pretty progress bar while snagging packages.\nFor those curious, the current (as of this date) version of npm should look like the following (and if it doesn't, you likely need to update it):\n\nSummary\nDO NOT USE YOUR OS PACKAGE MANAGER TO INSTALL NODE.JS OR NPM - You will get very bad results as it seems no OS is keeping these packages (not even close to) current. If you find that npm is running slow and it isn't your computer or internet, it is most likely because of a severely outdated version.\n",
            "\nYou can launch NPM using :\nnode --max-old-space-size=8000 $(which npm) install -g ionic\nAs described here, the default is 4000 (4Gb).\n",
            "\nI am using Linux and have nvm and working with more than 7 version of node\nAs of my experience I experienced the same situation with my latest project (actually not hours but minutes as I can't wait hours because of hourly project :))\nDisclaimer: don't try below option until you know how cache clean works\nnpm cache clean --force\nand then all working fine for me so it's looks like sometimes npm's cache gets confused with different versions of Node.\nOfficial documentation of Npm cache can be found here\n",
            "\nTry, node --max-old-space-size=<size> where size is in megabytes.\n"
        ],
        "answer": "A2",
        "tags": [
            "node.js",
            "npm",
            "npm-install"
        ]
    },
    {
        "question_id": "32621988",
        "question": "\nProblem: while developing using Electron, when you try to use any JS plugin that requires jQuery, the plugin doesn't find jQuery, even if you load in the correct path using script tags.\nFor example,\n<body>\n<p id=\"click-me\">Click me!</p>\n...\n<script src=\"node_modules/jquery/dist/jquery.min.js\"></script> //jQuery should be loaded now\n<script>$(\"#click-me\").click(() => {alert(\"Clicked\")});</script>\n</body>\n\nRunning this code above wouldn't work. In fact, open up DevTools, go to the Console view, and click on the <p> element. You should see that function $ is not defined or something to that effect.\n",
        "all_answers": [
            "\nAnother way of writing <script>window.$ = window.jQuery = require('./path/to/jquery');</script> is : \n<script src=\"./path/to/jquery\" onload=\"window.$ = window.jQuery = module.exports;\"></script>\n\n",
            "\nYou can put node-integration: false inside options on BrowserWindow.\neg: window = new BrowserWindow({'node-integration': false});\n",
            "\nA better and more generic solution IMO: \n<!-- Insert this line above script imports  -->\n<script>if (typeof module === 'object') {window.module = module; module = undefined;}</script>\n\n<!-- normal script imports etc  -->\n<script src=\"scripts/jquery.min.js\"></script>    \n<script src=\"scripts/vendor.js\"></script>    \n\n<!-- Insert this line after script imports -->\n<script>if (window.module) module = window.module;</script>\n\nBenefits\n\nWorks for both browser and electron with the same code\nFixes issues for ALL 3rd-party libraries (not just jQuery) without having to specify each one\nScript Build / Pack Friendly (i.e. Grunt / Gulp all scripts into vendor.js)\nDoes NOT require node-integration to be false\n\nsource here\n",
            "\nI think i understand your struggle i solved it little bit differently.I used script loader for my js file which is including jquery.Script loader takes your js file and attaching it to top of your vendor.js file it did the magic for me.\nhttps://www.npmjs.com/package/script-loader\nafter installing the script loader add this into your boot or application file.\nimport 'script!path/your-file.js';\n",
            "\nAs seen in https://github.com/atom/electron/issues/254 the problem is caused because of this code:\nif ( typeof module === \"object\" && typeof module.exports === \"object\" ) {\n  // set jQuery in `module`\n} else {\n  // set jQuery in `window`\n}\n\nThe jQuery code \"sees\" that its running in a CommonJS environment and ignores window.\nThe solution is really easy, instead of loading jQuery through <script src=\"...\">, you should load like this:\n<script>window.$ = window.jQuery = require('./path/to/jquery');</script>\n\nNote: the dot before the path is required, since it indicates that it's the current directory. Also, remember to load jQuery before loading any other plugin that depends on it.\n"
        ],
        "answer": "A3",
        "tags": [
            "jquery",
            "electron"
        ]
    },
    {
        "question_id": "953918",
        "question": "\n\n\n\nI have a div tag with width set to 800 pixels. When the browser width is greater than 800 pixels, it shouldn't stretch the div, but it should bring it to the middle of the page.\n",
        "all_answers": [
            "\nAdd only the class center-block to an image, this works with Bootstrap 4 as well:\n<img src=\"...\" alt=\"...\" class=\"center-block\" />\n\nNote: center-block works even when img-responsive is used\n",
            "\nSimply put all the images thumbnails inside a row/col divs like this:\n<div class=\"row text-center\">\n <div class=\"col-12\">\n  # your images here...\n </div>\n</div>\n\nand everything will work fine!\n",
            "\nThis should center the image and make it responsive.\n<img src=\"...\" class=\"img-responsive\" style=\"margin:0 auto;\"/>\n\n",
            "\n<body>\n    <div style=\"width:800px; margin:0 auto;\">\n        centered content\n    </div>\n</body>\n\n",
            "\nThere is .center-block class in Twitter Bootstrap 3 (Since v3.0.1), so use:\n<img src=\"...\" alt=\"...\" class=\"img-responsive center-block\" />\n\n",
            "\nYou can use property of d-block here or you can use a parent div with property 'text-center' in bootstrap or 'text-align: center' in css.\nImage by default is displayed as inline-block, you need to display it as block in order to center it with .mx-auto. This can be done with built-in .d-block:\n<div>\n    <img class=\"mx-auto d-block\" src=\"...\">  \n</div>\n\nOr leave it as inline-block and wrapped it in a div with .text-center:\n<div class=\"text-center\">\n    <img src=\"...\">  \n</div>\n\n",
            "\nIf you're using Bootstrap v3.0.1 or greater, you should use this solution instead. It doesn't override Bootstrap's styles with custom CSS, but instead uses a Bootstrap feature.\nMy original answer is shown below for posterity\n\nThis is a pleasantly easy fix. Because .img-responsive from Bootstrap already sets display: block, you can use margin: 0 auto to center the image:\n.product .img-responsive {\n    margin: 0 auto;\n}\n\n",
            "\nI would suggest a more \"abstract\" classification. Add a new class \"img-center\" which can be used in combination with .img-responsive class:\n// Center responsive images\n.img-responsive.img-center {\n  margin: 0 auto;\n}\n\n",
            "\nJust use .text-center class if you're using Bootstrap 3.\n<div class=\"text-center\">\n    <img src=\"...\" alt=\"...\"/>\n</div>\n\nNote: This doesn't work with img-responsive\n",
            "\n\nDo you mean that you want to center it vertically or horizontally? You said you specified the height to 800 pixels, and wanted the div not to stretch when the width was greater than that...\nTo center horizontally, you can use the margin: auto; attribute in CSS. Also, you'll have to make sure that the body and html elements don't have any margin or padding:\n\nhtml, body { margin: 0; padding: 0; }\n#centeredDiv { margin-right: auto; margin-left: auto; width: 800px; }\n\n"
        ],
        "answer": "A4",
        "tags": [
            "css",
            "html",
            "alignment",
            "center"
        ]
    },
    {
        "question_id": "9849719",
        "question": "\nstatic uint8_t togglecode[256] = {\n    [0x3A] CAPSLOCK,\n    [0x45] NUMLOCK,\n    [0x46] SCROLLLOCK\n};\n\nWhat's the meaning of [0x3A] here? I have only learned statements like int a[2] = {1, 2};\n",
        "all_answers": [
            "\nAccording to the GCC docs this is ISO C99 compliant. They refer to it as \"Designated Initializers\":\n\nTo specify an array index, write `[index] =' before the element value.\nFor example,\n int a[6] = { [4] = 29, [2] = 15 };\n\nis equivalent to\n int a[6] = { 0, 0, 15, 0, 29, 0 };\n\n\nI've never seen this syntax before, but I just compiled it with gcc 4.4.5, with -Wall. It compiled successfully and gave no warnings.\nAs you can see from that example, it allows you to initialize specific array elements, with the others being set to their default value (0).\n",
            "\nIt means initialise the n-th element of the array. The example you've given will mean that:\ntogglecode[0x3A] == CAPSLOCK\ntogglecode[0x45] == NUMLOCK\ntogglecode[0x46] == SCROLLLOCK\n\nThese are called \"designated initializers\", and are actually part of the C99 standard. However, the syntax without the = is not. From that page:\n\nAn alternative syntax for this which has been obsolete since GCC 2.5 but GCC still accepts is to write [index] before the element value, with no =. \n\n",
            "\nThat was introduced in C99 and it's called a designated initialiser.\nIt basically allows you to set specific values in an array with the rest left as defaults.\nIn this particular case, the array indexes are the keyboard scan codes. 0x3a is the scan code in set #1 (see section 10.6) for the CapsLock key, 0x45 is NumLock and 0x46 is ScrollLock.\nOn the first link above, it states that:\nint a[6] = { [4] = 29, [2] = 15 };\n\nis equivalent to:\nint a[6] = { 0, 0, 15, 0, 29, 0 };\n\nInterestingly enough, though the link states that = is necessary, that doesn't appear to be the case here. That's not part of the standard but is a hangover from a rather old version of gcc.\n",
            "\nIt's (close to) the syntax of designated initializers, a C99 feature.\nBasically, it initializes parts of an array, for example;\nint aa[4] = { [2] = 3, [1] = 6 };\n\nIntializes the second value of the array to 6, and the third to 3.\nIn your case the array offsets happen to be in hex (0x3a) which initializes the 58'th element of the array to the value of CAPSLOCK which presumably is defined in the code above the code you're showing.\nThe version in your code without the = seems to be a gcc specific extension.\n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "arrays"
        ]
    },
    {
        "question_id": "2095703",
        "question": "\nI am in need of an easy way to convert a date time stamp to UTC (from whatever timezone the server is in) HOPEFULLY without using any libraries.\n",
        "all_answers": [
            "\nTo parse the date, you should use:\n    DateTime::createFromFormat();\nEx:\n$dateDE = \"16/10/2013\";\n$dateUS = \\DateTime::createFromFormat(\"d.m.Y\", $dateDE)->format(\"m/d/Y\");\n\nHowever, careful, because this will crash with:\nPHP Fatal error: Call to a member function format() on a non-object \n\nYou actually need to check that the formatting went fine, first:\n$dateDE = \"16/10/2013\";\n$dateObj = \\DateTime::createFromFormat(\"d.m.Y\", $dateDE);\nif (!$dateObj)\n{\n    throw new \\UnexpectedValueException(\"Could not parse the date: $date\");\n}\n$dateUS = $dateObj->format(\"m/d/Y\");\n\nNow instead of crashing, you will get an exception, which you can catch, propagate, etc.\n$dateDE has the wrong format, it should be \"16.10.2013\";\n",
            "\nYou need to be careful with m/d/Y and m-d-Y formats. PHP considers / to mean m/d/Y and - to mean d-m-Y. I would explicitly describe the input format in this case:\n$ymd = DateTime::createFromFormat('m-d-Y', '10-16-2003')->format('Y-m-d');\n\nThat way you are not at the whims of a certain interpretation.\n",
            "\nhttp://php.net/manual/en/function.strtotime.php or if you need to not use a string but time components instead, then http://us.php.net/manual/en/function.mktime.php\n",
            "\nTry the getTimezone and setTimezone, see the example\n(But this does use a Class)\nUPDATE:\nWithout any classes you could try something like this:\n$the_date = strtotime(\"2010-01-19 00:00:00\");\necho(date_default_timezone_get() . \"<br />\");\necho(date(\"Y-d-mTG:i:sz\",$the_date) . \"<br />\");\necho(date_default_timezone_set(\"UTC\") . \"<br />\");\necho(date(\"Y-d-mTG:i:sz\", $the_date) . \"<br />\");\n\nNOTE: You might need to set the timezone back to the original as well\n",
            "\nUse strtotime() on your first date then date('Y-m-d') to convert it back:\n$time = strtotime('10/16/2003');\n\n$newformat = date('Y-m-d',$time);\n\necho $newformat;\n// 2003-10-16\n\nMake note that there is a difference between using forward slash / and hyphen - in the strtotime() function. To quote from php.net:\n\nDates in the m/d/y or d-m-y formats\n  are disambiguated by looking at the\n  separator between the various\n  components: if the separator is a\n  slash (/), then the American m/d/y is\n  assumed; whereas if the separator is a\n  dash (-) or a dot (.), then the\n  European d-m-y format is assumed.\nTo avoid potential ambiguity, it's best to use ISO 8601 (YYYY-MM-DD) dates or DateTime::createFromFormat() when possible.\n\n",
            "\nUse strtotime to generate a timestamp from the given string (interpreted as local time) and use gmdate to get it as a formatted UTC date back.\nExample\nAs requested, here’s a simple example:\necho gmdate('d.m.Y H:i', strtotime('2012-06-28 23:55'));\n\n"
        ],
        "answer": "A4",
        "tags": [
            "php",
            "datetime",
            "timezone",
            "utc"
        ]
    },
    {
        "question_id": "28476629",
        "question": "\nIn C#, we have Enumerable.First(predicate). Given this JavaScript code:\nfunction process() {\n  var firstMatch = ['a', 'b', 'c'].filter(function(e) {\n    return applyConditions(e);\n  }).shift();\n\n  if(!firstMatch) {\n    return;\n  }\n\n  // do something else\n}\n\nfunction applyConditions(element) {\n  var min = 97;\n  var max = 122;\n\n  var random = Math.floor(Math.random() * (max - min + 1) + min);\n\n  return element === String.fromCharCode(random);\n}\n\nother than forEach, using loop, using multiple or operators or implicitly calling some(predicate), is there a smarter way of finding the firstMatch? Preferably a JavaScript function (something like filterFirst(pedicate)) which short-circuits on first match resembling C#'s Enumerable.First() implementation? \nFWIW, I am targeting node.js / io.js runtimes.\n",
        "all_answers": [
            "\nYou could emulate this in the case where you want to return the first truthy value with reduce.\n['a', 'b', 'c'].reduce(function(prev, curr) { \n    return prev || predicate(curr) && curr; \n}, false);\n\nedit: made more terse with @BenjaminGruenbaum suggestion\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nNo need to reinvent the wheel, the correct way to do it is to use .find:\nvar firstMatch = ['a', 'b', 'c'].find(applyConditions);\n\nIf you're using a browser that does not support .find you can polyfill it\n",
            "\nUpdate 2020 - CLI\nAs @mix3d pointed out you can just run a command where file.js is your file and someFunction is your function optionally followed by parameters separated with spaces\nnpx run-func file.js someFunction \"just some parameter\"\n\nThat's it.\nfile.js called in the example above\nconst someFunction = (param) => console.log('Welcome, your param is', param)\n\n// exporting is crucial\nmodule.exports = { someFunction }\n\nMore detailed description\nRun directly from CLI (global)\nInstall\nnpm i -g run-func\n\nUsage i.e. run function \"init\", it must be exported, see the bottom\nrun-func db.js init\n\nor\nRun from package.json script (local)\nInstall\nnpm i -S run-func\n\nSetup\n\"scripts\": {\n   \"init\": \"run-func db.js init\"\n}\n\nUsage\nnpm run init\n\nParams\nAny following arguments will be passed as function parameters init(param1, param2)\nrun-func db.js init param1 param2\n\nImportant\nthe function (in this example init) must be exported in the file containing it\nmodule.exports = { init };\n\nor ES6 export\nexport { init };\n\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "arrays",
            "node.js",
            "linq",
            "filter"
        ]
    },
    {
        "question_id": "507343",
        "question": "\n\n\n\nAs a long-time Visual SourceSafe user (and hater) I was discussing switching to SVN with a colleague; he suggested using Git instead. Since, apparently, it can be used as peer-to-peer without a central server (we are a 3-developer team). \nI have not been able to find anything about tools that integrate Git with Visual Studio, though - does such a thing exist? \nWhat are the technologies available for using Git with Visual Studio? And what do I need to know about how they differ before I begin?\n",
        "all_answers": [
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nI use Git with Visual Studio for my port of Protocol Buffers to C#. I don't use the GUI - I just keep a command line open as well as Visual Studio.\nFor the most part it's fine - the only problem is when you want to rename a file. Both Git and Visual Studio would rather that they were the one to rename it. I think that renaming it in Visual Studio is the way to go though - just be careful what you do at the Git side afterwards. Although this has been a bit of a pain in the past, I've heard that it actually should be pretty seamless on the Git side, because it can notice that the contents will be mostly the same. (Not entirely the same, usually - you tend to rename a file when you're renaming the class, IME.)\nBut basically - yes, it works fine. I'm a Git newbie, but I can get it to do everything I need it to. Make sure you have a git ignore file for bin and obj, and *.user.\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIn Jan 2013, Microsoft announced that they are adding full Git support into all their ALM products. They have published a plugin for Visual Studio 2012 that adds Git source control integration.\nAlternatively, there is a project called Git Extensions that includes add-ins for Visual Studio 2005, 2008, 2010 and 2012, as well as Windows Explorer integration. It's regularly updated and having used it on a couple of projects, I've found it very useful.\nAnother option is Git Source Control Provider.\n"
        ],
        "answer": "A6",
        "tags": [
            "visual-studio",
            "git"
        ]
    },
    {
        "question_id": "28712248",
        "question": "\nI wanted to use the mongodb database, but I noticed that there are two different databases with either their own website and installation methods: mongodb and mongoose. So I came up asking myself this question: \"Which one do I use?\".\nSo in order to answer this question I ask the community if you could explain what are the differences between these two? And if possible pros and cons? Because they really look very similar to me.    \n",
        "all_answers": [
            "\nYou can set the connection to a variable then disconnect it when you are done:\nvar db = mongoose.connect('mongodb://localhost:27017/somedb');\n\n// Do some stuff\n\ndb.disconnect();\n\n",
            "\nI assume you already know that MongoDB is a NoSQL database system which stores data in the form of BSON documents. Your question, however is about the packages for Node.js.\nIn terms of Node.js, mongodb is the native driver for interacting with a mongodb instance and mongoose is an Object modeling tool  for MongoDB.\nmongoose is built on top of the mongodb driver to provide programmers with a way to model their data.\nEDIT:\nI do not want to comment on which is better, as this would make this answer opinionated. However I will list some advantages and disadvantages of using both approaches.\nUsing mongoose, a user can define the schema for the documents in a particular collection. It provides a lot of convenience in the creation and management of data in MongoDB. On the downside, learning mongoose can take some time, and has some limitations in handling schemas that are quite complex.\nHowever, if your collection schema is unpredictable, or you want a Mongo-shell like experience inside Node.js, then go ahead and use the mongodb driver. It is the simplest to pick up. The downside here is that you will have to write larger amounts of code for validating the data, and the risk of errors is higher.\n",
            "\nMongodb and Mongoose are two completely different things!\nMongodb is the database itself, while Mongoose is an object modeling tool for Mongodb\nEDIT: As pointed out MongoDB is the npm package, thanks!\n",
            "\nYou will get an error if you try to close/disconnect outside of the method. The best solution is to close the connection in both callbacks in the method. The dummy code is here.\nconst newTodo = new Todo({text:'cook dinner'});\n\nnewTodo.save().then((docs) => {\n  console.log('todo saved',docs);\n  mongoose.connection.close();\n},(e) => {\n  console.log('unable to save');\n});\n\n",
            "\nJust as Jake Wilson said: You can set the connection to a variable then disconnect it when you are done:\nlet db;\nmongoose.connect('mongodb://localhost:27017/somedb').then((dbConnection)=>{\n    db = dbConnection;\n    afterwards();\n});\n\n\nfunction afterwards(){\n\n    //do stuff\n\n    db.disconnect();\n}\n\nor if inside Async function:\n(async ()=>{\n    const db = await mongoose.connect('mongodb://localhost:27017/somedb', { useMongoClient: \n                  true })\n\n    //do stuff\n\n    db.disconnect()\n})\n\notherwise when i was checking it in my environment it has an error.\n",
            "\nThe other answer didn't work for me. I had to use mongoose.disconnect(); as stated in this answer. \n",
            "\nmongoose.connection.close(function(){\nconsole.log('Mongoose default connection disconnected through app termination');\nprocess.exit(0);\n});\n\nThis will close the mongoose connection and will also notify you by message in your console.\n",
            "\nYou can close the connection with\nmongoose.connection.close()\n\n",
            "\nI'm using version 4.4.2 and none of the other answers worked for me. But adding useMongoClient to the options and putting it into a variable that you call close on seemed to work. \nvar db = mongoose.connect('mongodb://localhost:27017/somedb', { useMongoClient: true })\n\n//do stuff\n\ndb.close()\n\n"
        ],
        "answer": "A2",
        "tags": [
            "node.js",
            "mongodb",
            "mongoose"
        ]
    },
    {
        "question_id": "935650",
        "question": "\nI'm using accepts_nested_attributes_for in one of my Rails models, and I want to save the children after creating the parent.\nThe form works perfectly, but the validation is failing. For simplicity's sake imagine the following:\nclass Project < ActiveRecord::Base\n  has_many :tasks\n  accepts_nested_attributes_for :tasks\nend\n\nclass Task < ActiveRecord::Base\n  belongs_to :project\n\n  validates_presence_of :project_id\n  validates_associated :project\nend\n\nAnd I am running:\nProject.create!(\n  :name => 'Something',\n  :task_attributes => [ { :name => '123' }, { :name => '456' } ]\n)\n\nUpon saving the project model, the validation is failing on the tasks because they don't have a project_id (since the project hasn't been saved).\nIt seems like Rails is following the pattern below:\n\nValidate Project\nValidate Tasks\nSave Project\nSave Tasks\n\nThe pattern should be:\n\nValidate Project\nOn Pass: Save Project and continue...\nValidate Tasks\n\n\nOn Pass: Save Tasks\nOn Fail: Delete Project (rollback maybe?)\n\n\nSo my question boils down to: How can I get Rails to run the project_id= (or project=) method and validation on the children (tasks) AFTER the parent (project) has been saved, but NOT save the parent (project) model if any child (task) is invalid?\nAny ideas?\n",
        "all_answers": [
            "\nUse this answer for Rails 2, otherwise see below for the :inverse_of answer\nYou can work around this by not checking for the project_id if the associated project is valid.\n\nclass Task < ActiveRecord::Base\n  belongs_to :project\n\n  validates_presence_of :project_id, :unless => lambda {|task| task.project.try(:valid?)}\n  validates_associated :project\nend\n\n",
            "\nContrary to what bigo suggests, it's not always acceptable to save the parent object first and then the children. Usually you want to make sure all objects validate before you start saving them. That gives the user the chance to re-edit the input form and correct any errors.\nThe problem you describe will be fixed in Rails 3.0. I would have posted a link to the Lighthouse ticket, but stackoverflow.com does not allow this because I'm a new user (#fail). But for the time being, you can use the plugin \"parental_control\", which will fix your \"bug\".\n",
            "\nRails 5 has a left_outer_joins method. So you can do\nUser.left_outer_joins(:user_points)\n\nor use the alias\nUser.left_joins(:user_points)\n\n",
            "\nJust for future reference, adding :all gives a deprecated message. In later versions of rails you can simply chain the methods like this:\nUser.joins(\"LEFT JOIN `user_points` ON user_points.user_id = users.id\").select(\"users.*, count(user_points.id)\").group(\"user_points.user_id\")\n\nOR use a scope like this:\nscope :my_scope_name_here, -> { \n        joins(\"LEFT JOIN `user_points` ON user_points.user_id = users.id\")\n        .select(\"users.*, count(user_points.id)\")\n        .group(\"user_points.user_id\")\n}\n\nYou can also chain .where between the .join and the .select.\nHope this helps someone in the future.\n",
            "\nYou could just create the project and only add the projects if it passes validation:\ntasks = params.delete(:task_attributes)\nif Project.create(params)\n  Project.update_attributes(:task_attributes => tasks)\nend\n\nCiao\n",
            "\nYou can try this\nUser.find(:all, limit: 10,\n            joins:  \"LEFT JOIN `user_points` ON user_points.user_id = users.id\" ,\n            select: \"users.*, count(user_points.id)\", \n            group:  \"user_points.user_id\")\n\n",
            "\nadd_index :subscriptions, [:user_id, :content_id], unique: true\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "validation",
            "activerecord",
            "nested"
        ]
    },
    {
        "question_id": "10834382",
        "question": "\nI want to plot unused levels (that is, levels where the count is 0) in my bar-plot, however, unused levels are dropped and I cannot figure out how to keep them\ndf <- data.frame(type=c(\"A\", \"A\", \"A\", \"B\", \"B\"), group=rep(\"group1\", 5))\ndf$type <- factor(df$type, levels=c(\"A\",\"B\", \"C\"))\n\nggplot(df, aes(x=group, fill=type)) + geom_bar()\n\nIn the above example, I want to see C plotted with a count of 0, but it is completely absent...\nThanks for any help\nUlrik \nEdit:\nThis does what I want\ndf <- data.frame(type=c(\"A\", \"A\", \"A\", \"B\", \"B\"), group=rep(\"group1\", 5))\ndf1 <- data.frame(type=c(\"A\", \"A\", \"A\", \"B\", \"B\", \"A\", \"A\", \"C\", \"B\", \"B\"), group=c(rep(\"group1\", 5),rep(\"group2\", 5)))\n\ndf$type <- factor(df$type, levels=c(\"A\",\"B\", \"C\"))\ndf1$type <- factor(df1$type, levels=c(\"A\",\"B\", \"C\"))\ndf <- data.frame(table(df))\n\ndf1 <- data.frame(table(df1))\n\nggplot(df, aes(x=group, y=Freq, fill=type)) + geom_bar(position=\"dodge\")\nggplot(df1, aes(x=group, y=Freq, fill=type)) + geom_bar(position=\"dodge\")\n\nGuess the solution is to calculate the frequencies using table() and then plot\n",
        "all_answers": [
            "\nYou need to set drop=FALSE on both scales (fill and x) like this:\nlibrary(ggplot2)\ndf <- data.frame(type=c(\"A\", \"A\", \"A\", \"B\", \"B\"), group=rep(\"group1\", 5))\ndf1 <- data.frame(type=c(\"A\", \"A\", \"A\", \"B\", \"B\", \"A\", \"A\", \"C\", \"B\", \"B\"), group=c(rep(\"group1\", 5),rep(\"group2\", 5)))\ndf$type <- factor(df$type, levels=c(\"A\",\"B\", \"C\"))\ndf1$type <- factor(df1$type, levels=c(\"A\",\"B\", \"C\"))\n\nplt <-  ggplot(df, aes(x=type, fill=type)) + \n          geom_bar(position='dodge') + \n          scale_fill_discrete(drop=FALSE) +\n          scale_x_discrete(drop=FALSE)\nplt1 <- ggplot(df1, aes(x=type, fill=type)) + \n          geom_bar(position='dodge') + \n          scale_fill_discrete(drop=FALSE) +\n          scale_x_discrete(drop=FALSE)\n\nEdit:\nI'm pretty sure this works. Forgot to change x to type instead of group and the position='dodge'! Just paste and test. The stat_bin deals with bins with zero counts. Check the docs.\n",
            "\nDoes this do what you want?\nggplot(df, aes(x=type)) + geom_bar() + scale_x_discrete(drop=FALSE)\n\n\n"
        ],
        "answer": "A1",
        "tags": [
            "r",
            "ggplot2",
            "legend",
            "levels"
        ]
    },
    {
        "question_id": "54704207",
        "question": "\nI'm getting this below warning message in my Xcode 10.1.\n\nThe iOS Simulator deployment targets are set to 7.0, but the range of supported deployment target versions for this platform is 8.0 to 12.1.\n\nMy simulator os in 12.1\nXcode 10.1\nAnd I updated my pod file.\n\nMy deployment target is 9.0\n\nIn my target\n\n",
        "all_answers": [
            "\nI solved this problem, I changed build system to Legacy Build System from New Build System\nIn Xcode v10+, select File > Project Settings\nIn previous Xcode, select File > Workspace Settings\n\nChange Build System to Legacy Build System from New Build System --> Click Done.\n\n",
            "\nYou can set up your podfile to automatically match the deployment target of all the podfiles to your current project deployment target like this :\npost_install do |installer|\n installer.pods_project.targets.each do |target|\n  target.build_configurations.each do |config|\n   config.build_settings['IPHONEOS_DEPLOYMENT_TARGET'] = '9.0'\n  end\n end\nend\n\n",
            "\nTry these steps:\n\nDelete your Podfile.lock\nDelete your Podfile\nBuild Project\nAdd initialization code from firebase\ncd /ios\npod install\nrun Project\n\nThis was what worked for me. \n",
            "\nThe problem is in your pod files deployment target iOS Version not in your project deployment target iOS Version, so you need to change the deployment iOS version for your pods as well to anything higher than 8.0 to do so open your project workspace and do this:\n1- Click on pods.\n2- Select each project and target and click on build settings.\n3- Under Deployment section change the iOS Deployment Target version to anything more than 8.0\n(better to try the same project version).\n4- Repeat this for every other project in your pods then run the app.\nsee the photo for details\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "xcode",
            "cocoapods",
            "ios-simulator",
            "google-fabric"
        ]
    },
    {
        "question_id": "15153776",
        "question": "\n\n\n\nI am trying to convert my base64 image string to an image file. This is my Base64 string:\nhttp://pastebin.com/ENkTrGNG\nUsing following code to convert it into an image file:\nfunction base64_to_jpeg( $base64_string, $output_file ) {\n    $ifp = fopen( $output_file, \"wb\" ); \n    fwrite( $ifp, base64_decode( $base64_string) ); \n    fclose( $ifp ); \n    return( $output_file ); \n}\n\n$image = base64_to_jpeg( $my_base64_string, 'tmp.jpg' );\n\nBut I am getting an error of invalid image, whats wrong here?\n",
        "all_answers": [
            "\nYou need to remove the part that says data:image/png;base64, at the beginning of the image data. The actual base64 data comes after that.\nJust strip everything up to and including base64, (before calling base64_decode() on the data) and you'll be fine.\n",
            "\nThe problem is that data:image/png;base64, is included in the encoded contents. This will result in invalid image data when the base64 function decodes it. Remove that data in the function before decoding the string, like so.\nfunction base64_to_jpeg($base64_string, $output_file) {\n    // open the output file for writing\n    $ifp = fopen( $output_file, 'wb' ); \n\n    // split the string on commas\n    // $data[ 0 ] == \"data:image/png;base64\"\n    // $data[ 1 ] == <actual base64 string>\n    $data = explode( ',', $base64_string );\n\n    // we could add validation here with ensuring count( $data ) > 1\n    fwrite( $ifp, base64_decode( $data[ 1 ] ) );\n\n    // clean up the file resource\n    fclose( $ifp ); \n\n    return $output_file; \n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "base64"
        ]
    },
    {
        "question_id": "5188914",
        "question": "\nI have a Git project which has a long history. I want to show the first commit.\nHow do I do this?\n",
        "all_answers": [
            "\nI found that:\ngit log --reverse\n\nshows commits from start.\n",
            "\ngit log $(git log --pretty=format:%H|tail -1)\n\n",
            "\nShort answer\ngit rev-list --max-parents=0 HEAD\n\n(from tiho's comment. As Chris Johnsen notices, --max-parents was introduced after this answer was posted.)\nExplanation\nTechnically, there may be more than one root commit. This happens when multiple previously independent histories are merged together. It is common when a project is integrated via a subtree merge.\nThe git.git repository has six root commits in its history graph (one each for Linus’s initial commit, gitk, some initially separate tools, git-gui, gitweb, and git-p4). In this case, we know that e83c516 is the one we are probably interested in. It is both the earliest commit and a root commit.\nIt is not so simple in the general case.\nImagine that libfoo has been in development for a while and keeps its history in a Git repository (libfoo.git). Independently, the “bar” project has also been under development (in bar.git), but not for as long libfoo (the commit with the earliest date in libfoo.git has a date that precedes the commit with the earliest date in bar.git). At some point the developers of “bar” decide to incorporate libfoo into their project by using a subtree merge. Prior to this merge it might have been trivial to determine the “first” commit in bar.git (there was probably only one root commit). After the merge, however, there are multiple root commits and the earliest root commit actually comes from the history of libfoo, not “bar”.\nYou can find all the root commits of the history DAG like this:\ngit rev-list --max-parents=0 HEAD\n\nFor the record, if --max-parents weren't available, this does also work:\ngit rev-list --parents HEAD | egrep \"^[a-f0-9]{40}$\"\n\nIf you have useful tags in place, then git name-rev might give you a quick overview of the history:\ngit rev-list --parents HEAD | egrep \"^[a-f0-9]{40}$\" | git name-rev --stdin\n\nBonus\nUse this often? Hard to remember? Add a git alias for quick access\ngit config --global alias.first \"rev-list --max-parents=0 HEAD\"\n\nNow you can simply do\ngit first\n\n",
            "\nYou can just reverse your log and just head it for the first result.\ngit log --pretty=oneline --reverse | head -1\n\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nNot the most beautiful way of doing it I guess:\ngit log --pretty=oneline | wc -l\n\nThis gives you a number then\ngit log HEAD~<The number minus one>\n\n"
        ],
        "answer": "A3",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "25976909",
        "question": "\nIn Swift, is there any way to check if an index exists in an array without a fatal error being thrown?\nI was hoping I could do something like this:\nlet arr: [String] = [\"foo\", \"bar\"]\nlet str: String? = arr[1]\nif let str2 = arr[2] as String? {\n    // this wouldn't run\n    println(str2)\n} else {\n    // this would be run\n}\n\nBut I get\n\nfatal error: Array index out of range\n\n",
        "all_answers": [
            "\nYou actually don't need to use a web and app URL anymore. The web URL will automatically open in the app if the user has it. Instagram or other apps implement this on their end as a Universal Link\nSwift 4\nfunc openInstagram(instagramHandle: String) {\n    guard let url = URL(string: \"https://instagram.com/\\(instagramHandle)\")  else { return }\n    if UIApplication.shared.canOpenURL(url) {\n        if #available(iOS 10.0, *) {\n            UIApplication.shared.open(url, options: [:], completionHandler: nil)\n        } else {\n            UIApplication.shared.openURL(url)\n        }\n    }\n}\n\n",
            "\nYou can rewrite this in a safer way to check the size of the array, and use a ternary conditional:\nif let str2 = (arr.count > 2 ? arr[2] : nil) as String?\n\n",
            "\nJust check if the index is less than the array size:\nif 2 < arr.count {\n    ...\n} else {\n    ...\n}\n\n",
            "\nAn elegant way in Swift:\nlet isIndexValid = array.indices.contains(index)\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n"
        ],
        "answer": "A4",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "9089953",
        "question": "\nHere is the story: I'm using SWFObject to insert a Flash object into my page. The embedding eats my span. So, I lose all my CSS for it. I was thinking of moving all of the CSS to the parent so I don't lose my CSS styles when the Flash appears. \nI have tried using a span within a span, but I don't think it's working. Is there a reason for this? I don't understand why you could have div within a div but not a span within a span.\nDoes it have to do with spans being inline?\n",
        "all_answers": [
            "\nAs of Feb. 2016, CSS 3 has the support mentioned below. Here is a snippet from a WooCommerce's single product page with price discount\n/*Price before discount on single product page*/\nbody.single-product .price del .amount {\ncolor:           hsl(0, 90%, 65%);\nfont-size:       15px;\ntext-decoration: line-through;\n/*noinspection CssOverwrittenProperties*/\ntext-decoration: white double line-through; /* Ignored in CSS1/CSS2 UAs */\n}\n\nResulting in:\n\n\nCSS 3 will likely have direct support using the text-decoration-color property. In particular:\n\nThe text-decoration-color CSS property sets the color used when drawing underlines, overlines, or strike-throughs specified by text-decoration-line. This is the preferred way to color these text decorations, rather than using combinations of other HTML elements.\n\nAlso see text-decoration-color in the CSS 3 draft spec.\nIf you want to use this method immediately, you probably have to prefix it, using -moz-text-decoration-color. (Also specify it without -moz-, for forward-compatibility.)\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n"
        ],
        "answer": "A3",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "5801813",
        "question": "\nI already found out with another question that Windows/MingW doesn't provide the nanosleep() and setitimer() alternatives to the obsolete usleep().\nBut my goal is to fix all warnings that cppcheck gives me, including the usleep() style warnings.\nSo, is there a workaround to somehow avoid usleep() on Windows without using cygwin or installing loads of new dependencies/libraries? Thanks.\n",
        "all_answers": [
            "\nI found this blog post about it. It uses QueryPerformanceCounter. The function posted:\n#include <windows.h>\n\nvoid uSleep(int waitTime) {\n    __int64 time1 = 0, time2 = 0, freq = 0;\n\n    QueryPerformanceCounter((LARGE_INTEGER *) &time1);\n    QueryPerformanceFrequency((LARGE_INTEGER *)&freq);\n\n    do {\n        QueryPerformanceCounter((LARGE_INTEGER *) &time2);\n    } while((time2-time1) < waitTime);\n}\n\nI hope this helps a bit.\n",
            "\nusleep() works with microseconds. In windows for getting microsecond precesion you should use QueryPerformanceCounter() winapi function. Here you can find how get that precesion using it.\n",
            "\nI have done it earlier.\nHope this helps, if this is exactly what you are looking for.\n\nLoad your certificate (in PCCERT_CONTEXT structure) from Windows Cert store using Crypto APIs.\nGet encrypted content of it in binary format as it is. [PCCERT_CONTEXT->pbCertEncoded].\nParse this binary buffer into X509 certificate Object using OpenSSL's d2i_X509() method.\nGet handle to OpenSSL's trust store using SSL_CTX_get_cert_store() method.\nLoad above parsed X509 certificate into this trust store using X509_STORE_add_cert() method.\nYou are done!\n\n",
            "\nIt depends what granularity you need. If you are talking milliseconds, then the Win32 Sleep function will do the job - see http://msdn.microsoft.com/en-us/library/ms686298%28v=vs.85%29.aspx. If you are talking microseconds, then there is no easy way to do it, and you would be lucky to get that sort of timer resolution on Windows (which is not  an RTOS), or on Linux, come to that.\n"
        ],
        "answer": "A2",
        "tags": [
            "c++",
            "windows",
            "cppcheck",
            "usleep"
        ]
    },
    {
        "question_id": "613119",
        "question": "\nWhere are the Windows binaries for the command-line version of SVN? Everywhere I search, it has to be some company's fancy client software with an installer.\nI'm working on a machine where I don't have administrator account. Just give me the plain command-line binaries, where the hell are they?\n",
        "all_answers": [
            "\nhttp://subversion.tigris.org/\nThe client-side binaries ship with the source, as well as several other packaged installers.\n",
            "\nActually, I had this problem same as you.\nMy windows is server 2008 and my subversion info is :\nTortoiseSVN 1.7.6, Build 22632 - 64 Bit , 2012/03/08 18:29:39\nSubversion 1.7.4, \napr 1.4.5\napr-utils 1.3.12\nneon 0.29.6\nOpenSSL 1.0.0g 18 Jan 2012\nzlib 1.2.5\nI used this way and I solved this problem.\nI used [group] option. this option makes problem. \nI rewrite authz file contents.\nI remove group option. and I set one by one.\nI use well.\nThanks for reading.\n",
            "\nThe former direct links don't work, but the subversion project now provides several offsite links to Windows binaries:\nhttp://subversion.apache.org/packages.html#windows\n",
            "\nAs a new user to these two software packages, I experienced the exact same problem.  As was also discovered above, my solution was to use the same case letters as is in the Repository path.\nHere's a tip that I find helpful:  In VisualSVN, you can right click on the path, then click \"Copy URL to Clipboard\" for pasting in Tortoise to be sure that the path is the identical case.\n",
            "\nThe solution for me was to check the case sensitivity of the username. A lot of people are mentioning that the URL is case sensitive, but it seems the username is as well!\n",
            "\nYou can get the \"Forbidden\" error if your user account lacks access permissions to a repository or repository path; it makes sense to check authorization settings for your user account. Make sure your system administrator hasn't provided you with No Access permission to the repository path.\nIf you are sure that permissions are set correctly, then double-check the URL you use. URLs in Apache Subversion are case-sensitive.\nAdditionally, I advise you to read articles on authorization in Subversion and VisualSVN Server:\n\nSVNBook about path-based authorization.\nVisualSVN Team's article about path-based authorization. It explains the principles of SVN authorization by comparing it with Windows Access Control.\n\n",
            "\nThe Command Line Client from CollabNet, while it does have an installer for windows, all it asks you is where you want to put the files, and then finish.  Its just the command line client, like it says, nothing else.  Subversion doesn't distribute their own binaries.\n\nThe Subversion project does not\n  officially endorse or maintain any\n  binary packages of the Subversion\n  software. However, volunteers have\n  created binary packages for different\n  distributions and platforms, and as a\n  convenience, we maintain a list of\n  links to them here. If there are any\n  problems with or questions about the\n  different binary packages please send\n  email to the Subversion users mailing\n  list.\n\n",
            "\nIf the problem lies client side, this could be one of the causes of the error.\nOn clients TortoiseSVN saves client credentials under\n\nTortoise settings / saved data / authentication data.\n\nI got the same error trying to commit my files, but my credentials were changed. Clearing this cache here will give you a popup on next commit attempt for re-entering your correct credentials.\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "svn",
            "command-line-tool",
            "binaries"
        ]
    },
    {
        "question_id": "2385799",
        "question": "\nI'd like to 'fake' a 404 page in Rails. In PHP, I would just send a header with the error code as such:\nheader(\"HTTP/1.0 404 Not Found\");\n\nHow is that done with Rails?\n",
        "all_answers": [
            "\nHTTP 404 Status\nTo return a 404 header, just use the :status option for the render method.\ndef action\n  # here the code\n\n  render :status => 404\nend\n\nIf you want to render the standard 404 page you can extract the feature in a method.\ndef render_404\n  respond_to do |format|\n    format.html { render :file => \"#{Rails.root}/public/404\", :layout => false, :status => :not_found }\n    format.xml  { head :not_found }\n    format.any  { head :not_found }\n  end\nend\n\nand call it in your action\ndef action\n  # here the code\n\n  render_404\nend\n\nIf you want the action to render the error page and stop, simply use a return statement.\ndef action\n  render_404 and return if params[:something].blank?\n\n  # here the code that will never be executed\nend\n\nActiveRecord and HTTP 404\nAlso remember that Rails rescues some ActiveRecord errors, such as the ActiveRecord::RecordNotFound displaying the 404 error page.\nIt means you don't need to rescue this action yourself\ndef show\n  user = User.find(params[:id])\nend\n\nUser.find raises an ActiveRecord::RecordNotFound when the user doesn't exist. This is a very powerful feature. Look at the following code\ndef show\n  user = User.find_by_email(params[:email]) or raise(\"not found\")\n  # ...\nend\n\nYou can simplify it by delegating to Rails the check. Simply use the bang version.\ndef show\n  user = User.find_by_email!(params[:email])\n  # ...\nend\n\n",
            "\nDon't render 404 yourself, there's no reason to; Rails has this functionality built in already. If you want to show a 404 page, create a render_404 method (or not_found as I called it) in ApplicationController like this: \ndef not_found\n  raise ActionController::RoutingError.new('Not Found')\nend\n\nRails also handles AbstractController::ActionNotFound, and ActiveRecord::RecordNotFound the same way.\nThis does two things better: \n1) It uses Rails' built in rescue_from handler to render the 404 page, and\n2) it interrupts the execution of your code, letting you do nice things like:\n  user = User.find_by_email(params[:email]) or not_found\n  user.do_something!\n\nwithout having to write ugly conditional statements.\nAs a bonus, it's also super easy to handle in tests.  For example, in an rspec integration test:\n# RSpec 1\n\nlambda {\n  visit '/something/you/want/to/404'\n}.should raise_error(ActionController::RoutingError)\n\n# RSpec 2+\n\nexpect {\n  get '/something/you/want/to/404'\n}.to raise_error(ActionController::RoutingError)\n\nAnd minitest:\nassert_raises(ActionController::RoutingError) do \n  get '/something/you/want/to/404'\nend\n\nOR refer more info from Rails render 404 not found from a controller action\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "http",
            "http-status-code-404"
        ]
    },
    {
        "question_id": "9995266",
        "question": "\nI have a Generic List as below\npublic static readonly List<Customer> Customers = new List<Customer>();\n\nI'm using the below methods for it:\n.Add\n.Find\n.FirstOrDefault\n\nThe last 2 are LINQ extensions.\nI'd need to make this thread-safe to be able to run multiple instances of the container class.\nHow to achieve that?\n",
        "all_answers": [
            "\nYou will need to use locks in every place where the collection gets modified or iterated over.\nEither that or use one of the new thread-safe data structures, like ConcurrentBag.\n",
            "\nIf those are the only functions you are using on List<T> then the easiest way is to write a quick wrapper that synchronizes access with a lock\nclass MyList<T> { \n  private List<T> _list = new List<T>();\n  private object _sync = new object();\n  public void Add(T value) {\n    lock (_sync) {\n      _list.Add(value);\n    }\n  }\n  public bool Find(Predicate<T> predicate) {\n    lock (_sync) {\n      return _list.Find(predicate);\n    }\n  }\n  public T FirstOrDefault() {\n    lock (_sync) {\n      return _list.FirstOrDefault();\n    }\n  }\n}\n\nI highly recommend the approach of a new type + private lock object.  It makes it much more obvious to the next guy who inherits your code what the actual intent was.\nAlso note that .Net 4.0 introduced a new set of collections specifically aimed at being used from multiple threads.  If one of these meets your needs I'd highly recommend using it over rolling your own. \n\nConcurrentStack<T>\nConcurrentQueue<T>\n\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nHere is a good write up about .NET events and race conditions with threads.  It covers some common scenarios and has some good references in it.\nHope this helps.\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "multithreading",
            "list",
            "generics"
        ]
    },
    {
        "question_id": "25549562",
        "question": "\nIn my project there is a method which only returns a const char*, whereas I need a char* string, as the API doesn't accept const char*.\nAny idea how to convert between const char* to char*?\n",
        "all_answers": [
            "\nThe difference is due to operator precedence.\nThe post-increment operator ++ has higher precedence than the dereference operator *. So *ptr++ is equivalent to *(ptr++). In other words, the post increment modifies the pointer, not what it points to.\nThe assignment operator += has lower precedence than the dereference operator *, so *ptr+=1 is equivalent to (*ptr)+=1. In other words, the assignment operator modifies the value that the pointer points to, and does not change the pointer itself. \n",
            "\nTo make sure you don't break stuff, make a copy of the returned string.\nThe function returning const char* expects this string will never be changed. Therefore things can/will break if your code or the API you pass it make a change after all.\nEven worse, if a change is made, your program is likely to crash you in case the returned string was literal (e.g. \"hello I'm a literal string\") because they are (often) stored in memory that can't be written to.\nYou could use strdup() for this, but read the small print. Or you can of course create your own version if it's not there on your platform.\n",
            "\nFirst of all you should do such things only if it is really necessary - e.g. to use some old-style API with char* arguments which are not modified. If an API function modifies the string which was const originally, then this is unspecified behaviour, very likely crash.\nUse cast:\n(char*)const_char_ptr\n\n",
            "\nVery good question.\nIn K&R \"C programming language\" \"5.1 Pointers and Addresses\", we can get an answer for this.\n\"The unary operators * and & bind more tightly than arithmetic operators\"\n*ptr += 1      //Increment what ptr points to.\n\n\"Unary operators like * and ++ associate right to left.\"\n*ptr++        //Increment prt instead of what ptr point to.\n\n//It works like *(ptr++).\nThe correct way is:\n(*ptr)++      //This will work.\n\n",
            "\nLet's apply parentheses to show the order of operations\na + b / c\na + (b/c)\n\nLet's do it again with\n*ptr   += 1\n(*ptr) += 1\n\nAnd again with\n*ptr++\n*(ptr++)\n\n\nIn *ptr += 1, we increment the value of the variable our pointer points to.\nIn *ptr++, we increment the pointer after our entire statement (line of code) is done, and return a reference to the variable our pointer points to.\n\nThe latter allows you to do things like:\nfor(int i = 0; i < length; i++)\n{\n    // Copy value from *src and store it in *dest\n    *dest++ = *src++;\n\n    // Keep in mind that the above is equivalent to\n    *(dest++) = *(src++);\n}\n\nThis is a common method used to copy a src array into another dest array.\n",
            "\nThe order of precedence for the 3 operators involved in your question is the following :\npost-increment ++ > dereference * > assignment +=\nYou can check this page for further details on the subject.\n\nWhen parsing an expression, an operator which is listed on some row will be bound tighter (as if by parentheses) to its arguments than any operator that is listed on a row further below it. For example, the expression *p++ is parsed as *(p++), and not as (*p)++.\n\nLong story short, in order to express this assignment *ptr+=1 using the post-increment operator you need to add parentheses to the dereference operator to give that operation precedence over ++ as in this (*ptr)++\n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "pointers",
            "const-char"
        ]
    },
    {
        "question_id": "409688",
        "question": "\nThis is a complex question, please consider carefully before answering.\nConsider this situation.  Two threads (a reader and a writer) access a single global int.  Is this safe?  Normally, I would respond without thought, yes!\nHowever, it seems to me that Herb Sutter doesn't think so.  In his articles on effective concurrency he discusses a flawed lock-free queue and the corrected version.\nIn the end of the first article and the beginning of the second he discusses a rarely considered trait of variables, write ordering.  Int's are atomic, good, but ints aren't necessarily ordered which could destroy any lock-free algorithm, including my above scenario.  I fully agree that the only way to guarantee correct multithreaded behavior on all platforms present and future is to use atomics(AKA memory barriers) or mutexes.\nMy question; is write re-odering ever a problem on real hardware?  Or is the multithreaded paranoia just being pedantic?\nWhat about classic uniprocessor systems?\nWhat about simpler RISC processors like an embedded power-pc?\nClarification:  I'm more interested in what Mr. Sutter said about the hardware (processor/cache) reordering variable writes.  I can stop the optimizer from breaking code with compiler switches or hand inspection of the assembly post-compilation.  However, I'd like to know if the hardware can still mess up the code in practice.\n",
        "all_answers": [
            "\nLike you said, because of reordering done at cache or processor level, you actually do need some sort of memory barrier to ensure proper synchronisation, especially for multi-processors (and especially on non-x86 platforms). (I am given to believe that single-processor systems don't have these issues, but don't quote me on this---I'm certainly more inclined to play safe and do the synchronised access anyway.)\n",
            "\nYup - use memory barriers to prevent instruction reordering where needed.  In some C++ compilers, the volatile keyword has been expanded to insert implicit memory barriers for every read and write - but this isn't a portable solution.  (Likewise with the Interlocked* win32 APIs).  Vista even adds some new finer-grained Interlocked APIs which let you specify read or write semantics.\nUnfortunately, C++ has such a loose memory model that any kind of code like this is going to be non-portable to some extent and you'll have to write different versions for different platforms.\n",
            "\nYour idea of inspecting the assembly is not good enough; the reordering can happen at the hardware level.\nTo answer your question \"is this ever a problem on read hardware:\" Yes!  In fact I've run into that problem myself.\nIs it OK to skirt the issue with uniprocessor systems or other special-case situations?  I would argue \"no\" because five years from now you might need to run on multi-core after all, and then finding all these locations will be tricky (impossible?).\nOne exception: Software designed for embedded hardware applications where indeed you have completely control over the hardware.  In fact I have \"cheated\" like this in those situations on e.g. an ARM processor.\n",
            "\nOn my system the behavior is same, but as Maxim mentioned, rand is not thread safe. When I change rand to rand_r, then the multi threaded code is faster as expected.\nvoid add_multi(int N, double& result) {\ndouble sum=0;\nunsigned int seed = time(NULL);\nfor (int i = 0; i < N; ++i){\n    sum+= sqrt(1.0*rand_r(&seed)/RAND_MAX);\n}\nresult = sum/N;\n}\n\n",
            "\nGCC Atomic Built-ins\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "c",
            "multithreading",
            "hardware"
        ]
    },
    {
        "question_id": "5414551",
        "question": "\n\nWhat is it a BLOB?\nHow can I use it?\nWhat are the differences between DBMS's BLOBs. I would like to save data using BLOBs into any DBMS and then read that BLOB with a library.\n\n",
        "all_answers": [
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nA BLOB is a Binary Large OBject. It is used to store large quantities of binary data in a database.\nYou can use it to store any kind of binary data that you want, includes images, video, or any other kind of binary data that you wish to store.\nDifferent DBMSes treat BLOBs in different ways; you should read the documentation of the databases you are interested in to see how (and if) they handle BLOBs.\n",
            "\nBLOB : \nBLOB (Binary Large Object) is a large object data type in the database system. BLOB could store a large chunk of data, document types and even media files like audio or video files. BLOB fields allocate space only whenever the content in the field is utilized. BLOB allocates spaces in Giga Bytes.  \nUSAGE OF BLOB : \nYou can write a binary large object (BLOB) to a database as either binary or character data, depending on the type of field at your data source. To write a BLOB value to your database, issue the appropriate INSERT or UPDATE statement and pass the BLOB value as an input parameter. If your BLOB is stored as text, such as a SQL Server text field, you can pass the BLOB as a string parameter. If the BLOB is stored in binary format, such as a SQL Server image field, you can pass an array of type byte as a binary parameter.  \nA useful link : Storing documents as BLOB in Database - Any disadvantages ?  \n"
        ],
        "answer": "A5",
        "tags": [
            "sql",
            "oracle",
            "blob",
            "database",
            "blobstore"
        ]
    },
    {
        "question_id": "10372877",
        "question": "\nI'm trying to create a new User in a Django project by the following code, but the highlighted line fires an exception.\ndef createUser(request):\n    userName = request.REQUEST.get('username', None)\n    userPass = request.REQUEST.get('password', None)\n    userMail = request.REQUEST.get('email', None)\n\n    # TODO: check if already existed\n\n    **user = User.objects.create_user(userName, userMail, userPass)**\n    user.save()\n\n    return render_to_response('home.html', context_instance=RequestContext(request))\n\nAny help?\n",
        "all_answers": [
            "\nThe correct way to create a user in Django is to use the create_user function. This will handle the hashing of the password, etc.. \nfrom django.contrib.auth.models import User\nuser = User.objects.create_user(username='john',\n                                 email='jlennon@beatles.com',\n                                 password='glass onion')\n\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nHave you confirmed that you are passing actual values and not None?\nfrom django.shortcuts import render\n\ndef createUser(request):\n    userName = request.REQUEST.get('username', None)\n    userPass = request.REQUEST.get('password', None)\n    userMail = request.REQUEST.get('email', None)\n\n    # TODO: check if already existed\n    if userName and userPass and userMail:\n       u,created = User.objects.get_or_create(userName, userMail)\n       if created:\n          # user was created\n          # set the password here\n       else:\n          # user was retrieved\n    else:\n       # request was empty\n\n    return render(request,'home.html')\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django"
        ]
    },
    {
        "question_id": "12800862",
        "question": "\nI want to run my django project under gunicorn on localhost. I installed and integrated gunicorn. When I run:\npython manage.py run_gunicorn\n\nIt works but there are no any static files (css and js)\nI disabled debug and template_debug in settings.py (made them false), but it is still same.  Am I missing something?\nI call statics like:\n{{ STATIC_URL }}css/etc....\n\n",
        "all_answers": [
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nThe gunicorn should be used to serve the python \"application\" itself, while the static files are served by a static file server ( such as Nginx ).\nThis is an excerpt from one of my configurations:\nupstream app_server_djangoapp {\n    server localhost:8000 fail_timeout=0;\n}\n\nserver {\n    listen < server port goes here >;\n    server_name < server name goes here >;\n\n    access_log  /var/log/nginx/guni-access.log;\n    error_log  /var/log/nginx/guni-error.log info;\n\n    keepalive_timeout 5;\n\n    root < application root directory goes here >;\n\n    location /static {    \n        autoindex on;    \n        alias < static folder directory goes here >;    \n    }\n\n    location /media {\n       autoindex on;\n       alias < user uploaded media file directory goes here >;\n    }\n\n    location / {\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n\n        if (!-f $request_filename) {\n            proxy_pass http://app_server_djangoapp;\n            break;\n        }\n    }\n}\n\nSome notes:\n\nThe static root, media root, static files path prefix and media file path prefix are set up in your settings.py\nOnce you have nginx set up to serve from the static content directory, you need to run \"python manage.py collectstatic\" in your project root so that the static files in the various apps can be copied to the static folder\n\nIn closing: while it is possible to serve static files from gunicorn ( by enabling a debug-only static file serving view ), that is considered bad practice in production.\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nWhen in development mode and when you are using some other server for local development add this to your urls.py\nfrom django.contrib.staticfiles.urls import staticfiles_urlpatterns\n\n# ... the rest of your URLconf goes here ...\n\nurlpatterns += staticfiles_urlpatterns()\n\nNote that staticfiles_urlpatterns() will only work when DEBUG = True is set in your settings.py.\nMore info here\nWhen in production you never, ever put gunicorn in front. Instead you use\na server like nginx which dispatches requests to a pool of gunicorn workers and also serves the static files.\nSee here\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "django",
            "gunicorn"
        ]
    },
    {
        "question_id": "12655136",
        "question": "\nHow to install phpunit?\nI read documentation https://github.com/sebastianbergmann/phpunit, but have an error:\n>pear upgrade PEAR\nNothing to upgrade\n\n>pear config-set auto_discover 1\nconfig-set succeeded\n\n>pear install pear.phpunit.de/PHPUnit\nNo releases available for package \"pear.phpunit.de/PHPUnit\"\ninstall failed\n\nHow can I fix this error?\n",
        "all_answers": [
            "\nOld answer (2014):\nIt's said that phpunit will not be available via PEAR since December 2014.\nSo it's easy to install it using composer:\ncomposer global require \"phpunit/phpunit=4.1.*\"\n\nUpdate 2019: it should be installed as a local (for your project) development package:\n composer require --dev phpunit/phpunit ^8\n\nUpdate 2020: it should be installed as a local (for your project) development package:\ncomposer require --dev phpunit/phpunit ^9.3\n",
            "\nTry the following instructions:\n\nIn the command prompt, switch to the directory that you installed PHP to by running cd C:\\php\\\nThen install PEAR by running php go-pear.phar\nPress Enter to accept the default when it asks you “Are you installing a system-wide PEAR or a local copy?”\nPress Enter again to accept the file layout.\nPress Enter to finish.\nRun the following commands (they may take a while to update, be patient):\n\npear channel-update pear.php.net\npear upgrade-all\npear channel-discover pear.phpunit.de\npear channel-discover components.ez.no\npear channel-discover pear.symfony-project.com\npear update-channels\n\nClear your pear cache pear clear-cache\nTo install PHPUnit, run pear install --alldeps --force phpunit/PHPUnit\nTo test that PHPUnit was successfully installed, run phpunit -v\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "windows",
            "installation",
            "phpunit"
        ]
    },
    {
        "question_id": "15644697",
        "question": "\nWhen I try to export my database through MySQL Workbench remotely from localserver,\nI am getting some below version error:\n\nmysqldump Version Mismatch  [Content] mysqldump.exe is version 5.5.16, but the MySQL Server to be dumped has version 5.6.10-log. Because the version of mysqldump is older than the server, some features may not be backed up properly. It is recommended you upgrade your local MySQL client programs, including mysqldump to a version equal to or newer than that of the target server. The path to the dump tool must then be set in Preferences -> Administrator -> Path to mysqldump Tool\n\nI am trying to find a solution - I searched for solution on google but couldn't find a good answer to solve the issue.\nDoes anyone know, how to fix this issue in MySQL Workbench?\n",
        "all_answers": [
            "\nGo to: Edit -> Preferences -> Administrator -> Path to Mysqldumptool:\nLook for file mysqldump.exe in your MySQL Server installation folder (it could be: mysql/bin/).\nThen click it, and OK. After that try to do the backup.\n",
            "\nThe message says you need a newer mysqldump tool. One that matches the server you want to dump from. So depending on the platform you are running get a copy of the mysqldump tool from a server installation that has a recent version. Each server comes with a mysqldump tool. So it should be easy to get a copy.\nPut the tool in a location where it has a persistent home, but does not conflict with other instances, and point MySQL Workbench at it (as the message says).\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "mysql",
            "export",
            "mysql-workbench"
        ]
    },
    {
        "question_id": "5600761",
        "question": "\nI know this question has been asked, at least here.\nBut there wasn't a satisfactory answer, at least not to me. There is a lot of talk about marshalling as regards interoperating with unmanaged code, but what about marshalling from one thread to another, as we have to do in .NET sometimes.\nThis makes me ask, what is marshalling, really? When you give a definition of marshalling, how would you define it so that it is explaining the case of interoperability, as well as the cases where you are \"marshalling\" between threads?\n",
        "all_answers": [
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nComputations often need to move data from one site to another, and don't have any shared memory.  So one computation sends a message containing the data to the other. \nHow should that data, if it is arbitrarily complicated, be sent in a message?\nMarshalling is the process of converting a data field, or an entire set of related structures, into a serialized string that can be sent in a message.  To marshall a binary\nnumber, one might convert it to hexadecimal digit string, if the message format must be text.  If the message will carry binary data, the binary number might be converted into 4  little-endian normalized binary bytes and sent that way.   Pointers are harder; one often has to convert them into an abstract reference (e.g., a \"node number\") that is independent of the actual memory locations.\nOf course, if you \"marshall\" data, you must eventually \"unmarshall\", which is the process of reading the serial stream and reconstructing the transmitted data (structure).\nOften there are (un)marshalling routines in a library that are used to accomplish this purpose, and sometimes there are even tools that will manufacture all the calls needed on the (un)marshalling routines to send/recieve the data.\n",
            "\nIt's usually used in the context of \"written in an XML format\" but it could be marshalled to any format.\n2.  To arrange, place, or set in methodical order.\n   (from American Heritage® Dictionary of the English Language)\n\nSo it means you're arranging the data in the methodical order/format you want. Often this is in XML format.\n"
        ],
        "answer": "A4",
        "tags": [
            ".net",
            "multithreading",
            "marshalling",
            "definition",
            "language-interoperability"
        ]
    },
    {
        "question_id": "10183291",
        "question": "\nLet's say my sample URL is\n\nhttp://example.com/one/two\n\nand I say I have the following route\napp.get('/one/two', function (req, res) {\n    var url = req.url;\n}\n\nThe value of url will be /one/two.\nHow do I get the full URL in Express?\nFor example, in the case above, I would like to receive http://example.com/one/two.\n",
        "all_answers": [
            "\n\nThe protocol is available as req.protocol. docs here\n\nBefore express 3.0, the protocol you can assume to be http unless you see that req.get('X-Forwarded-Protocol') is set and has the value https, in which case you know that's your protocol\n\nThe host comes from req.get('host') as Gopal has indicated\nHopefully you don't need a non-standard port in your URLs, but if you did need to know it you'd have it in your application state because it's whatever you passed to app.listen at server startup time. However, in the case of local development on a non-standard port, Chrome seems to include the port in the host header so req.get('host') returns localhost:3000, for example. So at least for the cases of a production site on a standard port and browsing directly to your express app (without reverse proxy), the host header seems to do the right thing regarding the port in the URL.\nThe path comes from req.originalUrl (thanks @pgrassant). Note this DOES include the query string. docs here on req.url and req.originalUrl. Depending on what you intend to do with the URL, originalUrl may or may not be the correct value as compared to req.url.\n\nCombine those all together to reconstruct the absolute URL.\n  var fullUrl = req.protocol + '://' + req.get('host') + req.originalUrl;\n\n",
            "\nYou can also set the path that static files will be served to the web from by specifying an additional (first) parameter to use() like so:\napp.use(\"/public\", express.static(__dirname + \"/public\"));\napp.use(\"/public2\", express.static(__dirname + \"/public2\"));\n\nThat way you get two different directories on the web that mirror your local directories, not one url path that fails over between two local directories.\nIn other words the URL pattern:\nhttp://your.server.com/public/*\n\nServes files from the local directory public while:\nhttp://your.server.com/public2/*\n\nServes files from the local directory public2.\nBTW this is also useful if you don't want static to serve the files from the root of your server but rather from a more qualified path.\nHTH\n",
            "\nYou need to construct it using req.headers.host + req.url.  Of course if you are hosting in a different port and such you get the idea ;-)\n",
            "\nYou can also \"merge\" directories into a single visible directory\nDirectory Structure\n\n/static\n/alternate_static\n\nCode\napp.use(\"/static\", express.static(__dirname + \"/static\"));\napp.use(\"/static\", express.static(__dirname + \"/alternate_static\"));\n\nBoth static and alternate_static will be served as if they were in the same directory. Watch out for filename clobbers, though. \n"
        ],
        "answer": "A1",
        "tags": [
            "node.js",
            "url",
            "express"
        ]
    },
    {
        "question_id": "21334348",
        "question": "\nI'm getting this kind of JSON reply from a curl command:\n[\n  {\n    \"cid\": 49,\n    \"pyn\": \"yi4\",\n    \"hans\": \"亿\",\n    \"hant\": \"億\",\n    \"tid\": 68,\n    \"l10n\": \"cent million\",\n    \"pid\": 1,\n    \"pos\": \"num\",\n    \"pos_txt\": \"\"\n  },\n  {\n    \"cid\": 50,\n    \"pyn\": \"yi4\",\n    \"hans\": \"亿\",\n    \"hant\": \"億\",\n    \"tid\": 69,\n    \"l10n\": \"100 millions\",\n    \"pid\": 1,\n    \"pos\": \"num\",\n    \"pos_txt\": \"\"\n  }\n]\n\nHow can I count the number of items in the array (here 2), using Bash or a command line (e.g. underscore) ?\n",
        "all_answers": [
            "\nJust throwing another solution in the mix...\nTry jq, a lightweight and flexible command-line JSON processor:\njq length /tmp/test.json\n\nPrints the length of the array of objects.\n",
            "\nA simple solution is to install jshon library :\njshon -l < /tmp/test.json\n2\n\n",
            "\nYou are POSTing the json incorrectly -- but even if it were correct, you would not be able to test using print_r($_POST) (read why here).  Instead, on your second page, you can nab the incoming request using file_get_contents(\"php://input\"), which will contain the POSTed json.  To view the received data in a more readable format, try this: \necho '<pre>'.print_r(json_decode(file_get_contents(\"php://input\")),1).'</pre>';\n\nIn your code, you are indicating Content-Type:application/json, but you are not json-encoding all of the POST data -- only the value of the \"customer\" POST field.  Instead, do something like this:\n$ch = curl_init( $url );\n# Setup request to send json via POST.\n$payload = json_encode( array( \"customer\"=> $data ) );\ncurl_setopt( $ch, CURLOPT_POSTFIELDS, $payload );\ncurl_setopt( $ch, CURLOPT_HTTPHEADER, array('Content-Type:application/json'));\n# Return response instead of printing.\ncurl_setopt( $ch, CURLOPT_RETURNTRANSFER, true );\n# Send request.\n$result = curl_exec($ch);\ncurl_close($ch);\n# Print response.\necho \"<pre>$result</pre>\";\n\nSidenote: You might benefit from using a third-party library instead of interfacing with the Shopify API directly yourself.\n",
            "\n$url = 'url_to_post';\n$data = array(\"first_name\" => \"First name\",\"last_name\" => \"last name\",\"email\"=>\"[email protected]\",\"addresses\" => array (\"address1\" => \"some address\" ,\"city\" => \"city\",\"country\" => \"CA\", \"first_name\" =>  \"Mother\",\"last_name\" =>  \"Lastnameson\",\"phone\" => \"555-1212\", \"province\" => \"ON\", \"zip\" => \"123 ABC\" ) );\n\n$postdata = json_encode($data);\n\n$ch = curl_init($url); \ncurl_setopt($ch, CURLOPT_POST, 1);\ncurl_setopt($ch, CURLOPT_POSTFIELDS, $postdata);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, 1); \ncurl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: application/json'));\n$result = curl_exec($ch);\ncurl_close($ch);\nprint_r ($result);\n\nThis code worked for me. You can try...\n"
        ],
        "answer": "A1",
        "tags": [
            "json",
            "bash",
            "curl",
            "jq"
        ]
    },
    {
        "question_id": "36433461",
        "question": "\nI want to be able to execute the command script1 in a project directory that will run node script1.js.\nscript1.js is a file in the same directory.  The command needs to be specific to the project directory, meaning that if I send someone else the project folder, they will be able to run the same command.  \nSo far I've tried adding:\n\"scripts\": {\n    \"script1\": \"node script1.js\"\n}\n\nto my package.json file but when I try running script1 I get the following output:\nzsh: command not found: script1\n\nDoes anyone know the steps necessary to add the script mentioned above to the project folder?\n*Note: the command can not be added to the bash profile (cannot be a machine specific command)\nPlease let me know if you need any clarification. \n",
        "all_answers": [
            "\nSteps are below:\n\nIn package.json add:\n\"bin\":{\n    \"script1\": \"bin/script1.js\" \n}\n\nCreate a bin folder in the project directory and add file runScript1.js with the code:\n#! /usr/bin/env node\nvar shell = require(\"shelljs\");\nshell.exec(\"node step1script.js\");\n\nRun npm install shelljs in terminal\nRun npm link in terminal\nFrom terminal you can now run script1 which will run node script1.js\n\nReference: http://blog.npmjs.org/post/118810260230/building-a-simple-command-line-tool-with-npm\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nI have created the following, and it's working on my system. Please try this:\npackage.json:\n{\n  \"name\": \"test app\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"start\": \"node script1.js\"   \n  }\n}\n\nscript1.js:\nconsole.log('testing')\n\nFrom your command line run the following command:\nnpm start\n\nAdditional use case \nMy package.json file has generally the following scripts, which enable me to watch my files for typescript, sass compilations and running a server as well.\n \"scripts\": {\n    \"start\": \"concurrently \\\"sass --watch ./style/sass:./style/css\\\" \\\"npm run tsc:w\\\" \\\"npm run lite\\\" \",    \n    \"tsc\": \"tsc\",\n    \"tsc:w\": \"tsc -w\", \n    \"lite\": \"lite-server\",\n    \"typings\": \"typings\",\n    \"postinstall\": \"typings install\" \n  }\n\n",
            "\nCustom Scripts\nnpm run-script <custom_script_name>\nor\nnpm run <custom_script_name>\nIn your example, you would want to run npm run-script script1 or npm run script1.\nSee https://docs.npmjs.com/cli/run-script\nLifecycle Scripts\nNode also allows you to run custom scripts for certain lifecycle events, like after npm install is run. These can be found here. \nFor example: \n\"scripts\": {\n    \"postinstall\": \"electron-rebuild\",\n},\n\nThis would run electron-rebuild after a npm install command.\n"
        ],
        "answer": "A4",
        "tags": [
            "javascript",
            "node.js",
            "package.json",
            "run-script"
        ]
    },
    {
        "question_id": "33978",
        "question": "\n\n\n\nHow would you go about finding out how much memory is being used by an object? I know it is possible to find out how much is used by a block of code, but not by an instantiated object (anytime during its life), which is what I want. \n",
        "all_answers": [
            "\nThere's no easy way to find out the memory size of a python object. One of the problems you may find is that Python objects - like lists and dicts - may have references to other python objects (in this case, what would your size be? The size containing the size of each object or not?). There are some pointers overhead and internal structures related to object types and garbage collection. Finally, some python objects have non-obvious behaviors. For instance, lists reserve space for more objects than they have, most of the time; dicts are even more complicated since they can operate in different ways (they have a different implementation for small number of keys and sometimes they over allocate entries).\nThere is a big chunk of code (and an updated big chunk of code) out there to try to best approximate the size of a python object in memory. \nYou may also want to check some old description about PyObject (the internal C struct that represents virtually all python objects).\n",
            "\nUse timeit.default_timer instead of timeit.timeit. The former provides the best clock available on your platform and version of Python automatically:\nfrom timeit import default_timer as timer\n\nstart = timer()\n# ...\nend = timer()\nprint(end - start) # Time in seconds, e.g. 5.38091952400282\n\ntimeit.default_timer is assigned to time.time() or time.clock() depending on OS. On Python 3.3+ default_timer is time.perf_counter() on all platforms. See Python - time.clock() vs. time.time() - accuracy?\nSee also:\n\nOptimizing code\nHow to optimize for speed\n\n",
            "\nUse time.time() to measure the elapsed wall-clock time between two points:\nimport time\n\nstart = time.time()\nprint(\"hello\")\nend = time.time()\nprint(end - start)\n\nThis gives the execution time in seconds.\n\nAnother option since Python 3.3 might be to use perf_counter or process_time, depending on your requirements. Before 3.3 it was recommended to use time.clock (thanks Amber). However, it is currently deprecated:\n\nOn Unix, return the current processor time as a floating point number\nexpressed in seconds. The precision, and in fact the very definition\nof the meaning of “processor time”, depends on that of the C function\nof the same name.\nOn Windows, this function returns wall-clock seconds elapsed since the\nfirst call to this function, as a floating point number, based on the\nWin32 function QueryPerformanceCounter(). The resolution is typically\nbetter than one microsecond.\nDeprecated since version 3.3: The behaviour of this function depends\non the platform: use perf_counter() or process_time() instead,\ndepending on your requirements, to have a well defined behaviour.\n\n",
            "\nI haven't any personal experience with either of the following, but a simple search for a \"Python [memory] profiler\" yield:\n\nPySizer, \"a memory profiler for Python,\" found at http://pysizer.8325.org/.  However the page seems to indicate that the project hasn't been updated for a while, and refers to...\nHeapy, \"support[ing] debugging and optimization regarding memory related issues in Python programs,\" found at http://guppy-pe.sourceforge.net/#Heapy.\n\nHope that helps.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "performance",
            "memory-profiling"
        ]
    },
    {
        "question_id": "8440439",
        "question": "\nI have a gateway script that returns JSON back to the client.\nIn the script I use set_error_handler to catch errors and still have a formatted return.\nIt is subject to 'Allowed memory size exhausted' errors, but rather than increase the memory limit with something like ini_set('memory_limit', '19T'), I just want to return that the user should try something else because it used to much memory.\nAre there any good ways to catch fatal errors?\n",
        "all_answers": [
            "\nyou could get the size of the memory already consumed by the process by using this function memory_get_peak_usage documentations are at http://www.php.net/manual/en/function.memory-get-peak-usage.php I think it would be easier if you could add a condition to redirect or stop the process before the memory limit is almost reached by the process. :)\n",
            "\nAs this answer suggests, you can use register_shutdown_function() to register a callback that'll check error_get_last().\nYou'll still have to manage the output generated from the offending code, whether by the @ (shut up) operator, or ini_set('display_errors', false)\n\nini_set('display_errors', false);\n\nerror_reporting(-1);\n\nset_error_handler(function($code, $string, $file, $line){\n        throw new ErrorException($string, null, $code, $file, $line);\n    });\n\nregister_shutdown_function(function(){\n        $error = error_get_last();\n        if(null !== $error)\n        {\n            echo 'Caught at shutdown';\n        }\n    });\n\ntry\n{\n    while(true)\n    {\n        $data .= str_repeat('#', PHP_INT_MAX);\n    }\n}\ncatch(\\Exception $exception)\n{\n    echo 'Caught in try/catch';\n}\n\nWhen run, this outputs Caught at shutdown. Unfortunately, the ErrorException exception object isn't thrown because the fatal error triggers script termination, subsequently caught only in the shutdown function.\nYou can check the $error array in the shutdown function for details on the cause, and respond accordingly. One suggestion could be reissuing the request back against your web application (at a different address, or with different parameters of course) and return the captured response.\nI recommend keeping error_reporting() high (a value of -1) though, and using (as others have suggested) error handling for everything else with set_error_handler() and ErrorException.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "memory"
        ]
    },
    {
        "question_id": "36337509",
        "question": "\nCan I implement this in Swift with Extensions without the need to inheritance?. \nI get this error \nExtensions May not contain Stored properties\nextension UIButton\n{\n    @IBInspectable var borderWidth : CGFloat\n        {\n        didSet{\n            layer.borderWidth = borderWidth\n        }\n    }\n\n}\n\n",
        "all_answers": [
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nExtensions cannot add stored properties. From the docs (Computed Properties section):\n\nNote\nExtensions can add new computed properties, but they cannot add stored\n  properties, or add property observers to existing properties.\n\nIf you have a need for stored properties, you should create a subclass, like so:\nclass CustomButton : UIButton\n{\n    @IBInspectable var borderWidth : CGFloat\n        {\n        didSet{\n            layer.borderWidth = borderWidth\n        }\n    }\n\n}\n\n",
            "\nYou can override the setter/getter so that it isn't a stored property and just forwards the set/get to the layer.\nextension UIButton {\n    @IBInspectable var borderWidth : CGFloat {\n        set {\n            layer.borderWidth = newValue\n        }\n\n        get {\n            return layer.borderWidth\n        }\n    }\n}\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "swift",
            "inheritance"
        ]
    },
    {
        "question_id": "9887009",
        "question": "\nI have a JSON object which is generated by PHP. It's an object with a set of dates. It has the timeStamp and then a formatted version of the date. How would I iterate through this in jQuery?\n{\n  \"dates\":[\n    {\n      \"timeStamp\": 1317596400,\n      \"formattedDate\": \"Mon 03 October 2011\"\n    },\n    {\n      \"timeStamp\": 1317682800,\n      \"formattedDate\": \"Tue 04 October 2011\"\n    },\n    {\n      \"timeStamp\": 1317855600,\n      \"formattedDate\": \"Thu 06 October 2011\"\n    }\n  ]\n}\n\nI've tried:\nfor (var i in data) { \n  alert(data.dates[i].timeStamp); \n};\n\nfor (var i in data) { \n  alert(data[i].dates.timeStamp); \n};\n\nand\nfor (var i in data) { \n  alert(data.dates.timeStamp[i]); \n};\n\n",
        "all_answers": [
            "\nI dont think youre returning json object from server. just a string.\nyou need the dataType of the return object to be json\n",
            "\nYou use $.each().\nIt looks like this:    \n$.each(data, function(n, elem) {\n    // here you process your data to data loaded to lines               \n});\n\n",
            "\nyou could also change from the .get() method to the .getJSON() method, jQuery will then parse the string returned as data to a javascript object and/or array that you can then reference like any other javascript object/array.\nusing your code above, if you changed .get to .getJSON, you should get an alert of [object Object] for each element in the array. If you changed the alert to alert(item.name) you will get the names.\n",
            "\njQuery.each() is probably the easiest way, check this out: http://api.jquery.com/jQuery.each/\neg \n$.each(dates, function(index, date) { alert(date.timeStamp); });\n\n",
            "\nYou have to parse the string as JSON (data[0] == \"[\" is an indication that data is actually a string, not an object):\ndata = $.parseJSON(data);\n$.each(data, function(i, item) {\n    alert(item);\n});\n\n",
            "\nSince you tagged your question as a jquery one, you should use $.each because it's jquery's iterator function:  \n$.each(data.dates, function(index, element) {\n    alert(element.timeStamp); \n});\n\nIf you want to stick to the for in syntax (which i see you've tried), a solution might be :  \nfor(var key in data.dates) {\n     alert(data.dates[key].timeStamp); \n} \n\nBut beware that the for in syntax may do more than you think it does: it iterates over the properties inherited from the prototype too, so it might be usefull to make sure you iterate only on the object instance properties:  \nfor(var key in data.dates) {\n    // if it's not something from the prototype\n    if(data.dates.hasOwnProperty(key)) {\n        alert(data.dates[key].timeStamp); \n    }\n} \n\nupdate\nAnother elegant way is to use the Object.keys method that returns an array containing all the keys in the targeted object to iterate over all the object's properties:  \nfor(var i=0, keys=Object.keys(data.dates), l=keys.length; i<l; i++) {\n    alert(data.dates[i].timeStamp);\n} \n\n"
        ],
        "answer": "A6",
        "tags": [
            "jquery",
            "json",
            "object",
            "loops"
        ]
    },
    {
        "question_id": "13200511",
        "question": "\nI'd like to generate an SQL Script that contains the SQL to create all of the triggers that exist in our database.  The triggers were added directly via the SSMS query pane so, there is currently no source other than the trigger on the database itself.  \nI have already tried the method where you right-click the database, select Tasks->Generate Scripts and used the \"Script Entire Database and All Objects\" option.  While this does create a SQL script for the tables and constraints, it does not generate SQL for the triggers.  \nI also understand that I can right click on each trigger in the database and select the Generate SQL Script option but, there is currently 46 tables under audit (For Insert, Update, and Delete).  \nRather manually generate an insert, update, and delete trigger script for each of the 46 tables, is there an easier way to do this?  Or, should I start clicking, copying, and pasting?\n",
        "all_answers": [
            "\nfyi The code I ended up with:     \nIF UPDATE (QtyToRepair)\n    begin\n        INSERT INTO tmpQtyToRepairChanges (OrderNo, PartNumber, ModifiedDate, ModifiedUser, ModifiedHost, QtyToRepairOld, QtyToRepairNew)\n        SELECT S.OrderNo, S.PartNumber, GETDATE(), SUSER_NAME(), HOST_NAME(), D.QtyToRepair, I.QtyToRepair FROM SCHEDULE S\n        INNER JOIN Inserted I ON S.OrderNo = I.OrderNo and S.PartNumber = I.PartNumber\n        INNER JOIN Deleted D ON S.OrderNo = D.OrderNo and S.PartNumber = D.PartNumber \n        WHERE I.QtyToRepair <> D.QtyToRepair\nend\n\n",
            "\nHow about this?\nselect text from syscomments where text like '%CREATE TRIGGER%'\nEDIT - per jj's comment below, syscomments is deprecated and will be removed in the future.  Please use either the wizard-based or script-based solutions listed above moving forward :)\n",
            "\nDatabase-> Tasks-> Generate Scripts -> Next -> Next\nOn Choose Script Options UI, under Table/View Options Heading, set Script Triggers to True.\n\n\n",
            "\nYou have two way for your question :\n1- Use Update Command in your Trigger.\nALTER TRIGGER [dbo].[tr_SCHEDULE_Modified]\n   ON [dbo].[SCHEDULE]\n   AFTER UPDATE\nAS BEGIN\n    SET NOCOUNT ON;\n    IF UPDATE (QtyToRepair) \n    BEGIN\n        UPDATE SCHEDULE \n        SET modified = GETDATE()\n           , ModifiedUser = SUSER_NAME()\n           , ModifiedHost = HOST_NAME()\n        FROM SCHEDULE S INNER JOIN Inserted I \n        ON S.OrderNo = I.OrderNo and S.PartNumber = I.PartNumber\n        WHERE S.QtyToRepair <> I.QtyToRepair\n    END \nEND\n\n2- Use Join between Inserted table and deleted table\nALTER TRIGGER [dbo].[tr_SCHEDULE_Modified]\n   ON [dbo].[SCHEDULE]\n   AFTER UPDATE\nAS BEGIN\n    SET NOCOUNT ON;    \n\n    UPDATE SCHEDULE \n    SET modified = GETDATE()\n       , ModifiedUser = SUSER_NAME()\n       , ModifiedHost = HOST_NAME()\n    FROM SCHEDULE S \n    INNER JOIN Inserted I ON S.OrderNo = I.OrderNo and S.PartNumber = I.PartNumber\n    INNER JOIN Deleted D ON S.OrderNo = D.OrderNo and S.PartNumber = D.PartNumber                  \n    WHERE S.QtyToRepair <> I.QtyToRepair\n    AND D.QtyToRepair <> I.QtyToRepair\nEND\n\nWhen you use update command for table SCHEDULE and Set QtyToRepair Column to new value, if new value equal to old value in one or multi row, solution 1 update all updated row in Schedule table but solution 2 update only schedule rows that old value not equal to new value.\n"
        ],
        "answer": "A3",
        "tags": [
            "sql",
            "sql-server-2008",
            "triggers"
        ]
    },
    {
        "question_id": "5781597",
        "question": "\nWhy does this line give the error Error: incomplete type is not allowed?\nstringstream ss;\n\n",
        "all_answers": [
            "\nBy definition, size_t is the result of the sizeof operator. size_t was created to refer to sizes.\nThe number of times you do something (10, in your example) is not about sizes, so why use size_t? int, or unsigned int, should be ok.\nOf course it is also relevant what you do with i inside the loop. If you pass it to a function which takes an unsigned int, for example, pick unsigned int.\nIn any case, I recommend to avoid implicit type conversions. Make all type conversions explicit.\n",
            "\n#include <sstream> and use the fully qualified name  i.e. std::stringstream ss;\n",
            "\nSome of the system headers provide a forward declaration of std::stringstream without the definition. This makes it an 'incomplete type'. To fix that you need to include the definition, which is provided in the <sstream> header:\n#include <sstream>\n\n",
            "\nA good rule of thumb is for anything that you need to compare in the loop condition against something that is naturally a std::size_t itself.\nstd::size_t is the type of any sizeof expression and as is guaranteed to be able to express the maximum size of any object (including any array) in C++. By extension it is also guaranteed to be big enough for any array index so it is a natural type for a loop by index over an array.\nIf you are just counting up to a number then it may be more natural to use either the type of the variable that holds that number or an int or unsigned int (if large enough) as these should be a natural size for the machine.\n",
            "\nThe size_t type is meant to specify the size of something so it's natural to use it, for example, getting the length of a string and then processing each character:\nfor (size_t i = 0, max = strlen (str); i < max; i++)\n    doSomethingWith (str[i]);\n\nYou do have to watch out for boundary conditions of course, since it's an unsigned type. The boundary at the top end is not usually that important since the maximum is usually large (though it is possible to get there). Most people just use an int for that sort of thing because they rarely have structures or arrays that get big enough to exceed the capacity of that int.\nBut watch out for things like:\nfor (size_t i = strlen (str) - 1; i >= 0; i--)\n\nwhich will cause an infinite loop due to the wrapping behaviour of unsigned values (although I've seen compilers warn against this). This can also be alleviated by the (slightly harder to understand but at least immune to wrapping problems):\nfor (size_t i = strlen (str); i-- > 0; )\n\nBy shifting the decrement into a post-check side-effect of the continuation condition, this does the check for continuation on the value before decrement, but still uses the decremented value inside the loop (which is why the loop runs from len .. 1 rather than len-1 .. 0).\n",
            "\nsize_t is the result type of the sizeof operator.\nUse size_t for variables that model size or index in an array. size_t conveys semantics: you immediately know it represents a size in bytes or an index, rather than just another integer.\nAlso, using size_t to represent a size in bytes helps making the code portable.\n"
        ],
        "answer": "A2",
        "tags": [
            "c++",
            "types",
            "stringstream"
        ]
    },
    {
        "question_id": "1812891",
        "question": "\nI'm trying to put some anti sql injection in place in java and am finding it very difficult to work with the the \"replaceAll\" string function. Ultimately I need a function that will convert any existing \\ to \\\\, any \" to \\\", any ' to \\', and any \\n to \\\\n so that when the string is evaluated by MySQL SQL injections will be blocked. \nI've jacked up some code I was working with and all the \\\\\\\\\\\\\\\\\\\\\\ in the function are making my eyes go nuts. If anyone happens to have an example of this I would greatly appreciate it.\n",
        "all_answers": [
            "\nUsing a regular expression to remove text which could cause a SQL injection sounds like the SQL statement is being sent to the database via a Statement rather than a PreparedStatement.\nOne of the easiest ways to prevent an SQL injection in the first place is to use a PreparedStatement, which accepts data to substitute into a SQL statement using placeholders, which does not rely on string concatenations to create an SQL statement to send to the database.\nFor more information, Using Prepared Statements from The Java Tutorials would be a good place to start.\n",
            "\n~ is the regular expression operator, and has the capabilities implied by that.  You can specify a full range of regular expression wildcards and quantifiers; see the documentation for details.  It is certainly more powerful than LIKE, and should be used when that power is needed, but they serve different purposes.\n",
            "\nPreparedStatements are the way to go, because they make SQL injection impossible.  Here's a simple example taking the user's input as the parameters:\npublic insertUser(String name, String email) {\n   Connection conn = null;\n   PreparedStatement stmt = null;\n   try {\n      conn = setupTheDatabaseConnectionSomehow();\n      stmt = conn.prepareStatement(\"INSERT INTO person (name, email) values (?, ?)\");\n      stmt.setString(1, name);\n      stmt.setString(2, email);\n      stmt.executeUpdate();\n   }\n   finally {\n      try {\n         if (stmt != null) { stmt.close(); }\n      }\n      catch (Exception e) {\n         // log this error\n      }\n      try {\n         if (conn != null) { conn.close(); }\n      }\n      catch (Exception e) {\n         // log this error\n      }\n   }\n}\n\nNo matter what characters are in name and email, those characters will be placed directly in the database.  They won't affect the INSERT statement in any way.\nThere are different set methods for different data types -- which one you use depends on what your database fields are.  For example, if you have an INTEGER column in the database, you should use a setInt method.  The PreparedStatement documentation lists all the different methods available for setting and getting data.\n",
            "\nThe only way to prevent SQL injection is with parameterized SQL. It simply isn't possible to build a filter that's smarter than the people who hack SQL for a living.\nSo use parameters for all input, updates, and where clauses. Dynamic SQL is simply an open door for hackers, and that includes dynamic SQL in stored procedures. Parameterize, parameterize, parameterize.\n"
        ],
        "answer": "A3",
        "tags": [
            "java",
            "sql",
            "regex",
            "escaping",
            "sql-injection"
        ]
    },
    {
        "question_id": "15306897",
        "question": "\nI have a venue, this venue has many events happening there. My models look like this:\nclass Venue(models.Model):\n    title = models.CharField(max_length=200)\n    date_published = models.DateTimeField('published date',default=datetime.now, blank=True)\n    venue_latitude = models.CharField(max_length=200)\n    venue_longitude = models.CharField(max_length=200)\n    venue_address = models.CharField(max_length=200)\n    venue_city = models.CharField(max_length=200)\n    venue_state = models.CharField(max_length=200)\n    venue_country = models.CharField(max_length=200)\n    description = models.TextField()\n    def __unicode__(self):\n        return u'%s' % (self.title)\n\nclass Event(models.Model):\n    title = models.CharField(max_length=200)\n    date_published = models.DateTimeField('published date',default=datetime.now, blank=True)\n    date_start = models.DateTimeField('start date')\n    date_end = models.DateTimeField('end date')\n    def __unicode__(self):\n        return self.title\n    description = models.TextField()\n    price = models.IntegerField(null=True, blank=True)\n    venue = models.ForeignKey(Venue)\n\nI'd like to display all the events that are happening at a certain venue. How can I do that? My current view looks like:\ndef detail(request, venue_id):\n    venue = get_object_or_404(Venue, pk=venue_id)\n    return render(request, 'venue-detail.html', {'venue': venue})\n\n",
        "all_answers": [
            "\nYou can use events = venue.event_set to go the other way.\nNote that venue.event_set is a manager object, like Event.objects, so you can call .all, .filter, .exclude and similar on it to get a queryset.\nSee the Django documentation\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nGo the other way round. Use Event model.\ndef detail(request, venue_id):\n    venue = Event.objects.filter(venue__id=venue_id)\n    return render(request, 'venue-detail.html', {'venue': venue})\n\nPS: I have never used get_object_or_404(). Modify code accordingly.\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django",
            "django-models",
            "django-views",
            "reverse-foreign-key"
        ]
    },
    {
        "question_id": "15189937",
        "question": "\nI'm trying to run a query of about 50,000 records using ActiveRecord's find_each method, but it seems to be ignoring my other parameters like so:\nThing.active.order(\"created_at DESC\").limit(50000).find_each {|t| puts t.id }\n\nInstead of stopping at 50,000 I'd like and sorting by created_at, here's the resulting query that gets executed over the entire dataset:\nThing Load (198.8ms)  SELECT \"things\".* FROM \"things\" WHERE \"things\".\"active\" = 't' AND (\"things\".\"id\" > 373343) ORDER BY \"things\".\"id\" ASC LIMIT 1000\n\nIs there a way to get similar behavior to find_each but with a total max limit and respecting my sort criteria?\n",
        "all_answers": [
            "\nfind_each uses find_in_batches under the hood.\nIts not possible to select the order of the records, as described in find_in_batches, is automatically set to ascending on the primary key (“id ASC”) to make the batch ordering work.\nHowever, the criteria is applied, what you can do is:\nThing.active.find_each(batch_size: 50000) { |t| puts t.id }\n\nRegarding the limit, it wasn't implemented yet:  https://github.com/rails/rails/pull/5696\n\nAnswering to your second question, you can create the logic yourself:\ntotal_records = 50000\nbatch = 1000\n(0..(total_records - batch)).step(batch) do |i|\n  puts Thing.active.order(\"created_at DESC\").offset(i).limit(batch).to_sql\nend\n\n",
            "\nThe documentation says that find_each and find_in_batches don't retain sort order and limit because:\n\nSorting ASC on the PK is used to make the batch ordering work.\nLimit is used to control the batch sizes.\n\nYou could write your own version of this function like @rorra did. But you can get into trouble when mutating the objects. If for example you sort by created_at and save the object it might come up again in one of the next batches. Similarly you might skip objects because the order of results has changed when executing the query to get the next batch. Only use that solution with read only objects.\nNow my primary concern was that I didn't want to load 30000+ objects into memory at once. My concern was not the execution time of the query itself. Therefore I used a solution that executes the original query but only caches the ID's. It then divides the array of ID's into chunks and queries/creates the objects per chunk. This way you can safely mutate the objects because the sort order is kept in memory.\nHere is a minimal example similar to what I did:\nbatch_size = 512\nids = Thing.order('created_at DESC').pluck(:id) # Replace .order(:created_at) with your own scope\nids.each_slice(batch_size) do |chunk|\n    Thing.find(chunk, :order => \"field(id, #{chunk.join(',')})\").each do |thing|\n      # Do things with thing\n    end\nend\n\nThe trade-offs to this solution are:\n\nThe complete query is executed to get the ID's\nAn array of all the ID's is kept in memory\nUses the MySQL specific FIELD() function\n\nHope this helps!\n",
            "\nYou can try this\nUser.find(:all, limit: 10,\n            joins:  \"LEFT JOIN `user_points` ON user_points.user_id = users.id\" ,\n            select: \"users.*, count(user_points.id)\", \n            group:  \"user_points.user_id\")\n\n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "ruby-on-rails",
            "activerecord"
        ]
    },
    {
        "question_id": "20081924",
        "question": "\nI am doing the following:\nmodel._meta.get_field('g').get_internal_type\n\nWhich returns the following:\n<bound method URLField.get_internal_type of <django.db.models.fields.URLField: g>>\n\nI only want the know that this field is \"URLField\" .  How do I extract that from this output?\nNote: I am doing this so that I can do validation on the fields. For example if a url , I want to check if it is well formed. \n",
        "all_answers": [
            "\nIf you were doing this:\nmodel._meta.get_field('g').get_internal_type()\n\nYou could not possibly get that as a result.\nInstead, you are doing this:\nmodel._meta.get_field('g').get_internal_type\n\nWhich, as explained here, does not call the method, it just refers to the method as a bound method object. The return value is not part of that bound method object, it's created by the method when the method is called. So, you have to call it. So you need the parentheses.\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nThe answer is to call the method instead:\nmy_type = field.get_internal_type()\n\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django",
            "django-models"
        ]
    },
    {
        "question_id": "4804581",
        "question": "\nI have the page structure as:\n<div class=\"parent\">\n    <div class=\"child-left floatLeft\">\n    </div>\n\n    <div class=\"child-right floatLeft\">\n    </div>\n</div>\n\nNow, the child-left DIV will have more content, so the parent DIV's height increases as per the child DIV. \nBut the problem is child-right height is not increasing. How can I make its height as equal to it's parent?\n",
        "all_answers": [
            "\nI have recently done this on my website using jQuery.  The code calculates the height of the tallest div and sets the other divs to the same height.  Here's the technique:\nhttp://www.broken-links.com/2009/01/20/very-quick-equal-height-columns-in-jquery/\nI don't believe height:100% will work, so if you don't explicitly know the div heights I don't think there is a pure CSS solution.\n",
            "\nSimply put all the images thumbnails inside a row/col divs like this:\n<div class=\"row text-center\">\n <div class=\"col-12\">\n  # your images here...\n </div>\n</div>\n\nand everything will work fine!\n",
            "\nIf you're using Bootstrap v3.0.1 or greater, you should use this solution instead. It doesn't override Bootstrap's styles with custom CSS, but instead uses a Bootstrap feature.\nMy original answer is shown below for posterity\n\nThis is a pleasantly easy fix. Because .img-responsive from Bootstrap already sets display: block, you can use margin: 0 auto to center the image:\n.product .img-responsive {\n    margin: 0 auto;\n}\n\n",
            "\nThere is .center-block class in Twitter Bootstrap 3 (Since v3.0.1), so use:\n<img src=\"...\" alt=\"...\" class=\"img-responsive center-block\" />\n\n",
            "\nThis should center the image and make it responsive.\n<img src=\"...\" class=\"img-responsive\" style=\"margin:0 auto;\"/>\n\n",
            "\nFor the parent element, add the following properties:\n.parent {\n    overflow: hidden;\n    position: relative;\n    width: 100%;\n}\n\nthen for .child-right these: \n.child-right {\n    background:green;\n    height: 100%;\n    width: 50%;\n    position: absolute;\n    right: 0;\n    top: 0;\n}\n\nFind more detailed results with CSS examples here and more information about equal height columns here.\n",
            "\nJust use .text-center class if you're using Bootstrap 3.\n<div class=\"text-center\">\n    <img src=\"...\" alt=\"...\"/>\n</div>\n\nNote: This doesn't work with img-responsive\n",
            "\nAdd only the class center-block to an image, this works with Bootstrap 4 as well:\n<img src=\"...\" alt=\"...\" class=\"center-block\" />\n\nNote: center-block works even when img-responsive is used\n",
            "\nDoes the parent have a height? If you set the parents height like so.\ndiv.parent { height: 300px };\n\nThen you can make the child stretch to the full height like this.\ndiv.child-right { height: 100% };\n\nEDIT\nHere is how you would do it using JavaScript.\n",
            "\nI would suggest a more \"abstract\" classification. Add a new class \"img-center\" which can be used in combination with .img-responsive class:\n// Center responsive images\n.img-responsive.img-center {\n  margin: 0 auto;\n}\n\n"
        ],
        "answer": "A6",
        "tags": [
            "html",
            "css",
            "layout"
        ]
    },
    {
        "question_id": "3654295",
        "question": "\nSome elements in my array are empty strings from users. $linksArray still has empty elements after the following:\nforeach($linksArray as $link)\n{\n    if($link == '')\n    {\n        unset($link);\n    }\n}\nprint_r($linksArray);\n\nThe empty() function doesn't work either.\n",
        "all_answers": [
            "\nAs you're dealing with an array of strings, you can simply use array_filter(), which conveniently handles all this for you:\n$linksArray = array_filter($linksArray);\n\nKeep in mind that if no callback is supplied, all entries of array equal to FALSE (see converting to boolean) will be removed. So if you need to preserve elements that are i.e. exact string '0', you will need a custom callback:\n// PHP 7.4 and later\nprint_r(array_filter($linksArray, fn($value) => !is_null($value) && $value !== ''));\n\n// PHP 5.3 and later\nprint_r(array_filter($linksArray, function($value) { return !is_null($value) && $value !== ''; }));\n\n// PHP < 5.3\nprint_r(array_filter($linksArray, create_function('$value', 'return $value !== \"\";')));\n\n\nNote: If you need to reindex the array after removing the empty elements, use:\n$linksArray = array_values(array_filter($linksArray));\n\n",
            "\n$arraysAreEqual = ($a == $b); // TRUE if $a and $b have the same key/value pairs.\n$arraysAreEqual = ($a === $b); // TRUE if $a and $b have the same key/value pairs in the same order and of the same types.\n\nSee Array Operators.\nEDIT\nThe inequality operator is != while the non-identity operator is !== to match the equality \noperator == and the identity operator ===.\n",
            "\nShort solution that works even with arrays which keys are given in different order:\npublic static function arrays_are_equal($array1, $array2)\n{\n    array_multisort($array1);\n    array_multisort($array2);\n    return ( serialize($array1) === serialize($array2) );\n}\n\n",
            "\nAccording to this page.\nNOTE: The accepted answer works for associative arrays, but it will not work as expected with indexed arrays (explained below). If you want to compare either of them, then use this solution. Also, this function may not works with multidimensional arrays (due to the nature of array_diff function).\nTesting two indexed arrays, which elements are in different order, using $a == $b or $a === $b fails, for example:\n<?php\n    (array(\"x\",\"y\") == array(\"y\",\"x\")) === false;\n?>\n\nThat is because the above means:\narray(0 => \"x\", 1 => \"y\") vs. array(0 => \"y\", 1 => \"x\").\nTo solve that issue, use:\n<?php\nfunction array_equal($a, $b) {\n    return (\n         is_array($a) \n         && is_array($b) \n         && count($a) == count($b) \n         && array_diff($a, $b) === array_diff($b, $a)\n    );\n}\n?>\n\nComparing array sizes was added (suggested by super_ton) as it may improve speed.\n",
            "\nTry serialize. This will check nested subarrays as well.\n$foo =serialize($array_foo);\n$bar =serialize($array_bar);\nif ($foo == $bar) echo \"Foo and bar are equal\";\n\n",
            "\nforeach($linksArray as $key => $link) \n{ \n    if($link === '') \n    { \n        unset($linksArray[$key]); \n    } \n} \nprint_r($linksArray); \n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "arrays",
            "string"
        ]
    },
    {
        "question_id": "5098558",
        "question": "\nThe code\nfloat x  = 3.141592653589793238;\ndouble z = 3.141592653589793238;\nprintf(\"x=%f\\n\", x);\nprintf(\"z=%f\\n\", z);\nprintf(\"x=%20.18f\\n\", x);\nprintf(\"z=%20.18f\\n\", z);\n\nwill give you the output\nx=3.141593\nz=3.141593\nx=3.141592741012573242\nz=3.141592653589793116\n\nwhere on the third line of output 741012573242 is garbage and on the fourth line 116 is garbage. Do doubles always have 16 significant figures while floats always have 7 significant figures? Why don't doubles have 14 significant figures?\n",
        "all_answers": [
            "\nFloating point numbers in C use IEEE 754 encoding.\nThis type of encoding uses a sign, a significand, and an exponent.\nBecause of this encoding, many numbers will have small changes to allow them to be stored.\nAlso, the number of significant digits can change slightly since it is a binary representation, not a decimal one.\nSingle precision (float) gives you 23 bits of significand, 8 bits of exponent, and 1 sign bit.\nDouble precision (double) gives you 52 bits of significand, 11 bits of exponent, and 1 sign bit.\n",
            "\nIt's usually based on significant figures of both the exponent and significand in base 2, not base 10. From what I can tell in the C99 standard, however, there is no specified precision for floats and doubles (other than the fact that 1 and 1 + 1E-5 / 1 + 1E-7 are distinguishable [float and double repsectively]). However, the number of significant figures is left to the implementer (as well as which base they use internally, so in other words, an implementation could decide to make it based on 18 digits of precision in base 3). [1]\nIf you need to know these values, the constants FLT_RADIX and FLT_MANT_DIG (and DBL_MANT_DIG / LDBL_MANT_DIG) are defined in float.h.\nThe reason it's called a double is because the number of bytes used to store it is double the number of a float (but this includes both the exponent and significand). The IEEE 754 standard (used by most compilers) allocate relatively more bits for the significand than the exponent (23 to 9 for float vs. 52 to 12 for double), which is why the precision is more than doubled.\n1: Section 5.2.4.2.2 ( http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf )\n",
            "\nFFCALL lets you build closures in C -- callback = alloc_callback(&function, data) returns a function pointer such that callback(arg1, ...) is equivalent to calling function(data, arg1, ...).  You will have to handle garbage collection manually, though.\nRelatedly, blocks have been added to Apple's fork of GCC; they're not function pointers, but they let you pass around lambdas while avoiding the need to build and free storage for captured variables by hand (effectively, some copying and reference counting happens, hidden behind some syntactic sugar and runtime libraries).\n",
            "\nYou can use GCC's nested functions to simulate lambda expressions, in fact, I have a macro to do it for me:\n#define lambda(return_type, function_body) \\\n  ({ \\\n    return_type anon_func_name_ function_body \\\n    anon_func_name_; \\\n  })\n\nUse like this:\nint (*max)(int, int) = lambda (int, (int x, int y) { return x > y ? x : y; });\n\n"
        ],
        "answer": "A1",
        "tags": [
            "c",
            "floating-point"
        ]
    },
    {
        "question_id": "2668678",
        "question": "\nI'm working on a feature to export search results to a CSV file to be opened in Excel.  One of the fields is a free-text field, which may contain line breaks, commas, quotations, etc.  In order to counteract this, I have wrapped the field in double quotes (\").\nHowever, when I import the data into Excel 2007, set the appropriate delimiter, and set the text qualifier to double quote, the line breaks are still creating new records at the line breaks, where I would expect to see the entire text field in a single cell.\nI've also tried replacing CR/LF (\\r\\n) with just CR (\\r), and again with just LF (\\n), but no luck.\nHas anyone else encountered this behavior, and if so, how did you fix it?\nTIA,\n-J\nEDIT:\nHere's a quick file I wrote by hand to duplicate the problem.\n\nID,Name,Description\n  \"12345\",\"Smith, Joe\",\"Hey.\n  My name is Joe.\"\n\nWhen I import this into Excel 2007, I end up with a header row, and two records.  Note that the comma in \"Smith, Joe\" is being handled properly.  It's just the line breaks that are causing problems.\n",
        "all_answers": [
            "\nFor second accuracy, yyyy-MM-dd HH:mm:ss should do the trick.\nI believe Excel is not very good with fractions of a second (loses them when interacting with COM object IIRC).\n",
            "\nI have finally found the problem!\nIt turns out that we were writing the file using Unicode encoding, rather than ASCII or UTF-8.  Changing the encoding on the FileStream seems to solve the problem.\nThanks everyone for all your suggestions!\n",
            "\nIf the field contains a leading space, Excel ignores the double quote as a text qualifier.  The solution is to eliminate leading spaces between the comma (field separator) and double-quote.  For example:\nBroken:\n  Name,Title,Description \n  \"John\", \"Mr.\", \"My detailed description\"\nWorking:\n  Name,Title,Description\n  \"John\",\"Mr.\",\"My detailed description\"\n"
        ],
        "answer": "A2",
        "tags": [
            "excel",
            "csv",
            "newline",
            "excel-2007"
        ]
    },
    {
        "question_id": "21237905",
        "question": "\nMy program needs to generate many random integers in some range (int min, int max). Each call will have a different range. What is a good (preferably thread-safe) way to do this? The following is not thread-safe (and uses rand(), which people seem to discourage):\nint intRand(const int & min, const int & max)\n{\n    return (rand() % (max+1-min)) + min;\n}\n\nThis is much slower, but uses <random>:\nint intRand(const int & min, const int & max) {\n    std::default_random_engine generator;\n    std::uniform_int_distribution<int> distribution(min,max);\n    return distribution(generator);\n}\n\nSomething like this is what I'm going for (the changeParameters function doesn't exist though):\nint intRand(const int & min, const int & max) {\n    static std::default_random_engine generator;\n    static std::uniform_int_distribution<int> distribution(0, 10);\n    distribution.changeParameters(min, max);\n    return distribution(generator);\n}\n\nAnother option would be to make a wide range on the uniform_int_distribution and then use mod like in the first example. However, I'm doing statistical work, so I want the numbers to come from as unbiased of a distribution as possible (e.g., if the range of the distribution used is not a multiple of (max-min), the distribution will be slightly biased). This is an option, but again, I would like to avoid it.\nSOLUTION This solution comes from the answers by @konrad-rudolph @mark-ransom and @mathk . The seeding of the random number generator is done to suit my particular needs. A more common approach would be to use time(NULL). If you make many threads in the same second, they would then get the same seed though. Even with clock() this is an issue, so we include the thread id. A drawback - this leaks memory --- one generator per thread.\n#if defined (_MSC_VER)  // Visual studio\n    #define thread_local __declspec( thread )\n#elif defined (__GCC__) // GCC\n    #define thread_local __thread\n#endif\n\n#include <random>\n#include <time.h>\n#include <thread>\n\nusing namespace std;\n\n/* Thread-safe function that returns a random number between min and max (inclusive).\nThis function takes ~142% the time that calling rand() would take. For this extra\ncost you get a better uniform distribution and thread-safety. */\nint intRand(const int & min, const int & max) {\n    static thread_local mt19937* generator = nullptr;\n    if (!generator) generator = new mt19937(clock() + this_thread::get_id().hash());\n    uniform_int_distribution<int> distribution(min, max);\n    return distribution(*generator);\n}\n\n",
        "all_answers": [
            "\nYou can use one default_random_engine per thread using Thread Local Storage.\nI can not tell you how to correctly use TLS since it is OS dependent. The best source you can use is to search through the internet.\n",
            "\nGCC Atomic Built-ins\n",
            "\nHave you tried this?\nint intRand(const int & min, const int & max) {\n    static thread_local std::mt19937 generator;\n    std::uniform_int_distribution<int> distribution(min,max);\n    return distribution(generator);\n}\n\nDistributions are extremely cheap (they will be completely inlined by the optimiser so that the only remaining overhead is the actual random number rescaling). Don’t be afraid to regenerate them as often as you need – in fact, resetting them would conceptually be no cheaper (which is why that operation doesn’t exist).\nThe actual random number generator, on the other hand, is a heavy-weight object carrying a lot of state and requiring quite some time to be constructed, so that should only be initialised once per thread (or even across threads, but then you’d need to synchronise access which is more costly in the long run).\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "multithreading",
            "random"
        ]
    },
    {
        "question_id": "6393632",
        "question": "\nIs there a way in jQuery where I can hide an element, but not change the DOM when it's hidden? I'm hiding a certain element but when it's hidden, the elements below it move up. I don't want that to happen. I want the space to stay the same, but the element to be shown/hidden at will.\nCan I do this?\n",
        "all_answers": [
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nTry setting the visibility to hidden:\n$(\"#id\").css(\"visibility\", \"hidden\");\n\n",
            "\nInstead of hide(), use:\ncss('visibility','hidden')\n\nhide() sets the display style to none, which completely removes the element from the document flow and causes it to not take up space.\nvisibility:hidden keeps the space as it is.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nAs of Feb. 2016, CSS 3 has the support mentioned below. Here is a snippet from a WooCommerce's single product page with price discount\n/*Price before discount on single product page*/\nbody.single-product .price del .amount {\ncolor:           hsl(0, 90%, 65%);\nfont-size:       15px;\ntext-decoration: line-through;\n/*noinspection CssOverwrittenProperties*/\ntext-decoration: white double line-through; /* Ignored in CSS1/CSS2 UAs */\n}\n\nResulting in:\n\n\nCSS 3 will likely have direct support using the text-decoration-color property. In particular:\n\nThe text-decoration-color CSS property sets the color used when drawing underlines, overlines, or strike-throughs specified by text-decoration-line. This is the preferred way to color these text decorations, rather than using combinations of other HTML elements.\n\nAlso see text-decoration-color in the CSS 3 draft spec.\nIf you want to use this method immediately, you probably have to prefix it, using -moz-text-decoration-color. (Also specify it without -moz-, for forward-compatibility.)\n"
        ],
        "answer": "A4",
        "tags": [
            "jquery",
            "html"
        ]
    },
    {
        "question_id": "13628791",
        "question": "\nHow do I determine whether a given integer is between two other integers (e.g. greater than/equal to 10000 and less than/equal to 30000)?\n",
        "all_answers": [
            "\nif 10000 <= number <= 30000:\n    pass\n\nFor details, see the docs.\n",
            "\nif number >= 10000 and number <= 30000:\n    print (\"you have to pay 5% taxes\")\n\n",
            "\nUse if number >= 10000 and number <= 30000:.  Alternately, Python has a shorthand for this sort of thing, if 10000 <= number <= 30000:.\n"
        ],
        "answer": "A1",
        "tags": [
            "python"
        ]
    },
    {
        "question_id": "44045311",
        "question": "\nI made an enum with Typescript to use in MyService.service.ts MyComponent.component.ts and MyComponent.component.html. \nexport enum ConnectionResult {\n    Success,\n    Failed     \n}\n\nI can easily get and compare a defined enum variable from MyService.service.ts:\nthis.result = this.myService.getConnectionResult();\n\nswitch(this.result)  \n{\n    case ConnectionResult.Failed:\n         doSomething();\n         break;\n    case ConnectionResult.Success:\n         doSomething();\n         break;\n}\n\nI also wanted to use the enum for a comparison within my HTML using the *ngIf statement:\n<div *ngIf=\"result == ConnectionResult.Success; else failed\">\n            <img src=\"../../assets/connection-success.png\" height=\"300px\" class=\"image-sign-style\" />\n</div>\n<ng-template #failed>\n       <img src=\"../../assets/connection-failed.png\" height=\"300px\" class=\"image-sign-style\" />\n</ng-template>\n\nThe code compiles but the browser gives me an error:\n\nCannot read property of undefined\n\n\nWith the following html indication error line:\n\nDoes anyone know why the enum cannot be approached like this?\n",
        "all_answers": [
            "\n(change) event bound to classical input change event. \nhttps://developer.mozilla.org/en-US/docs/Web/Events/change\nYou can use (change) event even if you don't have a model at your input as\n<input (change)=\"somethingChanged()\">\n\n(ngModelChange) is the @Output of ngModel directive. It fires when the model changes. You cannot use this event without ngModel directive. \nhttps://github.com/angular/angular/blob/master/packages/forms/src/directives/ng_model.ts#L124\nAs you discover more in the source code, (ngModelChange) emits the new value.\nhttps://github.com/angular/angular/blob/master/packages/forms/src/directives/ng_model.ts#L169\nSo it means you have ability of such usage:\n<input (ngModelChange)=\"modelChanged($event)\">\n\nmodelChanged(newObj) {\n    // do something with new value\n}\n\nBasically, it seems like there is no big difference between two, but ngModel events gains the power when you use [ngValue]. \n  <select [(ngModel)]=\"data\" (ngModelChange)=\"dataChanged($event)\" name=\"data\">\n      <option *ngFor=\"let currentData of allData\" [ngValue]=\"currentData\">\n          {{data.name}}\n      </option>\n  </select>\n\ndataChanged(newObj) {\n    // here comes the object as parameter\n}\n\nassume you try the same thing without \"ngModel things\"\n<select (change)=\"changed($event)\">\n    <option *ngFor=\"let currentData of allData\" [value]=\"currentData.id\">\n        {{data.name}}\n    </option>\n</select>\n\nchanged(e){\n    // event comes as parameter, you'll have to find selectedData manually\n    // by using e.target.data\n}\n\n",
            "\nYou will have to write it in the following way in .ts file.\nenum Tenure { day, week, all }\n\nexport class AppComponent {\n    tenure = Tenure.day\n    TenureType = Tenure\n}\n\nAnd now in html you can use this like\n*ngIf = \"tenure == TenureType.day ? selectedStyle : unSelectedStyle\"\n\nI hope it is more clear now. :)\n",
            "\nThe scope of the template is limited to the component instance members.\nIf you want to refer to something it needs to be available there\nclass MyComponent {\n  public get connectionResult(): typeof ConnectionResult {\n    return ConnectionResult; \n  }\n}\n\nIn the HTML you can now use\n*ngIf=\"connectionResult.Success\"\n\nSee also Angular2 access global variables from HTML template\n"
        ],
        "answer": "A2",
        "tags": [
            "html",
            "angular",
            "typescript",
            "enums"
        ]
    },
    {
        "question_id": "548063",
        "question": "\nAfter opening a pipe to a process with popen, is there a way to kill the process that has been started? (Using pclose is not what I want because that will wait for the process to finish, but I need to kill it.)\n",
        "all_answers": [
            "\nDon't use popen(), write your own wrapper that does what you'd like. \nIt's fairly straightforward to fork(), and then replace stdin & stdout\nby using dup2(), and then calling exec() on your child.\nThat way, your parent will have the exact child PID, and you can use\nkill() on that.\nGoogle search for \"popen2() implementation\" for some sample code on\nhow to implement what popen() is doing. It's only a dozen or so lines\nlong.  Taken from dzone.com we can see\nan example that looks like this:\n#define READ 0\n#define WRITE 1\n\npid_t\npopen2(const char *command, int *infp, int *outfp)\n{\n    int p_stdin[2], p_stdout[2];\n    pid_t pid;\n\n    if (pipe(p_stdin) != 0 || pipe(p_stdout) != 0)\n        return -1;\n\n    pid = fork();\n\n    if (pid < 0)\n        return pid;\n    else if (pid == 0)\n    {\n        close(p_stdin[WRITE]);\n        dup2(p_stdin[READ], READ);\n        close(p_stdout[READ]);\n        dup2(p_stdout[WRITE], WRITE);\n\n        execl(\"/bin/sh\", \"sh\", \"-c\", command, NULL);\n        perror(\"execl\");\n        exit(1);\n    }\n\n    if (infp == NULL)\n        close(p_stdin[WRITE]);\n    else\n        *infp = p_stdin[WRITE];\n\n    if (outfp == NULL)\n        close(p_stdout[READ]);\n    else\n        *outfp = p_stdout[READ];\n\n    return pid;\n}\n\nNB: Seems like popen2() is what you want, but my distribution doesn't seem to come with this method. \n",
            "\nThis file is missing. http://gcc.gnu.org/bugzilla/show_bug.cgi?id=58016\nIt was fixed only in gcc 4.9, as its release notes says (http://gcc.gnu.org/gcc-4.9/changes.html)\n",
            "\nThe obvious way is system(\"pkill process_name\");\nClearly this is problematic if you have more than one instance of the process running.\n",
            "\nI have also been looking for such a book, they are very hard to come by. This one will be released in May, if that's any help:\nhttp://www.manning.com/williams/\nI purchased this book:\nhttp://www.amazon.co.uk/gp/product/0123705916/ref=oss_product\nIt's very good, it's in java, but most of the principles apply to c/c++ anyway.\n",
            "\n\nIntroduction to parallel computing: https://computing.llnl.gov/tutorials/parallel_comp/\nPOSIX threads programming: https://computing.llnl.gov/tutorials/pthreads/\n\n",
            "\nGCC Atomic Built-ins\n",
            "\npopen does not actually start a thread, but rather forks a process. As I look at the definition, it doesn't look like there is an easy way to get PID of that process and kill it. There might be difficult ways like examining process tree, but i guess you'd be better off with using pipe, fork and exec functions to mimic behaviour of popen. Then you can use PID you get from fork() to kill the child process.\n"
        ],
        "answer": "A1",
        "tags": [
            "c",
            "multithreading",
            "kill",
            "popen"
        ]
    },
    {
        "question_id": "3450641",
        "question": "\nHow would I go about removing all empty elements (empty list items) from a nested Hash or YAML file?\n",
        "all_answers": [
            "\nYou could add a compact method to Hash like this\nclass Hash\n  def compact\n    delete_if { |k, v| v.nil? }\n  end\nend\n\nor for a version that supports recursion\nclass Hash\n  def compact(opts={})\n    inject({}) do |new_hash, (k,v)|\n      if !v.nil?\n        new_hash[k] = opts[:recurse] && v.class == Hash ? v.compact(opts) : v\n      end\n      new_hash\n    end\n  end\nend\n\n",
            "\nI know this thread is a bit old but I came up with a better solution which supports Multidimensional hashes. It uses delete_if? except its multidimensional and cleans out anything with a an empty value by default and if a block is passed it is passed down through it's children.\n# Hash cleaner\nclass Hash\n    def clean!\n        self.delete_if do |key, val|\n            if block_given?\n                yield(key,val)\n            else\n                # Prepeare the tests\n                test1 = val.nil?\n                test2 = val === 0\n                test3 = val === false\n                test4 = val.empty? if val.respond_to?('empty?')\n                test5 = val.strip.empty? if val.is_a?(String) && val.respond_to?('empty?')\n\n                # Were any of the tests true\n                test1 || test2 || test3 || test4 || test5\n            end\n        end\n\n        self.each do |key, val|\n            if self[key].is_a?(Hash) && self[key].respond_to?('clean!')\n                if block_given?\n                    self[key] = self[key].clean!(&Proc.new)\n                else\n                    self[key] = self[key].clean!\n                end\n            end\n        end\n\n        return self\n    end\nend\n\n",
            "\nUse hsh.delete_if. In your specific case, something like: hsh.delete_if { |k, v| v.empty? }\n",
            "\nThis one would delete empty hashes too:\nswoop = Proc.new { |k, v| v.delete_if(&swoop) if v.kind_of?(Hash);  v.empty? }\nhsh.delete_if &swoop\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "hash",
            "yaml"
        ]
    },
    {
        "question_id": "56553672",
        "question": "\nI have this code to display a list of custom rows.\nstruct ContentView : View {\n    var body: some View {\n        VStack(alignment: .leading) {\n            List(1...10) {_ in\n                CustomRow()\n            }\n        }\n    }\n}\n\nHowever, I want to remove the line on each row. I tried not using List and instead using ForEach inside ScrollView but it completely removes all the styling including its padding and margins. I just want to remove the lines and nothing else.\nPlease help, thank you.\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\niOS 15+:\nSimply add .listRowSeparator(.hidden) as a modifier to the view contained in the List. https://developer.apple.com/documentation/swiftui/texteditor/listrowseparator(_:edges:)\nList {\n    ForEach(garage.cars) { car in\n        Text(car.model)\n            .listRowSeparator(.hidden)\n    }\n}\n\niOS 13 only:\nAdding UITableView.appearance().separatorColor = .clear anywhere in your code before the List appears should work. While this solution removes the separators, note that all List instances will be bound to this style as there’s no official way currently to only remove separators of specific instances. You may be able to run this code in onAppear and undo it in onDisappear to keep styles different.\nAlso note that this code assumes Apple is using a UITableView to back List which is not true in the iOS 14 SDK. Hopefully they add an official API in the future. Credit to https://twitter.com/singy/status/1169269782400647168.\n",
            "\niOS 15:\nThis year Apple introduced a new modifier .listRowSeparator that can be used to style the separators. you can pass .hidden to hide it:\nList {\n    ForEach(items, id:\\.self) { \n        Text(\"Row \\($0)\")\n            .listRowSeparator(.hidden)\n    }\n}\n\n\niOS 14:\nyou may consider using a LazyVStack inside a ScrollView instead (because iOS is NOT supporting UIAppearance for SwiftUI lists anymore).\n\n\niOS 13:\n\n⚠️ This method is deprecated and it's not working from iOS 14\n\nThere is a UITableView behind SwiftUI's List for iOS 13. So to remove\nExtra separators (below the list):\nyou need a tableFooterView and to remove\nAll separators (including the actual ones):\nyou need separatorStyle to be .none\nExample of usage\ninit() {\n    if #available(iOS 14.0, *) { \n        // iOS 14 doesn't have extra separators below the list by default.\n    } else {\n        // To remove only extra separators below the list:\n        UITableView.appearance().tableFooterView = UIView()\n    }\n\n    // To remove all separators including the actual ones:\n    UITableView.appearance().separatorStyle = .none\n}\n\nvar body: some View {\n    List {\n        Text(\"Item 1\")\n        Text(\"Item 2\")\n        Text(\"Item 3\")\n    }\n}\n\nNote that a static list doesn't show extra separators below the list by default\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "swift",
            "swiftui"
        ]
    },
    {
        "question_id": "5030123",
        "question": "\nHow do I set a thread to a daemon thread in C#?\n",
        "all_answers": [
            "\nLike this:\nmyThread.IsBackground = true; \n\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nThough you have already answered your own question, I would still like to elaborate more on it.  \nIn C# .NET, unlike in Java\n   C# Background threads ~ Java Daemon threads  \n   C# Foreground threads ~ Java User threads\n\nBy default, threads you create explicitly are foreground threads.\n\"Background threads are identical to foreground threads, except that background threads do not prevent a process from terminating.\"\n(reference)\nYou can make a thread Daemon by  \nthread.IsBackground = true;  \n\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nYou can use join() to wait for all threads to finish. Like below:\nfor (int i = 0; i < 10; i++) \n{\n    Thread T1 = new Thread(new ThreadTest(i));                \n    T1.start();   \n    try {             \n       T1.join(); \n    } catch (InterruptedException e) {\n       e.printStackTrace();\n    }\n}\n\n",
            "\nBetter alternatives to join() method have been evolved over a period of time.\nExecutorService.html#invokeAll is one alternative.\n\nExecutes the given tasks, returning a list of Futures holding their status and results when all complete. Future.isDone() is true for each element of the returned list. \n\nNote that a completed task could have terminated either normally or by throwing an exception. The results of this method are undefined if the given collection is modified while this operation is in progress.\nForkJoinPool or Executors.html#newWorkStealingPool provides other alternatives to achieve the same purpose. \nExample code snippet:\n\nimport java.util.concurrent.*;\n\nimport java.util.*;\n\npublic class InvokeAllDemo{\n    public InvokeAllDemo(){\n        System.out.println(\"creating service\");\n        ExecutorService service = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\n\n        List<MyCallable> futureList = new ArrayList<MyCallable>();\n        for ( int i=0; i<10; i++){\n            MyCallable myCallable = new MyCallable((long)i);\n            futureList.add(myCallable);\n        }\n        System.out.println(\"Start\");\n        try{\n            List<Future<Long>> futures = service.invokeAll(futureList);  \n        }catch(Exception err){\n            err.printStackTrace();\n        }\n        System.out.println(\"Completed\");\n        service.shutdown();\n    }\n    public static void main(String args[]){\n        InvokeAllDemo demo = new InvokeAllDemo();\n    }\n    class MyCallable implements Callable<Long>{\n        Long id = 0L;\n        public MyCallable(Long val){\n            this.id = val;\n        }\n        public Long call(){\n            // Add your business logic\n            return id;\n        }\n    }\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "java",
            ".net",
            "multithreading",
            "daemon"
        ]
    },
    {
        "question_id": "1650941",
        "question": "\nThe django csrf middleware can't be disabled.  I've commented it out from my Middleware of my project but my logins are failing due to missing CSRF issues.  I'm working from the Django trunk.  How can CSRF cause issues if it is not enabled in middleware?\nI have to disable it because there are lots of POST requests on my site that CSRF just breaks.  Any feedback on how I can completely disable CSRF in a django trunk project?\nThe \"new' CSRF framework from Django's trunk is also breaking an external site that is coming in and doing a POST on a URL I'm giving them (this is part of a restful API.)  I can't disable the CSRF framework as I said earlier, how can I fix this?\n",
        "all_answers": [
            "\nIn general, you shouldn't be disabling CSRF protection, since doing so opens up security holes. If you insist, though…\nA new way of doing CSRF protection landed in trunk just recently. Is your site by chance still configured to do it the old way? Here are the docs for The New Way™ and here are the docs for The Old Way™.\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nSee answers below this for a better solution. Since I wrote this, a lot has changed. There are now better ways to disable CSRF.\nI feel your pain. It's not acceptable for a framework to change such fundamental functionality. Even if I want to start using this from now on, I have legacy sites on the same machine sharing a copy of django. Changes like this should require major version number revisions. 1.x --> 2.x. \nAnyway, to fix it I just commented it out and have stopped updating Django as often.\nFile: django/middleware/csrf.py\nAround line 160:\n            # check incoming token\n#            request_csrf_token = request.POST.get('csrfmiddlewaretoken', None)\n#            if request_csrf_token != csrf_token:\n#                if cookie_is_new:\n#                    # probably a problem setting the CSRF cookie\n#                    return reject(\"CSRF cookie not set.\")\n#                else:\n#                    return reject(\"CSRF token missing or incorrect.\")\n\n"
        ],
        "answer": "A4",
        "tags": [
            "django",
            "csrf"
        ]
    },
    {
        "question_id": "2672744",
        "question": "\nI feel this should be very simple but my brain is short-circuiting on it. If I have an object representing the current user, and want to query for all users except the current user, how can I do this, taking into account that the current user can sometimes be nil?\nThis is what I am doing right now:\ndef index\n  @users = User.all\n  @users.delete current_user\nend\n\nWhat I don't like is that I am doing post-processing on the query result. Besides feeling a little wrong, I don't think this will work nicely if I convert the query over to be run with will_paginate. Any suggestions for how to do this with a query? Thanks.\n",
        "all_answers": [
            "\nIt is possible to do the following in Rails 4 and up:\nUser.where.not(id: id)\n\nYou can wrap it in a nice scope.\nscope :all_except, ->(user) { where.not(id: user) }\n@users = User.all_except(current_user)\n\nOr use a class method if you prefer:\ndef self.all_except(user)\n  where.not(id: user)\nend\n\nBoth methods will return an AR relation object. This means you can chain method calls:\n@users = User.all_except(current_user).paginate\n\nYou can exclude any number of users because where() also accepts an array.\n@users = User.all_except([1,2,3])\n\nFor example:\n@users = User.all_except(User.unverified)\n\nAnd even through other associations:\nclass Post < ActiveRecord::Base\n  has_many :comments\n  has_many :commenters, -> { uniq }, through: :comments\nend\n\n@commenters = @post.commenters.all_except(@post.author)\n\nSee where.not() in the API Docs.\n",
            "\nYou can also create named_scope, e.g. in your model:\nnamed_scope :without_user, lambda{|user| user ? {:conditions => [\"id != ?\", user.id]} : {} }\n\nand in controller:\ndef index\n  @users = User.without_user(current_user).paginate\nend\n\nThis scope will return all users when called with nil and all users except given in param in other case. The advantage of this solution is that you are free to chain this call with other named scopes or will_paginate paginate method.\n",
            "\n@users = (current_user.blank? ? User.all : User.find(:all, :conditions => [\"id != ?\", current_user.id]))\n\n",
            "\nOne note on GhandaL's answer - at least in Rails 3, it's worth modifying to\nscope :without_user, lambda{|user| user ? {:conditions => [\"users.id != ?\", user.id]} : {} }\n\n(the primary change here is from 'id != ...' to 'users.id !=...'; also scope instead of named_scope for Rails 3)\nThe original version works fine when simply scoping the Users table.  When applying the scope to an association (e.g. team.members.without_user(current_user).... ), this change was required to clarify which table we're using for the id comparison.  I saw a SQL error (using SQLite) without it.\nApologies for the separate answer...i don't yet have the reputation to comment directly on GhandaL's answer.\n",
            "\nHere is a shorter version:\nUser.all :conditions => (current_user ? [\"id != ?\", current_user.id] : [])\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "activerecord"
        ]
    },
    {
        "question_id": "12774709",
        "question": "\nWhy is it taking more than an hour to simply update this table to add a column? This table has 15M rows.  It has 2 indexes and a single key primary key. The ALTER TABLE query has been in \"copy to tmp table\" state for 1 hour 15 minutes now.\nALTER TABLE `frugg`.`item_catalog_map` \nADD COLUMN `conversion_url` TEXT NULL DEFAULT NULL\n\nTable:\nmysql> describe item_catalog_map;\n+------------------------+---------------+------+-----+---------+-------+\n| Field                  | Type          | Null | Key | Default | Extra |\n+------------------------+---------------+------+-----+---------+-------+\n| catalog_unique_item_id | varchar(255)  | NO   | PRI | NULL    |       |\n| catalog_id             | int(11)       | YES  | MUL | NULL    |       |\n| item_id                | int(11)       | YES  | MUL | NULL    |       |\n| price                  | decimal(10,2) | YES  |     | 0.00    |       |\n+------------------------+---------------+------+-----+---------+-------+\n\nmysql> show index from item_catalog_map;\n+------------------+------------+----------------------+--------------+------------------------+-----------+-------------+----------+--------+------+------------+---------+\n| Table            | Non_unique | Key_name             | Seq_in_index | Column_name            | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment |\n+------------------+------------+----------------------+--------------+------------------------+-----------+-------------+----------+--------+------+------------+---------+\n| item_catalog_map |          0 | PRIMARY              |            1 | catalog_unique_item_id | A         |    15485115 |     NULL | NULL   |      | BTREE      |         |\n| item_catalog_map |          1 | IDX_ACD6184FCC3C66FC |            1 | catalog_id             | A         |          18 |     NULL | NULL   | YES  | BTREE      |         |\n| item_catalog_map |          1 | IDX_ACD6184F126F525E |            1 | item_id                | A         |    15485115 |     NULL | NULL   | YES  | BTREE      |         |\n+------------------+------------+----------------------+--------------+------------------------+-----------+-------------+----------+--------+------+------------+---------+\n\n",
        "all_answers": [
            "\nYour table has 15 million rows, which is something. The ALTER TABLE involves copying over all the data from the table and recreating the indexes. As a first measurement try copying the data file (item_catalog_map.MYD if it's MyISAM) in your filesystem and see how long that takes. This is the time the ALTER TABLE will at least take.\n",
            "\nMySQL’s ALTER TABLE performance can become a problem with very large tables. MySQL performs\nmost alterations by making an empty table with the desired new structure,  inserting all the data from the old table into the new one, and deleting the old table. This can take a very long time, especially if you’re short on memory and the table is large and has lots of indexes. Many people have  experience with ALTER TABLE operations that have taken hours or days to complete.\nAnyway if you need to proceed with alter table, maybe the following resources could help you:\n\nhttps://www.percona.com/doc/percona-toolkit/2.2/pt-online-schema-change.html\nhttps://github.com/soundcloud/lhm\nhttps://githubengineering.com/gh-ost-github-s-online-migration-tool-for-mysql/\n\n"
        ],
        "answer": "A2",
        "tags": [
            "mysql",
            "sql",
            "alter-table"
        ]
    },
    {
        "question_id": "12754024",
        "question": "\nI have the following model:\nfrom django.db import models\nfrom django.contrib.auth.models import User\n\n\nclass Profile(models.Model):\n    user = models.OneToOneField(User)\n    # ...\n\n    def __unicode__(self):\n        return u'%s %s' % (self.user.first_name, self.user.last_name)\n\nWhen using the Django admin to delete the user, the profile gets deleted as well, which is what I want. However, when using the Django admin to delete the profile, the user does not get deleted, which is not what I want. How can I make it so that deleting the profile will also delete the user?\n",
        "all_answers": [
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nSince Profile links to User, it is the dependent model in the relationship. Therefore when you delete a user, it deletes all dependent models. However when you delete a profile, since User does not depend on profile, it is not removed.\nUnfortunately, according to on_delete Django docs, there is no on_delete rule which deletes the parent relations. In order to do that, you can overwrite the Profile's delete method:\nclass Profile(models.Model):\n    # ...\n\n    def delete(self, *args, **kwargs):\n        self.user.delete()\n        return super(self.__class__, self).delete(*args, **kwargs)\n\nThen when doing:\nProfile.objects.get(...).delete()\n\nwill also delete the profile's user. However the delete method will not be called when deleting profiles using querysets (which is what is called in Django Admin) since then Django uses SQL DELETE to delete objects in bulk:\nProfile.objects.filter(...).delete()\n\nIn that case, as recommended by Django docs, you will have to use post_delete signal (docs).\nfrom django.dispatch import receiver\nfrom django.db.models.signals import post_delete\n\n@receiver(post_delete, sender=Profile)\ndef post_delete_user(sender, instance, *args, **kwargs):\n    if instance.user: # just in case user is not specified\n        instance.user.delete()\n\n",
            "\nUse a signal on the Profile's delete method to go and delete the related User:\nfrom django.db.models.signals import post_delete\n\ndef delete_related_user(sender, **kwargs):\n    deleted_profile = kwargs['instance']\n    deleted_profile.user.delete()\n\npost_delete.connect(delete_related_user, sender=Profile)\n\n"
        ],
        "answer": "A3",
        "tags": [
            "django"
        ]
    },
    {
        "question_id": "4222176",
        "question": "\nThe table in question contains roughly ten million rows.\nfor event in Event.objects.all():\n    print event\n\nThis causes memory usage to increase steadily to 4 GB or so, at which point the rows print rapidly. The lengthy delay before the first row printed surprised me – I expected it to print almost instantly.\nI also tried Event.objects.iterator() which behaved the same way.\nI don't understand what Django is loading into memory or why it is doing this. I expected Django to iterate through the results at the database level, which'd mean the results would be printed at roughly a constant rate (rather than all at once after a lengthy wait).\nWhat have I misunderstood?\n(I don't know whether it's relevant, but I'm using PostgreSQL.)\n",
        "all_answers": [
            "\nYou could create a custom field that auto-truncates the field (I think this code should work, but double-check it):\nclass TruncatingCharField(models.CharField):\n    def get_prep_value(self, value):\n        value = super(TruncatingCharField,self).get_prep_value(value)\n        if value:\n            return value[:self.max_length]\n        return value\n\nThen, instead of using models.CharField in your models.py file, you'd just use TruncatingCharField instead.\nget_prep_value prepares the value for a field for insertion in the database, so it's the ideal place to truncate.\n",
            "\nWhy don't you use a TextField? From the manual:\n\nFor large amounts of text, use\n  TextField.\n\n",
            "\nThis is from the docs: \n    http://docs.djangoproject.com/en/dev/ref/models/querysets/\n\nNo database activity actually occurs until you do something to evaluate the queryset.\n\nSo when the print event is run the query fires (which is a full table scan according to your command.) and loads the results. Your asking for all the objects and there is no way to get the first object without getting all of them. \nBut if you do something like:\nEvent.objects.all()[300:900]\n\nhttp://docs.djangoproject.com/en/dev/topics/db/queries/#limiting-querysets\nThen it will add offsets and limits to the sql internally.\n",
            "\nNate C was close, but not quite.\nFrom the docs:\n\nYou can evaluate a QuerySet in the following ways:\n\nIteration. A QuerySet is iterable, and it executes its database query the first time you iterate over it. For example, this will print the headline of all entries in the database:\nfor e in Entry.objects.all():\n    print e.headline\n\n\n\nSo your ten million rows are retrieved, all at once, when you first enter that loop and get the iterating form of the queryset.  The wait you experience is Django loading the database rows and creating objects for each one, before returning something you can actually iterate over.  Then you have everything in memory, and the results come spilling out.\nFrom my reading of the docs, iterator() does nothing more than bypass QuerySet's internal caching mechanisms.  I think it might make sense for it to a do a one-by-one thing, but that would conversely require ten-million individual hits on your database.  Maybe not all that desirable.\nIterating over large datasets efficiently is something we still haven't gotten quite right, but there are some snippets out there you might find useful for your purposes:\n\nMemory Efficient Django QuerySet iterator\nbatch querysets\nQuerySet Foreach\n\n"
        ],
        "answer": "A4",
        "tags": [
            "sql",
            "django",
            "postgresql",
            "django-orm"
        ]
    },
    {
        "question_id": "2681786",
        "question": "\nI need to get the last character of a string.\nSay I have \"testers\" as input string and I want the result to be \"s\". how can I do that in PHP?\n",
        "all_answers": [
            "\nsubstr($string, -1) \n\n",
            "\nsubstr(\"testers\", -1); // returns \"s\"\n\nOr, for multibyte strings :\nmb_substr(\"multibyte string…\", -1); // returns \"…\"\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "string"
        ]
    },
    {
        "question_id": "3779534",
        "question": "\n\n\n\nI am making a HTML/CSS/jQuery gallery, with several pages.\nI indeed have a \"next\" button, which is a simple link with a jQuery click listener.\nThe problem is that if the user click the button several times, the text of the button is selected, and then the full line of text. In my really darky design, that is really ugly and nonsensical.\nSo here is my question: Can you disable text selection on HTML?\nIf not, I'll terribly miss flash and its high level of configuration on textfields...\n",
        "all_answers": [
            "\nI'm not sure if you can turn it off, but you can change the colors of it :)\nmyDiv::selection,\nmyDiv::-moz-selection,\nmyDiv::-webkit-selection {\n    background:#000;\n    color:#fff;\n}\n\nThen just match the colors to your \"darky\" design and see what happens :)\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\n<div \n style=\"-moz-user-select: none; -webkit-user-select: none; -ms-user-select:none; user-select:none;-o-user-select:none;\" \n unselectable=\"on\"\n onselectstart=\"return false;\" \n onmousedown=\"return false;\">\n    Blabla\n</div>\n\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n"
        ],
        "answer": "A4",
        "tags": [
            "html",
            "css",
            "cross-browser",
            "textselection"
        ]
    },
    {
        "question_id": "591857",
        "question": "\nIf I throw a JavaScript exception myself (eg, throw \"AArrggg\"), how can I get the stack trace (in Firebug or otherwise)?  Right now I just get the message.\nedit: As many people below have posted, it is possible to get a stack trace for a JavaScript exception but I want to get a stack trace for my exceptions.  For example:\nfunction foo() {\n    bar(2);\n}\nfunction bar(n) {\n    if (n < 2)\n        throw \"Oh no! 'n' is too small!\"\n    bar(n-1);\n}\n\nWhen foo is called, I want to get a stack trace which includes the calls to foo, bar, bar.\n",
        "all_answers": [
            "\nEdit 2 (2017):\nIn all modern browsers you can simply call: console.trace(); (MDN Reference)\nEdit 1 (2013):\nA better (and simpler) solution as pointed out in the comments on the original question is to use the stack property of an Error object like so:\nfunction stackTrace() {\n    var err = new Error();\n    return err.stack;\n}\n\nThis will generate output like this:\nDBX.Utils.stackTrace@http://localhost:49573/assets/js/scripts.js:44\nDBX.Console.Debug@http://localhost:49573/assets/js/scripts.js:9\n.success@http://localhost:49573/:462\nx.Callbacks/c@http://localhost:49573/assets/js/jquery-1.10.2.min.js:4\nx.Callbacks/p.fireWith@http://localhost:49573/assets/js/jquery-1.10.2.min.js:4\nk@http://localhost:49573/assets/js/jquery-1.10.2.min.js:6\n.send/r@http://localhost:49573/assets/js/jquery-1.10.2.min.js:6\n\nGiving the name of the calling function along with the URL, its calling function, and so on.\nOriginal (2009):\nA modified version of this snippet may somewhat help:\nfunction stacktrace() { \n  function st2(f) {\n    return !f ? [] : \n        st2(f.caller).concat([f.toString().split('(')[0].substring(9) + '(' + f.arguments.join(',') + ')']);\n  }\n  return st2(arguments.callee.caller);\n}\n\n",
            "\nIf you have firebug, there's a break on all errors option in the script tab. Once the script has hit your breakpoint, you can look at firebug's stack window:\n\n",
            "\nI don't think there's anything built in that you can use however I did find lots of examples of people rolling their own.\n\nDIY javascript stack trace\nA Javascript stacktrace in any browser\n\n",
            "\nIt is easier to get a stack trace on Firefox than it is on IE but fundamentally here is what you want to do:\nWrap the \"problematic\" piece of code in a try/catch block:\ntry {\n    // some code that doesn't work\n    var t = null;\n    var n = t.not_a_value;\n}\n    catch(e) {\n}\n\nIf you will examine the contents of the \"error\" object it contains the following fields:\ne.fileName : The source file / page where the issue came from\ne.lineNumber : The line number in the file/page where the issue arose \ne.message : A simple message describing what type of error took place\ne.name : The type of error that took place, in the example above it should be 'TypeError'\ne.stack : Contains the stack trace that caused the exception\nI hope this helps you out.\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "stack-trace"
        ]
    },
    {
        "question_id": "342152",
        "question": "\nI was working with a new C++ developer a while back when he asked the question: \"Why can't variable names start with numbers?\"\nI couldn't come up with an answer except that some numbers can have text in them (123456L, 123456U) and that wouldn't be possible if the compilers were thinking everything with some amount of alpha characters was a variable name.\nWas that the right answer?  Are there any more reasons?\nstring 2BeOrNot2Be = \"that is the question\"; // Why won't this compile?\n\n",
        "all_answers": [
            "\nWell think about this:\nint 2d = 42;\ndouble a = 2d;\n\nWhat is a?  2.0?  or 42?\nHint, if you don't get it, d after a number means the number before it is a double literal\n",
            "\nIt means \"no value\". You use void to indicate that a function doesn't return a value or that it has no parameters or both. Pretty much consistent with typical uses of word void in English.\n",
            "\nBecause then a string of digits would be a valid identifier as well as a valid number.\nint 17 = 497;\nint 42 = 6 * 9;\nString 1111 = \"Totally text\";\n\n",
            "\nThere are two ways to use void:\nvoid foo(void);\n\nor\nvoid *bar(void*);\n\nThe first indicates that no argument is being passed or that no argument is being returned.\nThe second tells the compiler that there is no type associated with the data effectively meaning that the you can't make use of the data pointed to until it is cast to a known type.\nFor example you will see void* used a lot when you have an interface which calls a function whose parameters can't be known ahead of time.\nFor example, in the Linux kernel, when deferring work you will set up a function to be run at a latter time by giving it a pointer to the function to be run and a pointer to the data to be passed to the function:\nstruct _deferred_work {\nsruct list_head mylist;\n.worker_func = bar;\n.data        = somedata;\n} deferred_work;\n\nThen a kernel thread goes over a list of deferred work and when it gets to this node it effectively executes:\nbar(somedata);\n\nThen in bar you have:\nvoid bar(void* mydata) {\n    int *data = mydata;\n    /* Do something with data */;\n}\n\n",
            "\nI have always taken it to mean absent. Here are four cases in the C language that matches to this use of absent\n\nR f(void) - Function parameters are absent\nvoid f(P) - Return value is absent\nvoid *p - Type of what is pointed to is absent\n(void) p - Usage of value is absent\n\nOther C descendants use it for other things. The D programming language uses it for cases where an initializer is absent\n\nT t = void; - initializing value is absent\n\n",
            "\nBasically it means \"nothing\" or \"no type\"\nThere are 3 basic ways that void is used:\n\nFunction argument: int myFunc(void)\n-- the function takes nothing. \nFunction return value: void myFunc(int)\n-- the function returns nothing\nGeneric data pointer: void* data\n-- 'data' is a pointer to data of unknown type, and cannot be dereferenced\n\nNote: the void in a function argument is optional in C++, so int myFunc() is exactly the same as int myFunc(void), and it is left out completely in C#. It is always required for a return value.\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "variables",
            "programming-languages",
            "language-design",
            "variable-names"
        ]
    },
    {
        "question_id": "7726949",
        "question": "\nIs there a simple way to delete all tracking branches whose remote equivalent no longer exists?\nExample:\nBranches (local and remote)\n\nmaster\norigin/master\norigin/bug-fix-a\norigin/bug-fix-b\norigin/bug-fix-c\n\nLocally, I only have a master branch. Now I need to work on bug-fix-a, so I check it out, work on it, and push changes to the remote. Next I do the same with bug-fix-b.\nBranches (local and remote)\n\nmaster\nbug-fix-a\nbug-fix-b\norigin/master\norigin/bug-fix-a\norigin/bug-fix-b\norigin/bug-fix-c\n\nNow I have local branches master, bug-fix-a, bug-fix-b. The Master branch maintainer will merge my changes into master and delete all branches he has already merged.\nSo the current state is now:\nBranches (local and remote)\n\nmaster\nbug-fix-a\nbug-fix-b\norigin/master\norigin/bug-fix-c\n\nNow I would like to call some command to delete branches (in this case bug-fix-a, bug-fix-b), which are no longer represented in the remote repository.\nIt would be something like the existing command git remote prune origin, but more like git local prune origin.\n",
        "all_answers": [
            "\ngit fetch -p\n\nThis will prune any branches that no longer exist on the remote.\n",
            "\nRemove all branches that have been merged into master, but don't try to remove master itself:\ngit checkout master && git pull origin master && git fetch -p && git branch -d $(git branch --merged | grep master -v)\nor add an alias:\nalias gitcleanlocal=\"git checkout master && git pull origin master && git fetch -p && git branch -d $(git branch --merged | grep master -v)\"\nExplanation:\ngit checkout master  checkout master branch\ngit pull origin master  ensure local branch has all remote changes merged\ngit fetch -p remove references to remote branches that have been deleted\ngit branch -d $(git branch master --merged | grep master -v)  delete all branches that have been merged into master, but don't try to remove master itself\n",
            "\nI don't think there is a built-in command to do this, but it is safe to do the following:\ngit checkout master\ngit branch -d bug-fix-a\n\nWhen you use -d, git will refuse to delete the branch unless it is completely merged into HEAD or its upstream remote-tracking branch.  So, you could always loop over the output of git for-each-ref and try to delete each branch.  The problem with that approach is that I suspect that you probably don't want bug-fix-d to be deleted just because origin/bug-fix-d contains its history.  Instead, you could create a script something like the following:\n#!/bin/sh\n\ngit checkout master &&\nfor r in $(git for-each-ref refs/heads --format='%(refname:short)')\ndo\n  if [ x$(git merge-base master \"$r\") = x$(git rev-parse --verify \"$r\") ]\n  then\n    if [ \"$r\" != \"master\" ]\n    then\n      git branch -d \"$r\"\n    fi\n  fi\ndone\n\nWarning: I haven't tested this script - use only with care...\n",
            "\ngit remote prune origin prunes tracking branches not on the remote.\ngit branch --merged lists branches that have been merged into the current branch.\nxargs git branch -d deletes branches listed on standard input.\nBe careful deleting branches listed by git branch --merged. The list could include master or other branches you'd prefer not to delete.\nTo give yourself the opportunity to edit the list before deleting branches, you could do the following in one line:\ngit branch --merged >/tmp/merged-branches && \\\n  vi /tmp/merged-branches && xargs git branch -d </tmp/merged-branches\n\n"
        ],
        "answer": "A4",
        "tags": [
            "git",
            "git-branch"
        ]
    },
    {
        "question_id": "16815551",
        "question": "\nHow can I make this query in Laravel:\nSELECT \n    `p`.`id`,\n    `p`.`name`, \n    `p`.`img`, \n    `p`.`safe_name`, \n    `p`.`sku`, \n    `p`.`productstatusid` \nFROM `products` p \nWHERE `p`.`id` IN (\n    SELECT \n        `product_id` \n    FROM `product_category`\n    WHERE `category_id` IN ('223', '15')\n)\nAND `p`.`active`=1\n\nI could also do this with a join, but I need this format for performance.\n",
        "all_answers": [
            "\nHave a look at the advanced where clause documentation for Fluent. Here's an example of what you're trying to achieve:\nDB::table('users')\n    ->whereIn('id', function($query)\n    {\n        $query->select(DB::raw(1))\n              ->from('orders')\n              ->whereRaw('orders.user_id = users.id');\n    })\n    ->get();\n\nThis will produce:\nselect * from users where id in (\n    select 1 from orders where orders.user_id = users.id\n)\n\n",
            "\nI have solved this if you are using array called for 2 tables. Example you have,\n$tableA['yellow'] and $tableA['blue'] . You are getting these 2 values and you want to add another element inside them to separate them by their type.\nforeach ($tableA['yellow'] as $value) {\n    $value->type = 'YELLOW';  //you are adding new element named 'type'\n}\n\nforeach ($tableA['blue'] as $value) {\n    $value->type = 'BLUE';  //you are adding new element named 'type'\n}\n\nSo, both of the tables value will have new element called type.\n",
            "\nIt looks like you have everything correct according to Laravel docs, but you have a typo\n$item->push($product);\n\nShould be\n$items->push($product);\n\npush method appends an item to the end of the collection:\nI also want to think the actual method you're looking for is put\n$items->put('products', $product);\n\nput method sets the given key and value in the collection\n",
            "\nConsider this code:\nProducts::whereIn('id', function($query){\n    $query->select('paper_type_id')\n    ->from(with(new ProductCategory)->getTable())\n    ->whereIn('category_id', ['223', '15'])\n    ->where('active', 1);\n})->get();\n\n",
            "\nIf you want to add item to the beginning of the collection you can use prepend:\n$item->prepend($product, 'key');\n\n",
            "\nIf you want to add a product into the array you can use:\n$item['product'] = $product;\n\n",
            "\nAs mentioned above  if you wish to add as a new element your queried collection you can use:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n        $product = DB::select(DB::raw(' select * from product\n               where product_id = '. $id.';' ));\n\n        $items->push($product);\n        // or \n        // $items->put('products', $product);\n    }\n\nbut if you wish to add new element to each queried element you need to do like:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n           $product = DB::select(DB::raw(' select * from product\n                 where product_id = '. $id.';' ));\n    \n          $item->add_whatever_element_you_want = $product;\n    }\n\nadd_whatever_element_you_want can be whatever you wish that your element is named (like product for example).\n"
        ],
        "answer": "A4",
        "tags": [
            "php",
            "mysql",
            "laravel",
            "eloquent",
            "subquery"
        ]
    },
    {
        "question_id": "739260",
        "question": "\nI'm using Django 1.0.2.  I've written a ModelForm backed by a Model.  This model has a ForeignKey where blank=False.  When Django generates HTML for this form it creates a select box with one option for each row in the table referenced by the ForeignKey.  It also creates an option at the top of the list that has no value and displays as a series of dashes:\n<option value=\"\">---------</option>\n\nWhat I'd like to know is:\n\nWhat is the cleanest way to remove this auto-generated option from the select box?  \nWhat is the cleanest way to customize it so that it shows as:\n<option value=\"\">Select Item</option>\n\n\nIn searching for a solution I came across Django ticket 4653 which gave me the impression that others had the same question and that the default behavior of Django may have been modified.  This ticket is over a year old so I was hoping there might be a cleaner way to accomplish these things.\nThanks for any help,\nJeff\nEdit: I've configured the ForeignKey field as such: \nverb = models.ForeignKey(Verb, blank=False, default=get_default_verb)\n\nThis does set the default so that it's no longer the empty/dashes option but unfortunately it doesn't seem to resolve either of my questions.  That is, the empty/dashes option still appears in the list.\n",
        "all_answers": [
            "\nHaven't tested this, but based on reading Django's code here and here I believe it should work:\nclass ThingForm(forms.ModelForm):\n  class Meta:\n    model = Thing\n  \n  def __init__(self, *args, **kwargs):\n    super(ThingForm, self).__init__(*args, **kwargs)\n    self.fields['verb'].empty_label = None\n\nEDIT: This is documented, though you wouldn't necessarily know to look for ModelChoiceField if you're working with an auto-generated ModelForm.\nEDIT: As jlpp notes in his answer, this isn't complete - you have to re-assign the choices to the widgets after changing the empty_label attribute.  Since that's a bit hacky, the other option that might be easier to understand is just overriding the entire ModelChoiceField:\nclass ThingForm(forms.ModelForm):\n  verb = ModelChoiceField(Verb.objects.all(), empty_label=None)\n\n  class Meta:\n    model = Thing\n\n",
            "\nfrom the docs\n\nThe blank choice will not be included\n  if the model field has blank=False and\n  an explicit default value (the default\n  value will be initially selected\n  instead).\n\nso set the default and you're ok\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django",
            "django-models",
            "django-forms"
        ]
    },
    {
        "question_id": "67454",
        "question": "\nHow to serve users a dynamically generated ZIP archive in Django?\nI'm making a site, where users can choose any combination of available books and download them as ZIP archive. I'm worried that generating such archives for each request would slow my server down to a crawl. I have also heard that Django doesn't currently have a good solution for serving dynamically generated files.\n",
        "all_answers": [
            "\nCan't you just write a link to a \"zip server\" or whatnot?  Why does the zip archive itself need to be served from Django?  A 90's era CGI script to generate a zip and spit it to stdout is really all that's required here, at least as far as I can see.\n",
            "\nDjango doesn't directly handle the generation of dynamic content (specifically Zip files). That work would be done by Python's standard library. You can take a look at how to dynamically create a Zip file in Python here.\nIf you're worried about it slowing down your server you can cache the requests if you expect to have many of the same requests. You can use Django's cache framework to help you with that.\nOverall, zipping files can be CPU intensive but Django shouldn't be any slower than another Python web framework.\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nThe solution is as follows.\nUse Python module zipfile to create zip archive, but as the file specify StringIO object (ZipFile constructor requires file-like object). Add files you want to compress. Then in your Django application return the content of StringIO object in HttpResponse with mimetype set to application/x-zip-compressed (or at least application/octet-stream). If you want, you can set content-disposition header, but this should not be really required.\nBut beware, creating zip archives on each request is bad idea and this may kill your server (not counting timeouts if the archives are large). Performance-wise approach is to cache generated output somewhere in filesystem and regenerate it only if source files have changed. Even better idea is to prepare archives in advance (eg. by cron job) and have your web server serving them as usual statics.\n"
        ],
        "answer": "A5",
        "tags": [
            "python",
            "django"
        ]
    },
    {
        "question_id": "8094156",
        "question": "\nI wish to all know how the tables in my database are related to each other (i.e PK/FK/UK) and hence i created a database diagram of all my tables in SQL Server. The diagram that was created was not easily readable and had to scroll (horizontally and sometimes vertically) to see the table on the other end.\nIn short SQL's db diagram are not UI friendly when it comes to knowing relationships between many tables. \nMy (simple) Question: Is there something like database diagram which can do what db diagram did but in \"good\" way?\n",
        "all_answers": [
            "\nSometimes, a textual representation might also help; with this query on the system catalog views, you can get a list of all FK relationships and how the link two tables (and what columns they operate on).\nSELECT\n    fk.name 'FK Name',\n    tp.name 'Parent table',\n    cp.name, cp.column_id,\n    tr.name 'Refrenced table',\n    cr.name, cr.column_id\nFROM \n    sys.foreign_keys fk\nINNER JOIN \n    sys.tables tp ON fk.parent_object_id = tp.object_id\nINNER JOIN \n    sys.tables tr ON fk.referenced_object_id = tr.object_id\nINNER JOIN \n    sys.foreign_key_columns fkc ON fkc.constraint_object_id = fk.object_id\nINNER JOIN \n    sys.columns cp ON fkc.parent_column_id = cp.column_id AND fkc.parent_object_id = cp.object_id\nINNER JOIN \n    sys.columns cr ON fkc.referenced_column_id = cr.column_id AND fkc.referenced_object_id = cr.object_id\nORDER BY\n    tp.name, cp.column_id\n\nDump this into Excel, and you can slice and dice - based on the parent table, the referenced table or anything else.\nI find visual guides helpful - but sometimes, textual documentation is just as good (or even better) - just my 2 cents.....\n",
            "\nMicrosoft Visio is probably the best I've came across, although as far as I know it won't automatically generate based on your relationships.\nEDIT: try this in Visio, could give you what you need http://office.microsoft.com/en-us/visio-help/reverse-engineering-an-existing-database-HA001182257.aspx\n",
            "\nOr you can look at schemacrawler\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n"
        ],
        "answer": "A1",
        "tags": [
            "sql",
            "sql-server",
            "database",
            "t-sql"
        ]
    },
    {
        "question_id": "32728860",
        "question": "\nI am trying to setup webserver with PHP 7 RC3 + Nginx on Ubuntu 14.04 (for test purposes).\nI installed Ubuntu in Vagrant using ubuntu/trusty64 and PHP 7 RC 3 from Ondřej Surý (https://launchpad.net/~ondrej/+archive/ubuntu/php-7.0).\nI can not find the way to install MySQL PDO (PHP sees PDO class but not anything related to MySQL, like PDO::MYSQL_ATTR_DIRECT_QUERY etc.)\nLooks like there is no lib php7.0-mysql (by analogy with standard php5-mysqlnd and php7.0-fpm etc. from Ondřej)\nSection PDO in phpinfo():\nPDO support      enabled\nPDO drivers      no value\n\nHow can I get it?\n",
        "all_answers": [
            "\nYou can type hint this way using docblocks.\nPHP editor (IDE) like PhpStorm supports this very well and will properly resolve the class when iterating over such array.\n/**\n * @return YourClass[]\n */\npublic function getObjects(): array\n\nPHPStorm also supports nested arrays:\n/**\n * @return YourClass[][]\n */\npublic function getObjects(): array\n\nNewer versions of PHPStorm support phpstan/psalm format:\n/**\n * @return array<int, YourObject>\n */\npublic function getObjects(): array\n\nOr even generics:\n/**\n * @template T of object\n * @param class-string<T> $className\n * @return array<array-key, T>\n */\npublic function getCollectionOf(string $className): array\n\n",
            "\nSince eggyal didn't provided his comment as answer after he gave right advice in a comment - i am posting it here: In my case I had to install module php-mysql. See comments under the question for details.\n",
            "\nI had, pretty much, the same problem. I was able to see that PDO was enabled but I had no available drivers (using PHP 7-RC4). I managed to resolve the issue by adding the php_pdo_mysql extension to those which were enabled.\nHope this helps!\n",
            "\nI actually understand what you mean, but the answer unfortunately is that you can't do that. PHP7 lacks that kind of expressivity, so you can either declare your function to return \"array\" (a generic array) or you have to create a new class ItemArray which is an array of Item (but that meaning you will have to code it yourself).\nThere is currently no way to express \"I want an array of Item\" instances.\nEDIT: As an added reference, here the \"array of\" RFC of what you wanted to do, it has been declined due to various reasons.\n",
            "\nHad the same issue, resolved by actually enabling the extension in the php.ini with the right file name. It was listed as php_pdo_mysql.so but the module name in /lib/php/modules was called just pdo_mysql.so\nSo just remove the \"php_\" prefix from the php.ini file and then restart the httpd service and it worked like a charm.\nPlease note that I'm using Arch and thus path names and services may be different depending on your distrubution.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "mysql",
            "ubuntu",
            "pdo",
            "php-7"
        ]
    },
    {
        "question_id": "9601357",
        "question": "\nI have a <div> element and I want to put a border on it.  I know I can write style=\"border: 1px solid black\", but this adds 2px to either side of the div, which is not what I want.  \nI would rather have this border be -1px from the edge of the div. The div itself is 100px x 100px, and if I add a border, then I have to do some mathematics to make the border appear.\nIs there any way that I can make the border appear, and ensure the box will still be 100px (including the border)?\n",
        "all_answers": [
            "\nAdd only the class center-block to an image, this works with Bootstrap 4 as well:\n<img src=\"...\" alt=\"...\" class=\"center-block\" />\n\nNote: center-block works even when img-responsive is used\n",
            "\nfor consistent rendering between new and older browsers, add a double container, the outer with the width, the inner with the border.\n<div style=\"width:100px;\">\n<div style=\"border:2px solid #000;\">\ncontents here\n</div>\n</div>\n\nthis is obviously only if your precise width is more important than having extra markup!\n",
            "\nJust use .text-center class if you're using Bootstrap 3.\n<div class=\"text-center\">\n    <img src=\"...\" alt=\"...\"/>\n</div>\n\nNote: This doesn't work with img-responsive\n",
            "\nI would suggest a more \"abstract\" classification. Add a new class \"img-center\" which can be used in combination with .img-responsive class:\n// Center responsive images\n.img-responsive.img-center {\n  margin: 0 auto;\n}\n\n",
            "\nThere is .center-block class in Twitter Bootstrap 3 (Since v3.0.1), so use:\n<img src=\"...\" alt=\"...\" class=\"img-responsive center-block\" />\n\n",
            "\nSet box-sizing property to border-box:\n\n\ndiv {\r\n    box-sizing: border-box;\r\n    -moz-box-sizing: border-box;\r\n    -webkit-box-sizing: border-box;\r\n    width: 100px;\r\n    height: 100px;\r\n    border: 20px solid #f00;\r\n    background: #00f;\r\n    margin: 10px;\r\n}\r\n\r\ndiv + div {\r\n    border: 10px solid red;\r\n}\n<div>Hello!</div>\r\n<div>Hello!</div>\n\n\n\nIt works on IE8 & above.\n",
            "\nIf you're using Bootstrap v3.0.1 or greater, you should use this solution instead. It doesn't override Bootstrap's styles with custom CSS, but instead uses a Bootstrap feature.\nMy original answer is shown below for posterity\n\nThis is a pleasantly easy fix. Because .img-responsive from Bootstrap already sets display: block, you can use margin: 0 auto to center the image:\n.product .img-responsive {\n    margin: 0 auto;\n}\n\n",
            "\nThis should center the image and make it responsive.\n<img src=\"...\" class=\"img-responsive\" style=\"margin:0 auto;\"/>\n\n",
            "\nSimply put all the images thumbnails inside a row/col divs like this:\n<div class=\"row text-center\">\n <div class=\"col-12\">\n  # your images here...\n </div>\n</div>\n\nand everything will work fine!\n",
            "\nYou can use property of d-block here or you can use a parent div with property 'text-center' in bootstrap or 'text-align: center' in css.\nImage by default is displayed as inline-block, you need to display it as block in order to center it with .mx-auto. This can be done with built-in .d-block:\n<div>\n    <img class=\"mx-auto d-block\" src=\"...\">  \n</div>\n\nOr leave it as inline-block and wrapped it in a div with .text-center:\n<div class=\"text-center\">\n    <img src=\"...\">  \n</div>\n\n"
        ],
        "answer": "A6",
        "tags": [
            "html",
            "css",
            "border"
        ]
    },
    {
        "question_id": "2765421",
        "question": "\nHow do I:\n\nCreate a local branch from another branch (via git branch or git checkout -b).\n\nPush the local branch\nto the remote repository (i.e. publish), but make it\ntrackable so that git pull and git push will work.\n\n\n",
        "all_answers": [
            "\nI suppose that you have already cloned a project like:\ngit clone http://github.com/myproject.git\n\n\nThen in your local copy, create a new branch and check it out:\ngit checkout -b <newbranch>\n\nSupposing that you made a \"git bare --init\" on your server and created the myapp.git, you should:\ngit remote add origin ssh://example.com/var/git/myapp.git\ngit push origin master\n\nAfter that, users should be able to\ngit clone http://example.com/var/git/myapp.git\n\n\nNOTE: I'm assuming that you have your server up and running. If it isn't, it won't work. A good how-to is here.\nADDED\nAdd a remote branch:\ngit push origin master:new_feature_name\n\nCheck if everything is good (fetch origin and list remote branches):\ngit fetch origin\ngit branch -r\n\nCreate a local branch and track the remote branch:\ngit checkout -tb new_feature_name origin/new_feature_name\n\nUpdate everything:\ngit pull\n\n",
            "\nIn Git 1.7.0 and later, you can checkout a new branch:\ngit checkout -b <branch>\n\nEdit files, add and commit. Then push with the -u (short for --set-upstream) option:\ngit push -u origin <branch>\n\nGit will set up the tracking information during the push.\n",
            "\nPrior to the introduction of git push -u, there was no git push option to obtain what you desire. You had to add new configuration statements.\nIf you create a new branch using:\n$ git checkout -b branchB\n$ git push origin branchB:branchB\n\nYou can use the git config command to avoid editing directly the .git/config file:\n$ git config branch.branchB.remote origin\n$ git config branch.branchB.merge refs/heads/branchB\n\nOr you can edit manually the .git/config file to add tracking information to this branch:\n[branch \"branchB\"]\n    remote = origin\n    merge = refs/heads/branchB\n\n",
            "\nJust do:\ngit push origin <your_branch_name> --force\n\nor if you have a specific repo:\ngit push https://git.... --force\n\nThis will delete your previous commit(s) and push your current one.\nIt may not be proper, but if anyone stumbles upon this page, thought they might want a simple solution...\nShort flag\nAlso note that -f is short for --force, so\ngit push origin <your_branch_name> -f\n\nwill also work.\n",
            "\nedit Outdated, just use git push -u origin $BRANCHNAME\n\nUse git publish-branch from William's miscellaneous Git tools.\nOK, no Ruby, so - ignoring the safeguards! - take the last three lines of the script and create a bash script, git-publish-branch:\n#!/bin/bash\nREMOTE=$1 # Rewrite this to make it optional...\nBRANCH=$2\n# Uncomment the following line to create BRANCH locally first\n#git checkout -b ${BRANCH}\ngit push ${ORIGIN} ${BRANCH}:refs/heads/${BRANCH} &&\ngit config branch.${BRANCH}.remote ${REMOTE} &&\ngit config branch.${BRANCH}.merge refs/heads/${BRANCH}\n\nThen run git-publish-branch REMOTENAME BRANCHNAME, where REMOTENAME is usually origin (you may modify the script to take origin as default, etc...)\n"
        ],
        "answer": "A2",
        "tags": [
            "git",
            "repository",
            "git-branch",
            "git-push",
            "git-remote"
        ]
    },
    {
        "question_id": "483864",
        "question": "\nIs there a Windows command that will output the size in bytes of a specified file like this?\n> filesize test.jpg\n65212\n\nI know that the dir command outputs this information, but it outputs other information also.\nI could easily write such a program, but I would prefer to use a native Windows command if possible, or only what is available in a fresh install of Windows XP.\n",
        "all_answers": [
            "\nIn PowerShell you can do:\n$imageObj = New-Object System.IO.FileInfo(\"C:\\test.jpg\")    \n$imageObj.Length\n\n",
            "\nIf you are inside a batch script, you can use argument variable tricks to get the filesize:\nfilesize.bat:\n@echo off\necho %~z1\n\nThis gives results like the ones you suggest in your question.\nType\nhelp call\n\nat the command prompt for all of the crazy variable manipulation options. Also see this article for more information.\nEdit:\nThis only works in Windows 2000 and later\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "command-line"
        ]
    },
    {
        "question_id": "10728420",
        "question": "\nIs there any way of online editing the commit message in GitHub.com, after submission?\nFrom the command line, one can do\ngit commit --amend -m \"New commit message\"\n\nas correctly suggested in the following question:\n\nHow to modify existing, unpushed commit messages?\n\nTrying git pull and then git push has worked (without any other commit having interfered in the mean time).\nBut can it be done via the GitHub website?\n",
        "all_answers": [
            "\nI got the same problem while using a github repository, and connecting to it via https, while using the OS X Keychain Credential helper.\nMy problem was that I had the wrong credentials stored in OS X's Keychain (I was using the email address that I used to sign up for github.com rather than the [username]@github.com address it provides you). I deleted the old account in the keychain and only left the @github.com one and it fixed the problem.\nNot sure if it is related, but when I checked the user.email local config:\ngit config -l\n\nit showed the incorrect email address as well, so I updated the local git user.email to use the correct account too:\ngit config user.email <username>@github.com\n\n",
            "\nMake sure that your user account is added to the repository as a collaborator.\nSetting --> Collaborators\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nYou need to git push -f assuming that nobody has pulled the other commit before. Beware, you're changing history. \n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nNo, this is not directly possible. The hash for every Git commit is also calculated based on the commit message. When you change the commit message, you change the commit hash. If you want to push that commit, you have to force that push (git push -f). But if already someone pulled your old commit and started a work based on that commit, they would have to rebase their work onto your new commit.\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nMy issue was that I used the clone https url widget provided by github. That URL doesn't work for private repositories as you need to add a username to the front of it.  \nExample: a private repo owned by john and named widget with collaborator sam the correct url would be: \nhttps://sam@github.com/john/widget.git\nThe github provided url: \nhttps://github.com/john/widget.git\nThe error message leaves much to be desired.\n"
        ],
        "answer": "A8",
        "tags": [
            "git",
            "github",
            "commit",
            "post-commit"
        ]
    },
    {
        "question_id": "7088173",
        "question": "\nAim to Achieve:\nI want all objects where name attribute contains any word from the list.\nI have:\nlist = ['word1','word2','word3']\nob_list = data.objects.filter( // What to write here ?  )\n// or any other way to get the objects where any word in list is contained, in \n// the na-me attribute of data.\n\nFor example:\nif name=\"this is word2\": Then object with such a name should be returned since word2 is in the list.\nPlease help!\n",
        "all_answers": [
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nob_list = data.objects.filter(name__in=my_list)\n\nAnd BTW, avoid using the variable name \"list\" (Or any other python standard keyword), lest you get into some weird bugs later.\nUpdate: (I guess your question was updated too, because when I wrote the answer, I didn't see the part where you wrote you need a contains match and not an exact match)\nYou can do that using the regex search too, avoiding many Q expressions (which end up using that many where \"and\" clauses in the SQL, possibly dampening the performance), as follows:\ndata.objects.filter(name__regex=r'(word1|word2|word3)')\n\n",
            "\nYou could use Q objects to constuct a query like this:\nfrom django.db.models import Q\n\nob_list = data.objects.filter(reduce(lambda x, y: x | y, [Q(name__contains=word) for word in list]))\n\nEdit: \nreduce(lambda x, y: x | y, [Q(name__contains=word) for word in list]))\n\nis a fancy way to write\nQ(name__contains=list[0]) | Q(name__contains=list[1]) | ... | Q(name__contains=list[-1])\n\nYou could also use an explicit for loop to construct the Q object.\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nobj_list = [obj for obj in data.objects.all() if any(name in obj.name for name in list)]\n\nEdit: Just re-read your question. Don't know if you can do that with filter but you can do it with a list comprehension or generator expression.\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "django",
            "list"
        ]
    },
    {
        "question_id": "7341537",
        "question": "\n\n\n\nWe have this json schema draft. I would like to get a sample of my JSON data and generate a skeleton for the JSON schema, that I can rework manually, adding things like description, required, etc, which can not be infered from the specific examples.\nFor example, from my input example.json:\n{\n    \"foo\": \"lorem\", \n    \"bar\": \"ipsum\"\n}\n\nI would run my json_schema_generator tool and would get:\n{ \"foo\": {\n    \"type\" : \"string\",\n    \"required\" : true,\n    \"description\" : \"unknown\"\n  },\n  \"bar\": {\n    \"type\" : \"string\",\n    \"required\" : true,\n    \"description\" : \"unknown\"\n  }\n}\n\nThis example has been coded manually, so it may have errors.\nIs there any tool out there which could help me with the conversion JSON -> JSON schema?\n",
        "all_answers": [
            "\nSeeing that this question is getting quite some upvotes, I add new information (I am not sure if this is new, but I couldn't find it at the time)\n\nThe home of JSON Schema\nAn implementation of JSON Schema validation for Python\nRelated hacker news discussion\nA json schema generator in python, which is what I was looking for.\n\n",
            "\nYou might be looking for this:\nhttp://www.jsonschema.net\nIt is an online tool that can automatically generate JSON schema from JSON string. And you can edit the schema easily.\n",
            "\nAs Konrad's answer stated, use patternProperties. But use in place of properties, which is not needed, and I think Konrad just pasted from his reference example that was expecting a path starting with /. In the example below, the pattern match regex .* accepts any property name and I am allowing types of string or null only by using \"additionalProperties\": false.\n  \"patternProperties\": {\n    \"^.*$\": {\n      \"anyOf\": [\n        {\"type\": \"string\"},\n        {\"type\": \"null\"}\n      ]\n    }\n  },\n  \"additionalProperties\": false\n\n",
            "\nOn json-schema.org you will find something appropriate in the File System Example section. You can define patternProperties inside an object.\n{\n    \"type\": \"object\",\n    \"properties\": {\n        \"/\": {}\n    },\n    \"patternProperties\": {\n        \"^(label_name_[0-9]+)+$\": { \"type\": \"integer\" }\n    },\n    \"additionalProperties\": false,\n }\n\nThe regular expression (label_name_[0-9]+)+ should fit your needs. In JSON Schema regular expressions are explicitly anchored with ^ and $. The regular expressions defines, that there has to be at least one property (+). The property consists of label_name_ and a number between 0 and 9 whereas there has to be at least one number ([0-9]+), but there can also arbitrary many of them.\nBy setting additionalProperties to false it constrains object properties to match the regular expression.\n",
            "\nAfter several months, the best answer I have is my simple tool. It is raw but functional.\nWhat I want is something similar to this. The JSON data can provide a skeleton for the JSON schema. I have not implemented it yet, but it should be possible to give an existing JSON schema as basis, so that the existing JSON schema plus JSON data can generate an updated JSON schema. If no such schema is given as input, completely default values are taken.\nThis would be very useful in iterative development: the first time the tool is run, the JSON schema is dummy, but it can be refined automatically according to the evolution of the data.\n"
        ],
        "answer": "A1",
        "tags": [
            "json",
            "validation",
            "reflection",
            "jsonschema"
        ]
    },
    {
        "question_id": "39275947",
        "question": "\nI created an API spec from some JSON files and I am trying to test if the files validate against the API spec. \nThere are some good tools to validate against JSON Schema, but I did not have chance to find a tool to validate against specs created in the Swagger (tool for creating API schema). The only solution I found is generating a client/server in the Swagger-Editor, it is quite cumbersome.\nIs there already an existing tool to validate JSON against Swagger Schema?\n",
        "all_answers": [
            "\nIf your Swagger JSON is hosted, you could use the following url:\n    http://online.swagger.io/validator/debug?url=your_url\n",
            "\nArnaud in the comments is correct that there are two separate questions here.\n\nDo you want to validate that your spec is a valid OpenAPI (fka. Swagger) spec\n\nYou can\n\nCopy your spec to the online Swagger editor and it will throw errors. A quick dive through the source doesn't tell me what it's using to create those errors, but it doesn't seem to be contacting a server to do it...\nUse the official swagger-parser for Java.\nUse the unofficial swagger-parser for JavaScript (browser or Node).\n\n\nor validate that an implementation of this spec would produce JSON which is valid regarding your JSON schemas?\n\nIn other words, here's some JSON from a request or response body, is it correct?\nSwagger relies on another standard called JSON Schema for its schema objects, which are what actually describes the JSON (rather than endpoints or metadata). Swagger uses a subset of JSON Schema (missing: oneOf, patternProperties, among others). To that end, you can use a JSON Schema validator. There are 37 listed here; I'll give a shoutout to this online validator that also supports YAML schemas.\nBut, when I said Swagger relies on a subset of JSON API, I lied. There are a handful of fixed fields that have special meaning in Swagger that's not part of JSON Schema. One of them is discriminator which is used for polymorphism. I am not aware of a Swagger validator that can process discriminator. There are a fair number of tools for swagger and some claim to do validations, but many are abandonware, meant for old versions, not feature-complete, tied to other technologies, and so on. If there's a mature and well-maintained library that I'm missing, I'd love to know.\n",
            "\nThis is a known issue with Spring-Fox. See Issue #755. Based on zdila's comment 2 at this time alternative is to add @ApiImplicitParams which is not ideal but it does work.\n@ApiImplicitParams({\n    @ApiImplicitParam(name = \"page\", dataType = \"integer\", paramType = \"query\",\n            value = \"Results page you want to retrieve (0..N)\"),\n    @ApiImplicitParam(name = \"size\", dataType = \"integer\", paramType = \"query\",\n            value = \"Number of records per page.\"),\n    @ApiImplicitParam(name = \"sort\", allowMultiple = true, dataType = \"string\", paramType = \"query\",\n            value = \"Sorting criteria in the format: property(,asc|desc). \" +\n                    \"Default sort order is ascending. \" +\n                    \"Multiple sort criteria are supported.\")\n})\n\n[\n1 https://github.com/springfox/springfox/issues/755\n2 https://github.com/springfox/springfox/issues/755#issuecomment-135059871\n"
        ],
        "answer": "A2",
        "tags": [
            "json",
            "swagger",
            "swagger-ui",
            "jsonschema",
            "swagger-editor"
        ]
    },
    {
        "question_id": "34767635",
        "question": "\nI would like to print out a dataframe in Excel. I am using ExcelWriter as follows: \nwriter = pd.ExcelWriter('test.xlsx')\ndf = DataFrame(C,ind)    # C is the matrix and ind is the list of corresponding indices \ndf.to_excel(writer, startcol = 0, startrow = 5)\nwriter.save()\n\nThis produces what I need but in addition I would like to add a title with some text (explanations) for the data on top of the table (startcol=0 ,startrow=0).\nHow can I add a string title using ExcelWriter? \n",
        "all_answers": [
            "\nThere is a way to make it more pythonic (works with three or more letters and uses less magic numbers):\ndef col2num(col):\n    num = 0\n    for c in col:\n        if c in string.ascii_letters:\n            num = num * 26 + (ord(c.upper()) - ord('A')) + 1\n    return num\n\nAnd as a one-liner using reduce (does not check input and is less readable so I don't recommend it):\ncol2num = lambda col: reduce(lambda x, y: x*26 + y, [ord(c.upper()) - ord('A') + 1 for c in col])\n\n",
            "\nThis will do the trick:\nIn[16]: sheet = writer.sheets['Sheet1'] #change this to your own\nIn[17]: sheet.write(0,0,\"My documentation text\")\nIn[18]: writer.save()\n\n",
            "\nYou should be able to write text in a cell with the write_string method, adding some reference to XlsxWriter to your code:\nwriter = pd.ExcelWriter('test.xlsx')\ndf = DataFrame(C,ind)    # C is the matrix and ind is the list of corresponding indices \ndf.to_excel(writer, startcol = 0, startrow = 5)\n\nworksheet = writer.sheets['Sheet1']\nworksheet.write_string(0, 0, 'Your text here')\n\nwriter.save()\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "excel",
            "pandas",
            "dataframe",
            "xlsx"
        ]
    },
    {
        "question_id": "21262309",
        "question": "\nWhen writing RSpec tests, I find myself writing a lot of code that looks like this in order to ensure that a method was called during the execution of a test (for the sake of argument, let's just say I can't really interrogate the state of the object after the call because the operation the method performs is not easy to see the effect of).\ndescribe \"#foo\"\n  it \"should call 'bar' with appropriate arguments\" do\n    called_bar = false\n    subject.stub(:bar).with(\"an argument I want\") { called_bar = true }\n    subject.foo\n    expect(called_bar).to be_true\n  end\nend\n\nWhat I want to know is: Is there a nicer syntax available than this? Am I missing some funky RSpec awesomeness that would reduce the above code down to a few lines? should_receive sounds like it should do this but reading further it sounds like that's not exactly what it does. \n",
        "all_answers": [
            "\nit \"should call 'bar' with appropriate arguments\" do\n  expect(subject).to receive(:bar).with(\"an argument I want\")\n  subject.foo\nend\n\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThe below should work\ndescribe \"#foo\"\n  it \"should call 'bar' with appropriate arguments\" do\n     subject.stub(:bar)\n     subject.foo\n     expect(subject).to have_received(:bar).with(\"Invalid number of arguments\")\n  end\nend\n\nDocumentation: https://github.com/rspec/rspec-mocks#expecting-arguments\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "rspec"
        ]
    },
    {
        "question_id": "3392993",
        "question": "\nCan someone show me how to get the youtube id out of a url regardless of what other GET variables are in the URL.\nUse this video for example: http://www.youtube.com/watch?v=C4kxS1ksqtw&feature=related\nSo between v= and before the next &\n",
        "all_answers": [
            "\nif (preg_match('![?&]{1}v=([^&]+)!', $url . '&', $m))\n    $video_id = $m[1];\n\n",
            "\nUse parse_url() and parse_str().\n(You can use regexes for just about anything, but they are very easy to make an error in, so if there are PHP functions specifically for what you are trying to accomplish, use those.)\nparse_url takes a string and cuts it up into an array that has a bunch of info. You can work with this array, or you can specify the one item you want as a second argument. In this case we're interested in the query, which is PHP_URL_QUERY.\nNow we have the query, which is v=C4kxS1ksqtw&feature=relate, but we only want the part after v=. For this we turn to parse_str which basically works like GET on a string. It takes a string and creates the variables specified in the string. In this case $v and $feature is created. We're only interested in $v.\nTo be safe, you don't want to just store all the variables from the parse_url in your namespace (see mellowsoon's comment). Instead store the variables as elements of an array, so that you have control over what variables you are storing, and you cannot accidentally overwrite an existing variable.\nPutting everything together, we have:\n<?php\n$url = \"http://www.youtube.com/watch?v=C4kxS1ksqtw&feature=relate\";\nparse_str( parse_url( $url, PHP_URL_QUERY ), $my_array_of_vars );\necho $my_array_of_vars['v'];    \n  // Output: C4kxS1ksqtw\n?> \n\nWorking example\n\nEdit:\nhehe - thanks Charles. That made me laugh, I've never seen the Zawinski quote before:\nSome people, when confronted with a problem, think ‘I know, I’ll use regular expressions.’  Now they have two problems.\n– Jamie Zawinski\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "regex"
        ]
    },
    {
        "question_id": "26372198",
        "question": "\nFor testing and debugging I am trying to put the content of Dictionary to a String. But have no clue hows it going to achieve. Is it possible? If yes, how.\nDictionary is fetched from web service so I have no idea the key values it have. I want to use the data in app. \nIn Objective C %@ was enough to store anything in NSString.\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nJust use the description property of CustomStringConvertible as\n\nNote: Prior to Swift 3 (or perhaps before), CustomStringConvertible was known as Printable.\n",
            "\nYou can just print a dictionary directly without embedding it into a string:\nlet dict = [\"foo\": \"bar\", \"answer\": \"42\"]\n\nprintln(dict)\n// [foo: bar, answer: 42]\n\nOr you can embed it in a string like this:\nlet dict = [\"foo\": \"bar\", \"answer\": \"42\"]\n\nprintln(\"dict has \\(dict.count) items: \\(dict)\")\n  // dict has 2 items: [foo: bar, answer: 42]\n\n"
        ],
        "answer": "A4",
        "tags": [
            "swift",
            "ios8"
        ]
    },
    {
        "question_id": "26915193",
        "question": "\nHow can I find the vue.js component corresponding to a DOM element?\nIf I have\nelement = document.getElementById(id);\n\nIs there a vue method equivalent to the jQuery\n$(element)\n\n",
        "all_answers": [
            "\nThe proper way to do with would be to use the v-el directive to give it a reference. Then you can do this.$$[reference].\nUpdate for vue 2\nIn Vue 2 refs are used for both elements and components: http://vuejs.org/guide/migration.html#v-el-and-v-ref-replaced\n",
            "\nTry make-runnable.\nIn db.js, add require('make-runnable'); to the end.\nNow you can do:\nnode db.js init\n\nAny further args would get passed to the init method, in the form of a list or key-value pairs.\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nAs per the other answers, add the following to someFile.js\nmodule.exports.someFunction = function () {\n  console.log('hi');\n};\n\nYou can then add the following to package.json\n\"scripts\": {\n   \"myScript\": \"node -e 'require(\\\"./someFile\\\").someFunction()'\"\n}\n\nFrom the terminal, you can then call\nnpm run myScript\n\nI find this a much easier way to remember the commands and use them\n",
            "\nIf you want listen an event (i.e OnClick) on an input with \"demo\" id, you can use:\nnew Vue({\n  el: '#demo',\n  data: {\n    n: 0\n  },\n  methods: {\n   onClick: function (e) {\n     console.log(e.target.tagName) // \"A\"\n     console.log(e.targetVM === this) // true\n  }\n }\n})\n\n",
            "\nUpdate 2020 - CLI\nAs @mix3d pointed out you can just run a command where file.js is your file and someFunction is your function optionally followed by parameters separated with spaces\nnpx run-func file.js someFunction \"just some parameter\"\n\nThat's it.\nfile.js called in the example above\nconst someFunction = (param) => console.log('Welcome, your param is', param)\n\n// exporting is crucial\nmodule.exports = { someFunction }\n\nMore detailed description\nRun directly from CLI (global)\nInstall\nnpm i -g run-func\n\nUsage i.e. run function \"init\", it must be exported, see the bottom\nrun-func db.js init\n\nor\nRun from package.json script (local)\nInstall\nnpm i -S run-func\n\nSetup\n\"scripts\": {\n   \"init\": \"run-func db.js init\"\n}\n\nUsage\nnpm run init\n\nParams\nAny following arguments will be passed as function parameters init(param1, param2)\nrun-func db.js init param1 param2\n\nImportant\nthe function (in this example init) must be exported in the file containing it\nmodule.exports = { init };\n\nor ES6 export\nexport { init };\n\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "html",
            "node.js",
            "vue.js",
            "dom"
        ]
    },
    {
        "question_id": "4037795",
        "question": "\nIs there an easy way to add padding between the checkbox in a CheckBox control, and the associated text?\nI cannot just add leading spaces, because my label is multi-line.\nAs-is, the text is way too close to the checkbox:\n\n",
        "all_answers": [
            "\nI hate to answer my own question, but in this case I think I need to.  After checking it out, @Falmarri was on the right track with his answer.  The problem is that Android's CheckBox control already uses the android:paddingLeft property to get the text where it is.\nThe red line shows the paddingLeft offset value of the entire CheckBox\n\nIf I just override that padding in my XML layout, it messes up the layout.  Here's what setting paddingLeft=\"0\" does:\n\nTurns out you can't fix this in XML.  You have do it in code.  Here's my snippet with a hardcoded padding increase of 10dp.\nfinal float scale = this.getResources().getDisplayMetrics().density;\ncheckBox.setPadding(checkBox.getPaddingLeft() + (int)(10.0f * scale + 0.5f),\n        checkBox.getPaddingTop(),\n        checkBox.getPaddingRight(),\n        checkBox.getPaddingBottom());\n\nThis gives you the following, where the green line is the increase in padding.  This is safer than hardcoding a value, since different devices could use different drawables for the checkbox.\n\nUPDATE - As people have recently mentioned in answers below, this behavior has apparently changed in Jelly Bean (4.2).  Your app will need to check which version its running on, and use the appropriate method.\nFor 4.3+ it is simply setting padding_left. See htafoya's answer for details.\n",
            "\nYes, you can add padding by adding padding.\nandroid:padding=5dp\n",
            "\nAnswer 2:\nA very simple answer:\nUse on OnClickListener instead of OnCheckedChangeListener\n    someCheckBox.setOnClickListener(new OnClickListener(){\n\n        @Override\n        public void onClick(View v) {\n            // you might keep a reference to the CheckBox to avoid this class cast\n            boolean checked = ((CheckBox)v).isChecked();\n            setSomeBoolean(checked);\n        }\n\n    });\n\nNow you only pick up click events and don't have to worry about programmatic changes.\n\nAnswer 1:\nI have created a wrapper class (see Decorator Pattern) which handles this problem in an encapsulated way:\npublic class BetterCheckBox extends CheckBox {\n    private CompoundButton.OnCheckedChangeListener myListener = null;\n    private CheckBox myCheckBox;\n\n    public BetterCheckBox(Context context) {\n        super(context);\n    }\n\n    public BetterCheckBox(Context context, CheckBox checkBox) {\n        this(context);\n        this.myCheckBox = checkBox;\n    }\n\n    // assorted constructors here...    \n\n    @Override\n    public void setOnCheckedChangeListener(\n        CompoundButton.OnCheckedChangeListener listener){\n        if(listener != null) {\n            this.myListener = listener;\n        }\n        myCheckBox.setOnCheckedChangeListener(listener);\n    }\n\n    public void silentlySetChecked(boolean checked){\n        toggleListener(false);\n        myCheckBox.setChecked(checked);\n        toggleListener(true);\n    }\n\n    private void toggleListener(boolean on){\n        if(on) {\n            this.setOnCheckedChangeListener(myListener);\n        }\n        else {\n            this.setOnCheckedChangeListener(null);\n        }\n    }\n}\n\nCheckBox can still be declared the same in XML, but use this when initializing your GUI in code:\nBetterCheckBox myCheckBox;\n\n// later...\nmyCheckBox = new BetterCheckBox(context,\n    (CheckBox) view.findViewById(R.id.my_check_box));\n\nIf you want to set checked from code without triggering the listener, call  myCheckBox.silentlySetChecked(someBoolean) instead of setChecked.\n",
            "\n<CheckBox\n        android:paddingRight=\"12dip\" />\n\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "checkbox",
            "padding"
        ]
    },
    {
        "question_id": "7637144",
        "question": "\nDid anybody have similar problem with this, I import android project and I get \nerrors like \n[2011-10-03 17:20:09 - Screen] Android requires compiler compliance level 5.0 or 6.0. Found '1.7' instead. Please use Android Tools > Fix Project Properties.\n[2011-10-03 17:21:55 - App] Android requires compiler compliance level 5.0 or 6.0. Found '1.7' instead. Please use Android Tools > Fix Project Properties.\n[2011-10-03 17:21:59 - App] Android requires compiler compliance level 5.0 or 6.0. Found '1.7' instead. Please use Android Tools > Fix Project Properties.\n\nI got errors to delete all @Override above functions. I have Windows 7 x64, jvm7 x64. Does anyone have clue what is wrong ?( I done Android Tools -> Fix Project Properties but didn;t help )\n",
        "all_answers": [
            "\nThat isn't the problem, Jack. Android SDK isn't x64, but works ok with x64 jvm (and x64 eclipse IDE).\nAs helios said, you must set project compatibility to Java 5.0 or Java 6.0.\nTo do that, 2 options: \n\nRight-click on your project and select \"Android Tools -> Fix\nProject Properties\" (if this din't work, try second option)\nRight-click on your project and select \"Properties -> Java\n    Compiler\", check \"Enable project specific settings\" and select\n1.5 or 1.6 from \"Compiler compliance settings\" select box.\n\n",
            "\nI would recommend using x86 version of jvm. When I first got my new laptop (x64), I wanted to go x64 all the way (jvm, jdk, jre, eclipse, etc..). But once I finished setting everything up I realized that the Android SDK wasn't x64, so I had issues. Go back to x86 jvm and you should be ok.\nEDIT: 11/14/13\nI've seen some recent activity and figured I would elaborate a little more.\nI did not say it would not work with x64, I just recommended using x86.\nHere is a good post on the advantages / disadvantages of x64 JDK. Benefits of 64bit Java platform\nThought process: To what end? Why am I trying to using 64 bit JDK? Just because I have a 64-bit OS? Do I need any of the features of 64-bit JDK? Are there any extra features in the 64-bit JDK?! Why won't this s*** play nice together!? F*** it I'm going 32-bit.\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n"
        ],
        "answer": "A1",
        "tags": [
            "java",
            "android"
        ]
    },
    {
        "question_id": "23767489",
        "question": "\nI know a common characteristic of the file names of a number of unwanted files on my Windows computer. How can I remove all of these files from a given folder or folder hierarchy with a single regular expression PowerShell command?\n",
        "all_answers": [
            "\nYou could specify the directory to open when starting PowerShell:\npowershell.exe -NoExit -command \"& {Set-Location $env:systemroot}\"\n\nJust use it in your shortcut.\nOr use a profile to set a start directory.\n",
            "\nYou can use the command,\nls -name | select-string -pattern \".*\\(\\d+\\).*\" | %{rm $_}\n\nWhere the content of the quotation marks is your regular expression. The regex in this example searches for files that have (#) in the file name, where # is any nonnegative integer. This is useful for deleting duplicates in a folder where the same set of files have been dumped many times, such as by a music manager.\nIf you add a -r after the -name\nls -name -r | select-string -pattern \".*\\(\\d+\\).*\" | %{rm $_}\n\nit will recurse through subfolders and delete matching files in all subfolders.\nThe structure of the command is as follows:\n\nls is an alias for the powershell command get-childitem. It lists all elements in the current folder. The -name argument specifies that only the names are to be produced; I don't want other information like file size.\nselect-string is mostly equivalent to UNIX grep, where it matches a pattern (regex) to a bunch of line-separated strings. The -pattern parameter sets the cmdlet up to take a regex.\n%{rm $} is a foreach loop. It is saying, \"for each line piped into me (from select-string in this case)\", do the following action, where $ is the given line. In this case we are rm-ing the item, where rm is an alias for Remove-Item.\n\n",
            "\nYou can pipe a Get-ChildItem command through a Where-Object filter that accepts a RegEx pattern, and then pipe that into Remove-Item. I think that will get you a faster, and better result than using Select-String. With a command like:\nGet-ChildItem $Path | Where{$_.Name -Match \"<RegEx Pattern>\"} | Remove-Item\n\nThe Name attribute will only match the name of the file or folder, along with a file's extension. It will not match against other things along the path. This will pass a FileInfo object down the pipe, which Remove-Item takes as piped input and will remove the files in question.\nIf you want to include sub folders of your path you would add the -Recurse switch to your Get-ChildItem command, and it would look like this:\nGet-ChildItem $Path -Recurse | Where{$_.Name -Match \"<RegEx Pattern>\"} | Remove-Item\n\nIf you only want to delete files you can specify that in the Where statement by looking at the FileInfo object's PSIsContainer property and inverting it by prefixing the object with an exclamation point like such:\nGet-ChildItem $Path -Recurse | Where{$_.Name -Match \"<RegEx Pattern>\" -and !$_.PSIsContainer} | Remove-Item\n\n"
        ],
        "answer": "A3",
        "tags": [
            "regex",
            "windows",
            "file",
            "powershell",
            "file-io"
        ]
    },
    {
        "question_id": "533256",
        "question": "\nI have a table constructed like this :\noid | identifier | value\n1   | 10         | 101\n2   | 10         | 102\n3   | 20         | 201\n4   | 20         | 202\n5   | 20         | 203\n\nI'd like to query this table to get a result like this :\nidentifier | values[]\n10         | {101, 102}\n20         | {201, 202, 203}\n\nI can't figure a way to do that.\nIs that possible? How?\n",
        "all_answers": [
            "\nThis is a Postgres built-in since a few versions so you no longer need to define your own, the name is array_agg().\ntest=> select array_agg(n) from generate_series(1,10) n group by n%2;\n  array_agg   \n--------------\n {1,3,5,7,9}\n {2,4,6,8,10}\n\n(this is Postgres 8.4.8).\nNote that no ORDER BY is specified, so the order of the result rows depends on the grouping method used (here, hash) ie, it is not defined. Example:\ntest=> select n%2, array_agg(n) from generate_series(1,10) n group by (n%2);\n ?column? |  array_agg   \n----------+--------------\n        1 | {1,3,5,7,9}\n        0 | {2,4,6,8,10}\n\ntest=> select (n%2)::TEXT, array_agg(n) from generate_series(1,10) n group by (n%2)::TEXT;\n text |  array_agg   \n------+--------------\n 0    | {2,4,6,8,10}\n 1    | {1,3,5,7,9}\n\nNow, I don't know why you get {10,2,4,6,8} and {9,7,3,1,5}, since generate_series() should send the rows in order.\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nYou have to create an aggregate function, e.g.\nCREATE AGGREGATE array_accum (anyelement)\n(\nsfunc = array_append,\nstype = anyarray,\ninitcond = '{}'\n);\n\nthen\nSELECT identifier, array_accum(value) AS values FROM table GROUP BY identifier;\n\nHTH\n"
        ],
        "answer": "A1",
        "tags": [
            "sql",
            "postgresql"
        ]
    },
    {
        "question_id": "14940743",
        "question": "\n\n\n\nI would like to create views or dataframes from an existing dataframe based on column selections.\nFor example, I would like to create a dataframe df2 from a dataframe df1 that holds all columns from it except two of them. I tried doing the following, but it didn't work:\nimport numpy as np\nimport pandas as pd\n\n# Create a dataframe with columns A,B,C and D\ndf = pd.DataFrame(np.random.randn(100, 4), columns=list('ABCD'))\n\n# Try to create a second dataframe df2 from df with all columns except 'B' and D\nmy_cols = set(df.columns)\nmy_cols.remove('B').remove('D')\n\n# This returns an error (\"unhashable type: set\")\ndf2 = df[my_cols]\n\nWhat am I doing wrong? Perhaps more generally, what mechanisms does pandas have to support the picking and exclusions of arbitrary sets of columns from a dataframe?\n",
        "all_answers": [
            "\nYou don't really need to convert that into a set:\ncols = [col for col in df.columns if col not in ['B', 'D']]\ndf2 = df[cols]\n\n",
            "\nYou can either Drop the columns you do not need OR Select the ones you need\n# Using DataFrame.drop\ndf.drop(df.columns[[1, 2]], axis=1, inplace=True)\n\n# drop by Name\ndf1 = df1.drop(['B', 'C'], axis=1)\n\n# Select the ones you want\ndf1 = df[['a','d']]\n\n",
            "\nAlso have a look into the built-in DataFrame.filter function.\nMinimalistic but greedy approach (sufficient for the given df):\n\ndf.filter(regex=\"[^BD]\")\n\nConservative/lazy approach (exact matches only):\ndf.filter(regex=\"^(?!(B|D)$).*$\")\n\nConservative and generic:\nexclude_cols = ['B','C']\ndf.filter(regex=\"^(?!({0})$).*$\".format('|'.join(exclude_cols)))\n\n",
            "\nYou just need to convert your set to a list\nimport pandas as pd\ndf = pd.DataFrame(np.random.randn(100, 4), columns=list('ABCD'))\nmy_cols = set(df.columns)\nmy_cols.remove('B')\nmy_cols.remove('D')\nmy_cols = list(my_cols)\ndf2 = df[my_cols]\n\n",
            "\nHere's how to create a copy of a DataFrame excluding a list of columns:\ndf = pd.DataFrame(np.random.randn(100, 4), columns=list('ABCD'))\ndf2 = df.drop(['B', 'D'], axis=1)\n\nBut be careful! You mention views in your question, suggesting that if you changed df, you'd want df2 to change too. (Like a view would in a database.)\nThis method doesn't achieve that:\n>>> df.loc[0, 'A'] = 999 # Change the first value in df\n>>> df.head(1)\n     A         B         C         D\n0  999 -0.742688 -1.980673 -0.920133\n>>> df2.head(1) # df2 is unchanged. It's not a view, it's a copy!\n          A         C\n0  0.251262 -1.980673\n\nNote also that this is also true of @piggybox's method. (Although that method is nice and slick and Pythonic. I'm not doing it down!!)\nFor more on views vs. copies see this SO answer and this part of the Pandas docs which that answer refers to.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "pandas",
            "dataframe"
        ]
    },
    {
        "question_id": "725556",
        "question": "\nHow can I merge two MySQL tables that have the same structure?\nThe primary keys of the two tables will clash, so I have take that into account.\n",
        "all_answers": [
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nIt depends on the semantic of the primary key. If it's just autoincrement, then use something like:\ninsert into table1 (all columns except pk)\nselect all_columns_except_pk \nfrom table2;\n\nIf PK means something, you need to find a way to determine which record should have priority. You could create a select query to find duplicates first (see answer by cpitis). Then eliminate the ones you don't want to keep and use the above insert to add records that remain.\n",
            "\nINSERT\nINTO    first_table f\nSELECT  *\nFROM    second_table s\nON DUPLICATE KEY\nUPDATE\n        s.column1 = DO_WHAT_EVER_MUST_BE_DONE_ON_KEY_CLASH(f.column1)\n\n",
            "\nYou can also try:\nINSERT IGNORE\n  INTO table_1 \nSELECT *\n  FROM table_2\n     ;\n\nwhich allows those rows in table_1 to supersede those in table_2 that have a matching primary key, while still inserting rows with new primary keys.\nAlternatively, \nREPLACE\n   INTO table_1\n SELECT *\n   FROM table_2\n      ;\n\nwill update those rows already in table_1 with the corresponding row from table_2, while inserting rows with new primary keys.\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nIf you need to do it manually, one time:\nFirst, merge in a temporary table, with something like:\ncreate table MERGED as select * from table 1 UNION select * from table 2\n\nThen, identify the primary key constraints with something like\nSELECT COUNT(*), PK from MERGED GROUP BY PK HAVING COUNT(*) > 1\n\nWhere PK is the primary key field...\nSolve the duplicates.\nRename the table.\n[edited - removed brackets in the UNION query, which was causing the error in the comment below]\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n"
        ],
        "answer": "A4",
        "tags": [
            "sql",
            "mysql",
            "merge"
        ]
    },
    {
        "question_id": "3710204",
        "question": "\nisJsonString('{ \"Id\": 1, \"Name\": \"Coke\" }')\n\nshould be true and\nisJsonString('foo')\nisJsonString('<div>foo</div>')\n\nshould be false.\nI'm looking for a solution that doesn't use try/catch because I have my debugger set to \"break on all errors\" and that causes it to break on invalid JSON strings.\n",
        "all_answers": [
            "\nIn prototypeJS, we have method isJSON. You can try that. Even json might help.\n\"something\".isJSON();\n// -> false\n\"\\\"something\\\"\".isJSON();\n// -> true\n\"{ foo: 42 }\".isJSON();\n// -> false\n\"{ \\\"foo\\\": 42 }\".isJSON();\n// -> true\n\n",
            "\nYou can use the javascript eval() function to verify if it's valid.\ne.g.\nvar jsonString = '{ \"Id\": 1, \"Name\": \"Coke\" }';\nvar json;\n\ntry {\n  json = eval(jsonString);\n} catch (exception) {\n  //It's advisable to always catch an exception since eval() is a javascript executor...\n  json = null;\n}\n\nif (json) {\n  //this is json\n}\n\nAlternatively, you can use JSON.parse function from json.org:\ntry {\n  json = JSON.parse(jsonString);\n} catch (exception) {\n  json = null;\n}\n\nif (json) {\n  //this is json\n}\n\nHope this helps.\nWARNING: eval() is dangerous if someone adds malicious JS code, since it will execute it. Make sure the JSON String is trustworthy, i.e. you got it from a trusted source.\nEdit For my 1st solution, it's recommended to do this.\n try {\n      json = eval(\"{\" + jsonString + \"}\");\n    } catch (exception) {\n      //It's advisable to always catch an exception since eval() is a javascript executor...\n      json = null;\n    }\n\nTo guarantee json-ness. If the jsonString isn't pure JSON, the eval will throw an exception.\n",
            "\nUse a JSON parser like JSON.parse:\nfunction isJsonString(str) {\n    try {\n        JSON.parse(str);\n    } catch (e) {\n        return false;\n    }\n    return true;\n}\n\n",
            "\nA comment first. The question was about not using try/catch.\nIf you do not mind to use it, read the answer below.\nHere we just check a JSON string using a regexp, and it will work in most cases, not all cases.\nHave a look around the line 450 in https://github.com/douglascrockford/JSON-js/blob/master/json2.js\nThere is a regexp that check for a valid JSON, something like:\nif (/^[\\],:{}\\s]*$/.test(text.replace(/\\\\[\"\\\\\\/bfnrtu]/g, '@').\nreplace(/\"[^\"\\\\\\n\\r]*\"|true|false|null|-?\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d+)?/g, ']').\nreplace(/(?:^|:|,)(?:\\s*\\[)+/g, ''))) {\n\n  //the json is ok\n\n}else{\n\n  //the json is not ok\n\n}\n\nEDIT: The new version of json2.js makes a more advanced parsing than above, but still based on a regexp replace ( from the comment of @Mrchief )\n"
        ],
        "answer": "A4",
        "tags": [
            "javascript",
            "json"
        ]
    },
    {
        "question_id": "27809342",
        "question": "\nI have the following two Models:\nclass Store < ActiveRecord::Base\n    belongs_to :person\nend\n\nclass Person < ActiveRecord::Base\n    has_one :store\nend\n\nHere is the issue: I am trying to create a migration to create the foreign key within the people table. However, the column referring to the foreign key of Store is not named store_id as would be rails convention but is instead named foo_bar_store_id.  \nIf I was following the rails convention I would do the migration like this:\nclass AddReferencesToPeople < ActiveRecord::Migration\n  def change\n    add_reference :people, :store, index: true\n  end\nend\n\nHowever this will not work because the column name is not store_id but is foo_bar_store_id.  So how do I specify that the foreign key name is just different, but still maintain index: true to maintain fast performance?\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nEDIT: For those that see the tick and don't continue reading!\nWhile this answer achieves the goal of having an unconventional foreign key column name, with indexing, it does not add a fk constraint to the database. See the other answers for more appropriate solutions using add_foreign_key and/or 'add_reference'.\nNote: ALWAYS look at the other answers, the accepted one is not always the best!\nOriginal answer:\nIn your AddReferencesToPeople migration you can manually add the field and index using:\nadd_column :people, :foo_bar_store_id, :integer\nadd_index :people, :foo_bar_store_id\n\nAnd then let your model know the foreign key like so:  \nclass Person < ActiveRecord::Base\n  has_one :store, foreign_key: 'foo_bar_store_id'\nend\n\n",
            "\nUnder the covers add_reference is just delegating to add_column and add_index so you just need to take care of it yourself:\nadd_column :people, :foo_bar_store_id, :integer\nadd_index :people, :foo_bar_store_id\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "rails-migrations"
        ]
    },
    {
        "question_id": "22340258",
        "question": "\nIn my model, I want a field that has a list of triplets. e.g. [[1, 3, 4], [4, 2, 6], [8, 12, 3], [3, 3, 9]]. Is there a field that can store this data in the database?\n",
        "all_answers": [
            "\nYou can flatten the list and then store the values to a CommaSeparatedIntegerField. When you read back from the database, just group the values back into threes.\nDisclaimer: according to database normalization theory, it is better not to store collections in single fields; instead you would be encouraged to store the values in those triplets in their own fields and link them via foreign keys. In the real world, though, sometimes that is too cumbersome/slow.\n",
            "\nYou can convert it into string by using JSON and store it as string.\nFor example,\nIn [3]: json.dumps([[1, 3, 4], [4, 2, 6], [8, 12, 3], [3, 3, 9]])\n\nOut[3]: '[[1, 3, 4], [4, 2, 6], [8, 12, 3], [3, 3, 9]]'\n\nYou can add a method into your class to convert it automatically for you.\nimport json\n\n\nclass Foobar(models.Model):\n    foo = models.CharField(max_length=200)\n\n    def set_foo(self, x):\n        self.foo = json.dumps(x)\n\n    def get_foo(self):\n        return json.loads(self.foo)\n\nIf you're using Django 1.9 or above, and you use postgresql, there is a new class called JSONField, you should use it instead. Here is a link to it\nThere is a good talk about PostgreSQL JSONs and Arrays on youtube. Watch it, it has very good information.\n",
            "\nI think it will help you.\nfrom django.db import models\nimport ast\n\nclass ListField(models.TextField):\n    __metaclass__ = models.SubfieldBase\n    description = \"Stores a python list\"\n\n    def __init__(self, *args, **kwargs):\n        super(ListField, self).__init__(*args, **kwargs)\n\n    def to_python(self, value):\n        if not value:\n            value = []\n\n        if isinstance(value, list):\n            return value\n\n        return ast.literal_eval(value)\n\n    def get_prep_value(self, value):\n        if value is None:\n            return value\n\n        return unicode(value)\n\n    def value_to_string(self, obj):\n        value = self._get_val_from_obj(obj)\n        return self.get_db_prep_value(value)\n\nclass ListModel(models.Model):\n    test_list = ListField()\n\nExample :\n>>> ListModel.objects.create(test_list= [[1,2,3], [2,3,4,4]])\n<ListModel: ListModel object>\n>>> ListModel.objects.get(id=1)\n<ListModel: ListModel object>\n>>> o = ListModel.objects.get(id=1)\n>>> o.id\n1L\n>>> o.test_list\n[[1, 2, 3], [2, 3, 4, 4]]\n>>> \n\n"
        ],
        "answer": "A2",
        "tags": [
            "django",
            "django-orm"
        ]
    },
    {
        "question_id": "14319347",
        "question": "\nWhat's the difference between @title and title? Since both of them can be variable names. Also, how do I decide which kind of variable I should use? With @ or not? \n",
        "all_answers": [
            "\nThe difference is in the scope of the variable. The @version is available to all methods of the class instance.\nThe short answer, if you're in the controller and you need to make the variable available to the view then use @variable.\nFor a much longer answer try this: http://www.ruby-doc.org/docs/ProgrammingRuby/html/tut_classes.html\n",
            "\n@ variables are instance variables, without are local variables.\nRead more at http://ruby.about.com/od/variables/a/Instance-Variables.htm\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\ntitle is a local variable. They only exists within its scope (current block)\n@title is an instance variable - and is available to all methods within the class.\nYou can read more here:\nhttp://strugglingwithruby.blogspot.dk/2010/03/variables.html\nIn Ruby on Rails - declaring your variables in your controller as instance variables (@title) makes them available to your view.\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A4",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "variables"
        ]
    },
    {
        "question_id": "9618774",
        "question": "\nWhen I run my selenium test (mvn test) from jenkins (windows) I see only the console output. I don't see the real browsers getting opened . How can I configure jenkins so that I can see the browsers running the test?\n",
        "all_answers": [
            "\nOn Windows (with Windows Service).\nEdit the file C:\\Program Files (x86)\\Jenkins\\jenkins.xml with 8083 if you want 8083 port.\n<arguments>-Xrs -Xmx256m -Dhudson.lifecycle=hudson.lifecycle.WindowsServiceLifecycle -jar \"%BASE%\\jenkins.war\" --httpPort=8083</arguments>\n\n",
            "\nFor the benefit of Linux users who find themselves here: I found /etc/sysconfig/jenkins has a JENKINS_PORT=\"8080\", which you should probably change too.\n",
            "\nOn Debian 11 it ignores /etc/default/jenkins file.\nInstead you open /usr/lib/systemd/system/jenkins.service file and replace http-port there in the string:\nEnvironment=\"JENKINS_PORT=8080\"\n\n",
            "\nI got the solution. I ran jenkins from command prompt as \"java -jar jenkins.war\" instead of the windows installer version. Now I can see my browser based tests being executed.\n",
            "\nUse the following command at command prompt:\njava -jar jenkins.war --httpPort=9090\n\nIf you want to use https use the following command:\njava -jar jenkins.war --httpsPort=9090\n\nDetails are here\n",
            "\nIn CentOS/RedHat (assuming you installed the jenkins package)\nvim /etc/sysconfig/jenkins\n....\n# Port Jenkins is listening on.\n# Set to -1 to disable\n#\nJENKINS_PORT=\"8080\"\n\nchange it to any port you want.\n",
            "\nIf you are already doing what @Sachin suggests in a comment (i.e. looking at the machine where Jenkins actually runs) and still do not see the browsers, then your problem may be the following:\nIf you run Jenkins as a service in the background it won't open apps in the foreground. You may either try to run it not as a service in the foreground, or run it as a Local System account and check Allow the service to interact with desktop option. In the latter case you may get into permission problems, though.\nUpdate: To make sure this answer is understood properly by others: Jenkins Windows 'native' installation is not really native. It's a wrapper around Java that runs it as a service. \n",
            "\nWith Ubuntu 14.4 I had to change the file /etc/default/jenkins\nE.g.\n   #HTTP_PORT=8080\n   HTTP_PORT=8083\n\nand restart the service \n\nservice jenkins restart\n\n",
            "\nOpen the jenkins.xml in the jenkins home folder (usually C:\\Program Files (x86)\\Jenkins) and change the port number:\nhttpPort=xxxx\nto\nhttpPort=yyyy\n\nthen restart the service. it should change the setting permanently.\n"
        ],
        "answer": "A4",
        "tags": [
            "windows",
            "maven",
            "selenium",
            "jenkins",
            "webdriver"
        ]
    },
    {
        "question_id": "18334851",
        "question": "\nI am using the Bootstrap framework for my UI. I want to change the color of my glyphicons to blue, but not in all places. In some places it should use the default color.\nI have referred to these two links, but I am not finding anything helpful.\n\nCan I add color to bootstrap icons only using CSS?\nHow do I change Bootstrap 3's glyphicons to white?\n\nPlease note: I am using Bootstrap 2.3.2.\n",
        "all_answers": [
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nThe icon will adopt the color from value of the color css property of it's parent.\nYou can either add this directly to the style:\n<span class=\"glyphicon glyphicon-user\" style=\"color:blue\"></span>\n\nOr you can add it as a class to your icon and then set the font color to it in CSS\nHTML \n<span class=\"glyphicon glyphicon-search\"></span>\n<span class=\"glyphicon glyphicon-user blue\"></span>\n<span class=\"glyphicon glyphicon-trash\"></span>\n\nCSS\n.blue {\n    color: blue;\n}\n\nThis fiddle has an example.\n",
            "\nFinally I found answer myself. To add new icons in 2.3.2 bootstrap we have to add Font Awsome css in you file. After doing this we can override the styles with css to change the color and size.\n<link href=\"http://netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css\" rel=\"stylesheet\">\n\nCSS\n.brown{color:#9b846b}\n\nIf we want change the color of icon then just add brown class and icon will turn in brown color. It also provide icon of various size.\nHTML\n<p><i class=\"icon-camera-retro icon-large brown\"></i> icon-camera-retro</p> <!--brown class added-->\n<p><i class=\"icon-camera-retro icon-2x\"></i> icon-camera-retro</p>\n<p><i class=\"icon-camera-retro icon-3x\"></i> icon-camera-retro</p>\n<p><i class=\"icon-camera-retro icon-4x\"></i> icon-camera-retro</p>\n\n"
        ],
        "answer": "A4",
        "tags": [
            "html",
            "css",
            "twitter-bootstrap-2"
        ]
    },
    {
        "question_id": "24062285",
        "question": "\nI'd like a UITableView with subtitle-style cells that use dequeueReusableCellWithIdentifier.\nMy original Objective-C code was:\nstatic NSString *reuseIdentifier = @\"Cell\";\nUITableViewCell *cell = [tableView dequeueReusableCellWithIdentifier:reuseIdentifier];\nif(!cell)\n{\n    cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:reuseIdentifier];\n}\n\nAfter searching the few UITableView questions here already on SO, I thought to write it in Swift like so:\ntableView.registerClass(UITableViewCell.classForCoder(), forCellReuseIdentifier: \"Cell\")\n\nlet cell = tableView.dequeueReusableCellWithIdentifier(\"Cell\", forIndexPath: indexPath) as UITableViewCell\n\nBut that doesn't let me say I want a subtitle style.  So I tried this:\nvar cell :UITableViewCell = UITableViewCell(style: UITableViewCellStyle.Subtitle, reuseIdentifier: \"Cell\")\n\nWhich gives me a subtitle cell, but it doesn't let me dequeueReusableCellWithIdentifier.\nI've researched some more and looked at this video tutorial, but he creates a separate subclass of UITableViewCell which I assume is unnecessary as I accomplished this same effect previously in Obj-C.\nAny ideas? Thanks.\n",
        "all_answers": [
            "\nI engage you to look at this little UITableView-Example on Github: https://github.com/YANGReal/UITableView-Swift\nThey do like follows:\nfunc tableView(tableView: UITableView!, cellForRowAtIndexPath indexPath: NSIndexPath!) -> UITableViewCell!\n{\n   let cell = tableView .dequeueReusableCellWithIdentifier(\"cell\", forIndexPath: indexPath) as UITableViewCell\n   cell.textLabel.text = String(format: \"%i\", indexPath.row+1)\n   // set any other property of your cell here\n   return cell\n}\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nKeep in mind that UITableView is defined as an optional in the function, which means your initial cell declaration needs to check for the optional in the property. Also, the returned queued cell is also optional, so ensure you make an optional cast to UITableViewCell. Afterwards, we can force unwrap because we know we have a cell.\nvar cell:UITableViewCell? = \ntableView?.dequeueReusableCellWithIdentifier(reuseIdentifier) as? UITableViewCell\nif (cell == nil)\n{\n   cell = UITableViewCell(style: UITableViewCellStyle.Subtitle, \n                reuseIdentifier: reuseIdentifier)\n}\n// At this point, we definitely have a cell -- either dequeued or newly created,\n// so let's force unwrap the optional into a UITableViewCell\ncell!.detailTextLabel.text = \"some text\"\n\nreturn cell\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "uitableview",
            "swift"
        ]
    },
    {
        "question_id": "581426",
        "question": "\n\n\n\nThe question's pretty self-explanatory really. I know vaguely about vectors in maths, but I don't really see the link to C++ vectors. \n",
        "all_answers": [
            "\nYou can also use vector::insert.\nstd::vector<int> v;\nint a[5] = {2, 5, 8, 11, 14};\n\nv.insert(v.end(), a, a+5);\n\nEdit:\nOf course, in real-world programming you should use:\nv.insert(v.end(), a, a+(sizeof(a)/sizeof(a[0])));  // C++03\nv.insert(v.end(), std::begin(a), std::end(a));     // C++11\n\n",
            "\nSince c++17 you could use the following method:\n#include <iostream>\n#include <vector>\n\nusing namespace std;\n\nvector<int> vec;\ntemplate<typename... T>\nvoid vecPush(const T& ... x) {\n    (vec.push_back(x), ...);\n}\n\nint main() {\n    vecPush(4, 10, 4);\n    for(const auto& a : vec)\n        cout << a << \" \";\n    return 0;\n}\n\n",
            "\nI'd guess it comes from the term row vector. Also, computer scientists love thinking up new names for things...\n",
            "\nMathematical definition of a vector is a member of the set Sn, which is an ordered sequence of values in a specific set (S). This is what a C++ vector stores.\n",
            "\nAlso if you make it store integers or floating points it does make an excellent type for storing N dimensional vectors. After all all a vector is, is a list of numbers kept in a specific order.\n",
            "\nYou can also use Boost.Assignment:\nconst list<int> primes = list_of(2)(3)(5)(7)(11);\n\nvector<int> v; \nv += 1,2,3,4,5,6,7,8,9;\n\n",
            "\nA vector is simply a sequence of values, all of the same type. This is pretty much in line with the use in mathematics. I guess the mathematical idea that vectors should support some common operations (such as adding, and scaling by a scalar) are not carried over, the important aspect is mainly the structure.\n",
            "\nThese are the three most straight forward methods:\n1) Initialize from an initializer list:\nstd::vector<int> TestVector = {2,5,8,11,14};\n\n2) Assign from an initializer list:\nstd::vector<int> TestVector;\nTestVector.assign( {2,5,8,11,14} ); // overwrites TestVector\n\n3) Insert an initializer list at a given point:\nstd::vector<int> TestVector;\n...\nTestVector.insert(end(TestVector), {2,5,8,11,14} ); // preserves previous elements\n\n",
            "\nTry pass array to vector:\nint arr[] = {2,5,8,11,14};\nstd::vector<int> TestVector(arr, arr+5);\n\nYou could always call std::vector::assign to assign array to vector, call std::vector::insert to add multiple arrays.\nIf you use C++11, you can try:\nstd::vector<int> v{2,5,8,11,14};\n\nOr\nstd::vector<int> v = {2,5,8,11,14};\n\n",
            "\nYou can do it with initializer list:\nstd::vector<unsigned int> array;\n\n// First argument is an iterator to the element BEFORE which you will insert:\n// In this case, you will insert before the end() iterator, which means appending value\n// at the end of the vector.\narray.insert(array.end(), { 1, 2, 3, 4, 5, 6 });\n\n"
        ],
        "answer": "A4",
        "tags": [
            "c++",
            "stl",
            "vector"
        ]
    },
    {
        "question_id": "16357999",
        "question": "\nI wrote a function to get a current date and time in format: DD-MM-YYYY HH:MM:SS. It works but let's say, its pretty ugly. How can I do exactly the same thing but simpler?\nstring currentDateToString()\n{\n    time_t now = time(0);\n    tm *ltm = localtime(&now);\n\n    string dateString = \"\", tmp = \"\";\n    tmp = numToString(ltm->tm_mday);\n    if (tmp.length() == 1)\n        tmp.insert(0, \"0\");\n    dateString += tmp;\n    dateString += \"-\";\n    tmp = numToString(1 + ltm->tm_mon);\n    if (tmp.length() == 1)\n        tmp.insert(0, \"0\");\n    dateString += tmp;\n    dateString += \"-\";\n    tmp = numToString(1900 + ltm->tm_year);\n    dateString += tmp;\n    dateString += \" \";\n    tmp = numToString(ltm->tm_hour);\n    if (tmp.length() == 1)\n        tmp.insert(0, \"0\");\n    dateString += tmp;\n    dateString += \":\";\n    tmp = numToString(1 + ltm->tm_min);\n    if (tmp.length() == 1)\n        tmp.insert(0, \"0\");\n    dateString += tmp;\n    dateString += \":\";\n    tmp = numToString(1 + ltm->tm_sec);\n    if (tmp.length() == 1)\n        tmp.insert(0, \"0\");\n    dateString += tmp;\n\n    return dateString;\n}\n\n",
        "all_answers": [
            "\nSince C++11 you could use std::put_time from iomanip header:\n#include <iostream>\n#include <iomanip>\n#include <ctime>\n\nint main()\n{\n    auto t = std::time(nullptr);\n    auto tm = *std::localtime(&t);\n    std::cout << std::put_time(&tm, \"%d-%m-%Y %H-%M-%S\") << std::endl;\n}\n\nstd::put_time is a stream manipulator, therefore it could be used together with std::ostringstream in order to convert the date to a string:\n#include <iostream>\n#include <iomanip>\n#include <ctime>\n#include <sstream>\n\nint main()\n{\n    auto t = std::time(nullptr);\n    auto tm = *std::localtime(&t);\n\n    std::ostringstream oss;\n    oss << std::put_time(&tm, \"%d-%m-%Y %H-%M-%S\");\n    auto str = oss.str();\n\n    std::cout << str << std::endl;\n}\n\n",
            "\nyou can use asctime()  function of time.h to get a string simply .   \ntime_t _tm =time(NULL );\n\nstruct tm * curtime = localtime ( &_tm );\ncout<<\"The current date/time is:\"<<asctime(curtime);\n\nSample output:\nThe current date/time is:Fri Oct 16 13:37:30 2015\n\n",
            "\nNon C++11 solution: With the <ctime> header, you could use strftime. Make sure your buffer is large enough, you wouldn't want to overrun it and wreak havoc later.\n#include <iostream>\n#include <ctime>\n\nint main ()\n{\n  time_t rawtime;\n  struct tm * timeinfo;\n  char buffer[80];\n\n  time (&rawtime);\n  timeinfo = localtime(&rawtime);\n\n  strftime(buffer,sizeof(buffer),\"%d-%m-%Y %H:%M:%S\",timeinfo);\n  std::string str(buffer);\n\n  std::cout << str;\n\n  return 0;\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "string",
            "date",
            "datetime",
            "time"
        ]
    },
    {
        "question_id": "4824829",
        "question": "\nHow can I get the current session id in rails 3?\nI've tried the following with no luck:\nsession[:session_id]\nsession['session_id']\nsession[:id]\nsession['id']\nsession.id\nsession.session_id\n\n",
        "all_answers": [
            "\nHave you tried the following?\nrequest.session_options[:id]\n\n",
            "\nI can't test it right now but as far as I know the session id variable changed from 'id' to 'session_id' on Rails 3, have you tried that one? Hope it works for you.\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nI had a similar error and had to edit my manifest.js file in order to get it to work.\nEdit /assets/config.manifest.js and then\n// manifest.js\n//= link_tree ../images\n//= link_tree ../stylesheets .css\n\nThen do a bundle exec rake assets:precompile\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "session"
        ]
    },
    {
        "question_id": "1478295",
        "question": "\nSpecifically, how does it differ from the default  ( async: true ) ?\nIn what circumstances would I want to explicit set async to false, and does it have something to do with preventing other events on the page from firing ? \n",
        "all_answers": [
            "\nIf you disable asynchronous retrieval, your script will block until the request has been fulfilled. It's useful for performing some sequence of requests in a known order, though I find async callbacks to be cleaner.\n",
            "\n\nDoes it have something to do with\n  preventing other events on the page\n  from firing?\n\nYes.\nSetting async to false means that the statement you are calling has to complete before the next statement in your function can be called.  If you set async: true then that statement will begin it's execution and the next statement will be called regardless of whether the async statement has completed yet.\nFor more insight see: \njQuery ajax success anonymous function scope\n"
        ],
        "answer": "A2",
        "tags": [
            "jquery"
        ]
    },
    {
        "question_id": "26989078",
        "question": "\nIs there a better way to get the full url in django than doing the following:\nurl = request.META['HTTP_HOST']\n    + request.META['PATH_INFO']\n    + request.META['QUERY_STRING']\n\nIs there something like request.META['URL'] ?\n",
        "all_answers": [
            "\nYou can get full URL using request.build_absolute_uri method: \nFULL_URL_WITH_QUERY_STRING: request.build_absolute_uri()\nFULL_URL: request.build_absolute_uri('?')\nABSOLUTE_ROOT: request.build_absolute_uri('/')[:-1].strip(\"/\")\nABSOLUTE_ROOT_URL: request.build_absolute_uri('/').strip(\"/\")\n\nShould this will help full to you.\nThe best way to use ABSOLUTE URLS in Django, you can create a context_processors or middleware and  find your ABSOLUTE_URL and return that so that you can use any where in Django.\nLike this example:\ndef absolute(request):\n    urls = {\n        'ABSOLUTE_ROOT': request.build_absolute_uri('/')[:-1].strip(\"/\"),\n        'ABSOLUTE_ROOT_URL': request.build_absolute_uri('/').strip(\"/\"),\n    }\n\n    return urls\n\nAnd Then you should use {{ABSOLUTE_ROOT}} in any where into you django template. \n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nYou can use:\nrequest.build_absolute_uri()\n\nhttps://docs.djangoproject.com/en/dev/ref/request-response/#django.http.HttpRequest.build_absolute_uri\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django"
        ]
    },
    {
        "question_id": "10281962",
        "question": "\nIt seems the minlength attribute for an <input> field doesn't work.\nIs there any other attribute in HTML with the help of which I can set the minimal length of a value for fields?\n",
        "all_answers": [
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nThe minLength attribute (unlike maxLength) does not exist natively in HTML5. However, there a some ways to validate a field if it contains less than x characters.\nAn example is given using jQuery at this link: http://docs.jquery.com/Plugins/Validation/Methods/minlength\n<html>\n    <head>\n        <script src=\"http://code.jquery.com/jquery-latest.js\"></script>\n        <script type=\"text/javascript\" src=\"http://jzaefferer.github.com/jquery-validation/jquery.validate.js\"></script>\n        <script type=\"text/javascript\">\n            jQuery.validator.setDefaults({\n                debug: true,\n                success: \"valid\"\n            });;\n        </script>\n\n        <script>\n            $(document).ready(function(){\n                $(\"#myform\").validate({\n                    rules: {\n                        field: {\n                            required: true,\n                            minlength: 3\n                        }\n                    }\n                });\n            });\n        </script>\n    </head>\n\n    <body>\n        <form id=\"myform\">\n            <label for=\"field\">Required, Minimum length 3: </label>\n            <input class=\"left\" id=\"field\" name=\"field\" />\n            <br/>\n            <input type=\"submit\" value=\"Validate!\" />\n        </form>\n    </body>\n\n</html>\n\n",
            "\nYou can use the pattern attribute. The required attribute is also needed, otherwise an input field with an empty value will be excluded from constraint validation.\n<input pattern=\".{3,}\"   required title=\"3 characters minimum\">\n<input pattern=\".{5,10}\" required title=\"5 to 10 characters\">\n\nIf you want to create the option to use the pattern for \"empty, or minimum length\", you could do the following:\n<input pattern=\".{0}|.{5,10}\" required title=\"Either 0 OR (5 to 10 chars)\">\n<input pattern=\".{0}|.{8,}\"   required title=\"Either 0 OR (8 chars minimum)\">\n\n"
        ],
        "answer": "A4",
        "tags": [
            "html",
            "validation"
        ]
    },
    {
        "question_id": "8332443",
        "question": "\nI have an existing file on disk (say /folder/file.txt) and a FileField model field in Django.\nWhen I do \ninstance.field = File(file('/folder/file.txt'))\ninstance.save()\n\nit re-saves the file as file_1.txt (the next time it's _2, etc.).\nI understand why, but I don't want this behavior - I know the file I want the field to be associated with is really there waiting for me, and I just want Django to point to it.\nHow?\n",
        "all_answers": [
            "\nI had exactly the same problem! then I realize that my Models were causing that. example I hade my models like this:\nclass Tile(models.Model):\n  image = models.ImageField()\n\nThen, I wanted to have more the one tile referencing the same file in the disk! The way that I found to solve that was change my Model structure to this:\nclass Tile(models.Model):\n  image = models.ForeignKey(TileImage)\n\nclass TileImage(models.Model):\n  image = models.ImageField()\n\nWhich after I realize that make more sense, because if I want the same file being saved more then one in my DB I have to create another table for it! \nI guess you can solve your problem like that too, just hoping that you can change the models! \nEDIT\nAlso I guess you can use a different storage, like this for instance: SymlinkOrCopyStorage\nhttp://code.welldev.org/django-storages/src/11bef0c2a410/storages/backends/symlinkorcopy.py\n",
            "\nIf you want to do this permanently, you need to create your own FileStorage class\nimport os\nfrom django.conf import settings\nfrom django.core.files.storage import FileSystemStorage\n\nclass MyFileStorage(FileSystemStorage):\n\n    # This method is actually defined in Storage\n    def get_available_name(self, name):\n        if self.exists(name):\n            os.remove(os.path.join(settings.MEDIA_ROOT, name))\n        return name # simply returns the name passed\n\nNow in your model, you use your modified MyFileStorage\nfrom mystuff.customs import MyFileStorage\n\nmfs = MyFileStorage()\n\nclass SomeModel(model.Model):\n   my_file = model.FileField(storage=mfs)\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django",
            "file"
        ]
    },
    {
        "question_id": "1254170",
        "question": "\nI am trying to find out the number of queries executed by a utility function. I have written a unit test for this function and the function is working well. What I would like to do is track the number of SQL queries executed by the function so that I can see if there is any improvement after some refactoring.\ndef do_something_in_the_database():\n    # Does something in the database\n    # return result\n\nclass DoSomethingTests(django.test.TestCase):\n    def test_function_returns_correct_values(self):\n        self.assertEqual(n, <number of SQL queries executed>)\n\nEDIT: I found out that there is a pending Django feature request for this. However the ticket is still open. In the meantime is there another way to go about this?\n",
        "all_answers": [
            "\nSince Django 1.3 there is a assertNumQueries available exactly for this purpose.\nOne way to use it (as of Django 3.2) is as a context manager:\n# measure queries of some_func and some_func2\nwith self.assertNumQueries(2):\n    result = some_func()\n    result2 = some_func2()\n\n",
            "\nVinay's response is correct, with one minor addition.\nDjango's unit test framework actually sets DEBUG to False when it runs, so no matter what you have in settings.py, you will not have anything populated in connection.queries in your unit test unless you re-enable debug mode. The Django docs explain the rationale for this as:\n\nRegardless of the value of the DEBUG setting in your configuration file, all Django tests run with DEBUG=False. This is to ensure that the observed output of your code matches what will be seen in a production setting.\n\nIf you're certain that enabling debug will not affect your tests (such as if you're specifically testing DB hits, as it sounds like you are), the solution is to temporarily re-enable debug in your unit test, then set it back afterward:\ndef test_myself(self):\n    from django.conf import settings\n    from django.db import connection\n\n    settings.DEBUG = True\n    connection.queries = []\n\n    # Test code as normal\n    self.assert_(connection.queries)\n\n    settings.DEBUG = False\n\n",
            "\nIf you have DEBUG set to True in your settings.py (presumably so in your test environment) then you can count queries executed in your test as follows:\nfrom django.db import connection\n\nclass DoSomethingTests(django.test.TestCase):\n    def test_something_or_other(self):\n        num_queries_old = len(connection.queries)\n        do_something_in_the_database()\n        num_queries_new = len(connection.queries)\n        self.assertEqual(n, num_queries_new - num_queries_old)\n\n"
        ],
        "answer": "A1",
        "tags": [
            "django",
            "django-orm",
            "django-testing"
        ]
    },
    {
        "question_id": "1455190",
        "question": "\nWe're doing a small benchmark of MySQL where we want to see how it performs for our data.\nPart of that test is to see how it works when multiple concurrent threads hammers the server with various queries.\nThe MySQL documentation (5.0) isn't really clear about multi threaded clients. I should point out that I do link against the thread safe library (libmysqlclient_r.so)\nI'm using prepared statements and do both read (SELECT) and write (UPDATE, INSERT, DELETE). \n\nShould I open one connection per thread? And if so: how do I even do this.. it seems mysql_real_connect() returns the original DB handle which I got when I called mysql_init())\nIf not: how do I make sure results and methods such as mysql_affected_rows returns the correct value instead of colliding with other thread's calls (mutex/locks could work, but it feels wrong)\n\n",
        "all_answers": [
            "\nOn my system the behavior is same, but as Maxim mentioned, rand is not thread safe. When I change rand to rand_r, then the multi threaded code is faster as expected.\nvoid add_multi(int N, double& result) {\ndouble sum=0;\nunsigned int seed = time(NULL);\nfor (int i = 0; i < N; ++i){\n    sum+= sqrt(1.0*rand_r(&seed)/RAND_MAX);\n}\nresult = sum/N;\n}\n\n",
            "\nGCC Atomic Built-ins\n",
            "\nYou could create a connection pool.  Each thread that needs a connection could request a free one from the pool.  If there's no connection available then you either block, or grow the pool by adding a new connection to it.\nThere's an article here describing the pro's and cons of a connection pool (though it is java based)\nEdit: Here's a SO question / answer about connection pools in C\nEdit2: Here's a link to a sample Connection Pool for MySQL written in C++. (you should probably ignore the goto statements when you implement your own.)\n",
            "\nAs maintainer of a fairly large C application that makes MySQL calls from multiple threads, I can say I've had no problems with simply making a new connection in each thread.  Some caveats that I've come across:\n\nEdit: it seems this bullet only applies to versions < 5.5; see this page for your appropriate version: Like you say you're already doing, link against libmysqlclient_r.\nCall mysql_library_init() (once, from main()).  Read the docs about use in multithreaded environments to see why it's necessary.\nMake a new MYSQL structure using mysql_init() in each thread.  This has the side effect of calling mysql_thread_init() for you.  mysql_real_connect() as usual inside each thread, with its thread-specific MYSQL struct.\nIf you're creating/destroying lots of threads, you'll want to use mysql_thread_end() at the end of each thread (and mysql_library_end() at the end of main()).  It's good practice anyway.\n\nBasically, don't share MYSQL structs or anything created specific to that struct (i.e. MYSQL_STMTs) and it'll work as you expect.\nThis seems like less work than making a connection pool to me.\n",
            "\nSeems clear to me from the mySQL Docs that any specific MYSQL structure can be used in a thread without difficulty - using the same MYSQL structure in different threads simultaneously is clearly going to give you extremely unpredictable results as state is stored within the MYSQL connection.\nThus either create a connection per thread or used a pool of connections as suggested above and protect access to that pool (i.e. reserving or releasing a connection) using some kind of Mutex.\n",
            "\nMySQL Threaded Clients in C\nIt states that mysql_real_connect() is not thread safe by default. The client library needs to be compiled for threaded access.\n"
        ],
        "answer": "A4",
        "tags": [
            "c++",
            "mysql",
            "c",
            "multithreading",
            "connection-pooling"
        ]
    },
    {
        "question_id": "25589605",
        "question": "\nAssume we have an array of optionals defined:\nvar arrayOfOptionals: [String?] = [\"Seems\", \"like\", \"an\", nil, \"of\", \"optionals\"]\n\nI can force unwrap it in a short way: var arrayForCrash = arrayOfOptionals.map { $0! }\nBut that will make app to crash, is there any other short way(without explicitly unwrapping) how I can unwrap an array of optional?\n",
        "all_answers": [
            "\nSince it is an array of optionals, it is possible some of the entries are nil.  Instead of force unwrapping with !, use the nil coalescing operator to turns nils into empty strings.\nlet arrayOfOptionals: [String?] = [\"This\", \"array\", nil, \"has\", \"some\", \"nils\", nil]\n\nlet array:[String] = arrayOfOptionals.map{ $0 ?? \"\" }\n// array is now [\"This\", \"array\", \"\", \"has\", \"some\", \"nils\", \"\"]\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nHow about:\nimport Foundation\n\nvar test: [String!] = [\"this\",\"is\",\"a\",nil,\"test\"]\nfor string in test {\n    if string != nil {\n        print(string)\n    }\n}\n\nOutput is thisisatest.\n\nIn your case use [String!], if I understood you correctly.\n",
            "\nThis solution will get you a new array with all values unwrapped and all nil's filtered away.\nSwift 4.1:\nlet arrayOfOptionals: [String?] = [\"Seems\", \"like\", \"an\", nil, \"of\", \"optionals\"]\nlet arrayWithNoOptionals = arrayOfOptionals.compactMap { $0 }\n\nSwift 2.0:\nlet arrayOfOptionals: [String?] = [\"Seems\", \"like\", \"an\", nil, \"of\", \"optionals\"]\nlet arrayWithNoOptionals = arrayOfOptionals.flatMap { $0 }\n\nSwift 1.0:\nlet arrayOfOptionals: [String?] = [\"Seems\", \"like\", \"an\", nil, \"of\", \"optionals\"]\nlet arrayWithNoOptionals = arrayOfOptionals.filter { $0 != nil }.map { $0! }\n\n"
        ],
        "answer": "A4",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "879077",
        "question": "\nIf I have a multi-threaded program that reads a cache-type memory by reference. Can I change this pointer by the main thread without risking any of the other threads reading unexpected values.\nAs I see it, if the change is atomic the other threads will either read the older value or the newer value; never random memory (or null pointers), right?\nI am aware that I should probably use synchronisation methods anyway, but I'm still curious.\nAre pointer changes atomic?\nUpdate: My platform is 64-bit Linux (2.6.29), although I'd like a cross-platform answer as well :)\n",
        "all_answers": [
            "\nThe cop-out answer is that the C spec does not require a pointer assignment to be atomic, so you can't count on it being atomic.\nThe actual answer would be that it probably depends on your platform, compiler, and possibly the alignment of the stars on the day you wrote the program.\n",
            "\nThe only thing guaranteed by the standard is the sig_atomic_t type.\nAs you've seen from the other answers, it is likely to be OK when targeting generic x86 architecture, but very risky with more \"specialty\" hardware.\nIf you're really desperate to know, you can compare sizeof(sig_atomic_t) to sizeof(int*) and see what they are you your target system.\n",
            "\nThe C language says nothing about whether any operations are atomic. I've worked on microcontrollers with 8 bit buses and 16-bit pointers; any pointer operation on these systems would potentially be non-atomic. I think I remember Intel 386s (some of which had 16-bit buses) raising similar concerns. Likewise, I can imagine systems that have 64-bit CPUs, but 32-bit data buses, which might then entail similar concerns about non-atomic pointer operations. (I haven't checked to see whether any such systems actually exist.)\nEDIT: Michael's answer is well worth reading. Bus size vs. pointer size is hardly the only consideration regarding atomicity; it was simply the first counterexample that came to mind for me.\n",
            "\nYou didn't mention a platform.  So I think a slightly more accurate question would be \n\nAre pointer changes guaranteed to be atomic?\n\nThe distinction is necessary because different C/C++ implementations may vary in this behavior.  It's possible for a particular platform to guarantee atomic assignments and still be within the standard.  \nAs to whether or not this is guaranteed overall in C/C++, the answer is No.  The C standard makes no such guarantees.  The only way to guarantee a pointer assignment is atomic is to use a platform specific mechanism to guarantee the atomicity of the assignment.  For instance the Interlocked methods in Win32 will provide this guarantee.  \nWhich platform are you working on?\n",
            "\nAs others have mentioned, there is nothing in the C language that guarantees this, and it is dependent on your platform.\nOn most contemporary desktop platforms, the read/write to a word-sized, aligned location will be atomic.  But that really doesn't solve your problem, due to processor and compiler re-ordering of reads and writes.\nFor example, the following code is broken:\nThread A:\nDoWork();\nworkDone = 1;\n\nThread B:\nwhile(workDone != 0);\n\nReceiveResultsOfWork();\n\nAlthough the write to workDone is atomic, on many systems there is no guarantee by the processor that the write to workDone will be visible to other processors before writes done via DoWork() are visible.  The compiler may also be free to re-order the write to workDone to before the call to DoWork().  In both cases, ReceiveResultsOfWork() might start working on incomplete data.\nDepending on your platform, you may need to insert memory fences and so on to ensure proper ordering.  This can be very tricky to get right.\nOr just use locks.  Much simpler, much easier to verify as correct, and in most cases more than performant enough.\n",
            "\nGCC Atomic Built-ins\n"
        ],
        "answer": "A5",
        "tags": [
            "c",
            "multithreading",
            "synchronization"
        ]
    },
    {
        "question_id": "27932983",
        "question": "\nIn my script.js:\npic.src = \"/static/photos/1.jpg\"; // This works\npic2.src = \"{% static 'photos/1.jpg' %}\" // Does not work\n\nWhy in the world this happens? Since in my home.html, the {% static 'path' %} works:\n{% load staticfiles %}\n<script src=\"{% static 'script.js' %}\"></script>  // This works\n\nAnd is it {% load staticfiles %} or {% load static %} ? Both work for me, script.js is loaded.\n",
        "all_answers": [
            "\nYou can assign the path in your template and then use it in your javascript file.\nTemplate:\n<script>\n    var url = \"{% static 'photos/1.jpg' %}\";\n</script>\n\nJavascript:\npic2.src = url\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nSince you are using django's template language you can ONLY do this within your template between <script> tags. In other words if you wished to use your pic2.src javascript variable in an external script then you would need to declare it between <script> tags like so\n<script>\n    var pic2.src = \"{% static \"photos/1.jpg\" %}\"\n</script>\n\nAnd then you could access it in your external scripts that you might load like this:\n<script type=\"text/javascript\" src=\"{% static \"js/my_external_script.js\" %}\"></script>\n\nRegarding your question concerning load static and load staticfiles there is little distinction. Both act as a joiner for the STATIC_URL in your settings.py and the actual path to the file itself so both should work for your case. See here and here for more info.\n"
        ],
        "answer": "A4",
        "tags": [
            "django"
        ]
    },
    {
        "question_id": "10538539",
        "question": "\nIs it possible to join the results of 2 sql SELECT statements in one statement?\nI have a database of tasks where each record is a separate task, with deadlines (and a PALT, which is just an INT of days from start to deadline.  Age is also an INT number of days.)\nI want to have a table which has each person in the table, the number of tasks they have, and the number of LATE tasks they have (if any.)\nI can get this data in separate tables easily, like so:\nSELECT ks, COUNT(*) AS '# Tasks' FROM Table GROUP BY ks\n\nreturning data like:\nks        # Tasks\nperson1   7\nperson2   3\n\nand then I have:\nSELECT ks, COUNT(*) AS '# Late' FROM Table WHERE Age > Palt GROUP BY ks\n\nwhich returns:\nks        # Late\nperson1   1\nperson2   1\n\nAnd I want to join the results of these two select statements (by the KS)\nI'm trying to avoid using a temp table, but if that's the only practical way to do this, I'd like to know more about using temp tables in this fashion.\nI also tried to do some kind of count() of rows which satisfy a conditional, but I couldn't figure out how to do that either.  If it's possible, that would work too.\nAddendum:\nSorry, I want my results to have columns for KS, Tasks, and Late\nKS        # Tasks   # Late\nperson1   7         1\nperson2   3         1\nperson3   2         0  (or null)\n\nAdditionally, I want a person to show up even if they have no late tasks.\nSUM(CASE WHEN Age > Palt THEN 1 ELSE 0 END) Late\nworks well, thanks for this answer!\nTwo select statements also work, using a LEFT JOIN to join them also works, and I understand now how to join multiple selects in this fashion\n",
        "all_answers": [
            "\nSELECT t.*\nFROM unnest(ARRAY[1,2,3,2,3,5]) item_id\nLEFT JOIN items t on t.id=item_id\n\nThe above query select items from items table with ids: 1,2,3,2,3,5 in that order.\n",
            "\nSELECT t1.ks, t1.[# Tasks], COALESCE(t2.[# Late], 0) AS [# Late]\nFROM \n    (SELECT ks, COUNT(*) AS '# Tasks' FROM Table GROUP BY ks) t1\nLEFT JOIN\n    (SELECT ks, COUNT(*) AS '# Late' FROM Table WHERE Age > Palt GROUP BY ks) t2\nON (t1.ks = t2.ks);\n\n",
            "\nProbably normalizing your table would be the best advice I can give you.\nThe int_array contrib module has an idx function that will give you the int's index position in the array. Also there is an idx function on the snippets wiki that works for array's of any data types.\nSELECT i.*, idx(id_items, i.id) AS idx\nFROM some_chosen_data_in_order s\nJOIN items i ON i.id = ANY(s.id_items)\nORDER BY idx(id_items, i.id)\n\n",
            "\nyou can use the UNION ALL keyword for this.\nHere is the MSDN doc to do it in T-SQL http://msdn.microsoft.com/en-us/library/ms180026.aspx\nUNION ALL - combines  the result set\nUNION- Does something like a Set Union and doesnt output duplicate values\nFor the difference with an example: http://sql-plsql.blogspot.in/2010/05/difference-between-union-union-all.html\n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "select",
            "join",
            "group-by"
        ]
    },
    {
        "question_id": "4969217",
        "question": "\nI want my application user to be able to share/recommend my app to other users. I use the ACTION_SEND intent. I add plain text saying something along the lines of: install this cool application. But I can't find a way to enable users to directly go to the install screen of market place for instance. All I can provide them with is a web link or some text.\nIn other words I am looking for a very direct way for android users to have my app installed.\nThanks for any help/pointers,\nThomas\n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nTo be more exact \n   Intent intent = new Intent(Intent.ACTION_VIEW);\n   intent.setData(Uri.parse(\"https://play.google.com/store/apps/details?id=com.android.example\"));\n   startActivity(intent);\n\nor if you want to share your other apps from your dev. account you can do something like this\nIntent intent = new Intent(Intent.ACTION_VIEW);\nintent.setData(Uri.parse(\"https://play.google.com/store/apps/developer?id=Your_Publisher_Name\"));\nstartActivity(intent);\n\n",
            "\nThis will let you choose from email, whatsapp or whatever.\ntry { \n    Intent shareIntent = new Intent(Intent.ACTION_SEND);  \n    shareIntent.setType(\"text/plain\");\n    shareIntent.putExtra(Intent.EXTRA_SUBJECT, \"My application name\");\n    String shareMessage= \"\\nLet me recommend you this application\\n\\n\";\n    shareMessage = shareMessage + \"https://play.google.com/store/apps/details?id=\" + BuildConfig.APPLICATION_ID +\"\\n\\n\";\n    shareIntent.putExtra(Intent.EXTRA_TEXT, shareMessage);  \n    startActivity(Intent.createChooser(shareIntent, \"choose one\"));\n} catch(Exception e) { \n    //e.toString();\n}   \n\n",
            "\nThomas,\nYou would want to provide your users with a market:// link which will bring them directly to the details page of your app.  The following is from developer.android.com:\n\nLoading an application's Details page\nIn Android Market, every application\n  has a Details page that provides an\n  overview of the application for users.\n  For example, the page includes a short\n  description of the app and screen\n  shots of it in use, if supplied by the\n  developer, as well as feedback from\n  users and information about the\n  developer. The Details page also\n  includes an \"Install\" button that lets\n  the user trigger the download/purchase\n  of the application.\nIf you want to refer the user to a\n  specific application, your\n  application can take the user directly\n  to the application's Details page. To\n  do so, your application sends an\n  ACTION_VIEW Intent that includes a URI\n  and query parameter in this format:\nmarket://details?id=\nIn this case, the packagename\n  parameter is target application's\n  fully qualified package name, as\n  declared in the package attribute of\n  the manifest element in the\n  application's manifest file. For\n  example:\nmarket://details?id=com.example.android.jetboy\n\nSource: http://developer.android.com/guide/publishing/publishing.html\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "share"
        ]
    },
    {
        "question_id": "1226302",
        "question": "\nAre there any examples on the web of how to monitor delayed_job with Monit? \nEverything I can find uses God, but I refuse to use God since long running processes in Ruby generally suck. (The most current post in the God mailing list? God Memory Usage Grows Steadily.)\nUpdate: delayed_job now comes with a sample monit config based on this question.\n",
        "all_answers": [
            "\nHere is how I got this working.\n\nUse the collectiveidea fork of delayed_job besides being actively maintained, this version has a nice script/delayed_job daemon you can use with monit. Railscasts has a good episode about this version of delayed_job (ASCIICasts version). This script also has some other nice features, like the ability to run multiple workers. I don't cover that here.\nInstall monit. I installed from source because Ubuntu's version is so ridiculously out of date. I followed these instructions to get the standard init.d scripts that come with the Ubuntu packages. I also needed to configure with ./configure --sysconfdir=/etc/monit so the standard Ubuntu configuration dir was picked up.\nWrite a monit script. Here's what I came up with:\ncheck process delayed_job with pidfile /var/www/app/shared/pids/delayed_job.pid\nstart program = \"/var/www/app/current/script/delayed_job -e production start\"\nstop program = \"/var/www/app/current/script/delayed_job -e production stop\"\nI store this in my soucre control system and point monit at it with include /var/www/app/current/config/monit in the /etc/monit/monitrc file.\nConfigure monit. These instructions are laden with ads but otherwise OK.\nWrite a task for capistrano to stop and start. monit start delayed_job and monit stop delayed_job is what you want to run. I also reload monit when deploying to pick up any config file changes.\n\nProblems I ran into:\n\ndaemons gem must be installed for script/delayed_job to run. \nYou must pass the Rails environment to script/delayed_job with -e production (for example). This is documented in the README file but not in the script's help output.\nI use Ruby Enterprise Edition, so I needed to get monit to start with that copy of Ruby. Because of the way sudo handles the PATH in Ubuntu, I ended up symlinking  /usr/bin/ruby and /usr/bin/gem to the REE versions.\n\nWhen debugging monit, I found it helps to stop the init.d version and run it from the th command line, so you can get error messages. Otherwise it is very difficult to figure out why things are going wrong.\nsudo /etc/init.d/monit stop\nsudo monit start delayed_job\n\nHopefully this helps the next person who wants to monitor delayed_job with monit.\n",
            "\nI don't know with Monit, but I've written a couple Munin plugins to monitor Queue Size and Average Job Run Time. The changes I made to delayed_job in that patch might also make it easier for you to write Monit plugins in case you stick with that.\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "delayed-job",
            "monit",
            "god"
        ]
    },
    {
        "question_id": "9357026",
        "question": "\nIt takes roughly 3-4 seconds for the keyboard to pop up after I touch my UITextField. This only occurs on the first time the keyboard pops up since the app launched, afterwards the animation starts instantly.\nAt first I thought it was problem of loading too many images, or my UITableView, but I just created a brand new project with only a UITextField, and I still experience this problem. I'm using iOS 5, Xcode ver 4.2, and running on an iPhone 4S.\nThis is my code:\n#import \"ViewController.h\"\n\n@implementation ViewController\n\n- (void)viewDidLoad {\n    [super viewDidLoad];\n    \n    UITextField *textField = [[UITextField alloc] initWithFrame:CGRectMake(20, 20, 280, 30)];\n    textField.borderStyle = UITextBorderStyleRoundedRect;\n    textField.delegate = self;\n    [self.view addSubview:textField];\n}\n\n@end\n\nIs this a common problem for all apps?\nRight now, the only way I can make it somewhat better is by having textField become/resign first responder in viewDidAppear, but that doesn't solve the problem entirely - it just loads the delay onto when the view loads instead. If I click on textField immediately when the view loads, I still get the problem; if I wait 3-4 seconds after the view loads before touching the textField, I don't get the delay.\n",
        "all_answers": [
            "\nJust press ⌘K it will toggle keyboard.\n",
            "\nTo enable/disable simulator keyboard: click ⇧+⌘+K to show the keyboard on simulator, click again to disable (hide) the keyboard.\n⇧+⌘+K\nOR\n\nSimulator ->I/O ->Keyboard ->Toggle Software Keyboard\n",
            "\nSo the problem is NOT just limited to the first install as I had previously thought, but happens every time the app is launched. Here's my solution that solves the issue completely. \n- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions {\n  // Preloads keyboard so there's no lag on initial keyboard appearance.\n  UITextField *lagFreeField = [[UITextField alloc] init];\n  [self.window addSubview:lagFreeField];\n  [lagFreeField becomeFirstResponder];\n  [lagFreeField resignFirstResponder];\n  [lagFreeField removeFromSuperview];\n}\n\n",
            "\nTo enable/disable simulator keyboard,\n⌘ + K (Ctrl + k)\nTo disable input from your keyboard,\niOS Simulator -> Hardware -> Keyboard -> Uncheck \"Connect Hardware Keyboard\"\n",
            "\nI had the same issue. My solution was as follows:\n\niOS Simulator -> Hardware -> Keyboard\nUncheck \"Connect Hardware Keyboard\"\n\nMine was checked because I was using my mac keyboard, but if you make sure it is unchecked the iPhone keyboard will always come up.\n",
            "\nWhile testing in the ios8 beta simulator, you may toggle between the \"software keyboard\" and \"hardware keyboard\" with ⌘+K.\nUPDATE: Since iOS Simulator 8.0, the shortcut is ⇧+⌘+K.\n",
            "\nSimulator -> Hardware -> Keyboard -> Toggle Software Keyboard should solve this problem.\n\n",
            "\nThis seems to be a bug in iOS 8. There are two fixes to this problem :\n\nToggle between simulator keyboard and MacBook keyboard using the Command+K shortcut.\nReattach keyboard to simulator :\na. Open Simulator\nb. Select Hardware -> Keyboard\nc. Uncheck and then check 'Connect Hardware Keyboard'\n\n\nOR simply press the Shift + Command + K shortcut\n",
            "\nYeah, I also got a few seconds delay on the latest iPhone 4s. Don't panic. For some reasons, it only happens the first time the app is loaded from Xcode in Debug. When I did Release, I don't get the delay. Just forget it...\n",
            "\nYou can use :\n⇧+⌘+K to show keyboard on simulator.\n"
        ],
        "answer": "A3",
        "tags": [
            "objective-c",
            "ios",
            "cocoa-touch",
            "keyboard",
            "uitextfield"
        ]
    },
    {
        "question_id": "2865315",
        "question": "\nI was today asked in an interview over the Thread concepts in Java? The Questions were... \n\nWhat is a thread?\nWhy do we go for threading?\nA real time example over the threads.\nCan we create threads in Spring framework service class. \nCan flex call a thread?\n\nI did not answer any questions apart from definition of Thread, that too I just learnt from internet. \nCan anyone explain me clearly over this.\nUpdate:\nWhat is a difference between a thread and a normal java class.\nwhy do we need threading... can i execute business logic in threads.\nCan i call a different class methods in Threads. \n",
        "all_answers": [
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nI can answer the first 3 since I'm not too familiar with the threading features of Spring or Flex.\n\nA thread is an object that has its own registers and stack that can run parallel with other threads in a process (a process is a collection of threads).\nYou write multi-threaded code for the program to be responsive to user interactions. Think of how annoying it would be if you had to wait for your browser to finish downloading a file before you can continue browsing.\nI gave an example in #2. Other examples are any programs with a GUI (the GUI has to always be responsive to user input while performing background tasks), or server type software such as a web server where you might have to respond to 1000 requests a minute.  It would be better to have a separate thread for each of those responses.\n\n",
            "\nTo create threads, create a new class that extends the Thread class, and instantiate that class. The extending class must override the run method and call the start method to begin execution of the thread.\nInside run, you will define the code that constitutes a new thread. It is important to understand that run can call other methods, use other classes and declare variables just like the main thread. The only difference is that run establishes the entry point for another, concurrent thread of execution within your program. This will end when run returns.\nHere's an example:\npublic class MyThread extends Thread {\n    private final String name;\n\n    public MyThread(String name) {\n        this.name = name;\n    }\n\n    public void run() {\n        try {\n            for (; ; ) {\n                System.out.println(name);\n                Thread.sleep(1000);\n            }\n        } catch (InterruptedException e) {\n            System.out.println(\"sleep interrupted\");\n        }\n    }\n\n    public static void main(String[] args) {\n        Thread t1 = new MyThread(\"First Thread\");\n        Thread t2 = new MyThread(\"Second Thread\");\n        t1.start();\n        t2.start();\n    }\n}\n\nYou will see this on the screen:\nFirst Thread\nSecond Thread\nFirst Thread\nSecond Thread\nFirst Thread\n\nThis tutorial also explains the Runnable interface. With Spring, you could use a thread pool.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n"
        ],
        "answer": "A3",
        "tags": [
            "java",
            "multithreading"
        ]
    },
    {
        "question_id": "981262",
        "question": "\nI want to subtract between two date time values using SQL in MySQL such that I get the interval in minutes or seconds. Any ideas? I want to run a SQL query that retrieves uses from a database who have logged in like 10 minutes from the time.\n",
        "all_answers": [
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nThere are functions TIMEDIFF(expr1,expr2), which returns the value of expr1-expr2, and TIME_TO_SEC(expr3), which expresses expr3 in seconds.\nNote that expr1 and expr2 are datetime values, and expr3 is a time value only.\nCheck this link for more info.\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nYou can try and cast them to Unix Time stamp, and take the difference.\n"
        ],
        "answer": "A7",
        "tags": [
            "mysql",
            "sql",
            "date"
        ]
    },
    {
        "question_id": "28533602",
        "question": "\nIs there an easy way to navigate to the earliest commit of a large open-source project in GitHub?\nThe project has over 13,000 commits as of today. I don't want to press the \"Older\" button on the commit history page hundreds and hundreds of times to get to the initial commit (or first commit).\n",
        "all_answers": [
            "\nClone the repository, open with the command line and run $ git log --reverse\nThis will show the commits in reverse order.\nThen you can view it on github once you have the ID(Object Name) of the first commit ... something like... https://github.com/UserName/Repo/commit/6a5ace7b941120db5d2d50af6321770ddad4779e\n",
            "\n\nFeb. 2015: In GitHub, is there an easy way to navigate to the earliest commit of a large open source project? \n\nYes there now is! (Meaning: without cloning the repo, and applying git log in the  local clone)\nSince January 2017, you have \"Navigate file history faster with improved blame view\" on GitHub.\n\nWhether you're debugging a regression or trying to understand how some code came to have its current shape, you'll often want to see what a file looked like before a particular change.\n  With improved blame view, you can easily see how any portion of your file has evolved over time without viewing the file's full history.\n\nHere is a demo getting back to the original oldest commit of the git/git repo itself (47K+ commits)... in three clicks!\n\nThe trick here is to chose a file likely to be found in the first (or very early) commit, like a README.md.\n",
            "\nYou can navigate to a GitHub repository's first commit using the init bookmarklet.\n\nINIT\nA bookmarklet to quickly get you to the first commit of a repo.\nOverview\nBeing able to quickly navigate to the oldest commit in a repo is quite helpful. Go ahead and drag the bookmarklet (link) onto your bookmark bar and click it whenever you'd like to go to the first commit of a repo.\nUsage\nGo to any particular repo's landing page (e.g. like the one you're on) and click the bookmarklet, which will take you to the first page (initial commit). By default, it tracks the master branch, but if you change the branch on the landing page, it will go to that branch's first commit.\nRetrieved from README.md on GitHub\n\n\nDisclaimer: I contributed a small Readme update to init a few minutes before posting this answer.\n",
            "\nThere's no obvious UI to do this, but there is a way to construct the right URL to go to page one of the commit log.\nSuppose we want to find the first commit of the dotnet/runtime repository. First take a note of the number of commits in the repository: it is currently 125,882. Now go to the list of commits (click on commit count), and click \"Older\" once. The URL will be something like this: https://github.com/dotnet/runtime/commits/main?after=2aec3816f9bbc0eda3261daa335a05ea0df31b9c+34\nNotice the +34 part. That's how many commits are skipped. Change that to 125,882 minus 1 minus 35 per page, that gives us this URL, which takes you right to the first page of the dotnet/runtime commit history.\n"
        ],
        "answer": "A4",
        "tags": [
            "github"
        ]
    },
    {
        "question_id": "299802",
        "question": "\n\n\n\nIn Mootools, I'd just run if ($('target')) { ... }.  Does if ($('#target')) { ... } in jQuery work the same way?\n",
        "all_answers": [
            "\nno, jquery always returns a jquery object regardless if a selector was matched or not.\nYou need to use .length\nif ( $('#someDiv').length ){\n\n}\n\n",
            "\nAs the other commenters are suggesting the most efficient way to do it seems to be: \nif ($(selector).length ) {\n    // Do something\n}\n\nIf you absolutely must have an exists() function - which will be slower- you can do:\njQuery.fn.exists = function(){return this.length>0;}\n\nThen in your code you can use\nif ($(selector).exists()) {\n    // Do something\n}\n\nAs answered here\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "jquery",
            "jquery-selectors"
        ]
    },
    {
        "question_id": "8605516",
        "question": "\nI am required to have no option selected by default in drop down menu in HTML. However, I cannot use:\n\n\n<select>\n  <option></option>\n  <option>Option 1</option>\n  <option>Option 2</option>\n  <option>Option 3</option>\n</select>\n\n\n\nBecause for this I will have to validate to handle the first option.\nCan anyone help me in achieving this target without actually including the first option as part of the select tag?\n",
        "all_answers": [
            "\nThere is no HTML solution. By the HTML 4.01 spec, browser behavior is undefined if none of the option elements has the selected attribute, and what browsers do in practice is that they make the first option pre-selected.\nAs a workaround, you could replace the select element by a set of input type=radio elements (with the same name attribute). This creates a control of the same kind though with different appearance and user interface. If none of the input type=radio elements has the checked attribute, none of them is initially selected in most modern browsers.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nYou could use Javascript to achieve this. Try the following code:\nHTML\n<select id=\"myDropdown\">      \n    <option>Option 1</option>     \n    <option>Option 2</option>     \n    <option>Option 3</option>     \n</select> \n\nJS\ndocument.getElementById(\"myDropdown\").selectedIndex = -1;\n\nor JQuery\n$(\"#myDropdown\").prop(\"selectedIndex\", -1);\n\n",
            "\nMaybe this will be helpful\n\n\n<select>\n  <option disabled selected value> -- select an option -- </option>\n  <option>Option 1</option>\n  <option>Option 2</option>\n  <option>Option 3</option>\n</select>\n\n\n\n-- select an option -- Will be displayed by default. But if you choose an option, you will not be able to select it back.\nYou can also hide it using by adding an empty option\n<option style=\"display:none\">\nso it won't show up in the list anymore.\nOption 2\nIf you don't want to write CSS and expect the same behaviour of the solution above, just use:\n<option hidden disabled selected value> -- select an option -- </option>\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n"
        ],
        "answer": "A4",
        "tags": [
            "html"
        ]
    },
    {
        "question_id": "1616289",
        "question": "\n\n\n\nthis is more OS architecture question than programming directly, but still.  Why was the Windows registry created as a completely separate subsystem for storing system/application settings?  In *nix OS'es there is /etc directory which is perfectly understandable, as filesystem is a natural hierarchical way for storing settings, while Microsoft decided to create a completely outside hierarchical subsystem, which seems to be a foolish investment, why didn't they just use a filesystem hierarchy?\n",
        "all_answers": [
            "\nos.path.normpath(pathname) should also be mentioned as it converts / path separators into \\ separators on Windows. It also collapses redundant uplevel references... i.e., A/B and A/foo/../B and A/./B all become A/B.  And if you are Windows, these all become A\\B.\n",
            "\n\nEach application doesn't have to reinvent a config file format\nYou can easily use the registry in kernel mode code\n\nAs mentioned in the Old New Thing article cited by Bastien:\n\nThe system can handle concurrency issues for you\nYou can ACL registry keys\n\nI would also mention that many *nix frameworks have reinvented the registry...  Like gconfd on GNOME.\n",
            "\nThe idea is to have all settings for all programs stored in one single place instead of having them spread all over your disk.\n",
            "\nUse os.path.join().\nExample: os.path.join(pathfile,\"output\",\"log.txt\").\nIn your code that would be: rootTree.write(os.path.join(pathfile,\"output\",\"log.txt\"))\n",
            "\n\nCentralized -\nwhich is useful for roaming\nprofiles.  \nTransactional - \nwhich makes it harder to smash your\nconfiguration.\nSecurity - You can enforce read/write with better granularity than a file (per-key/value).\n\n",
            "\nFor starters, it's quicker to read and write to the registry during the course of a user session.\n",
            "\nYou can use os.sep:\n>>> import os\n>>> os.sep\n'/'\n\n",
            "\nUse:\nimport os\nprint os.sep\n\nto see how separator looks on a current OS.\nIn your code you can use:\nimport os\npath = os.path.join('folder_name', 'file_name')\n\n",
            "\n\n\nYou can use \"os.sep \"\n\n\n import os\n pathfile=os.path.dirname(templateFile)\n directory = str(pathfile)+os.sep+'output'+os.sep+'log.txt'\n rootTree.write(directory)\n\n",
            "\nDo a import os and then use os.sep\n",
            "\nIf you are fortunate enough to be running Python 3.4+, you can use pathlib:\nfrom pathlib import Path\n\npath = Path(dir, subdir, filename)  # returns a path of the system's path flavour\n\nor, equivalently,\npath = Path(dir) / subdir / filename\n\n",
            "\nThis article discusses INI files vs registry: https://devblogs.microsoft.com/oldnewthing/20071126-00/?p=24383.\n",
            "\nSome useful links that will help you:\n\nos.sep\nos.path\nos.pathsep\n\n",
            "\nDon't build directory and file names your self, use python's included libraries. \nIn this case the relevant one is os.path. Especially join which creates a new pathname from a directory and a file name or directory and split that gets the filename from a full path.\nYour example would be \npathfile=os.path.dirname(templateFile)\np = os.path.join(pathfile, 'output')\np = os.path.join( p, 'log.txt')\nrootTree.write(p)\n\n"
        ],
        "answer": "A5",
        "tags": [
            "windows",
            "unix",
            "registry"
        ]
    },
    {
        "question_id": "1346132",
        "question": "\nI have a DataTable that is filled in from an SQL query to a local database, but I don't know how to extract data from it.\nMain method (in test program):\nstatic void Main(string[] args)\n{\n    const string connectionString = \"server=localhost\\\\SQLExpress;database=master;integrated Security=SSPI;\";\n    DataTable table = new DataTable(\"allPrograms\");\n\n    using (var conn = new SqlConnection(connectionString))\n    {\n        Console.WriteLine(\"connection created successfuly\");\n\n        string command = \"SELECT * FROM Programs\";\n\n        using (var cmd = new SqlCommand(command, conn))\n        {\n            Console.WriteLine(\"command created successfuly\");\n\n            SqlDataAdapter adapt = new SqlDataAdapter(cmd);\n\n            conn.Open(); \n            Console.WriteLine(\"connection opened successfuly\");\n            adapt.Fill(table);\n            conn.Close();\n            Console.WriteLine(\"connection closed successfuly\");\n        }\n    }\n\n    Console.Read();\n}\n\nThe command I used to create the tables in my database:\ncreate table programs\n(\n    progid int primary key identity(1,1),\n    name nvarchar(255),\n    description nvarchar(500),\n    iconFile nvarchar(255),\n    installScript nvarchar(255)\n)\n\nHow can I extract data from the DataTable into a form meaningful to use?\n",
        "all_answers": [
            "\nThe @SqlZim's answer is correct but just to explain why this possibly have happened. I've had similar issue and this was caused by very innocent thing: adding default value to a column\nALTER TABLE MySchema.MyTable ADD \n  MyColumn int DEFAULT NULL;\n\nBut in the realm of MS SQL Server a default value on a colum is a CONSTRAINT. And like every constraint it has an identifier. And you cannot drop a column if it is used in a CONSTRAINT.\nSo what you can actually do avoid this kind of problems is always give your default constraints a explicit name, for example:\nALTER TABLE MySchema.MyTable ADD \n  MyColumn int NULL,\n  CONSTRAINT DF_MyTable_MyColumn DEFAULT NULL FOR MyColumn;\n\nYou'll still have to drop the constraint before dropping the column, but you will at least know its name up front.\n",
            "\nYou must remove the constraints from the column before removing the column. The name you are referencing is a default constraint. \ne.g. \nalter table CompanyTransactions drop constraint [df__CompanyTr__Creat__0cdae408];\nalter table CompanyTransactions drop column [Created];\n\n",
            "\nYou can set the datatable as a datasource to many elements.\nFor eg\ngridView\nrepeater\ndatalist\netc etc\nIf you need to extract data from each row then you can use\ntable.rows[rowindex][columnindex]\n\nor\nif you know the column name\ntable.rows[rowindex][columnname]\n\nIf you need to iterate the table then you can either use a for loop or a foreach loop like\nfor ( int i = 0; i < table.rows.length; i ++ )\n{\n    string name = table.rows[i][\"columnname\"].ToString();\n}\n\nforeach ( DataRow dr in table.Rows )\n{\n    string name = dr[\"columnname\"].ToString();\n}\n\n",
            "\nThe DataTable has a collection .Rows of DataRow elements.\nEach DataRow corresponds to one row in your database, and contains a collection of columns.\nIn order to access a single value, do something like this:\n foreach(DataRow row in YourDataTable.Rows)\n { \n     string name = row[\"name\"].ToString();\n     string description = row[\"description\"].ToString();\n     string icoFileName = row[\"iconFile\"].ToString();\n     string installScript = row[\"installScript\"].ToString();\n }\n\n"
        ],
        "answer": "A4",
        "tags": [
            "c#",
            "sql",
            "ado.net"
        ]
    },
    {
        "question_id": "7769591",
        "question": "\nI'm running this command on a batch file: \nfor %I in (*.txt *.doc) do copy %I c:\\test2\n\n...and it keeps returning:\n\nI was unexpected at this time.\n\nWhat is the cause of this error?\n",
        "all_answers": [
            "\nAs others have already said, parameters passed through the command line can be accessed in batch files with the notation %1 to %9. There are also two other tokens that you can use:\n\n%0 is the executable (batch file) name as specified in the command line.\n%* is all parameters specified in the command line -- this is very useful if you want to forward the parameters to another program.\n\nThere are also lots of important techniques to be aware of in addition to simply how to access the parameters.\nChecking if a parameter was passed\nThis is done with constructs like IF \"%~1\"==\"\", which is true if and only if no arguments were passed at all. Note the tilde character which causes any surrounding quotes to be removed from the value of %1; without a tilde you will get unexpected results if that value includes double quotes, including the possibility of syntax errors.\nHandling more than 9 arguments (or just making life easier)\nIf you need to access more than 9 arguments you have to use the command SHIFT. This command shifts the values of all arguments one place, so that %0 takes the value of %1, %1 takes the value of %2, etc. %9 takes the value of the tenth argument (if one is present), which was not available through any variable before calling SHIFT (enter command SHIFT /? for more options).\nSHIFT is also useful when you want to easily process parameters without requiring that they are presented in a specific order. For example, a script may recognize the flags -a and -b in any order. A good way to parse the command line in such cases is\n:parse\nIF \"%~1\"==\"\" GOTO endparse\nIF \"%~1\"==\"-a\" REM do something\nIF \"%~1\"==\"-b\" REM do something else\nSHIFT\nGOTO parse\n:endparse\nREM ready for action!\n\nThis scheme allows you to parse pretty complex command lines without going insane.\nSubstitution of batch parameters\nFor parameters that represent file names the shell provides lots of functionality related to working with files that is not accessible in any other way. This functionality is accessed with constructs that begin with %~.\nFor example, to get the size of the file passed in as an argument use\nECHO %~z1\n\nTo get the path of the directory where the batch file was launched from (very useful!) you can use\nECHO %~dp0\n\nYou can view the full range of these capabilities by typing CALL /? in the command prompt.\n",
            "\nIf being run from a batch file, variables need to be denoted with two percent signs, like %%I, only from the command line you use one\n",
            "\nIf you're running within a batch/cmd file, you need to double the % markers:\nfor %%i in (*.txt *.doc) do copy %%i c:\\test2\n\nThe single % variant only works from the command line.\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "batch-file",
            "error-handling",
            "arguments"
        ]
    },
    {
        "question_id": "11700985",
        "question": "\nCan someone tell me what I coded wrong? Everything is working, the only thing is that there is no margin at the top.\nHTML:\n<div id=\"contact_us\"> <!-- BEGIN CONTACT US -->\n  <span class=\"first_title\">Contact</span>\n  <span class=\"second_title\">Us</span>\n  <p class=\"content\">For any questions whatsoever please contact us through the following e-mail address:</p></br></br>\n  <p class=\"e-mail\">info@e-mail.com</p></br></br></br></br>\n  <p class=\"read_more\"><a href=\"underconstruction.html\">Read More</a></p>\n</div> <!-- END CONTACT US -->\n\nCSS:\nspan.first_title {\n  margin-top: 20px;\n  margin-left: 12px;\n  font-weight: bold;\n  font-size: 24px;\n  color: #221461;\n}\n\nspan.second_title {\n  margin-top: 20px;\n  font-weight: bold;\n  font-size: 24px;\n  color: #b8b2d4;\n}   \n\n",
        "all_answers": [
            "\nspan is an inline element that doesn't support vertical margins. Put the margin on the outer div instead.\n",
            "\nUnlike div, p 1 which are Block Level elements which can take up margin on all sides,span2 cannot as it's an Inline element which takes up margins horizontally only.\nFrom the specification:\n\nMargin properties specify the width of the margin area of a box. The\n  'margin' shorthand property sets the margin for all four sides while\n  the other margin properties only set their respective side. These\n  properties apply to all elements, but vertical margins will not have\n  any effect on non-replaced inline elements.\n\nDemo 1 (Vertical margin not applied as span is an inline element)\nSolution? Make your span element, display: inline-block; or display: block;.\nDemo 2\nWould suggest you to use display: inline-block; as it will be inline as well as block. Making it block only will result in your element to render on another line, as block level elements take 100% of horizontal space on the page, unless they are made inline-block or they are floated to left or right.\n\n1. Block Level Elements - MDN Source\n2. Inline Elements - MDN Resource\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n"
        ],
        "answer": "A2",
        "tags": [
            "css",
            "margin",
            "html"
        ]
    },
    {
        "question_id": "8031921",
        "question": "\nI believe that all of these (and even die() or die(0)) are identical.  If they are not identical, which is preferred for exiting a script successfully?  If they are identical, is there any preferred standard to indicate successful script completion?  I tend to use exit;.\nEDIT: All of the answers have \"die() and exit() are identical\" even though I say that in my question.  I updated to the title to hopefully make it clearer that this is NOT my question.  I want to clearly indicate success from a command line script.\n",
        "all_answers": [
            "\nAs several people have mentioned, die() and exit() are exactly the same.\nIf you look at the PHP documentation, there are two options for arguments:\n\nAn numeric value.  This is only useful if you are using PHP from the command line, as opposed to a web server.  A value of zero indicates success.  Nonzero indicates a failure condition occurred.\nA string value.  This will be displayed to the browser when the exit occurs.\n\nInstead of die() or exit(), I recommend using exceptions and a custom top-level exception handler to manage failure conditions.  \nYou have more flexibility that way to do things like automatic error logging.  Also, if you're using PHP to implement a JSON API, this exception handler can hand back a valid, error-indicating JSON snippet instead.\n",
            "\nThese are all identical. I'm pretty sure die() is just a straight-up alias to exit(), but even if it isn't, it still acts identically.\nWhen one of these functions is given a string argument, it prints out the string before terminating the process. When it encounters an integer under 255, that integer is considered the return code for the process, which gets passed back to the process which invoked the PHP script. This is particularly useful when writing command line applications (PHP isn't web-only!).\nAs far as the difference between exit, exit(), and exit(0), there really is none. There is definitely no difference between the first two because exit is technically a language construct, not a function, so it can be called with or without parentheses, just like echo. Returning a code of 0 means \"this program ran successfully/without errors\", and while I don't know what exactly happens when you don't pass an argument, PHP.net says that an argument-less exit indicates success, so I would bet it returns 0, though again PHP.net doesn't show a default for the argument.\n",
            "\ndie() is typically used to kill the script with an error output:\ndie(\"There was a fatal error\");\n\nwhere-as exit is typically used as a successful exit (At least in my coding)\nThe PHP Manual says that the functions are identical.\n",
            "\ndie(); is just a synonym for exit(); and is functionally identical.\nThe standard way is to use exit code zero to signify success, and anything else to denote an error condition.\n",
            "\ndie is exactly equivalent to exit.\nFrom the manual:\n\nIf status is an integer, that value will be used as the exit status..\n\nThis is only useful if you have some sort of wrapper that does something based on the exit status. Unless you have a specific need to report an exit code to the outside world, just exit;.\n"
        ],
        "answer": "A2",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "2357230",
        "question": "\nIs there a generally accepted way to comment functions in Python? Is the following acceptable?\n#########################################################\n# Create a new user\n#########################################################\ndef add(self):\n\n",
        "all_answers": [
            "\nThe correct way to do it is to provide a docstring. That way, help(add) will also spit out your comment.\ndef add(self):\n    \"\"\"Create a new user.\n    Line 2 of comment...\n    And so on... \n    \"\"\"\n\nThat's three double quotes to open the comment and another three double quotes to end it. You can also use any valid Python string. It doesn't need to be multiline and double quotes can be replaced by single quotes. \nSee: PEP 257\n",
            "\nRead about using docstrings in your Python code.\nAs per the Python docstring conventions:\n\nThe docstring for a function or method should summarize its behavior and document its arguments, return value(s), side effects, exceptions raised, and restrictions on when it can be called (all if applicable). Optional arguments should be indicated. It should be documented whether keyword arguments are part of the interface.\n\nThere will be no golden rule, but rather provide comments that mean something to the other developers on your team (if you have one) or even to yourself when you come back to it six months down the road.\n"
        ],
        "answer": "A1",
        "tags": [
            "python"
        ]
    },
    {
        "question_id": "30913201",
        "question": "\nI want to pass named arguments to the target function, while creating a Thread object. \nFollowing is the code that I have written:\nimport threading\n\ndef f(x=None, y=None):\n    print x,y\n\nt = threading.Thread(target=f, args=(x=1,y=2,))\nt.start()\n\nI get a syntax error for \"x=1\", in Line 6.\nI want to know how I can pass keyword arguments to the target function.\n",
        "all_answers": [
            "\nTry to replace args with kwargs={x: 1, y: 2}.\n",
            "\nIt's pretty simple to delegate a method to a thread or sub-process using BaseEventLoop.run_in_executor:\nimport asyncio\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef cpu_bound_operation(x):\n    time.sleep(x) # This is some operation that is CPU-bound\n\n@asyncio.coroutine\ndef main():\n    # Run cpu_bound_operation in the ProcessPoolExecutor\n    # This will make your coroutine block, but won't block\n    # the event loop; other coroutines can run in meantime.\n    yield from loop.run_in_executor(p, cpu_bound_operation, 5)\n\n\nloop = asyncio.get_event_loop()\np = ProcessPoolExecutor(2) # Create a ProcessPool with 2 processes\nloop.run_until_complete(main())\n\nAs for whether to use a ProcessPoolExecutor or ThreadPoolExecutor, that's kind of hard to say; pickling a large object will definitely eat some CPU cycles, which initially would make you think ProcessPoolExecutor is the way to go. However, passing your 100MB object to a Process in the pool would require pickling the instance in your main process, sending the bytes to the child process via IPC, unpickling it in the child, and then pickling it again so you can write it to disk. Given that, my guess is the pickling/unpickling overhead will be large enough that you're better off using a ThreadPoolExecutor, even though you're going to take a performance hit because of the GIL.\nThat said, it's very simple to test both ways and find out for sure, so you might as well do that.\n",
            "\nt = threading.Thread(target=f, kwargs={'x': 1,'y': 2})\n\nthis will pass a dictionary with the keyword arguments' names as keys and argument values as values in the dictionary.\nthe other answer above won't work, because the \"x\" and \"y\" are undefined in that scope.\nanother example, this time with multiprocessing, passing both positional and keyword arguments:\nthe function used being:\ndef f(x, y, kw1=10, kw2='1'):\n    pass\n\nand then when called using multiprocessing:\np = multiprocessing.Process(target=f, args=('a1', 2,), kwargs={'kw1': 1, 'kw2': '2'})\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "multithreading",
            "python-2.7",
            "python-multithreading",
            "keyword-argument"
        ]
    },
    {
        "question_id": "13002626",
        "question": "\nI'm reading the Laravel Blade documentation and I can't figure out how to assign variables inside a template for use later. I can't do {{ $old_section = \"whatever\" }} because that will echo \"whatever\" and I don't want that.\nI understand that I can do <?php $old_section = \"whatever\"; ?>, but that's not elegant.\nIs there a better, elegant way to do that in a Blade template?\n",
        "all_answers": [
            "\nI have solved this if you are using array called for 2 tables. Example you have,\n$tableA['yellow'] and $tableA['blue'] . You are getting these 2 values and you want to add another element inside them to separate them by their type.\nforeach ($tableA['yellow'] as $value) {\n    $value->type = 'YELLOW';  //you are adding new element named 'type'\n}\n\nforeach ($tableA['blue'] as $value) {\n    $value->type = 'BLUE';  //you are adding new element named 'type'\n}\n\nSo, both of the tables value will have new element called type.\n",
            "\nI don't think that you can - but then again, this kind of logic should probably be handled in your controller and passed into the view already set.\n",
            "\nAs mentioned above  if you wish to add as a new element your queried collection you can use:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n        $product = DB::select(DB::raw(' select * from product\n               where product_id = '. $id.';' ));\n\n        $items->push($product);\n        // or \n        // $items->put('products', $product);\n    }\n\nbut if you wish to add new element to each queried element you need to do like:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n           $product = DB::select(DB::raw(' select * from product\n                 where product_id = '. $id.';' ));\n    \n          $item->add_whatever_element_you_want = $product;\n    }\n\nadd_whatever_element_you_want can be whatever you wish that your element is named (like product for example).\n",
            "\nIt looks like you have everything correct according to Laravel docs, but you have a typo\n$item->push($product);\n\nShould be\n$items->push($product);\n\npush method appends an item to the end of the collection:\nI also want to think the actual method you're looking for is put\n$items->put('products', $product);\n\nput method sets the given key and value in the collection\n",
            "\n$item = collect();\n$item->push($product);\n\n",
            "\nIf you want to add item to the beginning of the collection you can use prepend:\n$item->prepend($product, 'key');\n\n",
            "\nThis is what i would do...\n$items = Item::find($id);\nforeach($items as $item){\n    $product = Product::find($id);\n    $item->product = $product;\n}\n\nThis would assign $product to each $item\n",
            "\nIt is discouraged to do in a view so there is no blade tag for it.\nIf you do want to do this in your blade view, you can either just open a php tag as you wrote it or register a new blade tag. Just an example:\n<?php\n/**\n * <code>\n * {? $old_section = \"whatever\" ?}\n * </code>\n */\nBlade::extend(function($value) {\n    return preg_replace('/\\{\\?(.+)\\?\\}/', '<?php ${1} ?>', $value);\n});\n\n",
            "\nIf you want to add a product into the array you can use:\n$item['product'] = $product;\n\n"
        ],
        "answer": "A8",
        "tags": [
            "php",
            "laravel",
            "laravel-blade"
        ]
    },
    {
        "question_id": "5013367",
        "question": "\nthis is my code :\n{% for i,j in enumerate(a) %}\n    {{i}} ,{{j}}\n{% endfor%}\n\nbut , it show a error , i think it cant run the enumerate method ,\nso how to run the enumerate  in django template ,\nthanks\n",
        "all_answers": [
            "\nyou can use {{ forloop.counter }} or {{ forloop.counter0 }} for the same effect, the latter is 0-indexed, thus more like enumerate.\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nsettings.py\nALLOWED_HOSTS = ['*'] // if you are in dev or docker\n\nEdited\nOk guys, dont do this in production if you are not using docker, just put the IP addr.\nGrettings\n",
            "\n{% for item in a %}\n    {{ forloop.counter }}, {{ item }}\n{% endfor %}\n\nLink related\n",
            "\nThe template subsystem has some special constructs built into the for/endfor block that allows you to access the current index of the loop without having to call enumerate.\n{% for j in a %}\n    {{ forloop.counter0 }}, {{ j }}\n{% endfor %}\n\nWhile this snippet solves your immediate problem, if you're expecting to have access to Python builtins and other Python constructs inside your Django templates, you may be misunderstanding the sandbox that it provides/enforces.  \n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n",
            "\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['62.63.141.41', 'namjoosadr.com']\n\nand then restart your apache. in ubuntu:\n/etc/init.d/apache2 restart\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n"
        ],
        "answer": "A5",
        "tags": [
            "python",
            "django",
            "templates"
        ]
    },
    {
        "question_id": "4686583",
        "question": "\n\n\n\nI am by no means an expert at Javascript, but I have been reading Mark Pilgrim's \"Dive into HTML5\" webpage and he mentioned something that I would like a better understanding of.\nHe states:\n\nFinally, you use the double-negative trick to force the result to a Boolean value (true or false).\n\nfunction supports_canvas() {\n  return !!document.createElement('canvas').getContext;\n}\n\nIf anyone can explain this a little better I would appreciate it!\n",
        "all_answers": [
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nIn javascript, using the \"bang\" operator (!) will return true if the given value is true, 1, not null, etc. It will return false if the value is undefined, null, 0, or an empty string.\nSo the bang operator will always return a boolean value, but it will represent the opposite value of what you began with. If you take the result of that operation and \"bang\" it again, you can reverse it again, but still end up with a boolean (and not undefined, null, etc).\nUsing the bang twice will take a value that could have been undefined, null, etc, and make it just plain false. It will take a value that could have been 1, \"true\", etc. and make it just plain true.\nThe code could have been written:\nvar context = document.createElement('canvas').getContext;\nvar contextDoesNotExist = !context;\nvar contextExists = !contextDoesNotExist;\nreturn contextExists;\n\n",
            "\nA logical NOT operator ! converts a value to a boolean that is the opposite of its logical value. \nThe second ! converts the previous boolean result back to the boolean representation of  its original logical value.\nFrom these docs for the Logical NOT operator:\n\nReturns false if its single operand can be converted to true; otherwise, returns true.\n\nSo if getContext gives you a \"falsey\" value, the !!  will make it return the boolean value false. Otherwise it will return true.\nThe \"falsey\" values are:\n\nfalse\nNaN\nundefined\nnull\n\"\" (empty string)\n0\n\n"
        ],
        "answer": "A4",
        "tags": [
            "javascript",
            "html"
        ]
    },
    {
        "question_id": "22700728",
        "question": "\nI ran into a problem using composer for installing/uninstalling some dependencies in laravel, which come back after deleting them from composer.json and deleting their vendor folder.\nI initially used dflydev's markdown package, but now I want to change it to michelf's php-markdown, but I can't uninstall the old one since it comes back loaded from cache. I checked at AppData\\Roaming\\Composer and it is empty.\nAny clue as to why this is happening?\n  - Installing dflydev/markdown (dev-master dee1f7a)\n    Loading from cache\n\n",
        "all_answers": [
            "\nYou can use the following command to clear the cache irrespective of the OS you are on:\nphp composer.phar clear-cache\n\nor if composer is installed globally\ncomposer clear-cache\n\n",
            "\nrun the following command\nrm -rf ~/.composer/cache*\n\nif Permission denied add sudo\n",
            "\ncomposer caches packages under vendor/packagename convention. So you shouldn't run into any issue, just because the packagename is used in another vendor's package.\nthe cache locations are:\n\nWindows: %LOCALAPPDATA%\\Composer\\files\\vendor\\packagename\nLinux: ~/.composer/cache/files/vendor/packagename\nmacOS:  ~/Library/Caches/composer/files/packagename\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "composer-php"
        ]
    },
    {
        "question_id": "3249524",
        "question": "\n\n\n\nI would like to make several statements that give standard output without seeing newlines in between statements.\nSpecifically, suppose I have:\nfor item in range(1,100):\n    print item\n\nThe result is:\n1\n2\n3\n4\n.\n.\n.\n\nHow get this to instead look like:\n1 2 3 4 5 ...\n\nEven better, is it possible to print the single number over the last number, so only one number is on the screen at a time?\n",
        "all_answers": [
            "\nUse print item, to make the print statement omit the newline.\nIn Python 3, it's print(item, end=\" \").\nIf you want every number to display in the same place, use for example (Python 2.7):\nto = 20\ndigits = len(str(to - 1))\ndelete = \"\\b\" * (digits + 1)\nfor i in range(to):\n    print \"{0}{1:{2}}\".format(delete, i, digits),\n\nIn Python 3, it's a bit more complicated; here you need to flush sys.stdout or it won't print anything until after the loop has finished:\nimport sys\nto = 20\ndigits = len(str(to - 1))\ndelete = \"\\b\" * (digits)\nfor i in range(to):\n   print(\"{0}{1:{2}}\".format(delete, i, digits), end=\"\")\n   sys.stdout.flush()\n\n",
            "\nChange print item to:\n\nprint item, in Python 2.7\nprint(item, end=\" \") in Python 3\n\nIf you want to print the data dynamically use following syntax:\n\nprint(item, sep=' ', end='', flush=True) in Python 3\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "printing"
        ]
    },
    {
        "question_id": "15300887",
        "question": "\nI have two C# winform (.NET 4.0) forms that each run separate but similar automated tasks continuously.  Separate in that they are distinct processes/workflows, but similar enough in how they operate to share the same resources (methods, data models, assemblies, etc) in the project.  \nBoth forms are complete, but now I'm not sure how to run the program so that each window opens on launch and runs independently.  The program will be \"always-on\" when deployed.\nThis might seem a little basic, but most of my development experience has been web applications. Threading/etc is still a little foreign to me. I've researched but most of the answers I've found relate to user interaction and sequential use cases -- this will just be one system continuously running two distinct processes, which will need to interact with the world independently.\nPotential solutions I've found might involve multi-threading, or maybe some kind of MDI, or a few folks have suggested the DockPanelSuite (although being in a super-corporate environment, downloading third party files is easier said than done).\nstatic class Program\n{\n    /// <summary>\n    /// The main entry point for the application.\n    /// </summary>\n    [STAThread]\n    static void Main()\n    {\n        Application.EnableVisualStyles();\n        Application.SetCompatibleTextRenderingDefault(false);\n\n        // Rather than specifying frmOne or frmTwo,\n        // load both winforms and keep them running.\n        Application.Run(new frmOne());\n    }\n}\n\n",
        "all_answers": [
            "\nYou can create a new ApplicationContext to represent multiple forms:\npublic class MultiFormContext : ApplicationContext\n{\n    private int openForms;\n    public MultiFormContext(params Form[] forms)\n    {\n        openForms = forms.Length;\n\n        foreach (var form in forms)\n        {\n            form.FormClosed += (s, args) =>\n            {\n                //When we have closed the last of the \"starting\" forms, \n                //end the program.\n                if (Interlocked.Decrement(ref openForms) == 0)\n                    ExitThread();\n            };\n\n            form.Show();\n        }\n    }\n}\n\nUsing that you can now write:\nApplication.EnableVisualStyles();\nApplication.SetCompatibleTextRenderingDefault(false);\nApplication.Run(new MultiFormContext(new Form1(), new Form2()));\n\n",
            "\nIf you really need two windows/forms to run on two separate UI threads, you could do something like this:\nstatic class Program\n{\n    [STAThread]\n    static void Main()\n    {\n        Application.EnableVisualStyles();\n        Application.SetCompatibleTextRenderingDefault(false);\n\n        var thread = new Thread(ThreadStart);\n        // allow UI with ApartmentState.STA though [STAThread] above should give that to you\n        thread.TrySetApartmentState(ApartmentState.STA); \n        thread.Start(); \n\n        Application.Run(new frmOne());\n    }\n\n    private static void ThreadStart()\n    {\n        Application.Run(new frmTwo()); // <-- other form started on its own UI thread\n    }\n}\n\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "multithreading",
            "winforms"
        ]
    },
    {
        "question_id": "3406171",
        "question": "\nWhat is the difference between var_dump() and print_r() in terms of spitting out an array as string?\n",
        "all_answers": [
            "\nThe var_dump function displays structured information about variables/expressions including its type and value. Arrays are explored recursively with values indented to show structure. It also shows which array values and object properties are references.\nThe print_r() displays information about a variable in a way that's readable by humans. array values will be presented in a format that shows keys and elements. Similar notation is used for objects.\nExample:\n$obj = (object) array('qualitypoint', 'technologies', 'India');\n\nvar_dump($obj) will display below output in the screen.\nobject(stdClass)#1 (3) {\n [0]=> string(12) \"qualitypoint\"\n [1]=> string(12) \"technologies\"\n [2]=> string(5) \"India\"\n}\n\nAnd, print_r($obj) will display below output in the screen.\nstdClass Object ( \n [0] => qualitypoint\n [1] => technologies\n [2] => India\n)\n\nMore Info\n\nvar_dump\nprint_r\n\n",
            "\nvar_dump() will show you the type of the thing as well as what's in it.\nSo you'll get => (string)\"var\" Example is here.\nprint_r() will just output the content.\nWould output => \"var\" Example is here.\n",
            "\nvar_dump displays structured information about the object / variable. This includes type and values. Like print_r arrays are recursed through and indented.\nprint_r displays human readable information about the values with a format presenting keys and elements for arrays and objects.\nThe most important thing to notice is var_dump will output type as well as values while print_r does not.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "arrays"
        ]
    },
    {
        "question_id": "3701404",
        "question": "\nIs there a way to list all commits that changed a specific file?\n",
        "all_answers": [
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\nIt should be as simple as git log <somepath>; check the manpage (git-log(1)).\nPersonally I like to use git log --stat <path> so I can see the impact of each commit on the file.\n",
            "\nThe --follow works for a particular file\ngit log --follow -- filename\n\nDifference to other solutions given\nNote that other solutions include git log path (without the --follow). That approach is handy if you want to track e.g. changes in a directory, but stumbles when files were renamed (thus use --follow filename).\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nRemove the last commit before push\ngit reset --soft HEAD~1\n1 means the last commit, if you want to remove two last use 2, and so forth*\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\ngit log path should do what you want. From the git log man page:\n[--] <path>…\n\nShow only commits that affect any of the specified paths. To prevent confusion with\noptions and branch names, paths may need to be prefixed with \"-- \" to separate them\nfrom options or refnames.\n\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n"
        ],
        "answer": "A5",
        "tags": [
            "git",
            "commit"
        ]
    },
    {
        "question_id": "52351756",
        "question": "\nIm new in Django and I can't figure out this error. Help please. It gave TypeError - save() got an unexpected keyword argument 'force_insert'. I tested the code below and they were able to save the new user registration but now it won't save anymore...\nHere is part of the views.py that i think got some problem:\n    from django.shortcuts import render, redirect\n    from django.contrib.auth.forms import UserCreationForm\n    from django.contrib import messages\n    from django.contrib.auth.decorators import login_required\n    from . forms import UserRegisterForm, UserUpdateForm, ProfileUpdateForm\n\n    def register(request):\n        if request.method == 'POST':\n            form = UserRegisterForm(request.POST)\n            if form.is_valid():\n            username = form.cleaned_data.get('username')\n            form.save(force_insert=False)\n            messages.success(request, f'Thank you {username}! Your account has been created!')\n            return redirect('login')\n    else:\n        form = UserRegisterForm()\n\n    return render(request, 'users/register.html', {'form':form})\n\nand the models.py\nfrom django.db import models\nfrom django.contrib.auth.models import User\nfrom PIL import Image\n\nclass Profile(models.Model):\n    user = models.OneToOneField(User, on_delete=models.CASCADE)\n    image = models.ImageField(default='profile_pics/default.jpg', upload_to='profile_pics')\n\n    def __str__(self):\n        return (self.user)\n\n    def save(self):\n        super().save()\n\n        img = Image.open(self.image.path)\n\n        if img.height > 300 or img.width > 300:\n            output_size = (300,300)\n            img.thumbnail(output_size)\n            img.save(self.image.path)'\n\n",
        "all_answers": [
            "\nYou've overridden the save method, but you haven't preserved its signature. Yo need to accept the same arguments as the original method, and pass them in when calling super.\ndef save(self, *args, **kwargs):\n    super().save((*args, **kwargs)\n    ...\n\n",
            "\nWhen you are overriding model's save method in Django, you should also pass *args and **kwargs to overridden method. this code may work fine:\ndef save(self, *args, **kwargs):\n    super(Profile, self).save(*args, **kwargs)\n\n    img = Image.open(self.image.path)\n\n    if img.height > 300 or img.width > 300:\n        output_size = (300,300)\n        img.thumbnail(output_size)\n        img.save(self.image.path)'\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django"
        ]
    },
    {
        "question_id": "35059916",
        "question": "\nMy API is returning a JSON object on error but the status code is HTTP 200:\nresponse = JsonResponse({'status': 'false', 'message': message})\nreturn response\n\nHow can I change the response code to indicate an error?\n",
        "all_answers": [
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nJsonResponse normally returns HTTP 200, which is the status code for 'OK'. In order to indicate an error, you can add an HTTP status code to JsonResponse as it is a subclass of HttpResponse:\nresponse = JsonResponse({'status':'false','message':message}, status=500)\n\n",
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['62.63.141.41', 'namjoosadr.com']\n\nand then restart your apache. in ubuntu:\n/etc/init.d/apache2 restart\n\n",
            "\nsettings.py\nALLOWED_HOSTS = ['*'] // if you are in dev or docker\n\nEdited\nOk guys, dont do this in production if you are not using docker, just put the IP addr.\nGrettings\n",
            "\nReturn an actual status\nJsonResponse(status=404, data={'status':'false','message':message})\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django",
            "django-views"
        ]
    },
    {
        "question_id": "1295068",
        "question": "\n\n\n\nIs there a way to simulate the *nix tail command on the Windows command line? I have a file and I want a way to snip off the first n lines of text. For example:\nD:\\>type file.txt\nline one\nline two\nline three\nD:\\>*[call to tail]* > result.txt\n\nD:\\>type result.txt\nline two\nline three\n\n",
        "all_answers": [
            "\nYou could get CoreUtils from GnuWin32, which is a collection of standard unix tools, ported to Windows.\nIt, among other things, contains head.\n",
            "\nIf you want the head command, one easy way to get it is to install Cygwin. Then you'll have all the UNIX tools at your disposal.\nIf that isn't a good solution, then you can try using findstr and do a search for the end-of-line indicator.\nfindstr on MSDN: http://technet.microsoft.com/en-us/library/bb490907.aspx\n",
            "\nThere's a free head utility on this page that you can use. I haven't tried it yet.\n",
            "\nI don't think there is way out of the box. There is no such command in DOS and batch files are far to limited to simulate it (without major pain).\n",
            "\nNo exact equivalent. However there exist a native DOS command \"more\" that has a +n option that will start outputting the file after the nth line:\nDOS Prompt:\nC:\\>more +2 myfile.txt\n\nThe above command will output everything after the first 2 lines.\nThis is actually the inverse of Unix head:\nUnix console:\nroot@server:~$ head -2 myfile.txt\n\nThe above command will print only the first 2 lines of the file.\n"
        ],
        "answer": "A5",
        "tags": [
            "windows",
            "command-line"
        ]
    },
    {
        "question_id": "820781",
        "question": "\nI have a controller with multiple actions that take :year and :month as\nattributes from the URL. I have made a private method check_date to\ncheck the date is valid and check the date is not in the future.\ndef check_date(year, month)\n  if month < 1 || month > 12 || year < 2000\n    flash[:notice] = I18n.t 'archive.invalid_date'\n    redirect_to :action => 'index'\n  elsif year > Date.today.year || (year == Date.today.year && month > Date.today.month)\n    flash[:notice] = I18n.t 'archive.no_future'\n    redirect_to :action => 'month_index', \n      :year => Date.today.year, \n      :month => Date.today.month,\n      :type => params[:type]\n  end\nend\n\nIs there a rails way of ending controller execution after the\nredirect_to? \nWays I can think of are either to throw an exception after the redirect_to or to return a value from check_date and check it in each action that calls it - something like\ndef month_index \n  year = params[:year].to_i\n  month = params[:month].to_i\n  if !check_date(year, month)\n    return\n  ...\nend\n\nBut I wonder if there is some nice rails way of doing this. I was half\nhoping that having called redirect_to rails would recognise I wanted to\nstop, but that doesn't seem to happen.\n",
        "all_answers": [
            "\nYou probably want to use filters.\nIf you call your check_date as a before_filter in the controller, the fact that it rendered or redirected will prevent the controller from ever calling the action method. It ends there and then.\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nredirect_to just tells rails what to render when it finishes.  Rails will get confused if you add other render or redirect_to directives after the one you really want, so just return from the controller after the redirect_to - it's the 'normal' rails way to do things.\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "error-handling"
        ]
    },
    {
        "question_id": "12233046",
        "question": "\nI have a django 1.4 app with a populated postgres 9.1 database in development server locally. After successful deployment, I wanted to move the data from local to online database, so I used:\npg_dump -f dump.sql -Ox database\n\nand then restored on the server with:\npsql -1 -f dump.sql database\n\nNow trying to login online to the website admin throws a \"permission denied for relation django_session\" exception. I've tried to dump the data with/without -Ox switch and all its combinations but without success. I am also dropping the database and recreating it from scratch on the server with the correct owner as set in settings.py.\nIf I run a normal syndb without a restore then everything works well.\nAm I missing something here?\n",
        "all_answers": [
            "\nTry to do this from postgres user:\nsudo su - postgres\npg_dump -f dump.sql -Ox database\n\nOr just pass -U flag:\npg_dump -f dump.sql -Ox database -U postgres\n\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nIt turns out that you should grant explicit ownership of all objects in the database to the owner after restore. The owner is not a superuser. It's not enough to only set the owner at database creation time. The final solution for migration goes like this:\non the client:\npg_dump -f dump.sql -Ox database\n\non the server:\nsu postgres    \ndropdb database\ncreatedb database -O user\npsql database -f dump.sql\n\nand then to set the privileges:\npsql database -c \"GRANT ALL ON ALL TABLES IN SCHEMA public to user;\"\npsql database -c \"GRANT ALL ON ALL SEQUENCES IN SCHEMA public to user;\"\npsql database -c \"GRANT ALL ON ALL FUNCTIONS IN SCHEMA public to user;\"\n\nNote that we could've run the sql command in psql console but this form is easily embeddable in scripts and such.\n"
        ],
        "answer": "A4",
        "tags": [
            "django",
            "postgresql"
        ]
    },
    {
        "question_id": "3302476",
        "question": "\nI'm adding this table:\nCREATE TABLE contenttype (\n        contenttypeid INT UNSIGNED NOT NULL AUTO_INCREMENT,\n        class VARBINARY(50) NOT NULL,\n        packageid INT UNSIGNED NOT NULL,\n        canplace ENUM('0','1') NOT NULL DEFAULT '0',\n        cansearch ENUM('0','1') NOT NULL DEFAULT '0',\n        cantag ENUM('0','1') DEFAULT '0',\n        canattach ENUM('0','1') DEFAULT '0',\n        isaggregator ENUM('0', '1') NOT NULL DEFAULT '0',\n        PRIMARY KEY (contenttypeid),\n        UNIQUE KEY packageclass (packageid, class)\n);\n\nAnd I get a 1050 \"table already exists\"\nBut the table does NOT exist. Any ideas?\nEDIT: more details because everyone seems to not believe me :)\nDESCRIBE contenttype\n\nyields:\n\n1146 - Table 'gunzfact_vbforumdb.contenttype' doesn't exist\n\nand\nCREATE TABLE gunzfact_vbforumdb.contenttype(\ncontenttypeid INT UNSIGNED NOT NULL AUTO_INCREMENT ,\nclass VARBINARY( 50 ) NOT NULL ,\npackageid INT UNSIGNED NOT NULL ,\ncanplace ENUM( '0', '1' ) NOT NULL DEFAULT '0',\ncansearch ENUM( '0', '1' ) NOT NULL DEFAULT '0',\ncantag ENUM( '0', '1' ) DEFAULT '0',\ncanattach ENUM( '0', '1' ) DEFAULT '0',\nisaggregator ENUM( '0', '1' ) NOT NULL DEFAULT '0',\nPRIMARY KEY ( contenttypeid ) ,\n\nYields:\n\n1050 - Table 'contenttype' already exists\n\n",
        "all_answers": [
            "\nSounds like you have Schroedinger's table... \nSeriously now, you probably have a broken table. Try:\n\nDROP TABLE IF EXISTS contenttype\nREPAIR TABLE contenttype\nIf you have sufficient permissions, delete the data files (in /mysql/data/db_name)\n\n",
            "\nFirst check if you are in the right database USE yourDB and try Select * from contenttype just to see what is it and if it exists really...\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n"
        ],
        "answer": "A1",
        "tags": [
            "mysql",
            "sql",
            "mysql-error-1146",
            "mysql-error-1050"
        ]
    },
    {
        "question_id": "15346863",
        "question": "\nI am running various Java benchmarks and would like to archive the results. I execute the (dacapo) benchmark like this:\nC:\\VM\\jre\\bin\\java  -jar C:\\benchmarks\\dacapo-9.12-bach.jar %arg1% > %time::=%\n\nI pass the type of benchmark in over a parameter, thats what %arg1% is.\nYou can see that I am redirecting the output to a textfile. Unfortunately, the first and last line of the output is still printed in the console and not into the textfile:\n===== DaCapo 9.12 luindex starting =====\n===== DaCapo 9.12 luindex PASSED in 2000 msec =====\n\nEspecially the last line would be important to have in the text file :)\nIs there a trick to force this behavior?\n",
        "all_answers": [
            "\nAdd 2>&1 to your command:\n C:\\VM\\jre\\bin\\java  -jar C:\\benchmarks\\dacapo-9.12-bach.jar %arg1% 2>&1 > %time::=% \n\nThis will redirect STDERR to STDOUT which is then redirected into your textfile.\n",
            "\nYou must redirect STDOUT and STDERR.\ncommand > logfile 2>&1\nSTDIN is file descriptor #0, STDOUT is file descriptor #1 and STDERR is file descriptor #2.\nJust as \"command > file\" redirects STDOUT to a file, you may also redirect arbitrary file descriptors to each other. The >& operator redirects between file descriptors. So, 2 >& 1 redirects all STDERR output to STDOUT.  \nFurthermore, take care to add 2>&1 at the end of the instruction because on Windows, the order of redirection is important as command 2>&1 > logfile will produce an empty file, as Dawid added in the comments.\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "batch-file",
            "dacapo"
        ]
    },
    {
        "question_id": "294250",
        "question": "\nSuppose that I have a <div> that I wish to center in the browser's display (viewport). To do so, I need to calculate the width and height of the <div> element. \nWhat should I use? Please include information on browser compatibility.\n",
        "all_answers": [
            "\nThese solutions will work:\nAs mentioned in comments use defer:\n<script src=\"deferMe.js\" defer></script>\n\nor\n<body onload=\"script();\">\n\nor\ndocument.onload = function ...\n\nor even\nwindow.onload = function ...\n\nNote that the last option is a better way to go since it is unobstrusive and is considered more standard.\n",
            "\nYou should use the .offsetWidth and .offsetHeight properties.\nNote they belong to the element, not .style.\nvar width = document.getElementById('foo').offsetWidth;\n\nThe .getBoundingClientRect() function returns the dimensions and location of the element as floating-point numbers after performing CSS transforms.\n> console.log(document.getElementById('foo').getBoundingClientRect())\nDOMRect {\n    bottom: 177,\n    height: 54.7,\n    left: 278.5,​\n    right: 909.5,\n    top: 122.3,\n    width: 631,\n    x: 278.5,\n    y: 122.3,\n}\n\n",
            "\nNOTE: this answer was written in 2008. At the time the best cross-browser solution for most people really was to use jQuery. I'm leaving the answer here for posterity and, if you're using jQuery, this is a good way to do it. If you're using some other framework or pure JavaScript the accepted answer is probably the way to go.\nAs of jQuery 1.2.6 you can use one of the core CSS functions, height and width (or outerHeight and outerWidth, as appropriate).\nvar height = $(\"#myDiv\").height();\nvar width = $(\"#myDiv\").width();\n\nvar docHeight = $(document).height();\nvar docWidth = $(document).width();\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "html",
            "dhtml"
        ]
    },
    {
        "question_id": "6871016",
        "question": "\nI have a date \"10/10/11(m-d-y)\" and I want to add 5 days to it using a Python script. Please consider a general solution that works on the month ends also.\nI am using following code:\nimport re\nfrom datetime import datetime\n\nStartDate = \"10/10/11\"\n\nDate = datetime.strptime(StartDate, \"%m/%d/%y\")\n\nprint Date -> is printing '2011-10-10 00:00:00'\nNow I want to add 5 days to this date. I used the following code:\nEndDate = Date.today()+timedelta(days=10)\n\nWhich returned this error:\nname 'timedelta' is not defined\n\n",
        "all_answers": [
            "\nFor all coming along and searching for an implementation:\nThe above posts are related to datetime.timedelta, which is sadly not having properties for hours and seconds. So far it was not mentioned, that there is a package, which is having these. You can find it here:\n\nCheck the source: https://github.com/andrewp-as-is/timedelta.py\nAvailable via pip: https://pypi.org/project/timedelta/\n\nExample - Calculation:\n>>> import timedelta\n\n>>> td = timedelta.Timedelta(days=2, hours=2)\n\n# init from datetime.timedelta\n>>> td = timedelta.Timedelta(datetime1 - datetime2)\n\nExample - Properties:\n>>> td = timedelta.Timedelta(days=2, hours=2)\n>>> td.total.seconds\n180000\n>>> td.total.minutes\n3000\n>>> td.total.hours\n50\n>>> td.total.days\n2\n\nI hope this could help someone...\n",
            "\nImport timedelta and date first.\nfrom datetime import timedelta, date\n\nAnd date.today() will return today's datetime, which you can then add a timedelta to it:\nend_date = date.today() + timedelta(days=10)\n\n",
            "\nI guess you are missing something like that:\nfrom datetime import timedelta\n\n",
            "\nThe previous answers are correct but it's generally a better practice to do:\nimport datetime\n\nThen you'll have, using datetime.timedelta:\ndate_1 = datetime.datetime.strptime(start_date, \"%m/%d/%y\")\n\nend_date = date_1 + datetime.timedelta(days=10)\n\n",
            "\nThis is a bit more compact, you get the hours, minutes and seconds in two lines.\ndays = td.days\nhours, remainder = divmod(td.seconds, 3600)\nminutes, seconds = divmod(remainder, 60)\n# If you want to take into account fractions of a second\nseconds += td.microseconds / 1e6\n\n",
            "\ndays, hours, minutes = td.days, td.seconds // 3600, td.seconds // 60 % 60\n\nAs for DST, I think the best thing is to convert both datetime objects to seconds. This way the system calculates DST for you.\n>>> m13 = datetime(2010, 3, 13, 8, 0, 0)  # 2010 March 13 8:00 AM\n>>> m14 = datetime(2010, 3, 14, 8, 0, 0)  # DST starts on this day, in my time zone\n>>> mktime(m14.timetuple()) - mktime(m13.timetuple())     # difference in seconds\n82800.0\n>>> _/3600                                                # convert to hours\n23.0\n\n",
            "\nIf you have a datetime.timedelta value td, td.days already gives you the \"days\" you want. timedelta values keep fraction-of-day as seconds (not directly hours or minutes) so you'll indeed have to perform \"nauseatingly simple mathematics\", e.g.:\ndef days_hours_minutes(td):\n    return td.days, td.seconds//3600, (td.seconds//60)%60\n\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "date",
            "datetime",
            "timedelta"
        ]
    },
    {
        "question_id": "15027282",
        "question": "\nI am trying to do a foreach on a vector of attacks, each attack has a unique ID say, 1-3.\nThe class method takes the keyboard input of 1-3.\nI am trying to use a foreach to run through my elements in m_attack to see if the number matches, if it does... do something.\nThe problem I'm seeing is this:\na'for each' statement cannot operate on an expression of type \"std::vector<Attack\n\nAm I going about this totally wrong, I have C# experience and is kind of what I'm basing this on, any help would be appreciated.\nMy code is as follows:\nIn header\nvector<Attack> m_attack;\n\nIn class\nint Player::useAttack (int input)\n{\n\n    for each (Attack* attack in m_attack) // Problem part\n    {  \n        //Psuedo for following action\n        if (attack->m_num == input)\n        {\n            //For the found attack, do it's damage\n            attack->makeDamage();\n        }\n    }\n}\n\n",
        "all_answers": [
            "\nC++ does not have the for_each loop feature in its syntax. You have to use c++11 or use the template function std::for_each.\nstruct Function {\n    int input;\n    Function(int input): input(input) {}\n    void operator()(Attack& attack) {\n        if(attack->m_num == input) attack->makeDamage();\n    }\n};\nFunction f(input);\nstd::for_each(m_attack.begin(), m_attack.end(), f);\n\n",
            "\nThis is how it would be done in a loop in C++(11):\n   for (const auto& attack : m_attack)\n    {  \n        if (attack->m_num == input)\n        {\n            attack->makeDamage();\n        }\n    }\n\nThere is no for each in C++. Another option is to use std::for_each with a suitable functor (this could be anything that can be called with an Attack* as argument).\n",
            "\nFor next examples assumed that you use C++11.\nExample with ranged-based for loops:\nfor (auto &attack : m_attack) // access by reference to avoid copying\n{  \n    if (attack.m_num == input)\n    {\n        attack.makeDamage();\n    }\n}\n\nYou should  use const auto &attack depending on the behavior of makeDamage().\nYou can use std::for_each from standard  library + lambdas:\nstd::for_each(m_attack.begin(), m_attack.end(),\n        [](Attack * attack)\n        {\n            if (attack->m_num == input)\n            {\n                attack->makeDamage();\n            }\n        }\n);\n\nIf you are uncomfortable using std::for_each, you can loop over m_attack using iterators:\nfor (auto attack = m_attack.begin(); attack != m_attack.end(); ++attack)\n{  \n    if (attack->m_num == input)\n    {\n        attack->makeDamage();\n    }\n}\n\nUse m_attack.cbegin() and m_attack.cend() to get const iterators.\n",
            "\nTry pass array to vector:\nint arr[] = {2,5,8,11,14};\nstd::vector<int> TestVector(arr, arr+5);\n\nYou could always call std::vector::assign to assign array to vector, call std::vector::insert to add multiple arrays.\nIf you use C++11, you can try:\nstd::vector<int> v{2,5,8,11,14};\n\nOr\nstd::vector<int> v = {2,5,8,11,14};\n\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "for-loop",
            "vector",
            "each"
        ]
    },
    {
        "question_id": "33251373",
        "question": "\nAgainst the traditional approach of prompting user to go to the settings page and enable location services and come back again, I have noticed a simpler way of doing the same in some of the latest apps.\nReferring to below screenshot, it prompts a dialog to user to enable the location services with just one click and it works in those apps.\nHow can I achieve the same?\n\n",
        "all_answers": [
            "\nAndroid Marshmallow 6 supports runtime permission. Runtime permissions only work on Marshmallow and on pre-Marshmallow it still works the old way.\nYou can learn more about it in this Android Developer official Video:\nhttps://www.youtube.com/watch?v=C8lUdPVSzDk\nAnd requesting permission: http://developer.android.com/training/permissions/requesting.html\n",
            "\nThis dialog is created by LocationSettingsRequest.Builder available in the Google Play Services.\nYou need to add a dependency to your app build.gradle:\ncompile 'com.google.android.gms:play-services-location:10.0.1'\n\nThen you can use this minimal example:\nprivate void displayLocationSettingsRequest(Context context) {\n    GoogleApiClient googleApiClient = new GoogleApiClient.Builder(context)\n            .addApi(LocationServices.API).build();\n    googleApiClient.connect();\n\n    LocationRequest locationRequest = LocationRequest.create();\n    locationRequest.setPriority(LocationRequest.PRIORITY_HIGH_ACCURACY);\n    locationRequest.setInterval(10000);\n    locationRequest.setFastestInterval(10000 / 2);\n\n    LocationSettingsRequest.Builder builder = new LocationSettingsRequest.Builder().addLocationRequest(locationRequest);\n    builder.setAlwaysShow(true);\n\n    PendingResult<LocationSettingsResult> result = LocationServices.SettingsApi.checkLocationSettings(googleApiClient, builder.build());\n    result.setResultCallback(new ResultCallback<LocationSettingsResult>() {\n        @Override\n        public void onResult(LocationSettingsResult result) {\n            final Status status = result.getStatus();\n            switch (status.getStatusCode()) {\n                case LocationSettingsStatusCodes.SUCCESS:\n                    Log.i(TAG, \"All location settings are satisfied.\");\n                    break;\n                case LocationSettingsStatusCodes.RESOLUTION_REQUIRED:\n                    Log.i(TAG, \"Location settings are not satisfied. Show the user a dialog to upgrade location settings \");\n\n                    try {\n                        // Show the dialog by calling startResolutionForResult(), and check the result\n                        // in onActivityResult().\n                        status.startResolutionForResult(MainActivity.this, REQUEST_CHECK_SETTINGS);\n                    } catch (IntentSender.SendIntentException e) {\n                        Log.i(TAG, \"PendingIntent unable to execute request.\");\n                    }\n                    break;\n                case LocationSettingsStatusCodes.SETTINGS_CHANGE_UNAVAILABLE:\n                    Log.i(TAG, \"Location settings are inadequate, and cannot be fixed here. Dialog not created.\");\n                    break;\n            }\n        }\n    });\n}\n\nYou can find the complete example here.\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n"
        ],
        "answer": "A2",
        "tags": [
            "android",
            "location"
        ]
    },
    {
        "question_id": "182287",
        "question": "\nWhy can't I pass the table name to a prepared PDO statement?\n$stmt = $dbh->prepare('SELECT * FROM :table WHERE 1');\nif ($stmt->execute(array(':table' => 'users'))) {\n    var_dump($stmt->fetchAll());\n}\n\nIs there another safe way to insert a table name into a SQL query? With safe, I mean that I don't want to do\n$sql = \"SELECT * FROM $table WHERE 1\"\n\n",
        "all_answers": [
            "\nTable and Column names CANNOT be replaced by parameters in PDO.\nIn that case you will simply want to filter and sanitize the data manually. One way to do this is to pass in shorthand parameters to the function that will execute the query dynamically and then use a switch() statement to create a white list of valid values to be used for the table name or column name. That way no user input ever goes directly into the query. So for example:\nfunction buildQuery( $get_var ) \n{\n    switch($get_var)\n    {\n        case 1:\n            $tbl = 'users';\n            break;\n    }\n\n    $sql = \"SELECT * FROM $tbl\";\n}\n\nBy leaving no default case or using a default case that returns an error message you ensure that only values that you want used get used.\n",
            "\nUsing the former isn't inherently more safe than the latter, you need to sanitize the input whether it's part of a parameter array or a simple variable.  So I don't see anything wrong with using the latter form with $table, provided you make sure that the content of $table is safe (alphanum plus underscores?) before using it.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "pdo"
        ]
    },
    {
        "question_id": "6675994",
        "question": "\nI am currently working on a project that is a spinoff (fork) from a framework I have been working on.\nThis project is intended to be pretty generic, but now I need to fork the codebase again for a client of mine.\nAt this moment, I have created a custom branch for my client, but I'd rather have a standalone repository for this.\n\nIs is possible to 'fork a fork'?\nIf not, what alternatives do I have?\n\nOutline of the situation:\n\nFramework repository (original)\n\n\nGeneric application repository (fork)\n\n\n(not yet) Client repository (fork of application)\n\n\n\nNote: when trying to  'fork a fork' in Github, you will receive a notification that you have already forked the project:\n\n",
        "all_answers": [
            "\nSimple answer: Yes and no.\nNo, for a single account as you are unable to create two repositories with the same name (and forks always have the same name).\nYes, for multiple accounts. So you could setup an organization for your second fork.\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nI got the same problem while using a github repository, and connecting to it via https, while using the OS X Keychain Credential helper.\nMy problem was that I had the wrong credentials stored in OS X's Keychain (I was using the email address that I used to sign up for github.com rather than the [username]@github.com address it provides you). I deleted the old account in the keychain and only left the @github.com one and it fixed the problem.\nNot sure if it is related, but when I checked the user.email local config:\ngit config -l\n\nit showed the incorrect email address as well, so I updated the local git user.email to use the correct account too:\ngit config user.email <username>@github.com\n\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nMy issue was that I used the clone https url widget provided by github. That URL doesn't work for private repositories as you need to add a username to the front of it.  \nExample: a private repo owned by john and named widget with collaborator sam the correct url would be: \nhttps://sam@github.com/john/widget.git\nThe github provided url: \nhttps://github.com/john/widget.git\nThe error message leaves much to be desired.\n",
            "\nMake sure that your user account is added to the repository as a collaborator.\nSetting --> Collaborators\n",
            "\nI contacted GitHub support about this 'issue' and they confirmed this is not possible. Also, it is very unlikely that such a feature will be implemented in the future.\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n"
        ],
        "answer": "A10",
        "tags": [
            "git",
            "github",
            "version-control",
            "branch"
        ]
    },
    {
        "question_id": "22355828",
        "question": "\nWhat I want is get an object from an API with a HTTP (eg, jQuery's AJAX) request to an external api. How do I start? I did research on Mr Google but I can't find anything helping.\nIm starting to wonder is this is even possible?\nIn this post Laravel 4 make post request from controller to external url with data it looks like it can be done. But there's no example nor any source where to find some documentation.\nPlease help me out?\n",
        "all_answers": [
            "\nIf you want to add item to the beginning of the collection you can use prepend:\n$item->prepend($product, 'key');\n\n",
            "\nIf you want to add a product into the array you can use:\n$item['product'] = $product;\n\n",
            "\nI have solved this if you are using array called for 2 tables. Example you have,\n$tableA['yellow'] and $tableA['blue'] . You are getting these 2 values and you want to add another element inside them to separate them by their type.\nforeach ($tableA['yellow'] as $value) {\n    $value->type = 'YELLOW';  //you are adding new element named 'type'\n}\n\nforeach ($tableA['blue'] as $value) {\n    $value->type = 'BLUE';  //you are adding new element named 'type'\n}\n\nSo, both of the tables value will have new element called type.\n",
            "\nIt looks like you have everything correct according to Laravel docs, but you have a typo\n$item->push($product);\n\nShould be\n$items->push($product);\n\npush method appends an item to the end of the collection:\nI also want to think the actual method you're looking for is put\n$items->put('products', $product);\n\nput method sets the given key and value in the collection\n",
            "\nYou just want to call an external URL and use the results? PHP does this out of the box, if we're talking about a simple GET request to something serving JSON:\n$json = json_decode(file_get_contents('http://host.com/api/stuff/1'), true);\n\nIf you want to do a post request, it's a little harder but there's loads of examples how to do this with curl. \nSo I guess the question is; what exactly do you want?\n",
            "\nBased upon an answer of a similar question here:\nhttps://stackoverflow.com/a/22695523/1412268\nTake a look at Guzzle\n$client = new GuzzleHttp\\Client();\n$res = $client->get('https://api.github.com/user', ['auth' =>  ['user', 'pass']]);\necho $res->getStatusCode(); // 200\necho $res->getBody(); // { \"type\": \"User\", ....\n\n",
            "\nAs mentioned above  if you wish to add as a new element your queried collection you can use:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n        $product = DB::select(DB::raw(' select * from product\n               where product_id = '. $id.';' ));\n\n        $items->push($product);\n        // or \n        // $items->put('products', $product);\n    }\n\nbut if you wish to add new element to each queried element you need to do like:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n           $product = DB::select(DB::raw(' select * from product\n                 where product_id = '. $id.';' ));\n    \n          $item->add_whatever_element_you_want = $product;\n    }\n\nadd_whatever_element_you_want can be whatever you wish that your element is named (like product for example).\n"
        ],
        "answer": "A6",
        "tags": [
            "php",
            "http",
            "laravel",
            "request"
        ]
    },
    {
        "question_id": "20786593",
        "question": "\nI'd like to handle situations when there is no internet connection. Usually I'd run:\nConnectivityManager cm =\n    (ConnectivityManager)context.getSystemService(Context.CONNECTIVITY_SERVICE);\n\nNetworkInfo activeNetwork = cm.getActiveNetworkInfo();\nboolean isConnected = activeNetwork != null &&\n                  activeNetwork.isConnectedOrConnecting();\n\n(from here) before sending the requests to the network and notify user if there were no internet connection.\nFrom what I saw Retrofit does not handle this situation specifically. If there is no internet connection I'll just get RetrofitError with timeout as a reason. \nIf I'd like to incorporate this kind of check into every HTTP request with Retrofit, how should I do it? Or should I do it at all.\nThanks\nAlex\n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\n@AlexV are you sure that the RetrofitError contains a timeout as a reason (SocketTimeOutException when getCause() is called) when there is no internet connection? \nAs far as I know when there is no internet connection the RetrofitError contains a ConnectionException as cause. \nIf you implement an ErrorHandler you can do something like this:\npublic class RetrofitErrorHandler implements ErrorHandler {\n\n    @Override\n    public Throwable handleError(RetrofitError cause) {\n        if (cause.isNetworkError()) {\n            if (cause.getCause() instanceof SocketTimeoutException) {\n                return new MyConnectionTimeoutException();\n            } else {\n                return new MyNoConnectionException();\n            }\n        } else {\n            [... do whatever you want if it's not a network error ...]  \n        }\n    }\n\n}\n\n",
            "\nWhat I ended up doing is creating a custom Retrofit client that checks for connectivity before executing a request and throws an exception.\npublic class ConnectivityAwareUrlClient implements Client {\n\n    Logger log = LoggerFactory.getLogger(ConnectivityAwareUrlClient.class);\n\n    public ConnectivityAwareUrlClient(Client wrappedClient, NetworkConnectivityManager ncm) {\n        this.wrappedClient = wrappedClient;\n        this.ncm = ncm;\n    }\n\n    Client wrappedClient;\n    private NetworkConnectivityManager ncm;\n\n    @Override\n    public Response execute(Request request) throws IOException {\n        if (!ncm.isConnected()) {\n            log.debug(\"No connectivity %s \", request);\n            throw new NoConnectivityException(\"No connectivity\");\n        }\n        return wrappedClient.execute(request);\n    }\n}\n\nand then use it when configuring RestAdapter\nRestAdapter.Builder().setEndpoint(serverHost)\n                     .setClient(new ConnectivityAwareUrlClient(new OkHttpClient(), ...))\n\n"
        ],
        "answer": "A4",
        "tags": [
            "android",
            "retrofit"
        ]
    },
    {
        "question_id": "2542599",
        "question": "\nWhen doing a console application in Java with Eclipse, I see the output being put in a text box in the IDE itself, instead of having a console popping up like in Visual Studio. This comes in handy, as even after the program has exited, I can still make good use of the text that was written in it, as it doesn't get erased until I run it again. Is it possible to achieve anything like that with Visual Studio? I know that instead of doing\nSystem.Console.WriteLine(str);\n\nI can do\nSystem.Diagnostics.Debug.WriteLine(str);\n\nbut it is not quite the same thing, as you get a lot of \"junk\" in the Output window, as all the loaded symbols and such.\nEven better, is it possible to have everything done in the IDE itself, when you run your application, instead of having the console running?\n",
        "all_answers": [
            "\nI had exact same error after adding a new configuration via ConfigurationManager in Visual Studio.\nIt turned out when the 'Production' configuration was added for the whole solution (and each project) the OutputPath element was not added to the .csproj files.\nTo fix, I went to the Build tab in project properties, changed OutputPath from \\bin\\Production\\ to \\bin\\Production (deleted trailing \\) and saved changes. This forced creation of the OutputPath element in the .csproj file and the project has built successfully.\nSounds like a glitch to me.\n",
            "\nIn the Tools -> Visual Studio Options Dialog -> Debugging ->  Check the \"Redirect All Output Window Text to the Immediate Window\".\n",
            "\nUse System.Diagnostics.Trace\nDepending on what listeners you attach, trace output can go to the debug window, the console, a file, database, or all at once.  The possibilities are literally endless, as implementing your own TraceListener is extremely simple.\n",
            "\nYou could create a wrapper application that you run instead of directly running your real app.  The wrapper application can listen to stdout and redirect everything to Trace.  Then change the run settings to launch your wrapper and pass in the path to the real app to run.\nYou could also have the wrapper auto-attach the debugger to the new process if a debugger is attached to the wrapper.\n",
            "\nIf you are using WiX look at this (there is a bug)\nhttp://www.cnblogs.com/xixifusigao/archive/2012/03/20/2407651.html\nSometimes new build configurations get added to the .wixproj file further down the file, that is, separated from their sibling config definitions by other unrelated XML elements.\nSimply edit the .wixproj file so that all the <PropertyGroup> sections that define your build configs are adjacent to one another. (To edit the .wixproj in VS2013 right click on project in Solution Explorer, Unload project, right-click again->Edit YourProject.wixproj. Reload after editing the file.)\n",
            "\nThe error shown in visual studio for the project (Let's say A) does not have issues. When I looked at the output window for the build line by line for each project, I saw that it was complaining about another project (B) that had been referred as assembly in project A. Project B added into the solution. But it had not been referred in the project A  as project reference instead as assembly reference from different location. That location contains the assembly which compiled for Platform AnyCpu. Then I removed the assembly reference from the project A and added project B as a reference. It started compiling. \nNot sure though how this fix worked.\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "visual-studio",
            "console"
        ]
    },
    {
        "question_id": "5732798",
        "question": "\nso when you initialize an array, you can assign multiple values to it in one spot:\nint array [] = {1,3,34,5,6}\n\nbut what if the array is already initialized and I want to completely replace the values of the elements in that array in one line\nso \nint array [] = {1,3,34,5,6}\narray [] = {34,2,4,5,6}\n\ndoesn't seem to work...\nis there a way to do so?\n",
        "all_answers": [
            "\nYou have to replace the values one by one such as in a for-loop or copying another array over another such as using memcpy(..) or std::copy\ne.g.\nfor (int i = 0; i < arrayLength; i++) {\n    array[i] = newValue[i];\n}\n\nTake care to ensure proper bounds-checking and any other checking that needs to occur to prevent an out of bounds problem.\n",
            "\nIf you put the declaration in a header file, and the definition in a separate .cpp file, and #include the header from a different .cpp file, you will be able to see the difference.\nSpecifically, suppose:\nlib.h\nint Add(int a, int b);\n\nlib.cpp\nint Add(int a, int b = 3) {\n   ...\n}\n\ntest.cpp\n#include \"lib.h\"\n\nint main() {\n    Add(4);\n}\n\nThe compilation of test.cpp will not see the default parameter declaration, and will fail with an error.\nFor this reason, the default parameter definition is usually specified in the function declaration:\nlib.h\nint Add(int a, int b = 3);\n\n",
            "\nThere is a difference between initialization and assignment. What you want to do is not initialization, but assignment. But such assignment to array is not possible in C++.\nHere is what you can do:\n#include <algorithm>\n\nint array [] = {1,3,34,5,6};\nint newarr [] = {34,2,4,5,6};\nstd::copy(newarr, newarr + 5, array);\n\n\nHowever, in C++0x, you can do this:\nstd::vector<int> array = {1,3,34,5,6};\narray = {34,2,4,5,6};\n\nOf course, if you choose to use std::vector instead of raw array.\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "arrays",
            "programming-languages",
            "syntax"
        ]
    },
    {
        "question_id": "1236593",
        "question": "\nIf fruits is the list ['apples', 'oranges', 'pears'],\nis there a quick way using django template tags to produce \"apples, oranges, and pears\"?\nI know it's not difficult to do this using a loop and {% if counter.last %} statements, but because I'm going to use this repeatedly I think I'm going to have to learn how to write custom tags filters, and I don't want to reinvent the wheel if it's already been done.\nAs an extension, my attempts to drop the Oxford Comma (ie return \"apples, oranges and pears\") are even messier.\n",
        "all_answers": [
            "\nI would suggest a custom django templating filter rather than a custom tag -- filter is handier and simpler (where appropriate, like here). {{ fruits | joinby:\", \" }} looks like what I'd want to have for the purpose... with a custom joinby filter:\ndef joinby(value, arg):\n    return arg.join(value)\n\nwhich as you see is simplicity itself!\n",
            "\nFirst choice: use the existing join template tag.\nhttp://docs.djangoproject.com/en/dev/ref/templates/builtins/#join\nHere's their example\n{{ value|join:\" // \" }}\n\nSecond choice: do it in the view.\nfruits_text = \", \".join( fruits )\n\nProvide fruits_text to the template for rendering.\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nHere's the filter I wrote to solve my problem (it doesn't include the Oxford comma)\ndef join_with_commas(obj_list):\n    \"\"\"Takes a list of objects and returns their string representations,\n    separated by commas and with 'and' between the penultimate and final items\n    For example, for a list of fruit objects:\n    [<Fruit: apples>, <Fruit: oranges>, <Fruit: pears>] -> 'apples, oranges and pears'\n    \"\"\"\n    if not obj_list:\n        return \"\"\n    l=len(obj_list)\n    if l==1:\n        return u\"%s\" % obj_list[0]\n    else:    \n        return \", \".join(str(obj) for obj in obj_list[:l-1]) \\\n                + \" and \" + str(obj_list[l-1])\n\nTo use it in the template: {{ fruits|join_with_commas }}\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n"
        ],
        "answer": "A5",
        "tags": [
            "python",
            "django",
            "list",
            "django-templates"
        ]
    },
    {
        "question_id": "3636914",
        "question": "\nIs there a way to see what would be pushed if I did a git push command?\nWhat I'm picturing is something like the \"Files Changed\" tab of Github's \"pull request\" feature. When I issue a pull request, I can look and see what will be pulled in if they accept my pull request: \nCommand line is OK, but I'd prefer some sort of GUI (like the screenshot above).\n",
        "all_answers": [
            "\nThere is always dry-run:\ngit push --dry-run\n\nIt will do everything except for the actually sending of the data. \nIf you want a more graphical view you have a bunch of options.\nTig and the gitk script that come with git both display the current branch of your local copy and the branch of the remote or origin.\n\nSo any commits you make that are after the origin are the commits that will be pushed.\nOpen gitk from shell while in the branch you want to push by typing gitk&, then to see the difference between what is on the remote and what you are about to push to the remote, select your local unpushed commit and right-click on the remote and choose \"Diff this -> selected\":\n\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nUse git gui, there you can see a list of what changed in your actual commit. You can also use gitk wich provides an easy interface for reflogs. Just compare between remotes/... and master to see, what will be pushed. It provides an interface similar to your screenshot.\nBoth programs are included in git.\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nFor a list of files to be pushed, run:\ngit diff --stat --cached [remote/branch]\n\nexample: \ngit diff --stat --cached origin/master\n\nFor the code diff of the files to be pushed, run:\ngit diff [remote repo/branch]\n\nTo see full file paths of the files that will change, run:\ngit diff --numstat [remote repo/branch]\n\nIf you want to see these diffs in a GUI, you will need to configure git for that. See How do I view 'git diff' output with a visual diff program?.\n"
        ],
        "answer": "A7",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "3038302",
        "question": "\nWhy does ZeroMemory(), and similar calls exist in the Windows API when there are memset and related calls in the C standard library already? Which ones should I call? I can guess the answer is \"depends\". On what?\n",
        "all_answers": [
            "\nBecause, ZeroMemory don't require line of comment\n",
            "\nBecause the Windows API should be language-agnostic. It provides sufficient functionality for developers, regardless of the language they use. Of course, eventually many functions will duplicate existing functionality offered by the languages.\nYou should call the winapi functions (and macros) directly whenever you need a certain level of control -- compare fopen() with CreateFile() for instance. Otherwise, prefer language-specific constructs over API calls. At least, you gain more platform-independence.\n",
            "\nIn C and C++, ZeroMemory() and memset() are the exact same thing.\n/* In winnt.h */\n#define RtlZeroMemory(Destination,Length) memset((Destination),0,(Length))\n\n/* In winbase.h */\n#define ZeroMemory RtlZeroMemory\n\nWhy use ZeroMemory() then? To make it obvious. But I prefer memset() in C or C++ programs.\n",
            "\nZeroMemory and such are part of the windows API itself. memset is part of the C standard library.\nFor typical userland code, I'd normally use memset (or the equivalent provided by your language of choice). If you're writing kernel code (e.g., a device driver) using something like ZeroMemory is more attractive. Since your code executes in kernel mode anyway, you don't incur the cost of a task switch to use it. Since it's already in the Windows code, you aren't carrying around extra code in your driver to duplicate what's already there. At the same time, you do incur the cost of a function call, and in the case or zeroing (especially a small block of) memory, inline code may be significantly faster, and a rep stosd doesn't take much code (in fact, setting up and using rep stosd may take less code that a function call).\n",
            "\nAccording to MSDN, ZeroMemory is a macro. It probably exists as a convenience (e.g., naming convention) or for backwards compatibility.\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "c",
            "windows",
            "winapi",
            "memset"
        ]
    },
    {
        "question_id": "40760625",
        "question": "\nI want to check a permission inside a fragment. \nmy code:\n        // Here, thisActivity is the current activity\n        if (ContextCompat.checkSelfPermission(getActivity(),\n                Manifest.permission.ACCESS_FINE_LOCATION)\n                != PackageManager.PERMISSION_GRANTED) {\n\n\n            // Should we show an explanation?\n            if (ActivityCompat.shouldShowRequestPermissionRationale(getActivity(),\n                    android.Manifest.permission.ACCESS_FINE_LOCATION)) {\n\n                // Show an explanation to the user *asynchronously* -- don't block\n                // this thread waiting for the user's response! After the user\n                // sees the explanation, try again to request the permission.\n\n            } else {\n\n                // No explanation needed, we can request the permission.\n\n                ActivityCompat.requestPermissions(getActivity(),\n                        new String[]{android.Manifest.permission.ACCESS_FINE_LOCATION},\n                        1);\n\n\n\n                // MY_PERMISSIONS_REQUEST_READ_CONTACTS is an\n                // app-defined int constant. The callback method gets the\n                // result of the request.\n            }\n        }\n\nbut onRequestPermissionsResult not called after allow or deny.\n@Override\npublic void onRequestPermissionsResult(int requestCode,\n                                       String permissions[], int[] grantResults) {\n    switch (requestCode) {\n        case 1: {\n            Log.e(\"test\",\"0\");\n            // If request is cancelled, the result arrays are empty.\n            if (grantResults.length > 0\n                    && grantResults[0] == PackageManager.PERMISSION_GRANTED) {\n\n                // permission was granted, yay! Do the\n                // contacts-related task you need to do.\n                //yes\n\n                Log.e(\"test\",\"1\");\n\n                Intent intent = new Intent(getActivity(), MapsActivity.class);\n                intent.putExtra(\"latitude\", 35.694828);\n                intent.putExtra(\"longitude\", 51.378129);\n                startActivity(intent);\n\n            } else {\n                utilityFunctions.showSweetAlertWarning(getActivity(),r.getString(R.string.str_warning_title_empty),\n                        r.getString(R.string.str_you_must_allow_this_permission_toast),\n                        r.getString(R.string.str_warning_btn_login));\n\n                Log.e(\"test\",\"2\");\n            }\n            return;\n        }\n\n        // other 'case' lines to check for other\n        // permissions this app might request\n    }\n}\n\n",
        "all_answers": [
            "\nLook at the getFragmentManager().popBackStack() methods (there are several to choose from)\nhttp://developer.android.com/reference/android/app/FragmentManager.html#popBackStack()\n",
            "\nIf you closed your permission of app from settings , you can not open your permission from code or your android version lower than Marshmallow.\nYou can check this documentation \nhttps://developer.android.com/training/permissions/requesting.html\nAnd this is a example\nhttps://www.learn2crack.com/2015/10/android-marshmallow-permissions.html \n",
            "\nI have done following to check a permission inside a fragment.\nif (ActivityCompat.checkSelfPermission(getContext(),\n            android.Manifest.permission.ACCESS_FINE_LOCATION) != PackageManager.PERMISSION_GRANTED &&\n            ActivityCompat.checkSelfPermission(getContext(),\n                    android.Manifest.permission.ACCESS_COARSE_LOCATION) != PackageManager.PERMISSION_GRANTED) {\n         requestPermissions(getActivity(),\n                new String[]{android.Manifest.permission.ACCESS_COARSE_LOCATION,\n                        android.Manifest.permission.ACCESS_FINE_LOCATION},\n                REQUEST_LOCATION);\n    } else {\n        Log.e(\"DB\", \"PERMISSION GRANTED\");\n    }\n\nUpdate\nSince Fragment.requestPermissions is now deprecated, Google advises using registerForActivityResult instead.\nI have done the request like this:\nval permissionLauncher = registerForActivityResult(\n    ActivityResultContracts.RequestPermission()\n) { isGranted ->\n    if (isGranted) {\n        // Do if the permission is granted\n    }\n    else {\n        // Do otherwise\n    }\n}\n\npermissionLauncher.launch(Manifest.permission.ACCESS_FINE_LOCATION)\n\nFor more documentation on this method you can check this link.\n"
        ],
        "answer": "A3",
        "tags": [
            "java",
            "android",
            "kotlin",
            "android-fragments",
            "android-permissions"
        ]
    },
    {
        "question_id": "6597196",
        "question": "\nI have a TextBox in my C# program. I need focus to be on this TextBox when the program starts.\nI tried this on Form_Load:\nMyTextBox.Focus();\n\nbut it doesn't work.\nHow do I put focus on this when the form loads?\n",
        "all_answers": [
            "\ncheck your tab order and make sure the textbox is set to zero\n",
            "\nYou can use Cursor.Current.\n// Set cursor as hourglass\nCursor.Current = Cursors.WaitCursor;\n\n// Execute your time-intensive hashing code here...\n\n// Set cursor as default arrow\nCursor.Current = Cursors.Default;\n\nHowever, if the hashing operation is really lengthy (MSDN defines this as more than 2-7 seconds), you should probably use a visual feedback indicator other than the cursor to notify the user of the progress. For a more in-depth set of guidelines, see this article.\nEdit:\nAs @Am pointed out, you may need to call Application.DoEvents(); after Cursor.Current = Cursors.WaitCursor; to ensure that the hourglass is actually displayed. \n",
            "\nSet theActiveControl property of the form and you should be fine.\nthis.ActiveControl = yourtextboxname;\n\n",
            "\nBuilding on the previous, my preferred approach (since this is a frequently performed action) is to wrap the wait cursor code in an IDisposable helper class so it can be used with using() (one line of code), take optional parameters, run the code within, then clean up (restore cursor) afterwards.\npublic class CursorWait : IDisposable\n{\n    public CursorWait(bool appStarting = false, bool applicationCursor = false)\n    {\n        // Wait\n        Cursor.Current = appStarting ? Cursors.AppStarting : Cursors.WaitCursor;\n        if (applicationCursor) Application.UseWaitCursor = true;\n    }\n\n    public void Dispose()\n    {\n        // Reset\n        Cursor.Current = Cursors.Default;\n        Application.UseWaitCursor = false;\n    }\n}\n\nUsage:\nusing (new CursorWait())\n{\n    // Perform some code that shows cursor\n}\n\n",
            "\nYou could try: \nMyTextBox.Select();\nAccording to the documentation:\n\nThe Select method activates the control if the control's Selectable\n  style bit is set to true in ControlStyles, it is contained in another\n  control, and all its parent controls are both visible and enabled.\n\nYou can first check if the control can be selectable by inspecting the MyTextBox.CanSelect property.\n",
            "\nActually, \nCursor.Current = Cursors.WaitCursor;\n\ntemporarily sets the Wait cursor, but doesn’t ensure that the Wait cursor shows until the end of your operation. Other programs or controls within your program can easily reset the cursor back to the default arrow as in fact happens when you move mouse while operation is still running. \nA much better way to show the Wait cursor is to set the UseWaitCursor property in a form to true:\nform.UseWaitCursor = true;\n\nThis will display wait cursor for all controls on the form until you set this property to false.\nIf you want wait cursor to be shown on Application level you should use:\nApplication.UseWaitCursor = true;\n\n",
            "\nIt is easier to use UseWaitCursor at the Form or Window level.\nA typical use case can look like below:\n    private void button1_Click(object sender, EventArgs e)\n    {\n\n        try\n        {\n            this.Enabled = false;//optional, better target a panel or specific controls\n            this.UseWaitCursor = true;//from the Form/Window instance\n            Application.DoEvents();//messages pumped to update controls\n            //execute a lengthy blocking operation here, \n            //bla bla ....\n        }\n        finally\n        {\n            this.Enabled = true;//optional\n            this.UseWaitCursor = false;\n        }\n    }\n\nFor a better UI experience you should use Asynchrony from a different thread.\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "winforms",
            "focus",
            "setfocus"
        ]
    },
    {
        "question_id": "1094867",
        "question": "\nExecutor seems like a clean abstraction. When would you want to use Thread directly rather than rely on the more robust executor?\n",
        "all_answers": [
            "\nYou don't use Thread unless you need more specific behaviour that is not found in Thread itself. You then extend Thread and add your specifically wanted behaviour. \nElse just use Runnable or Executor.\n",
            "\nI use Thread when I need some pull based message processing. E.g. a Queue is take()-en in a loop in a separate thread. For example, you wrap a queue in an expensive context - lets say a JDBC connection, JMS connection, files to process from single disk, etc.\nBefore I get cursed, do you have some scenario?\nEdit: \nAs stated by others, the Executor (ExecutorService) interface has more potential, as you can use the Executors to select a behavior: scheduled, prioritized, cached etc. in Java 5+ or a  j.u.c backport for Java 1.4.\nThe executor framework has protection against crashed runnables and automatically re-create worker threads. One drawback in my opinion, that you have to explicitly shutdown() and awaitTermination() them before you exit your application - which is not so easy in GUI apps.\nIf you use bounded queues you need to specify a RejectedExecutionHandler or the new runnables get thrown away.\nYou might have a look at Brian Goetz et al: Java Concurrency in Practice (2006)\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nTo give some history, Executors were only added as part of the java standard in Java 1.5. So in some ways Executors can be seen as a new better abstraction for dealing with Runnable tasks.\nA bit of an over-simplification coming... - Executors are threads done right so use them in preference.\n",
            "\nThere is no advantage to using raw threads. You can always supply Executors with a Thread factory, so even the option of custom thread creation is covered.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n"
        ],
        "answer": "A4",
        "tags": [
            "java",
            "multithreading",
            "concurrency",
            "executor"
        ]
    },
    {
        "question_id": "7787120",
        "question": "\nI am trying to create a python script which I will later run as a service. Now I want to run a particular part of the code only when iTunes is running. I understand from some research that polling the entire command list and then searching for the application for that list is expensive. \nI found out that processes on UNIX-based operating systems create a lock file to notify that a program is currently running, at which point we can use os.stat(location_of_file) to check if the file exists to determine if a program is running or not.\nIs there a similar lock file created on Windows?\nIf not what are the various ways in Python by which we can determine if a process is running or not?\nI am using python 2.7 and iTunes COM interface.\n",
        "all_answers": [
            "\nYou can not rely on lock files in Linux or Windows.  I would just bite the bullet and iterate through all the running programs.  I really do not believe it will be as \"expensive\" as you think.  psutil is an excellent cross-platform python module cable of enumerating all the running programs on a system.\nimport psutil    \n\"someProgram\" in (p.name() for p in psutil.process_iter())\n\n",
            "\nLock files are generally not used on Windows (and rarely on Unix). Typically when a Windows program wants to see if another instance of itself is already running, it will call FindWindow with a known title or class name.\ndef iTunesRunning():\n    import win32ui\n    # may need FindWindow(\"iTunes\", None) or FindWindow(None, \"iTunes\")\n    # or something similar\n    if FindWindow(\"iTunes\", \"iTunes\"):\n        print \"Found an iTunes window\"\n        return True\n\n",
            "\nWould you be happy with your Python command running another program to get the info?\nIf so, I'd suggest you have a look at PsList and all its options. For example, The following would tell you about any running iTunes process\nPsList itunes\n\nIf you can work out how to interpret the results, this should hopefully get you going.\nEdit:\nWhen I'm not running iTunes, I get the following:\npslist v1.29 - Sysinternals PsList\nCopyright (C) 2000-2009 Mark Russinovich\nSysinternals\n\nProcess information for CLARESPC:\n\nName                Pid Pri Thd  Hnd   Priv        CPU Time    Elapsed Time\niTunesHelper       3784   8  10  229   3164     0:00:00.046     3:41:05.053\n\nWith itunes running, I get this one extra line:\niTunes              928   8  24  813 106168     0:00:08.734     0:02:08.672\n\nHowever, the following command prints out info only about the iTunes program itself, i.e. with the -e argument:\npslist -e itunes\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "windows",
            "python-2.7"
        ]
    },
    {
        "question_id": "48911087",
        "question": "\nThere is an option to comment on a range of lines in file on github, see How to refer to a specific line or range of lines in github?\nBut is there similar option to comment on range of lines inside pull request?\n\nWhen I click on line, only single line is highlighted yellow and R### (e.g. R446) is appended to url, clicking another line with shift pressed doesn't do anything. I tried to change url to R446-450 but it didn't do anything. Changing it to #L450-458 also didn't do anything. Also even that single highlighted line doesn't seem to affect anything.\nClicking blue plus that appears on hover creates comment window, but it only commenting on a single line.\nCommenting on single line results in this\n\nComment on pull-request page shows only 4 lines above selected/commented line, but I'm interested in showing 7 lines, not 4\n",
        "all_answers": [
            "\nSince Oct. 2019, Nat Friedman (CEO of GitHub) declares that feature available\n(And, see below, since Feb. 2020, multi-lines comment reference is possible)\n\n🔥\n  Multi-line comments are here!\n  Click and drag to comment on multiple lines in a pull request diff. ✨\nThese little quality-of-life improvements are at the heart of what we love doing at GitHub. \n  🥰\n\n\nThanks to:\n\nJohn Caine\nMike Skalnik\nPat Nakajima\nMike Chlipala\nJoel Califa\nMatt Colyer\nMelanie Gilman\n\n\nNick Craver immediately asks:\n\nFollow-up question: are there plans to support suggestions?\n  It seems to apply to the last line at the moment:\n\n\nThat would be, according to Nat, \"Coming early next year\".  \nUpdate Feb. 2020: \"A new interaction for multi-line pull request comments \"\n\nTo leave a comment referencing multiple lines, you can either:\n\nclick on a line number in the diff view, hold Shift, click on a second line number and click the \"+\" button next to the second line number; or\nclick and hold to the right of a line number, drag and then release the mouse when you’ve reached the desired line.\n\n\nThis was announced by Nat Friedman\n\nShipping today on GitHub: multi-line suggestions! \n\n\nWith, again, special thanks to Melanie Gilman, Pat Nakajima, Mike Chlipala, Joel Califa, John Caine, Matt Colyer and \n, and Kelly Arwine.\nGitHub Changelog also references this.\n\nHenry adds an observation \n\nA smaller side effect, but I assume being able to share a multi-line diff in the PR is new too!\n\nExample: babel/babel PR 10511 diff-L261-L263\n\nBut that was available since July 2019\n",
            "\nIt isn't possible to comment on multiple lines in a pull request review at GitHub. I hope they will create a new feature where this is possible.\nBut what you can do, there is a little (time consuming) workaround:\nIf you go in to the code, in the branch with the changes, you can select multiple lines and then copy a permalink for those lines. When you paste this link into your review comment, it will be shown as a code snippet.\nFor more, read this: https://help.github.com/articles/creating-a-permanent-link-to-a-code-snippet/\nUpdate Github has released a new feature where this is possible. See VonC's answer :-)\n",
            "\nThe multiline comment feature is now available on GitHub. Enjoy! \n"
        ],
        "answer": "A1",
        "tags": [
            "github",
            "pull-request"
        ]
    },
    {
        "question_id": "14174044",
        "question": "\nI'm new to rails, and I'm writing a RESTful website using the CRUD technique. So far I have created three pages, all of which allow the user to create, edit, and delete a row from the database. However, my fourth page will need to include an upload file form, but a) I don't know how the filesystem works with Rails thus I don't know where files should be stored. The file would be around 100kb and couldn't be stored in temporary storage because it will be constantly downloaded. And b) I don't know how to write to a file.\nIt would be great if you could tell me how to do what I mentioned above - create an upload input on an input form, and to then write the file to a filepath in a separate directory.\n",
        "all_answers": [
            "\nThere is a nice gem especially for uploading files : carrierwave. If the wiki does not help , there is a nice RailsCast about the best way to use it . Summarizing , there is a field type file in Rails forms , which invokes the file upload dialog. You can use it , but the 'magic' is done by carrierwave gem . \nI don't know what do you mean with \"how to write to a file\" , but I hope this is a nice start. \n",
            "\nUpdate 2018\nWhile everything written below still holds true, Rails 5.2 now includes active_storage, which allows stuff like uploading directly to S3 (or other cloud storage services), image transformations, etc. You should check out the rails guide and decide for yourself what fits your needs.\n\nWhile there are plenty of gems that solve file uploading pretty nicely (see https://www.ruby-toolbox.com/categories/rails_file_uploads for a list), rails has built-in helpers which make it easy to roll your own solution.\nUse the file_field-form helper in your form, and rails handles the uploading for you:\n<%= form_for @person do |f| %>\n  <%= f.file_field :picture %>\n<% end %>\n\nYou will have access in the controller to the uploaded file as follows:\nuploaded_io = params[:person][:picture]\nFile.open(Rails.root.join('public', 'uploads', uploaded_io.original_filename), 'wb') do |file|\n  file.write(uploaded_io.read)\nend\n\nIt depends on the complexity of what you want to achieve, but this is totally sufficient for easy file uploading/downloading tasks. This example is taken from the rails guides, you can go there for further information: http://guides.rubyonrails.org/form_helpers.html#uploading-files\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "file-upload",
            "file-io"
        ]
    },
    {
        "question_id": "40325422",
        "question": "\nI'm adding a BottomNavigationView to a project, and I would like to have a different text (and icon tint) color for the selected tab (to achieve greying out non-selected tabs effect). Using a different color with android:state_selected=\"true\" in a color selector resource file doesn't seem to work. I also tried having additional item entries with android:state_focused=\"true\" or android:state_enabled=\"true\", no effect unfortunately. Also tried setting the state_selected attribute to false (explicitly) for the default (non-selected) color, with no luck.\nHere is how I add the view to my layout:\n<android.support.design.widget.BottomNavigationView\n        android:id=\"@+id/bottom_navigation\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"wrap_content\"\n        android:layout_alignParentBottom=\"true\"\n        app:itemBackground=\"@color/silver\"\n        app:itemIconTint=\"@color/bnv_tab_item_foreground\"\n        app:itemTextColor=\"@color/bnv_tab_item_foreground\"\n        app:menu=\"@menu/bottom_nav_bar_menu\" />\n\nHere is my color selector (bnv_tab_item_foreground.xml):\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<selector xmlns:android=\"http://schemas.android.com/apk/res/android\">\n    <item android:color=\"@android:color/darker_gray\"  />\n    <item android:state_selected=\"true\" android:color=\"@android:color/holo_blue_dark\" />\n</selector>\n\nAnd my menu resource (bottom_nav_bar_menu.xml):\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<menu xmlns:android=\"http://schemas.android.com/apk/res/android\">\n\n    <item\n        android:id=\"@+id/action_home\"\n        android:icon=\"@drawable/ic_local_taxi_black_24dp\"\n        android:title=\"@string/home\" />\n    <item\n        android:id=\"@+id/action_rides\"\n        android:icon=\"@drawable/ic_local_airport_black_24dp\"\n        android:title=\"@string/rides\"/>\n    <item\n        android:id=\"@+id/action_cafes\"\n        android:icon=\"@drawable/ic_local_cafe_black_24dp\"\n        android:title=\"@string/cafes\"/>\n    <item\n        android:id=\"@+id/action_hotels\"\n        android:icon=\"@drawable/ic_local_hotel_black_24dp\"\n        android:title=\"@string/hotels\"/>\n\n</menu>\n\nI would appreciate any help.\n",
        "all_answers": [
            "\nWhile making a selector, always keep the default state at the end, otherwise only default state would be used. You need to reorder the items in your selector as:\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<selector xmlns:android=\"http://schemas.android.com/apk/res/android\">\n    <item android:state_checked=\"true\" android:color=\"@android:color/holo_blue_dark\" />\n    <item android:color=\"@android:color/darker_gray\"  />\n</selector>\n\nAnd the state to be used with BottomNavigationBar is state_checked not state_selected.\n",
            "\nJust set this to v21/styles.xml file\n <item name=\"android:windowDrawsSystemBarBackgrounds\">true</item>\n <item name=\"android:statusBarColor\">@color/colorPrimaryDark</item>\n\nand be sure \n <item name=\"android:windowTranslucentStatus\">false</item>\n\n",
            "\nUse android:fitsSystemWindows=\"true\" in the root view of your layout (LinearLayout in your case).\n",
            "\nTry using android:state_enabled rather than android:state_selected for the selector item attributes.\n",
            "\nNone of the answers worked for me, but this is what finally worked after I set: \nandroid:fitsSystemWindows=\"false\"\n\nIn parent activity layout file it's not suggested at many places but it's work for me and saves my day\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "material-design",
            "navigationbar"
        ]
    },
    {
        "question_id": "2422798",
        "question": "\nI am trying to learn python and am making a program that will output a script.  I want to use os.path.join, but am pretty confused.  According to the docs if I say:\nos.path.join('c:', 'sourcedir')\n\nI get \"C:sourcedir\".  According to the docs, this is normal, right?\nBut when I use the copytree command, Python will output it the desired way, for example:\nimport shutil\nsrc = os.path.join('c:', 'src')\ndst = os.path.join('c:', 'dst')\nshutil.copytree(src, dst)\n\nHere is the error code I get:\n\nWindowsError: [Error 3] The system cannot find the path specified: 'C:src/*.*'\n\nIf I wrap the os.path.join with os.path.normpath I get the same error.\nIf this os.path.join can't be used this way, then I am confused as to its purpose.\nAccording to the pages suggested by Stack Overflow, slashes should not be used in join—that is correct, I assume?\n",
        "all_answers": [
            "\nto join a windows path, try\nmypath=os.path.join('c:\\\\', 'sourcedir')\n\nbasically, you will need to escape the slash\n",
            "\nThe reason os.path.join('C:', 'src') is not working as you expect is because of something in the documentation that you linked to:\n\nNote that on Windows, since there is a\n  current directory for each drive,\n  os.path.join(\"c:\", \"foo\") represents a\n  path relative to the current directory\n  on drive C: (c:foo), not c:\\foo.\n\nAs ghostdog said, you probably want mypath=os.path.join('c:\\\\', 'sourcedir')\n",
            "\n\nThat makes me think dulwich is not\n  installed correctly, or not in the\n  path.\n\nYou're absolutely right. Mercurial binary distributions for Windows are 'frozen' - they use the Python code and interpreter bundled with them and therefore independent of packages installed in system PYTHONPATH. When you specify path to hggit extension in Mercurial.ini, hg tries to import it using direct path, but dulwich library is not imported explicitly by hg and doesn't bundled with its library, so the import fails.\nIt is possible to add both Dulwich and HgGit into library.zip that is installed along with hg.exe, but for me the best way is to install everything from source including Mercurial and execute commands using .bat files installed into \\Python\\Scripts. In this case you will need to:\n\nInstall Mercurial from source. This builds \"pure\" version, because Windows users usually don't have Visual Studio or alternative compiler for compiling C speedups.\nInstall Dulwich - I'd use latest trunk snapshot for both Git and Dulwich.\npython setup.py --pure install\nInstall latest HgGit snapshot\npython setup.py install\nEdit Mercurial.ini to enable hggit =\nLaunch Mercurial using your \\Python\\Scripts\\hg.bat\n\n",
            "\nWindows has a concept of current directory for each drive.  Because of that, \"c:sourcedir\" means \"sourcedir\" inside the current C: directory, and you'll need to specify an absolute directory.\nAny of these should work and give the same result, but I don't have a Windows VM fired up at the moment to double check:\n\"c:/sourcedir\"\nos.path.join(\"/\", \"c:\", \"sourcedir\")\nos.path.join(\"c:/\", \"sourcedir\")\n\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "windows",
            "path-manipulation"
        ]
    },
    {
        "question_id": "12312325",
        "question": "\nI am using Window Application for my project. There is situation where i need to define string enum and using it in my project.\ni.e.\nDim PersonalInfo As String = \"Personal Info\"\nDim Contanct As String = \"Personal Contanct\"\n\n    Public Enum Test\n        PersonalInfo\n        Contanct\n    End Enum\n\nNow i want value of that variable PersonalInfo and Contract as \"Personal Info\" and \"Personal Contanct\".\nHow can i get this value using ENUM? or anyother way to do it.\nThanks in advance...\n",
        "all_answers": [
            "\n\nHow can i get this value using ENUM? or anyother way to do it.\n\nThere are three common ways of mapping enum values to strings:\n\nUse a Dictionary(Of YourEnumType, String)\nDecorate the enum values with attributes (e.g. DescriptionAttribute) and fetch them with reflection\nUse a Switch statement\n\nThe first of these options is probably the simplest, in my view.\n",
            "\nUse regular expression\nno need to convert it to char array\nif(Regex.IsMatch(\"yourString\",\".*?[a-zA-Z].*?\"))\n{\nerrorCounter++;\n}\n\n",
            "\nReplace your for loop by this : \nerrorCounter = Regex.Matches(yourstring,@\"[a-zA-Z]\").Count;\n\nRemember to use Regex class, you have to using System.Text.RegularExpressions; in your import\n",
            "\nYou could just create a new type\n''' <completionlist cref=\"Test\"/>\nClass Test\n\n    Private Key As String\n\n    Public Shared ReadOnly Contact  As Test = New Test(\"Personal Contanct\")\n    Public Shared ReadOnly PersonalInfo As Test = New Test(\"Personal Info\")\n\n    Private Sub New(key as String)\n        Me.Key = key\n    End Sub\n\n    Public Overrides Function ToString() As String\n        Return Me.Key\n    End Function\nEnd Class\n\nand when you use it, it kinda looks like an enum:\nSub Main\n\n    DoSomething(Test.Contact)\n    DoSomething(Test.PersonalInfo)\n\nEnd Sub\n\nSub DoSomething(test As Test)\n    Console.WriteLine(test.ToString())\nEnd Sub\n\noutput:\n\nPersonal Contanct\n  Personal Info\n\n",
            "\nWhat about:\n//true if it doesn't contain letters\nbool result = hello.Any(x => !char.IsLetter(x));\n\n",
            "\nYou could use RegEx:\nRegex.IsMatch(hello, @\"^[a-zA-Z]+$\");\n\nIf you don't like that, you can use LINQ:\nhello.All(Char.IsLetter);\n\nOr, you can loop through the characters, and use isAlpha:\nChar.IsLetter(character);\n\n",
            "\nFor a minimal change:\nfor(int i=0; i<str.Length; i++ )\n   if(str[i] >= 'a' && str[i] <= 'z' || str[i] >= 'A' && str[i] <= 'Z')\n      errorCount++;\n\nYou could use regular expressions, at least if speed is not an issue and you do not really need the actual exact count.\n",
            "\nYou can look for regular expression \nRegex.IsMatch(str, @\"^[a-zA-Z]+$\");\n\n"
        ],
        "answer": "A4",
        "tags": [
            "vb.net",
            "string",
            "enums",
            "windows"
        ]
    },
    {
        "question_id": "32851720",
        "question": "\nThe answer in\nHow to strip special characters out of string? \nis not working.\nHere is what I got and it gives me an error  \nfunc removeSpecialCharsFromString(str: String) -> String {\n    let chars: Set<String> = Set(arrayLiteral: \"abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLKMNOPQRSTUVWXYZ1234567890+-*=(),.:!_\")\n\n    return String(str.characters.filter { chars.contains($0) }) //error here at $0\n}\n\nThe error at $0 says\n\n_Element (aka Character) cannot be converted to expected argument type 'String'.\n\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nLike this:\nfunc removeSpecialCharsFromString(text: String) -> String {\n    let okayChars : Set<Character> = \n        Set(\"abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLKMNOPQRSTUVWXYZ1234567890+-*=(),.:!_\".characters)\n    return String(text.characters.filter {okayChars.contains($0) })\n}\n\nAnd here's how to test:\nlet s = removeSpecialCharsFromString(\"père\") // \"pre\"\n\n",
            "\nIn Swift 1.2,\nlet chars = Set(\"abcde...\")\n\ncreated a set containing all characters from the given string.\nIn Swift 2.0 this has to be done as\nlet chars = Set(\"abcde...\".characters)\n\nThe reason is that a string itself does no longer conform to\nSequenceType, you have to use the characters view explicitly.\nWith that change, your method compiles and works as expected:\nfunc removeSpecialCharsFromString(str: String) -> String {\n    let chars = Set(\"abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLKMNOPQRSTUVWXYZ1234567890+-*=(),.:!_\".characters)\n    return String(str.characters.filter { chars.contains($0) })\n}\n\nlet cleaned = removeSpecialCharsFromString(\"ab€xy\")\nprint(cleaned) // abxy\n\nRemark: @Kametrixom suggested to create the set only once. So if there is \nperformance issue with the above method you can either move the\ndeclaration of the set outside of the function, or make it a \nlocal static:\nfunc removeSpecialCharsFromString(str: String) -> String {\n    struct Constants {\n        static let validChars = Set(\"abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLKMNOPQRSTUVWXYZ1234567890+-*=(),.:!_\".characters)\n    }\n    return String(str.characters.filter { Constants.validChars.contains($0) })\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "string",
            "swift"
        ]
    },
    {
        "question_id": "2229498",
        "question": "\nIf C does not support passing a variable by reference, why does this work?\n#include <stdio.h>\n\nvoid f(int *j) {\n  (*j)++;\n}\n\nint main() {\n  int i = 20;\n  int *p = &i;\n  f(p);\n  printf(\"i = %d\\n\", i);\n\n  return 0;\n}\n\nOutput:\n$ gcc -std=c99 test.c\n$ a.exe\ni = 21 \n\n",
        "all_answers": [
            "\nBecause there is no pass-by-reference in the above code. Using pointers (such as void func(int* p)) is pass-by-address.\nThis is pass-by-reference in C++ (won't work in C):\nvoid func(int& ref) {ref = 4;}\n\n...\nint a;\nfunc(a);\n// a is 4 now\n\n",
            "\nThe difference is due to operator precedence.\nThe post-increment operator ++ has higher precedence than the dereference operator *. So *ptr++ is equivalent to *(ptr++). In other words, the post increment modifies the pointer, not what it points to.\nThe assignment operator += has lower precedence than the dereference operator *, so *ptr+=1 is equivalent to (*ptr)+=1. In other words, the assignment operator modifies the value that the pointer points to, and does not change the pointer itself. \n",
            "\n\nIn C, Pass-by-reference is simulated\n  by passing the address of a variable\n  (a pointer) and dereferencing that\n  address within the function to read or\n  write the actual variable.  This will\n  be referred to as \"C style\n  pass-by-reference.\"\n\nSource: www-cs-students.stanford.edu\n",
            "\nThe order of precedence for the 3 operators involved in your question is the following :\npost-increment ++ > dereference * > assignment +=\nYou can check this page for further details on the subject.\n\nWhen parsing an expression, an operator which is listed on some row will be bound tighter (as if by parentheses) to its arguments than any operator that is listed on a row further below it. For example, the expression *p++ is parsed as *(p++), and not as (*p)++.\n\nLong story short, in order to express this assignment *ptr+=1 using the post-increment operator you need to add parentheses to the dereference operator to give that operation precedence over ++ as in this (*ptr)++\n",
            "\nBecause you're passing the value of the pointer to the method and then dereferencing it to get the integer that is pointed to.\n",
            "\n'Pass by reference' (by using pointers) has been in C from the beginning. Why do you think it's not?\n",
            "\nYour example works because you are passing the address of your variable to a function that manipulates its value with the dereference operator. \nWhile C does not support reference data types, you can still simulate passing-by-reference by explicitly passing pointer values, as in your example.\nThe C++ reference data type is less powerful but considered safer than the pointer type inherited from C. This would be your example, adapted to use C++ references:\nvoid f(int &j) {\n  j++;\n}\n\nint main() {\n  int i = 20;\n  f(i);\n  printf(\"i = %d\\n\", i);\n\n  return 0;\n}\n\n"
        ],
        "answer": "A5",
        "tags": [
            "c",
            "pointers",
            "pass-by-reference"
        ]
    },
    {
        "question_id": "12361700",
        "question": "\nI just got upgraded to a free github micro plan using my university email address. I'm planning to use the private repositories for some class projects this semester, but I'm wondering what will happen to those repositories at the end of 2 years when my free student upgrade expires. I'm assuming it's the same thing that happens when you downgrade from a micro to a free account.\nWill my repositories disappear, become public, or just become read-only? I've searched around a bit and haven't been able to find an answer.\n",
        "all_answers": [
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nAfter the two years, you will have to start paying for private repositories ($7/month) otherwise your repositories will be removed after a retention period.\nThey will give you 30 days to pay or they will remove the repositories.\n",
            "\n(Disclosure: I work at GitHub)\nSo long as you're still a student, you're eligible for the academic discount. Once your coupon expires, you can re-apply for the student discount.\nWhen you re-apply, be sure you've added your school-issued email address to your account, that will expedite the approval process.\nYou will receive a notification email before your discount expires. When the discount does expire, your account will be locked which means that you won't be able to access your private repositories. Your private repositories will not be deleted and they will not be made public.\nOf course, if you ever have any troubles, you can always email support@github.com.\n"
        ],
        "answer": "A3",
        "tags": [
            "github"
        ]
    },
    {
        "question_id": "1443210",
        "question": "\nI've got a project checked locally from GitHub, and that remote repository has since had changes made to it. What's the correct command to update my local copy with the latest changes?\n",
        "all_answers": [
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\nI have experienced the same situation I did the below as this much easier.\nBy passing commit-Id you can reach to the particular commit you want to go:\ngit reset --hard {commit-id}\n\nAs you want to remove your last commit so you need to pass the commit-Id where you need to move your pointer:\ngit reset --hard db0c078d5286b837532ff5e276dcf91885df2296\n\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\ngit fetch [remotename]\n\nHowever you'll need to merge any changes into your local branches. If you're on a branch that's tracking a remote branch on Github, then\ngit pull\n\nwill first do a fetch, and then merge in the tracked branch\n",
            "\nRemove the last commit before push\ngit reset --soft HEAD~1\n1 means the last commit, if you want to remove two last use 2, and so forth*\n",
            "\nProbably:\nwas:    git pull origin master\nnow:    git pull origin main\n",
            "\nThis is what I do:\nFirst checkout your branch (for my case master branch):\ngit checkout master\n\nThen reset to remote HEAD^ (it'll remove all your local changes), force clean and pull:\ngit reset HEAD^ --hard && git clean -df && git pull\n\n"
        ],
        "answer": "A10",
        "tags": [
            "git",
            "github"
        ]
    },
    {
        "question_id": "4758145",
        "question": "\nI have a default scope on products due to information security constraints.\nclass Product < ActiveRecord::Base\n  has_many :photos\n\n  default_scope where('visible = 1')\nend\n\nIn my associated Photo model, however, I also have to find products that should not be visible.\nclass Photo < ActiveRecord::Base\n  belongs_to :product\nend\n\nmy_photo.product\n\nIn other cases, I can use unscoped in order to bypass the default_scope, e.g. in Product.unscoped.find_by_title('abc'). However:\nHow to remove the scope when using associations of a record?\nmy_photo.unscoped.product does not make sense as my_photo does not have a method called unscoped. Neither does my_photo.product.unscoped make sense as my_photo.product may already be nil.\n",
        "all_answers": [
            "\nruby on rails notes has a very nice blogpost about commenting in erb-files\nthe short version is\nto comment a single line use\n<%# commented line %>\n\nto comment a whole block use a if false to surrond your code like this\n<% if false %>\ncode to comment\n<% end %>\n\n",
            "\nOh. I fooled myself. Thought the following would not work... but it does:\nProduct.unscoped do\n  my_photo.product\nend\n\nNotice that you have to call unscoped on the model with the default_scope that should be bypassed.\nAlso, inheritance has to be respected. If you have class InsuranceProduct < Productand class FinancialProduct < Product and a default_scope in Product, all of the following two combinations will work:\nInsuranceProduct.unscoped do\n  my_record.insurance_products\nend\n\nFinancialProduct.unscoped do\n  my_record.financial_products\nend\n\nProduct.unscoped do\n  my_record.products\nend\n\nHowever, the following will not work although the scope is defined in Product:\nProduct.unscoped do\n  my_record.financial_products\nend\n\nI guess that's another quirk of STI in Ruby / Rails.\n",
            "\nNote that if you want to comment out a single line of printing erb you should do like this\n<%#= [\"Buck\", \"Papandreou\"].join(\" you \") %>\n\n",
            "\nTry this in your Today model:\nhas_many :tasks, :order => 'priority DESC'\n\nEDIT: As mentioned in comment below, in Rails 4+, this is now:\nhas_many :tasks, -> { order(:priority => :desc) }\n\n(more info here)\n",
            "\nNew answer\nThis question should help you figure out how to bypass the default where clause for your association.\nIt's worth repeating though that if you're regularly having to avoid a scope then it probably should be a default. Create a visible non-default scope and use that explicitly in your associations.\n",
            "\nDirect solution would be to include the tasks table name before priority:\nToday.where(:user_id => current_user.id).includes(:tasks).order('tasks.priority').first\n# joins(:tasks) is not required\n\nOr, if you don't want to have the table name hardcoded, you can merge with scope from Task model:\nToday.where(:user_id => current_user.id).joins(:tasks).includes(:tasks).merge(Task.order(:priority)).first\n# joins(:tasks) here is required\n\nAlso, you can add has_many: todays to User model to ditch the where clause and do:\ncurrent_user.todays.includes(:tasks).order('tasks.priority').first\n# or\ncurrent_user.todays.joins(:tasks).includes(:tasks).merge(Task.order(:priority)).first\n\nBut if you need only/always to order by priority, and do not need other different orderings, adding order to has_many :tasks is easier.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby-on-rails-3",
            "scope",
            "arel"
        ]
    },
    {
        "question_id": "42125",
        "question": "\nI have a library I created,\nFile mylib.c:\n#include <mylib.h>\n\nint\ntestlib() {\n    printf(\"Hello, World!\\n\");\n    return (0);\n}\n\nFile mylib.h:\n#include <stdio.h>\nextern int testlib();\n\nIn my program, I've attempted to call this library function:\nFile myprogram.c:\n#include <mylib.h>\n\nint\nmain (int argc, char *argv[]) {\n    testlib();\n    return (0);\n}\n\nWhen I attempt to compile this program I get the following error:\nIn file included from myprogram.c:1\nmylib.h:2 warning: function declaration isn't a prototype\nI'm using: gcc (GCC) 3.4.5 20051201 (Red Hat 3.4.5-2)\nWhat is the proper way to declare a function prototype?\n",
        "all_answers": [
            "\nFunctional programming is not about lambdas, it is all about pure functions.  So the following broadly promote functional style:\n\nOnly use function arguments, do not use global state.\nMinimise side effects i.e. printf, or any IO.  Return data describing IO which can be executed instead of causing the side effects directly in all functions.  \n\nThis can be achieved in plain c, no need for magic.\n",
            "\nYou can use GCC's nested functions to simulate lambda expressions, in fact, I have a macro to do it for me:\n#define lambda(return_type, function_body) \\\n  ({ \\\n    return_type anon_func_name_ function_body \\\n    anon_func_name_; \\\n  })\n\nUse like this:\nint (*max)(int, int) = lambda (int, (int x, int y) { return x > y ? x : y; });\n\n",
            "\nHartel & Muller's book, Functional C, can nowadays (2012-01-02) be found at: http://eprints.eemcs.utwente.nl/1077/ (there is a link to PDF version).\n",
            "\nTry:\nextern int testlib(void);\n\n",
            "\nFFCALL lets you build closures in C -- callback = alloc_callback(&function, data) returns a function pointer such that callback(arg1, ...) is equivalent to calling function(data, arg1, ...).  You will have to handle garbage collection manually, though.\nRelatedly, blocks have been added to Apple's fork of GCC; they're not function pointers, but they let you pass around lambdas while avoiding the need to build and free storage for captured variables by hand (effectively, some copying and reference counting happens, hidden behind some syntactic sugar and runtime libraries).\n",
            "\nIn C int foo() and int foo(void) are different functions. int foo() accepts an arbitrary number of arguments, while int foo(void) accepts 0 arguments. In C++ they mean the same thing. I suggest that you use void consistently when you mean no arguments.\nIf you have a variable a, extern int a; is a way to tell the compiler that a is a symbol that might be present in a different translation unit (C compiler speak for source file), don't resolve it until link time. On the other hand, symbols which are function names are anyway resolved at link time. The meaning of a storage class specifier on a function (extern, static) only affects its visibility and extern is the default, so extern is actually unnecessary.\nI suggest removing the extern, it is extraneous and is usually omitted. \n"
        ],
        "answer": "A6",
        "tags": [
            "c",
            "gcc"
        ]
    },
    {
        "question_id": "1186400",
        "question": "\nI'm trying to find the best way to set default values for objects in Rails.  \nThe best I can think of is to set the default value in the new method in the controller. \nDoes anyone have any input if this is acceptable or if there's a better way to do it?\n",
        "all_answers": [
            "\n\"Correct\" is a dangerous word in Ruby.  There's usually more than one way to do anything.  If you know you'll always want that default value for that column on that table, setting them in a DB migration file is the easiest way:\nclass SetDefault < ActiveRecord::Migration\n  def self.up\n    change_column :people, :last_name, :type, :default => \"Doe\"\n  end\n\n  def self.down\n    # You can't currently remove default values in Rails\n    raise ActiveRecord::IrreversibleMigration, \"Can't remove the default\"\n  end\nend\n\nBecause ActiveRecord autodiscovers your table and column properties, this will cause the same default to be set in any model using it in any standard Rails app.\nHowever, if you only want default values set in specific cases -- say, it's an inherited model that shares a table with some others -- then another elegant way is do it directly in your Rails code when the model object is created:\nclass GenericPerson < Person\n  def initialize(attributes=nil)\n    attr_with_defaults = {:last_name => \"Doe\"}.merge(attributes)\n    super(attr_with_defaults)\n  end\nend\n\nThen, when you do a GenericPerson.new(), it'll always trickle the \"Doe\" attribute up to Person.new() unless you override it with something else.\n",
            "\nIf you are referring to ActiveRecord objects, you have (more than) two ways of doing this:\n1. Use a :default parameter in the DB\nE.G.\nclass AddSsl < ActiveRecord::Migration\n  def self.up\n    add_column :accounts, :ssl_enabled, :boolean, :default => true\n  end\n\n  def self.down\n    remove_column :accounts, :ssl_enabled\n  end\nend\n\nMore info here: http://api.rubyonrails.org/classes/ActiveRecord/Migration.html\n2. Use a callback\nE.G. before_validation_on_create\nMore info here: http://api.rubyonrails.org/classes/ActiveRecord/Callbacks.html#M002147\n",
            "\nIf you are just setting defaults for certain attributes of a database backed model I'd consider using sql default column values - can you clarify what types of defaults you are using?\nThere are a number of approaches to handle it, this plugin looks like an interesting option.\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby"
        ]
    },
    {
        "question_id": "559415",
        "question": "\nIs there any easy LINQ expression to concatenate my entire List<string> collection items to a single string with a delimiter character?\nWhat if the collection is of custom objects instead of string? Imagine I need to concatenate on object.Name.\n",
        "all_answers": [
            "\nstring result = String.Join(delimiter, list);\n\nis sufficient.\n",
            "\nGood question. I've been using\nList<string> myStrings = new List<string>{ \"ours\", \"mine\", \"yours\"};\nstring joinedString = string.Join(\", \", myStrings.ToArray());\n\nIt's not LINQ, but it works.\n",
            "\nThe following query works. It uses each group to do the select instead of SelectMany. SelectMany works on each element from each collection. For example, in your query you have a result of 2 collections. SelectMany gets all the results, a total of 3, instead of each collection. The following code works on each IGrouping in the select portion to get your aggregate operations working correctly.\nvar results = from line in Lines\n              group line by line.ProductCode into g\n              select new ResultLine {\n                ProductName = g.First().Name,\n                Price = g.Sum(pc => pc.Price).ToString(),\n                Quantity = g.Count().ToString(),\n              };\n\n",
            "\nI don't understand where the first \"result with sample data\" is coming from, but the problem in the console app is that you're using SelectMany to look at each item in each group.\nI think you just want:\nList<ResultLine> result = Lines\n    .GroupBy(l => l.ProductCode)\n    .Select(cl => new ResultLine\n            {\n                ProductName = cl.First().Name,\n                Quantity = cl.Count().ToString(),\n                Price = cl.Sum(c => c.Price).ToString(),\n            }).ToList();\n\nThe use of First() here to get the product name assumes that every product with the same product code has the same product name. As noted in comments, you could group by product name as well as product code, which will give the same results if the name is always the same for any given code, but apparently generates better SQL in EF.\nI'd also suggest that you should change the Quantity and Price properties to be int and decimal types respectively - why use a string property for data which is clearly not textual?\n",
            "\nList<string> strings = new List<string>() { \"ABC\", \"DEF\", \"GHI\" };\nstring s = strings.Aggregate((a, b) => a + ',' + b);\n\n",
            "\nWarning - Serious Performance Issues\nThough this answer does produce the desired result, it suffers from poor performance compared to other answers here. Be very careful about deciding to use it\n\nBy using LINQ, this should work;\nstring delimiter = \",\";\nList<string> items = new List<string>() { \"foo\", \"boo\", \"john\", \"doe\" };\nConsole.WriteLine(items.Aggregate((i, j) => i + delimiter + j));\n\nclass description:\npublic class Foo\n{\n    public string Boo { get; set; }\n}\n\nUsage:\nclass Program\n{\n    static void Main(string[] args)\n    {\n        string delimiter = \",\";\n        List<Foo> items = new List<Foo>() { new Foo { Boo = \"ABC\" }, new Foo { Boo = \"DEF\" },\n            new Foo { Boo = \"GHI\" }, new Foo { Boo = \"JKL\" } };\n\n        Console.WriteLine(items.Aggregate((i, j) => new Foo{Boo = (i.Boo + delimiter + j.Boo)}).Boo);\n        Console.ReadKey();\n\n    }\n}\n\nAnd here is my best :)\nitems.Select(i => i.Boo).Aggregate((i, j) => i + delimiter + j)\n\n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            "linq",
            ".net-3.5"
        ]
    },
    {
        "question_id": "29392422",
        "question": "\nI'm having problems posting JSON with UTF-8 encoding using RestTemplate. Default encoding for JSON is UTF-8 so the media type shouldn't even contain the charset. I have tried to put charset in the MediaType but it doesn't seem to work anyway.\nMy code:\nString dataJson = \"{\\\"food\\\": \\\"smörrebröd\\\"}\";\nHttpHeaders headers = new HttpHeaders();\nMediaType mediaType = new MediaType(\"application\", \"json\", StandardCharsets.UTF_8);\nheaders.setContentType(mediaType);\n\nHttpEntity<String> entity = new HttpEntity<String>(dataJson, headers);\nRestTemplate restTemplate = new RestTemplate();\nResponseEntity<Boolean> formEntity = restTemplate.exchange(postUrl, HttpMethod.POST, entity, Boolean.class);\n\n",
        "all_answers": [
            "\nrestTemplate.getMessageConverters().add(0, new StringHttpMessageConverter(StandardCharsets.UTF_16LE));\n\nString response = restTemplate.getForObject(url, String.class);\n\n",
            "\nI'm pretty sure that won't work. There may be a workaround, but the much easier way would be to introduce a wrapper Object and change your signature:\npublic class PersonContext{\n    private UserContext userContext;\n    private Person person;\n    // getters and setters\n}\n\n\npublic Person createPerson(@RequestBody PersonContext personContext)\n\n",
            "\nYou can write your own security filter that will parse your JSON.\nhttp://docs.spring.io/spring-security/site/docs/3.0.x/reference/core-web-filters.html\nYou can use the BasicAuthenticationFilter as a reference:\nhttp://docs.spring.io/spring-security/site/docs/3.0.x/apidocs/org/springframework/security/web/authentication/www/BasicAuthenticationFilter.html\n",
            "\nYou need to add StringHttpMessageConverter to rest template's message converter with charset UTF-8. Like this \nRestTemplate restTemplate = new RestTemplate();\nrestTemplate.getMessageConverters()\n        .add(0, new StringHttpMessageConverter(StandardCharsets.UTF_8));\n\n"
        ],
        "answer": "A4",
        "tags": [
            "json",
            "spring",
            "resttemplate"
        ]
    },
    {
        "question_id": "4233626",
        "question": "\nHow to allow multi-line in Android's EditText view?\n",
        "all_answers": [
            "\nEditText has singleLine property. You can set in the XML or by calling setSingleLine(false);\nhttp://developer.android.com/reference/android/widget/TextView.html#setSingleLine%28%29\n",
            "\n2020 solution via Material Design Components for Android:\nAdd Material Components to your gradle setup:\nLook for latest version from here: https://maven.google.com/\nimplementation 'com.google.android.material:material:1.3.0'\n\nor if you havent updated to using AndroidX libs, you can add it this way:\nimplementation 'com.android.support:design:28.0.0'\n\nThen\n<com.google.android.material.textfield.TextInputLayout\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"wrap_content\"\n    android:hint=\"@string/hint_text\"\n    app:endIconMode=\"clear_text\">\n\n  <com.google.android.material.textfield.TextInputEditText\n      android:layout_width=\"match_parent\"\n      android:layout_height=\"wrap_content\"/>\n\n</com.google.android.material.textfield.TextInputLayout>\n\nPay attention to: app:endIconMode=\"clear_text\"\nAs discussed here Material design docs\n",
            "\nUse the following layout:\n<FrameLayout\n    android:layout_width=\"fill_parent\"\n    android:layout_height=\"wrap_content\"\n    android:layout_marginTop=\"9dp\"\n    android:padding=\"5dp\">\n\n    <EditText\n        android:id=\"@+id/calc_txt_Prise\"\n        android:layout_width=\"fill_parent\"\n        android:layout_height=\"wrap_content\"\n        android:inputType=\"numberDecimal\"  \n        android:layout_marginTop=\"20dp\"\n        android:textSize=\"25dp\"\n        android:textColor=\"@color/gray\"\n        android:textStyle=\"bold\"\n        android:hint=\"@string/calc_txt_Prise\"\n        android:singleLine=\"true\" />\n\n    <Button\n        android:id=\"@+id/calc_clear_txt_Prise\"      \n        android:layout_width=\"wrap_content\"\n        android:layout_height=\"wrap_content\"\n        android:layout_marginRight=\"10dp\"\n        android:layout_gravity=\"right|center_vertical\"\n        android:background=\"@drawable/delete\" />\n\n</FrameLayout>\n\nYou can also use the button's id and perform whatever action you want on its onClickListener method.\n",
            "\nBy default all the EditText widgets in Android are multi-lined.\nHere is some sample code:\n<EditText\n    android:inputType=\"textMultiLine\" <!-- Multiline input -->\n    android:lines=\"8\" <!-- Total Lines prior display -->\n    android:minLines=\"6\" <!-- Minimum lines -->\n    android:gravity=\"top|start\" <!-- Cursor Position -->\n    android:maxLines=\"10\" <!-- Maximum Lines -->\n    android:layout_height=\"wrap_content\" <!-- Height determined by content -->\n    android:layout_width=\"match_parent\" <!-- Fill entire width -->\n    android:scrollbars=\"vertical\" <!-- Vertical Scroll Bar -->\n/>\n\n",
            "\nIf you happen to use DroidParts, I've just added ClearableEditText.\nHere's what it looks like with a custom background & clear icon set to abs__ic_clear_holo_light from ActionBarSherlock:\n\n"
        ],
        "answer": "A4",
        "tags": [
            "android",
            "android-edittext",
            "multiline"
        ]
    },
    {
        "question_id": "1676688",
        "question": "\nI'm trying to set up WordPress. I have Apache and MySQL running, and the accounts and database are all set up. I tried to make a simple connection:\n<?php\n    $conn = mysql_connect('localhost', 'USER', 'PASSWORD');\n    if(!$conn) {\n        echo 'Error: ' . mysql_errno() . ' - ' . mysql_error();\n    }\n?>\n\nAnd I always get this:\n\nError: 2002 - No such file or\n  directory\n\nWhat file or directory could it be talking about?\nI'm on a OS X Snow Leopard, using the built-in Apache. I installed MySQL using the x86_64 dmg.\nUPDATE: I found that the socket is at /tmp/mysql.sock, so In php.ini, I replaced all occurrences of the wrong path with that.\n",
        "all_answers": [
            "\nFirst, ensure MySQL is running. Command: mysqld start\nIf you still cannot connect then:\nWhat does your /etc/my.cnf look like? (or /etc/msyql/my.cnf)\nThe other 2 posts are correct in that you need to check your socket because 2002 is a socket error.\nA great tutorial on setting up LAMP is: http://library.linode.com/lamp-guides/centos-5.3/index-print\n",
            "\nI'd check your php.ini file and verify the mysql.default_socket is set correctly and also verify that your mysqld is correctly configured with a socket file it can access. Typical default is \"/tmp/mysql.sock\".\n",
            "\nIf you use Linux: the path to the mysql.sock file is wrong. This is usually because you are using (LAMPP) XAMPP and it isn't in /tmp/mysql.sock\nOpen the php.ini file and find this line:\nmysql.default_socket\n\nAnd make it\nmysql.default_socket = /path/to/mysql.sock\n\n",
            "\nNot that it helps you much, but in the recent versions (and even less recent) of MySQL, error code 2002 means “Can't connect to local MySQL server through socket [name-of-socket]”, so that might tell you a bit more.\n"
        ],
        "answer": "A3",
        "tags": [
            "php",
            "mysql",
            "connection"
        ]
    },
    {
        "question_id": "5836662",
        "question": "\nHow can I do this:\npublic class Main extends ListActivity , ControlMenu \n\nAlso, I would like to know that is this approach is okay that I have made the menus in class which is ControlMenu and I am extending in rest of the activities. \n",
        "all_answers": [
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nYes. slandau is right. Java does not allow extending from several classes.\nWhat you want is probably public class Main extends ListActivity implements ControlMenu. I am guessing you are trying to make a list.\nHope that helps.\n",
            "\nYou can only Extend a single class. And implement Interfaces from many sources. \nExtending multiple classes is not available. The only solution I can think of is not inheriting either class but instead having an internal variable of each class and doing more of a proxy by redirecting the requests to your object to the object that you want them to go to.\n public class CustomActivity extends Activity {\n\n     private AnotherClass mClass;\n\n     protected void onCreate(Bundle savedInstanceState) {\n         super.onCreate(savedInstanceState);\n         mClass = new AnotherClass(this);\n     }\n\n     //Implement each method you want to use.\n     public String getInfoFromOtherClass()\n     {\n        return mClass.getInfoFromOtherClass();\n     }\n }\n\nthis is the best solution I have come up with.\nYou can get the functionality from both classes and Still only actually be of one class type.\nThe drawback is that you cannot fit into the Mold of the Internal class using a cast.\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nMake an interface. Java doesn't have multiple inheritance. \nhttp://csis.pace.edu/~bergin/patterns/multipleinheritance.html\n",
            "\nYou will want to use interfaces. Generally, multiple inheritance is bad because of the Diamond Problem:\nabstract class A {\n abstract string foo();\n}\n\nclass B extends A {\n string foo () { return \"bar\"; }\n}\n\nclass C extends A  {\n string foo() {return \"baz\"; }\n}\n\nclass D extends B, C {\n string foo() { return super.foo(); } //What do I do? Which method should I call?\n}\n\nC++ and others have a couple ways to solve this, eg\nstring foo() { return B::foo(); }\n\nbut Java only uses interfaces. \nThe Java Trails have a great introduction on interfaces: http://download.oracle.com/javase/tutorial/java/concepts/interface.html\nYou'll probably want to follow that before diving into the nuances in the Android API.\n"
        ],
        "answer": "A3",
        "tags": [
            "java",
            "android"
        ]
    },
    {
        "question_id": "13436408",
        "question": "\nIf you run a .bat or .cmd file with %0|%0 inside, your computer starts to use a lot of memory and after several minutes, is restarted. Why does this code block your Windows? And what does this code programmatically do? Could it be considered a \"bug\"?\n",
        "all_answers": [
            "\nThis is the Windows version of a fork bomb.\n%0 is the name of the currently executing batch file. A batch file that contains just this line:\n%0|%0\n\nIs going to recursively execute itself forever, quickly creating many processes and slowing the system down.\nThis is not a bug in windows, it is just a very stupid thing to do in a batch file.\n",
            "\n%0 will never end, but it never creates more than one process because it instantly transfers control to the 2nd batch script (which happens to be itself).\nBut a Windows pipe creates a new process for each side of the pipe, in addition to the parent process. The parent process can't finish until each side of the pipe terminates. So the main program with a simple pipe will have 3 processes. You can see how the bomb quickly get's out of control if each side of the pipe recursively calls the parent batch!\n"
        ],
        "answer": "A1",
        "tags": [
            "windows",
            "command-line"
        ]
    },
    {
        "question_id": "40804648",
        "question": "\nI am trying to deserialize a JSON string received from a Web API\ntry\n{\n    string r = await App.client.GetUser();\n\n    App.Authentication = JsonConvert.DeserializeObject<ApiResult>(r);\n\n    await DisplayAlert(\"TEST\", App.Authentication.ToString(), \"OK\");\n\n    Application.Current.MainPage = new Schedule();\n}\ncatch (Exception p)\n{\n    await DisplayAlert(\"Getting Authentication failed\", p.ToString(), \"TEST\");\n}\n\nHowever it gives the error: Could not Cast or Convert System.String to App1.ApiResult\nApp.Authentication = JsonConvert.DeserializeObject<ApiResult>(r);\nApp.Authentication:\npublic static ApiResult Authentication = new ApiResult();`\n\nJSON string:\n\n\"\\\"{\\\\\"status\\\\\":\\\\\"0\\\\\",\\\\\"message\\\\\":{\\\\\"ID\\\\\":5,\\\\\"FirstName\\\\\":\\\\\"John\\\\\",\\\\\"LastName\\\\\":\\\\\"Doe\\\\\",\\\\\"Email\\\\\":\\\\\"[email protected]\\\\\",\\\\\"Password\\\\\":\\\\\"testPass\\\\\",\\\\\"CreationDate\\\\\":\\\\\"2016-10-26T15:01:08\\\\\",\\\\\"RoleID\\\\\":1,\\\\\"doorCode\\\\\":9999}}\\\"\"\n\nApiResult Class:\npublic class ApiResult\n{\n    public string status { get; set; }\n    public Account message { get; set; }\n}\n\nAccount Class:\npublic class Account\n{\n    public string status { get; set; }\n    public int ID { get; set; }\n    public string FirstName { get; set; }\n    public string LastName { get; set; }\n    public string Email { get; set; }\n    public string Password { get; set; }\n    public DateTime CreationDate { get; set; }\n    public int RoleID { get; set; }\n    public int doorCode { get; set; }\n}\n\nThe full error message:\n\n{\"Error converting value\n  \\\"{\\\"status\\\":\\\"0\\\",\\\"message\\\":{\\\"ID\\\":5,\\\"FirstName\\\":\\\"John\\\",\\\"LastName\\\":\\\"Doe\\\",\\\"Email\\\":\\\"[email protected]\\\",\\\"Password\\\":\\\"testPass\\\",\\\"CreationDate\\\":\\\"2016-10-26T15:01:08\\\",\\\"RoleID\\\":1,\\\"doorCode\\\":9999}}\\\"\n  to type 'App1.ApiResult'. Path '', line 1, position 232.\"}\n\n",
        "all_answers": [
            "\nJSON.Net\n",
            "\nYou should also try my ServiceStack JsonSerializer - it's the fastest .NET JSON serializer at the moment based on the benchmarks of the leading JSON serializers and supports serializing any POCO Type, DataContracts, Lists/Dictionaries, Interfaces, Inheritance, Late-bound objects including anonymous types, etc.\nBasic Example\nvar customer = new Customer { Name=\"Joe Bloggs\", Age=31 };\nvar json = customer.ToJson();\nvar fromJson = json.FromJson<Customer>(); \n\nNote: Only use Microsofts JavaScriptSerializer if performance is not important to you as I've had to leave it out of my benchmarks since its up to 40x-100x slower than the other JSON serializers.\n",
            "\nTry using App.Authentication = JObject.Parse(request.Content.ReadAsStringAsync().Result);\n",
            "\nIt appears that the json you receive has been serialized twice - first from ApiResult to string, then to string again:\n\"\\\"{\\\\\"status\\\\\":\\\\\"0\\\\\",\\\\\"message\\\\\":...\n\nThe first double-quote might be added by your debugger, but the second (the escaped \\\" one) really appears to be part of the data you're processing. The error message also makes sense this way, it deserializes a string and then attempts to cast it to an ApiResult.\nTry deserializing the data as a string and then deserializing its result to an ApiResult, to be sure this is the case - and if so, the server code will need to be changed.\n"
        ],
        "answer": "A4",
        "tags": [
            "c#",
            "json",
            "serialization"
        ]
    },
    {
        "question_id": "5615648",
        "question": "\nI have this code which calculates the distance between two coordinates. The two functions are both within the same class.\nHowever, how do I call the function distToPoint in the function isNear?\nclass Coordinates:\n    def distToPoint(self, p):\n        \"\"\"\n        Use pythagoras to find distance\n        (a^2 = b^2 + c^2)\n        \"\"\"\n        ...\n\n    def isNear(self, p):\n        distToPoint(self, p)\n        ...\n\n",
        "all_answers": [
            "\nNames surrounded by double underscores are \"special\" to Python. They're listed in the Python Language Reference, section 3, \"Data model\".\n",
            "\nThe other respondents are correct in describing the double leading and trailing underscores as a naming convention for \"special\" or \"magic\" methods.\nWhile you can call these methods directly ([10, 20].__len__() for example), the presence of the underscores is a hint that these methods are intended to be invoked indirectly (len([10, 20]) for example).  Most python operators have an associated \"magic\" method (for example, a[x] is the usual way of invoking a.__getitem__(x)).\n",
            "\nFrom the Python PEP 8 -- Style Guide for Python Code:\n\nDescriptive: Naming Styles\nThe following special forms using leading or trailing underscores are\n  recognized (these can generally be combined with any case convention):\n\n_single_leading_underscore: weak \"internal use\" indicator. E.g. from M import * does not import objects whose name starts with an underscore.\nsingle_trailing_underscore_: used by convention to avoid conflicts with Python keyword, e.g.\nTkinter.Toplevel(master, class_='ClassName')\n__double_leading_underscore: when naming a class attribute, invokes name mangling (inside class FooBar, __boo becomes _FooBar__boo; see below).  \n__double_leading_and_trailing_underscore__: \"magic\" objects or attributes that live in user-controlled namespaces.  E.g. __init__,\n  __import__ or __file__.  Never invent such names; only use them as documented.\n\n\nNote that names with double leading and trailing underscores are essentially reserved for Python itself: \"Never invent such names; only use them as documented\".\n",
            "\nSince these are member functions, call it as a member function on the instance, self.\ndef isNear(self, p):\n    self.distToPoint(p)\n    ...\n\n",
            "\nThat doesn't work because distToPoint is inside your class, so you need to prefix it with the classname if you want to refer to it, like this: classname.distToPoint(self, p). You shouldn't do it like that, though. A better way to do it is to refer to the method directly through the class instance (which is the first argument of a class method), like so: self.distToPoint(p).\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "class",
            "function",
            "call"
        ]
    },
    {
        "question_id": "8914257",
        "question": "\nIs there any actual difference between these two lines of code?\nini_set('max_execution_time', 20*60);\nset_time_limit(20*60);\n\n",
        "all_answers": [
            "\nNo there isn't.\necho ini_get('max_execution_time'); // 30\nset_time_limit(100);\necho ini_get('max_execution_time'); // 100\n\nRegarding timer reset, it is reset in both cases:\nini_set('max_execution_time', 10);\n\nfor ($i=0; $i<50000000; $i++) {\n\n}\n\nini_set('max_execution_time', 10); // timer is reset, just as it would be with set_time_limit\n\nfor ($i=0; $i<50000000; $i++) {\n\n}\n\necho 'done';\n\n",
            "\nLooking at the current source: \n/* {{{ proto bool set_time_limit(int seconds)\n   Sets the maximum time a script can run */\nPHP_FUNCTION(set_time_limit)\n{\n    zend_long new_timeout;\n    char *new_timeout_str;\n    int new_timeout_strlen;\n    zend_string *key;\n\n    if (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"l\", &new_timeout) == FAILURE) {\n        return;\n    }\n\n    new_timeout_strlen = zend_spprintf(&new_timeout_str, 0, ZEND_LONG_FMT, new_timeout);\n\n    key = zend_string_init(\"max_execution_time\", sizeof(\"max_execution_time\")-1, 0);\n    if (zend_alter_ini_entry_chars_ex(key, new_timeout_str, new_timeout_strlen, PHP_INI_USER, PHP_INI_STAGE_RUNTIME, 0 TSRMLS_CC) == SUCCESS) {\n        RETVAL_TRUE;\n    } else {\n        RETVAL_FALSE;\n    }\n    zend_string_release(key);\n    efree(new_timeout_str);\n}\n/* }}} */\n\nset_time_limit() is indeed just a convenience wrapper around the according ini_set() call. It doesn't even seem to perform the advertised timer reset. (But I would guess the \"timer\" actually isn't a separate entity, but the ini value itself is used as such.)\n",
            "\nAccording to the php manual, set_time_limit() will reset the execution timer when called.  I don't believe ini_set() has the same side-effect, which would be the difference between the two.\nSee http://php.net/manual/en/function.set-time-limit.php for more information.\nUpdate: since examining various portions of the php source code (including that referenced by mario's answer), it is my conclusion that ini_set() and set_time_limit() are precisely equivalent.\nini_set() does indeed reset the timer (though I'm still at a loss as to how either function performs the reset, I would have to look up the function that kills the script when the timer ends to figure that one out).\n"
        ],
        "answer": "A2",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "1327102",
        "question": "\nI am using the thread.Abort method to kill the thread, but it not working. Is there any other way of terminating the thread?\nprivate void button1_Click(object sender, EventArgs e)\n{\n    if (Receiver.IsAlive == true)\n    {\n        MessageBox.Show(\"Alive\");\n        Receiver.Abort();\n    }\n    else\n    {\n        MessageBox.Show(\"Dead\");\n        Receiver.Start();\n    }\n}\n\nI am using this but every time I get the Alive status, Receiver is my global thread.\n",
        "all_answers": [
            "\nHere is a good write up about .NET events and race conditions with threads.  It covers some common scenarios and has some good references in it.\nHope this helps.\n",
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nThread will be killed when it finishes its work, so if you are using loops or something, you should pass variable to the thread to stop the loop. After that, the thread will be finished.\n",
            "\nThe reason it's hard to just kill a thread is because the language designers want to avoid the following problem: your thread takes a lock, and then you kill it before it can release it. Now anyone who needs that lock will get stuck.\nWhat you have to do is use some global variable to tell the thread to stop. You have to manually, in your thread code, check that global variable and return if you see it indicates you should stop.\n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            "winforms",
            "multithreading"
        ]
    },
    {
        "question_id": "180103",
        "question": "\nI am using some nested layouts in Ruby on Rails, and in one of the layouts i have a need to read in a string from a div and set that as the title of the document. What is correct way (if any) to set the title of the document?\n<script type=\"text/javascript\">\n$(document).ready(function() {\n\n    // ???\n\n});\n</script>\n\n",
        "all_answers": [
            "\n<script type=\"text/javascript\">\n$(document).ready(function() {\n\n    $(this).attr(\"title\", \"sometitle\");\n\n});\n</script>\n\n",
            "\nThe following should work but it wouldn't be SEO compatible. It's best to put the title in the title tag.\n<script type=\"text/javascript\">\n\n    $(document).ready(function() {\n        document.title = 'blah';\n    });\n\n</script>\n\n",
            "\nLike this:\n$(document).ready(function ()\n{\n    document.title = \"Hello World!\";\n});\n\nBe sure to set a default-title if you want your site to be properly indexed by search-engines.\nA little tip:\n$(function ()\n{\n    // this is a shorthand for the whole document-ready thing\n    // In my opinion, it's more readable \n});\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "jquery",
            "ruby-on-rails"
        ]
    },
    {
        "question_id": "28281653",
        "question": "\nI'm trying to have a handler in my Mac OS X app written in Swift for a global (system-wide) hotkey combo but I just cannot find proper documentation for it. I've read that I'd have to mess around in some legacy Carbon API for it, is there no better way? Can you show me some proof of concept Swift code? Thanks in advance!\n",
        "all_answers": [
            "\nSince Swift 2.0, you can now pass a function pointer to C APIs.\nvar gMyHotKeyID = EventHotKeyID()\ngMyHotKeyID.signature = OSType(\"swat\".fourCharCodeValue)\ngMyHotKeyID.id = UInt32(keyCode)\n\nvar eventType = EventTypeSpec()\neventType.eventClass = OSType(kEventClassKeyboard)\neventType.eventKind = OSType(kEventHotKeyPressed)\n\n// Install handler.\nInstallEventHandler(GetApplicationEventTarget(), {(nextHanlder, theEvent, userData) -> OSStatus in\n    var hkCom = EventHotKeyID()\n    GetEventParameter(theEvent, EventParamName(kEventParamDirectObject), EventParamType(typeEventHotKeyID), nil, sizeof(EventHotKeyID), nil, &hkCom)\n\n    // Check that hkCom in indeed your hotkey ID and handle it.\n}, 1, &eventType, nil, nil)\n\n// Register hotkey.\nlet status = RegisterEventHotKey(UInt32(keyCode), UInt32(modifierKeys), gMyHotKeyID, GetApplicationEventTarget(), 0, &hotKeyRef)\n\n",
            "\nI don't believe you can do this in 100% Swift today. You'll need to call InstallEventHandler() or CGEventTapCreate(), and both of those require a CFunctionPointer, which can't be created in Swift. Your best plan is to use established ObjC solutions such as DDHotKey and bridge to Swift.\nYou can try using NSEvent.addGlobalMonitorForEventsMatchingMask(handler:), but that only makes copies of events. You can't consume them. That means the hotkey will also be passed along to the currently active app, which can cause problems. Here's an example, but I recommend the ObjC approach; it's almost certainly going to work better.\nlet keycode = UInt16(kVK_ANSI_X)\nlet keymask: NSEventModifierFlags = .CommandKeyMask | .AlternateKeyMask | .ControlKeyMask\n\nfunc handler(event: NSEvent!) {\n    if event.keyCode == self.keycode &&\n        event.modifierFlags & self.keymask == self.keymask {\n            println(\"PRESSED\")\n    }\n}\n\n// ... to set it up ...\n    let options = NSDictionary(object: kCFBooleanTrue, forKey: kAXTrustedCheckOptionPrompt.takeUnretainedValue() as NSString) as CFDictionaryRef\n    let trusted = AXIsProcessTrustedWithOptions(options)\n    if (trusted) {\n        NSEvent.addGlobalMonitorForEventsMatchingMask(.KeyDownMask, handler: self.handler)\n    }\n\nThis also requires that accessibility services be approved for this app. It also doesn't capture events that are sent to your own application, so you have to either capture them with your responder chain, our use addLocalMointorForEventsMatchingMask(handler:) to add a local handler.\n"
        ],
        "answer": "A1",
        "tags": [
            "swift",
            "macos",
            "cocoa",
            "keyboard-shortcuts"
        ]
    },
    {
        "question_id": "6588068",
        "question": "\nWe have a web app that exports CSV files containing foreign characters with UTF-8, no BOM. Both Windows and Mac users get garbage characters in Excel. I tried converting to UTF-8 with BOM; Excel/Win is fine with it, Excel/Mac shows gibberish. I'm using Excel 2003/Win, Excel 2011/Mac.\nHere's all the encodings I tried:\nEncoding  BOM      Win                            Mac\n--------  ---      ----------------------------   ------------\nutf-8     --       scrambled                      scrambled\nutf-8     BOM      WORKS                          scrambled\nutf-16    --       file not recognized            file not recognized\nutf-16    BOM      file not recognized            Chinese gibberish\nutf-16LE  --       file not recognized            file not recognized\nutf-16LE  BOM      characters OK,                 same as Win\n                   row data all in first field\n\nThe best one is UTF-16LE with BOM, but the CSV is not recognized as such. The field separator is comma, but semicolon doesn't change things.\nIs there any encoding that works in both worlds?\n",
        "all_answers": [
            "\nThe lowdown is: There is no solution. Excel 2011/Mac cannot correctly interpret a CSV file containing umlauts and diacritical marks no matter what encoding or hoop jumping you do. I'd be glad to hear someone tell me different!\n",
            "\nFor UTF-16LE with BOM if you use tab characters as your delimiters instead of commas Excel will recognise the fields. The reason it works is that Excel actually ends up using its Unicode *.txt parser.\nCaveat: If the file is edited in Excel and saved, it will be saved as tab-delimited ASCII. The problem now is that when you re-open the file Excel assumes it's real CSV (with commas), sees that it's not Unicode, so parses it as comma-delimited - and hence will make a hash of it!\nUpdate: The above caveat doesn't appear to be happening for me today in Excel 2010 (Windows) at least, although there does appear to be a difference in saving behaviour if:\n\nyou edit and quit Excel (tries to save as 'Unicode *.txt')\n\ncompared to:\n\nediting and closing just the file (works as expected).\n\n",
            "\ninstead of csv, trying outputting html with an XLS extension and \"application/excel\" mime-type. I know this will work in Windows, but can't speak for MacOS\n",
            "\nIt seems to my case that Excel 2011 for Mac OS is not using Encoding.GetEncoding(\"10000\") as i thought and wasted 2 days with but the same iso as on Microsoft OS.\nThe best proof for this is to make a file in Excel 2011 for MAC with special chars, save it as CSV and then open it in MAC text editor and the chars are scrambled.\nFor me this approach worked - meaning that csv export on Excel 2011 on MAC OS has special western europeean chars inside:\nEncoding isoMacOS = Encoding.GetEncoding(\"iso-8859-1\");\nEncoding defaultEncoding = Encoding.Default; \n\n// Convert the string into a byte array.\nbyte[] defaultEncodingBytes = defaultEncoding.GetBytes(exportText);\n\n// Perform the conversion from one encoding to the other.\nbyte[] ansiBytes = Encoding.Convert(defaultEncoding, isoMacOS, defaultEncodingBytes);\n\ndecodedString = isoMacOS.GetString(ansiBytes);\n\n",
            "\nFor second accuracy, yyyy-MM-dd HH:mm:ss should do the trick.\nI believe Excel is not very good with fractions of a second (loses them when interacting with COM object IIRC).\n"
        ],
        "answer": "A1",
        "tags": [
            "windows",
            "excel",
            "macos",
            "csv",
            "utf"
        ]
    },
    {
        "question_id": "26647152",
        "question": "\nI'm coding in C++. If I have some function void foo(vector<int> test) and I call it in my program, will the vector be passed by value or reference? I'm unsure because I know vectors and arrays are similar and that a function like void bar(int test[]) would pass test in by reference (pointer?) instead of by value. My guess is that I would need to pass the vector by pointer/reference explicitly if I wanted to avoid passing by value but I'm not sure.\n",
        "all_answers": [
            "\nA vector is functionally same as an array. But, to the language vector is a type, and int is also a type. To a function argument, an array of any type (including vector[]) is treated as pointer. A vector<int> is not same as int[] (to the compiler). vector<int> is non-array, non-reference, and non-pointer - it is being passed by value, and hence it will call copy-constructor. \nSo, you must use vector<int>& (preferably with const, if function isn't modifying it) to pass it as a reference.\n",
            "\nvoid foo(vector<int> test)\nvector would be passed by value in this.\nYou have more ways to pass vectors depending on the context:-\n1) Pass by reference:- This will let function foo change your contents of the vector. More efficient than pass by value as copying of vector is avoided.\n2) Pass by const-reference:- This is efficient as well as reliable when you don't want function to change the contents of the vector.\n",
            "\nIn C++, things are passed by value unless you specify otherwise using the &-operator (note that this operator is also used as the 'address-of' operator, but in a different context). This is all well documented, but I'll re-iterate anyway:\nvoid foo(vector<int> bar); // by value\nvoid foo(vector<int> &bar); // by reference (non-const, so modifiable inside foo)\nvoid foo(vector<int> const &bar); // by const-reference\n\nYou can also choose to pass a pointer to a vector (void foo(vector<int> *bar)), but unless you know what you're doing and you feel that this is really is the way to go, don't do this.\nAlso, vectors are not the same as arrays! Internally, the vector keeps track of an array of which it handles the memory management for you, but so do many other STL containers. You can't pass a vector to a function expecting a pointer or array or vice versa (you can get access to (pointer to) the underlying array and use this though). Vectors are classes offering a lot of functionality through its member-functions, whereas pointers and arrays are built-in types. Also, vectors are dynamically allocated (which means that the size may be determined and changed at runtime) whereas the C-style arrays are statically allocated (its size is constant and must be known at compile-time), limiting their use.\nI suggest you read some more about C++ in general (specifically array decay), and then have a look at the following program which illustrates the difference between arrays and pointers:\nvoid foo1(int *arr) { cout << sizeof(arr) << '\\n'; }\nvoid foo2(int arr[]) { cout << sizeof(arr) << '\\n'; }\nvoid foo3(int arr[10]) { cout << sizeof(arr) << '\\n'; }\nvoid foo4(int (&arr)[10]) { cout << sizeof(arr) << '\\n'; }\n\nint main()\n{\n    int arr[10] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n    foo1(arr);\n    foo2(arr);\n    foo3(arr);\n    foo4(arr);\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "arrays",
            "vector"
        ]
    },
    {
        "question_id": "3294889",
        "question": "\nd = {'x': 1, 'y': 2, 'z': 3}\n\nfor key in d:\n    print(key, 'corresponds to', d[key])\n\nHow does Python recognize that it needs only to read the key from the dictionary? Is key a special keyword, or is it simply a variable?\n",
        "all_answers": [
            "\nWhen you iterate through dictionaries using the for .. in ..-syntax, it always iterates over the keys (the values are accessible using dictionary[key]).\nTo iterate over key-value pairs, use the following:\n\nfor k,v in dict.iteritems() in Python 2\nfor k,v in dict.items() in Python 3\n\n",
            "\nkey is just a variable name.  \nfor key in d:\n\nwill simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:\nFor Python 3.x:\nfor key, value in d.items():\n\nFor Python 2.x:\nfor key, value in d.iteritems():\n\nTo test for yourself, change the word key to poop.\nIn Python 3.x, iteritems() was replaced with simply items(), which returns a set-like view backed by the dict, like iteritems() but even better. \nThis is also available in 2.7 as viewitems(). \nThe operation items() will work for both 2 and 3, but in 2 it will return a list of the dictionary's (key, value) pairs, which will not reflect changes to the dict that happen after the items() call. If you want the 2.x behavior in 3.x, you can call list(d.items()).\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "dictionary"
        ]
    },
    {
        "question_id": "12974474",
        "question": "\n\n\n\nI have a list of tuples l = [(1,2), (3,4), (8,9)]. How can I, succinctly and Pythonically, unzip this list into two independent lists, to get [ [1, 3, 8], [2, 4, 9] ]?\nIn other words, how do I get the inverse of what zip does?\n",
        "all_answers": [
            "\nUse a dict comprehension (Python 2.7 and later):\n{key: value for key, value in zip(keys, values)}\n\n\nAlternatively, use the dict constructor (for str keys only):\npairs = [('a', 1), ('b', 2)]\ndict(pairs)                          # → {'a': 1, 'b': 2}\ndict((k, v + 10) for k, v in pairs)  # → {'a': 11, 'b': 12}\n\nGiven separate lists of keys and values, use the dict constructor with zip:\nkeys = ['a', 'b']\nvalues = [1, 2]\ndict(zip(keys, values))              # → {'a': 1, 'b': 2}\n\n",
            "\nIn Python 3 and Python 2.7+, dictionary comprehensions look like the below:\nd = {k:v for k, v in iterable}\n\nFor Python 2.6 or earlier, see fortran's answer.\n",
            "\nIn fact, you don't even need to iterate over the iterable if it already comprehends some kind of mapping, the dict constructor doing it graciously for you:\n>>> ts = [(1, 2), (3, 4), (5, 6)]\n>>> dict(ts)\n{1: 2, 3: 4, 5: 6}\n>>> gen = ((i, i+1) for i in range(1, 6, 2))\n>>> gen\n<generator object <genexpr> at 0xb7201c5c>\n>>> dict(gen)\n{1: 2, 3: 4, 5: 6}\n\n",
            "\nIf you want a list of lists:\n>>> [list(t) for t in zip(*l)]\n[[1, 3, 8], [2, 4, 9]]\n\nIf a list of tuples is OK:\n>>> zip(*l)\n[(1, 3, 8), (2, 4, 9)]\n\n",
            "\nUse zip(*list):\n>>> l = [(1,2), (3,4), (8,9)]\n>>> list(zip(*l))\n[(1, 3, 8), (2, 4, 9)]\n\nThe zip() function pairs up the elements from all inputs, starting with the first values, then the second, etc. By using *l you apply all tuples in l as separate arguments to the zip() function, so zip() pairs up 1 with 3 with 8 first, then 2 with 4 and 9. Those happen to correspond nicely with the columns, or the transposition of l.\nzip() produces tuples; if you must have mutable list objects, just map() the tuples to lists or use a list comprehension to produce a list of lists:\nmap(list, zip(*l))          # keep it a generator\n[list(t) for t in zip(*l)]  # consume the zip generator into a list of lists\n\n"
        ],
        "answer": "A5",
        "tags": [
            "python",
            "list",
            "tuples",
            "list-comprehension"
        ]
    },
    {
        "question_id": "29210325",
        "question": "\nI am using web pack with sass loader like this:\nmodule.exports = {\n  module: {\n    loaders: [\n      {\n        test: /\\.scss$/,\n        loader: \"style!css!sass\"\n      }\n    ]\n  }\n};\n\nBut i see the styles apply to the style tag, where is the generate css file?\n",
        "all_answers": [
            "\nUpdate 2020 - CLI\nAs @mix3d pointed out you can just run a command where file.js is your file and someFunction is your function optionally followed by parameters separated with spaces\nnpx run-func file.js someFunction \"just some parameter\"\n\nThat's it.\nfile.js called in the example above\nconst someFunction = (param) => console.log('Welcome, your param is', param)\n\n// exporting is crucial\nmodule.exports = { someFunction }\n\nMore detailed description\nRun directly from CLI (global)\nInstall\nnpm i -g run-func\n\nUsage i.e. run function \"init\", it must be exported, see the bottom\nrun-func db.js init\n\nor\nRun from package.json script (local)\nInstall\nnpm i -S run-func\n\nSetup\n\"scripts\": {\n   \"init\": \"run-func db.js init\"\n}\n\nUsage\nnpm run init\n\nParams\nAny following arguments will be passed as function parameters init(param1, param2)\nrun-func db.js init param1 param2\n\nImportant\nthe function (in this example init) must be exported in the file containing it\nmodule.exports = { init };\n\nor ES6 export\nexport { init };\n\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nAs per the other answers, add the following to someFile.js\nmodule.exports.someFunction = function () {\n  console.log('hi');\n};\n\nYou can then add the following to package.json\n\"scripts\": {\n   \"myScript\": \"node -e 'require(\\\"./someFile\\\").someFunction()'\"\n}\n\nFrom the terminal, you can then call\nnpm run myScript\n\nI find this a much easier way to remember the commands and use them\n",
            "\nIf you want a separate CSS file when using Webpack, you need to use the extract-text-webpack-plugin.\n",
            "\nBy default, the style-loader inlines the compiled css into your bundle, which are added to the head of the page with the output file e.g. bundle.js. Using the extract-text-webpack-plugin you can remove the compiled css from the bundle, and export it to a separate file.\nFirst - wrap your loader in the plugin:\n loaders: [{\n  test: /\\.scss$/,\n  loader: ExtractTextPlugin.extract(\n    \"style\",\n    \"css!sass\")\n }]\n},\n\nThen tell the plugin what to call the file it generates:\nplugins: [\n    new ExtractTextPlugin(\"app.css\")\n ]\n\nInclude this file in your HTML normally. \n"
        ],
        "answer": "A5",
        "tags": [
            "javascript",
            "node.js",
            "sass",
            "webpack"
        ]
    },
    {
        "question_id": "985272",
        "question": "\nI would like to have users click a link, then it selects the HTML text in another element (not an input).\nBy \"select\" I mean the same way you would select text by dragging your mouse over it. This has been a bear to research because everyone talks about \"select\" or \"highlight\" in other terms.\nIs this possible? My code so far:\nHTML:\n<a href=\"javascript:\" onclick=\"SelectText('xhtml-code')\">Select Code</a>\n<code id=\"xhtml-code\">Some Code here </code>\n\nJS:\nfunction SelectText(element) {\n    $(\"#\" + element).select();\n}\n\nAm I missing something blatantly obvious?\n",
        "all_answers": [
            "\nAccording to the jQuery documentation of select(): \n\nTrigger the select event of each matched element. This causes all of the functions that have been bound to that select event to be executed, and calls the browser's default select action on the matching element(s).\n\nThere is your explanation why the jQuery select() won't work in this case.\n",
            "\nHave a look at the Selection object (Gecko engine) and the TextRange object (Trident engine.) I don't know about any JavaScript frameworks that have cross-browser support for this implemented, but I've never looked for it either, so it's possible that even jQuery has it.\n",
            "\nPlain Javascript\n\n\nfunction selectText(nodeId) {\n    const node = document.getElementById(nodeId);\n\n    if (document.body.createTextRange) {\n        const range = document.body.createTextRange();\n        range.moveToElementText(node);\n        range.select();\n    } else if (window.getSelection) {\n        const selection = window.getSelection();\n        const range = document.createRange();\n        range.selectNodeContents(node);\n        selection.removeAllRanges();\n        selection.addRange(range);\n    } else {\n        console.warn(\"Could not select text in node: Unsupported browser.\");\n    }\n}\n\nconst clickable = document.querySelector('.click-me');\nclickable.addEventListener('click', () => selectText('target'));\n<div id=\"target\"><p>Some text goes here!</p><p>Moar text!</p></div>\n<p class=\"click-me\">Click me!</p>\n\n\n\nHere is a working demo. For those of you looking for a jQuery plugin, I made one of those too.\n\njQuery (original answer)\nI have found a solution for this in this thread. I was able to modify the info given and mix it with a bit of jQuery to create a totally awesome function to select the text in any element, regardless of browser:\nfunction SelectText(element) {\n    var text = document.getElementById(element);\n    if ($.browser.msie) {\n        var range = document.body.createTextRange();\n        range.moveToElementText(text);\n        range.select();\n    } else if ($.browser.mozilla || $.browser.opera) {\n        var selection = window.getSelection();\n        var range = document.createRange();\n        range.selectNodeContents(text);\n        selection.removeAllRanges();\n        selection.addRange(range);\n    } else if ($.browser.safari) {\n        var selection = window.getSelection();\n        selection.setBaseAndExtent(text, 0, text, 1);\n    }\n}\n\n",
            "\nThis thread (dead link) contains really wonderful stuff. But I'm not able to do it right on this page using FF 3.5b99 + FireBug due to \"Security Error\".\nYipee!! I was able to select whole right hand sidebar with this code hope it helps you:\n    var r = document.createRange();\n    var w=document.getElementById(\"sidebar\");  \n    r.selectNodeContents(w);  \n    var sel=window.getSelection(); \n    sel.removeAllRanges(); \n    sel.addRange(r); \n\nPS:- I was not able to use objects returned by jquery selectors like\n   var w=$(\"div.welovestackoverflow\",$(\"div.sidebar\"));\n   \n   //this throws **security exception**\n\n   r.selectNodeContents(w);\n\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "jquery"
        ]
    },
    {
        "question_id": "1756825",
        "question": "\nI am interested in forcing a CPU cache flush in Windows (for benchmarking reasons, I want to emulate starting with no data in CPU cache), preferably a basic C implementation or Win32 call.\nIs there a known way to do this with a system call or even something as sneaky as doing say a large memcpy?\nIntel i686 platform (P4 and up is okay as well). \n",
        "all_answers": [
            "\nFortunately, there is more than one way to explicitly flush the caches.\nThe instruction \"wbinvd\" writes back modified cache content and marks the caches empty. It executes a bus cycle to make external caches flush their data. Unfortunately, it is a privileged instruction. But if it is possible to run the test program under something like DOS, this is the way to go. This has the advantage of keeping the cache footprint of the \"OS\" very small.\nAdditionally, there is the \"invd\" instruction, which invalidates caches without flushing them back to main memory. This violates the coherency of main memory and cache, so you have to take care of that by yourself. Not really recommended.\nFor benchmarking purposes, the simplest solution is probably copying a large memory block to a region marked with WC (write combining) instead of WB. The memory mapped region of the graphics card is a good candidate, or you can mark a region as WC by yourself via the MTRR registers.\nYou can find some resources about benchmarking short routines at Test programs for measuring clock cycles and performance monitoring.\n",
            "\nThere are x86 assembly instructions to force the CPU to flush certain cache lines (such as CLFLUSH), but they are pretty obscure. CLFLUSH in particular only flushes a chosen address from all levels of cache (L1, L2, L3).\n\nsomething as sneaky as doing say a large memcopy?\n\nYes, this is the simplest approach, and will make sure that the CPU flushes all levels of cache. Just exclude the cache flushing time from your benchmakrs and you should get a good idea how your program performs under cache pressure.\n",
            "\nThere is unfortunately no way to explicitly flush the cache. A few of your options are:\n1.) Thrash the cache by doing some very large memory operations between iterations of the code you're benchmarking.\n2.) Enable Cache Disable in the x86 Control Registers and benchmark that. This will probably disable the instruction cache also, which may not be what you want.\n3.) Implement the portion of your code your benchmarking (if it's possible) using Non-Temporal instructions. Though, these are just hints to the processor about using the cache, it's still free to do what it wants.\n1 is probably the easiest and sufficient for your purposes.\nEdit: Oops, I stand corrected there is an instruction to invalidate the x86 cache, see drhirsch's answer\n"
        ],
        "answer": "A1",
        "tags": [
            "c",
            "windows",
            "x86",
            "cpu",
            "cpu-cache"
        ]
    },
    {
        "question_id": "6590688",
        "question": "\nI'm thinking about putting the virtualenv for a Django web app I am making inside my git repository for the app. It seems like an easy way to keep deploy's simple and easy. Is there any reason why I shouldn't do this?\n",
        "all_answers": [
            "\nI use pip freeze to get the packages I need into a requirements.txt file and add that to my repository.  I tried to think of a way of why you would want to store the entire virtualenv, but I could not.\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nI think one of the main problems which occur is that the virtualenv might not be usable by other people. Reason is that it always uses absolute paths. So if you virtualenv was for example in /home/lyle/myenv/ it will assume the same for all other people using this repository (it must be exactly the same absolute path). You can't presume people using the same directory structure as you.\nBetter practice is that everybody is setting up their own environment (be it with or without virtualenv) and installing libraries there. That also makes you code more usable over different platforms (Linux/Windows/Mac), also because virtualenv is installed different in each of them.\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n",
            "\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['62.63.141.41', 'namjoosadr.com']\n\nand then restart your apache. in ubuntu:\n/etc/init.d/apache2 restart\n\n",
            "\nsettings.py\nALLOWED_HOSTS = ['*'] // if you are in dev or docker\n\nEdited\nOk guys, dont do this in production if you are not using docker, just put the IP addr.\nGrettings\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django",
            "virtualenv"
        ]
    },
    {
        "question_id": "21160774",
        "question": "\nI have created two GitHub accounts.  One for my work user and one for my personal self.  I needed to do catch up on some work and as such cloned my work repo onto my personal PC.  In order to do simple \"git push origin master\" commits without entering my username and password the whole time I simply want to add my public key from my home pc to the work repo.  However Github gives this error:\nError: Key already use\n\nAfter a bit of Googling I came across this link which states \"To resolve the issue, remove the key from the other account or repository and add it to your account\"  Of course there is a duplicate key as I've added my home public key to github so that I can code on my own personal projects. After all I want to be able to code to my work repo using both my work pc and personal pc.\nHow can you add multiple \"same\" public keys without Github throwing that error and also why in the world, is that error thrown in the first place?\n",
        "all_answers": [
            "\nYou can create one more key pair, say id_rsa_personal.pub, and add it to the Github account.\nNext, create/edit the .ssh/config file.\n# Default GitHub\nHost github.com\n  HostName github.com\n  User git\n  IdentityFile ~/.ssh/id_rsa\n\nHost github-public\n  HostName github.com\n  User git\n  IdentityFile ~/.ssh/id_rsa_public\n\nHost github-personal\n  HostName github.com\n  User git\n  IdentityFile ~/.ssh/id_rsa_personal\n\nThe above file will help you to use more than one Github account. For background info, refer to the answers to this question.\nNext, you will need to alter your .git/config remote url to point to:\ngithub-personal:<gh_username>/<gh_reponame>.git\nRather than the usual:\ngit@github.com:<gh_username>/<gh_reponame>.git\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nJohn commented that it didn't work for him.\nPerhaps the step you're missing is you need to alter your .git/config remote url to point to git@github-personal/<reponame>.git etc.. rather than the usual git@github.com/<reponame>.git\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nThe key could be already in use on other github projects as deploy key, that's a bit tricky to find but run:\nssh -T -ai ~/.ssh/KEY_NAME git@github.com\nchange KEY_NAME with the name of your SSH private key and you will be good to go\nfrom: https://help.github.com/articles/error-key-already-in-use/#finding-where-the-key-has-been-used\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n"
        ],
        "answer": "A8",
        "tags": [
            "git",
            "github",
            "ssh",
            "ssh-keys",
            "public-key"
        ]
    },
    {
        "question_id": "3246482",
        "question": "\nIs there any nice command line MySQL client for windows? I mean a single exe that allows connecting and running a sample query. I've googled and only could find big graphical environments like toad or mysql workbench. I need only a simple command line tool, where can  I download sth like this?\nEDIT: I don't want to install the whole MySQL package on my PC. I know it's inside the mysql package but how do I download only this cmd line client. Because i don't need anything else.\n",
        "all_answers": [
            "\nI have similar requirement where I need a MySQL client but not server (running in a virtual machine and don't want any additional overhead) and for me the easiest thing was to install MySQL community server taking typical installation options but NOT configure the server, so it never starts, never runs. Added C:\\Program Files (x86)\\MySQL\\MySQL Server 5.5\\bin to system path environment variable and I'm able to use the MySQL command line client mssql.exe and mysqladmin.exe programs. \n",
            "\nmysql.exe is included in mysql package. You don't have to install anything additionally.\n",
            "\nYou can access mySQL in command line just by typing:\nC:\\www\\mysql\\bin> mysql -u root -p\n\nAfter which you can type sql commands normally such as:\nmysql> SHOW DATABASES;\n\nHere, I am assuming you mySQL installation directory is C:\\www\\mysql.\n",
            "\nmysql.exe can do just that....\nTo connect,\nmysql -u root -p (press enter)\nIt should prompt you to enter root password (u = username, p = password)\nThen you can use SQL database commands to do pretty much anything....\n",
            "\nWhen you go to the MySQL download page, choose the platform \"Microsoft Windows\". Then download the \"Windows (x86, xx-bit), ZIP Archive\" (be sure to select the one with size over 140M.\nThe binaries will be in the \"bin\" folder.\nI understand that this is not just the client binaries, but at least you don't have to install and setup the entire server.\n"
        ],
        "answer": "A5",
        "tags": [
            "mysql",
            "windows"
        ]
    },
    {
        "question_id": "27983",
        "question": "\nI have a table of tags and want to get the highest count tags from the list.\nSample data looks like this\nid (1) tag ('night')\nid (2) tag ('awesome')\nid (3) tag ('night')\n\nusing\nSELECT COUNT(*), `Tag` from `images-tags`\nGROUP BY `Tag`\n\ngets me back the data I'm looking for perfectly. However, I would like to organize it, so that the highest tag counts are first, and limit it to only send me the first 20 or so.\nI tried this...\nSELECT COUNT(id), `Tag` from `images-tags`\nGROUP BY `Tag`\nORDER BY COUNT(id) DESC\nLIMIT 20\n\nand I keep getting an \"Invalid use of group function - ErrNr 1111\"\nWhat am I doing wrong?\nI'm using MySQL 4.1.25-Debian\n",
        "all_answers": [
            "\nIn all versions of MySQL, simply alias the aggregate in the SELECT list, and order by the alias:\nSELECT COUNT(id) AS theCount, `Tag` from `images-tags`\nGROUP BY `Tag`\nORDER BY theCount DESC\nLIMIT 20\n\n",
            "\nMySQL prior to version 5 did not allow aggregate functions in ORDER BY clauses.\nYou can get around this limit with the deprecated syntax:\nSELECT COUNT(id), `Tag` from `images-tags`\nGROUP BY `Tag`\nORDER BY 1 DESC\nLIMIT 20\n\n1, since it's the first column you want to group on.\n",
            "\nIn Oracle, something like this works nicely to separate your counting and ordering a little better.  I'm not sure if it will work in MySql 4.\nselect 'Tag', counts.cnt\nfrom\n  (\n  select count(*) as cnt, 'Tag'\n  from 'images-tags'\n  group by 'tag'\n  ) counts\norder by counts.cnt desc\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nI don't know about MySQL, but in MS SQL, you can use the column index in the order by clause.  I've done this before when doing counts with group bys as it tends to be easier to work with.\nSo\nSELECT COUNT(id), `Tag` from `images-tags`\nGROUP BY `Tag`\nORDER BY COUNT(id) DESC\nLIMIT 20\n\nBecomes\nSELECT COUNT(id), `Tag` from `images-tags`\nGROUP BY `Tag`\nORDER 1 DESC\nLIMIT 20\n\n"
        ],
        "answer": "A1",
        "tags": [
            "mysql",
            "sql",
            "mysql-error-1111"
        ]
    },
    {
        "question_id": "18180060",
        "question": "\nI want to zip a directory using the batch file command (Windows XP batch file).\nFor example, if I want to unzip a file means I can use the jar -xf file.zip(java) bat file command.\nLike that I want a command line batch to zip a directory.\n",
        "all_answers": [
            "\nYou can use the following command:\nzip -r nameoffile.zip directory\n\nHope this helps.\n",
            "\nIf you are using Ubuntu Linux:\n\nInstall zip\nsudo apt-get install zip\n\nZip your folder:\nzip -r {filename.zip} {foldername}\n\n\nIf you are using Microsoft Windows:\nWindows does not come with a command-line zip program, despite Windows Explorer natively supporting Zip files since the Plus! pack for Windows 98.\nI recommend the open-source 7-Zip utility which includes a command-line executable and supports many different archive file types, especially its own *.7z format which offers superior compression ratios to traditional (PKZIP) *.zip files:\n\nDownload 7-Zip from the 7-Zip home page\nAdd the path to 7z.exe to your PATH environment variable. See this QA: \nHow to set the path and environment variables in Windows\nOpen a new command-prompt window and use this command to create a PKZIP *.zip file:\n7z a -tzip {yourfile.zip} {yourfolder}\n\n\nCross-platform Java:\nIf you have the Java JDK installed then you can use the jar utility to create Zip files, as *.jar files are essentially just renamed *.zip (PKZIP) files:\njar -cfM {yourfile.zip} {yourfolder}\n\nExplanation:\n* -c compress\n* -f specify filename\n* -M do not include a MANIFEST file\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "batch-file",
            "command-line",
            "command-prompt"
        ]
    },
    {
        "question_id": "1187970",
        "question": "\nI would like to know how to I exit from Python without having an traceback dump on the output. \nI still want want to be able to return an error code but I do not want to display the traceback log.\nI want to be able to exit using exit(number) without trace but in case of an Exception (not an exit) I want the trace.\n",
        "all_answers": [
            "\nimport sys\nsys.exit(1)\n\n",
            "\nexit is a helper for the interactive shell - sys.exit is intended for use in programs.\n\nThe site module (which is imported automatically during startup, except if the -S command-line option is given) adds several constants to the built-in namespace (e.g. exit). They are useful for the interactive interpreter shell and should not be used in programs.\n\n\nTechnically, they do mostly the same: raising SystemExit. sys.exit does so in sysmodule.c:\nstatic PyObject *\nsys_exit(PyObject *self, PyObject *args)\n{\n    PyObject *exit_code = 0;\n    if (!PyArg_UnpackTuple(args, \"exit\", 0, 1, &exit_code))\n        return NULL;\n    /* Raise SystemExit so callers may catch it or clean up. */\n    PyErr_SetObject(PyExc_SystemExit, exit_code);\n   return NULL;\n}\n\nWhile exit is defined in site.py and _sitebuiltins.py, respectively.\nclass Quitter(object):\n    def __init__(self, name):\n        self.name = name\n    def __repr__(self):\n        return 'Use %s() or %s to exit' % (self.name, eof)\n    def __call__(self, code=None):\n        # Shells like IDLE catch the SystemExit, but listen when their\n        # stdin wrapper is closed.\n        try:\n            sys.stdin.close()\n        except:\n            pass\n        raise SystemExit(code)\n__builtin__.quit = Quitter('quit')\n__builtin__.exit = Quitter('exit')\n\n\nNote that there is a third exit option, namely os._exit, which exits without calling cleanup handlers, flushing stdio buffers, etc. (and which  should normally only be used in the child process after a fork()).\n",
            "\nIf I use exit() in a code and run it in the shell, it shows a message asking whether I want to kill the program or not. It's really disturbing.\nSee here\nBut sys.exit() is better in this case. It closes the program and doesn't create any dialogue box. \n",
            "\nYou are presumably encountering an exception and the program is exiting because of this (with a traceback).  The first thing to do therefore is to catch that exception, before exiting cleanly (maybe with a message, example given).\nTry something like this in your main routine:\nimport sys, traceback\n\ndef main():\n    try:\n        do main program stuff here\n        ....\n    except KeyboardInterrupt:\n        print \"Shutdown requested...exiting\"\n    except Exception:\n        traceback.print_exc(file=sys.stdout)\n    sys.exit(0)\n\nif __name__ == \"__main__\":\n    main()\n\n",
            "\nsomething like import sys; sys.exit(0) ?\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "exit",
            "traceback"
        ]
    },
    {
        "question_id": "3017",
        "question": "\nBy \"generate\", I mean auto-generation of the code necessary for a particular selected (set of) variable(s).\nBut any more explicit explication or comment on good practice is welcome.\n",
        "all_answers": [
            "\nThe error shown in visual studio for the project (Let's say A) does not have issues. When I looked at the output window for the build line by line for each project, I saw that it was complaining about another project (B) that had been referred as assembly in project A. Project B added into the solution. But it had not been referred in the project A  as project reference instead as assembly reference from different location. That location contains the assembly which compiled for Platform AnyCpu. Then I removed the assembly reference from the project A and added project B as a reference. It started compiling. \nNot sure though how this fix worked.\n",
            "\nIf you are using Visual Studio 2005 and up, you can create a setter/getter real fast using the insert snippet command.\nRight click on your code, click on Insert Snippet (Ctrl+K,X), and then choose \"prop\" from the list.\n",
            "\nRather than using Ctrl + K, X you can also just type prop and then hit Tab twice.\n",
            "\nI don't have Visual Studio installed on my machine anymore (and I'm using Linux), but I do remember that there was an wizard hidden somewhere inside one of the menus that gave access to a class builder.\nWith this wizard, you could define all your classes' details, including methods and attributes. If I remember well, there was an option through which you could ask Visual Studio to create the setters and getters automatically for you.\nI know it's quite vague, but check it out and you might find it.\n",
            "\nBy generate, do you mean auto-generate? If that's not what you mean:\nVisual Studio 2008 has the easiest implementation for this:\npublic PropertyType PropertyName { get; set; }\n\nIn the background this creates an implied instance variable to which your property is stored and retrieved.\nHowever if you want to put in more logic in your Properties, you will have to have an instance variable for it:\nprivate PropertyType _property;\n\npublic PropertyType PropertyName\n{\n    get\n    {\n        //logic here \n        return _property;\n    }\n    set\n    {\n        //logic here\n        _property = value;\n    }\n }\n\nPrevious versions of Visual Studio always used this longhand method as well.\n",
            "\nIf you are using WiX look at this (there is a bug)\nhttp://www.cnblogs.com/xixifusigao/archive/2012/03/20/2407651.html\nSometimes new build configurations get added to the .wixproj file further down the file, that is, separated from their sibling config definitions by other unrelated XML elements.\nSimply edit the .wixproj file so that all the <PropertyGroup> sections that define your build configs are adjacent to one another. (To edit the .wixproj in VS2013 right click on project in Solution Explorer, Unload project, right-click again->Edit YourProject.wixproj. Reload after editing the file.)\n",
            "\nI had exact same error after adding a new configuration via ConfigurationManager in Visual Studio.\nIt turned out when the 'Production' configuration was added for the whole solution (and each project) the OutputPath element was not added to the .csproj files.\nTo fix, I went to the Build tab in project properties, changed OutputPath from \\bin\\Production\\ to \\bin\\Production (deleted trailing \\) and saved changes. This forced creation of the OutputPath element in the .csproj file and the project has built successfully.\nSounds like a glitch to me.\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "visual-studio",
            "setter",
            "getter"
        ]
    },
    {
        "question_id": "11014013",
        "question": "\nI can't seem to find any information about how to copy a directory using NSIS ?, i know there is a file command but is there any command to copy a directory . \n",
        "all_answers": [
            "\nYou can use the Rscript front end to run code as if it were in a running R session. Say the package you want to install is foo.zip in the current working directory. I'm probably abusing Rscript here, but it works for me:\nRscript -e \"install.packages('foo.zip', repos = NULL)\"\n\nYou need to supply the path to the binary package if it is not in the directory where there script is running. repos = NULL is the trick to get install.packages() to work from a local file. Read ?install.packages for more info on other arguments you might want to specify, especially lib. Note that you don't benefit from automatic dependency resolution when doing this - you need a repo for that and if you supply one, R will try to download packages.\nYou are right about R CMD INSTALL; the R Installation and Administration manual has the following in Section 6.3:\n\nTo install packages from source in a Unix-alike use\n    R CMD INSTALL -l /path/to/library pkg1 pkg2 ...\n\n\n",
            "\nThe File instruction extracts files from your installer and CopyFiles copies files and/or directories that already exist on the end-users system (You can use $EXEDIR if you need to copy files off a dvd where your installer is also located...)\n",
            "\nAn alternative for newbies like me that is hassle free would be:\n install.packages(file.choose(), repos=NULL)\n\nThe file.choose() command will show a window allowing you to choose the .zip file or the tar.gz file where you downloaded it. \nThis command is very useful when you don't have enough rights on a Windows machine and run R from a flash drive like myself. \nIt is also useful before running this command to RENAME the zip file you are going to install into the package name that you intend to use.\n",
            "\nThe syntax is same for both directory and file, except that you need to specify a directory by providing a \\ at the end. File command copies the directory if the specified argument is a directory. For eg, you can do:\nSetOutPath \"outputPath\"\nFile \"myDirectory\\\" #note back slash at the end\n\nBut that copies only the top level directory. To recursively do it, you have /r switch\nSetOutPath \"outputPath\"\nFile /nonfatal /a /r \"myDirectory\\\" #note back slash at the end\n\nwhich copies the contents of myDirectory (but not myDirectory folder itself). /nonfatal ignores without an error if there is no particular directory. /a copies file attributes as well. /x switch is used to exclude files.\nOtherwise,\nSetOutPath \"outputPath\\myDirectory\"\nFile /nonfatal /a /r \"myDirectory\\\" #note back slash at the end\n\ncopies all the contents of myDirectory including myDirectory folder to outputPath.\n",
            "\nI found how to do it , sorry for the trouble . \nExtract the files to a directory which can't exist beforehand\nCreateDirectory $Installdir\\extracting\n\nSetOutPath $Installdir\\extracting\n\nFile Directory\\*\n\n",
            "\nAn addition to @moldovean's answer:\nI used to save the zipped file(copy from temp to a R download folder for future reference).\nWhen I updated R from 2.15.1 to 3.0.1, I run these commands for easy installation:\nsetwd(\"C:/Downloads/R Packages\");\npackages<-dir();\ninstall.packages(x, repos=NULL) #where x is the name of package\n\nAnd R installed all packages automatically from zipped files. Now I can update all of them with one command only(google it)\n"
        ],
        "answer": "A4",
        "tags": [
            "windows",
            "installation",
            "nsis"
        ]
    },
    {
        "question_id": "623051",
        "question": "\nSimilar to this question: Checkboxes on Rails\nWhat's the correct way of making radio buttons that are related to a certain question in Ruby on Rails? At the moment I have:\n<div class=\"form_row\">\n    <label for=\"theme\">Theme:</label>\n    <br><%= radio_button_tag 'theme', 'plain', true %> Plain\n    <br><%= radio_button_tag 'theme', 'desert' %> Desert\n    <br><%= radio_button_tag 'theme', 'green' %> Green\n    <br><%= radio_button_tag 'theme', 'corporate' %> Corporate\n    <br><%= radio_button_tag 'theme', 'funky' %> Funky\n</div>\n\nI also want to be able to automatically check the previously selected items (if this form was re-loaded). How would I load the params into the default value of these?\n",
        "all_answers": [
            "\nHmm, from the docs I don't see how you can set the ID on the radio buttons... the label's for attribute tries to link to the ID on the radio.\nrails docs for radio_button_tag\nThat said, from the doc, that first param is the \"name\"... which if that is what it is creating, should group them alltogether.  If not, maybe its a bug?\nHmm, wonder if these have been fixed:\nhttp://dev.rubyonrails.org/ticket/2879\nhttp://dev.rubyonrails.org/ticket/3353\n",
            "\nAs in this previous post, with a slight twist:\n<div class=\"form_row\">\n    <label for=\"theme\">Theme:</label>\n    <% [ 'plain', 'desert', 'green', 'corporate', 'funky' ].each do |theme| %>\n      <br><%= radio_button_tag 'theme', theme, @theme == theme %>\n      <%= theme.humanize %>\n    <% end %>\n</div>\n\nWhere\n@theme = params[:theme]\n\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "webforms",
            "radio-button"
        ]
    },
    {
        "question_id": "25824908",
        "question": "\nI have been developing an app for 1 or 2 weeks now and just yesterday I have updated my iPhone 5S to the iOS 8 GM. Everything worked fine and I could test on my device as well until I deleted the app from my phone and wanted to build again. The following error appeared:\nCould not launch \"My App\"\nprocess launch failed: Security\n\n\nWhen I test with the simulator it works fine.\nIs this because of the iOS 8 GM update and how can I fix this launch problem?\nI want to be able to test on my iPhone and in the simulator.\n",
        "all_answers": [
            "\nIf you get this, the app has installed on your device. You have to tap the icon. It will ask you if you really want to run it. Say “yes” and then Build & Run again.\nAs from iOS 9, it is required to go to Settings → General → Device Management → Developer App → Trust`.\nOn some versions of iOS, you will have to go to Settings → General → Profile instead.\n",
            "\nI have the same issue. I click ok in xcode and when launching the app on my iPhone I'm asked if I want to trust this application. Doing it, the app runs and further build-and-run from xcode went without any issue until deleting the app from the iPhone and reinstalling it. Then goto first line ;-)\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "xcode",
            "process",
            "build"
        ]
    },
    {
        "question_id": "23948527",
        "question": "\nI am working with configuring Django project with Nginx and Gunicorn.\nWhile I am accessing my port gunicorn mysite.wsgi:application --bind=127.0.0.1:8001 in Nginx server, I am getting the following error in my error log file;\n\n2014/05/30 11:59:42 [crit] 4075#0: *6 connect() to 127.0.0.1:8001 failed (13: Permission denied) while connecting to upstream, client: 127.0.0.1, server: localhost, request: \"GET / HTTP/1.1\", upstream: \"http://127.0.0.1:8001/\", host: \"localhost:8080\"\n\nBelow is the content of my nginx.conf file;\nserver {\n    listen 8080;\n    server_name localhost;\n    access_log  /var/log/nginx/example.log;\n    error_log /var/log/nginx/example.error.log;\n\n    location / {\n        proxy_pass http://127.0.0.1:8001;\n        proxy_set_header X-Forwarded-For $remote_addr;\n        proxy_set_header Host $http_host;\n    }\n}\n\nIn the HTML page I am getting 502 Bad Gateway.\nWhat mistake am I doing?\n",
        "all_answers": [
            "\nsettings.py\nALLOWED_HOSTS = ['*'] // if you are in dev or docker\n\nEdited\nOk guys, dont do this in production if you are not using docker, just put the IP addr.\nGrettings\n",
            "\nDisclaimer\nMake sure there are no security implications for your use-case before running this.\nAnswer\nI had a similar issue getting Fedora 20, Nginx, Node.js, and Ghost (blog) to work. It turns out my issue was due to SELinux.\nThis should solve the problem:\nsetsebool -P httpd_can_network_connect 1\n\nDetails\nI checked for errors in the SELinux logs:\nsudo cat /var/log/audit/audit.log | grep nginx | grep denied\n\nAnd found that running the following commands fixed my issue:\nsudo cat /var/log/audit/audit.log | grep nginx | grep denied | audit2allow -M mynginx\nsudo semodule -i mynginx.pp\n\nOption #2 (probably more secure)\nsetsebool -P httpd_can_network_relay 1\n\nhttps://security.stackexchange.com/questions/152358/difference-between-selinux-booleans-httpd-can-network-relay-and-httpd-can-net\nReferences\nhttp://blog.frag-gustav.de/2013/07/21/nginx-selinux-me-mad/\nhttps://wiki.gentoo.org/wiki/SELinux/Tutorials/Where_to_find_SELinux_permission_denial_details\nhttp://wiki.gentoo.org/wiki/SELinux/Tutorials/Managing_network_port_labels\n",
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n",
            "\nI have solved my problem by running my Nginx as the user I'm currently logged in with, mulagala.\nBy default the user as nginx is defined at the very top section of the nginx.conf file as seen below;\nuser nginx; # Default Nginx user\n\nChange nginx to the name of your current user - here, mulagala.\nuser mulagala; # Custom Nginx user (as username of the current logged in user)\n\nHowever, this may not address the actual problem and may actually have casual side effect(s).\nFor an effective solution, please refer to Joseph Barbere's solution.\n"
        ],
        "answer": "A2",
        "tags": [
            "django",
            "python-2.7",
            "nginx",
            "gunicorn"
        ]
    },
    {
        "question_id": "5544774",
        "question": "\nI'm writing an application with python and sqlalchemy-0.7. It starts by initializing the sqlalchemy orm (using declarative) and then it starts a multithreaded web server - I'm currently using web.py for rapid prototyping but that could change in the future. I will also add other \"threads\" for scheduled jobs and so on, probably using other python threads.\nFrom SA documentation I understand I have to use scoped_session() to get a thread-local session, so my web.py app should end up looking something like:\nimport web\nfrom myapp.model import Session  # scoped_session(sessionmaker(bind=engine))\nfrom myapp.model import This, That, AndSoOn\nurls = blah...\napp  = web.application(urls, globals())\n\nclass index:\n    def GET(self):\n        s = Session()\n        # get stuff done\n        Session().remove()\n        return(stuff)\n\nclass foo:\n    def GET(self):\n        s = Session()\n        # get stuff done\n        Session().remove()\n        return(stuff)\n\nIs that the Right Way to handle the session?\nAs far as I understand, I should get a scoped_session at every method since it'll give me a thread local session that I could not obtain beforehand (like at the module level).\nAlso, I should call .remove() or .commit() or something like them at every method end, otherwise the session will still contain Persistent objects and I would not be able to query/access the same objects in other threads?\nIf that pattern is the correct one, it could probably be made better by writing it only once, maybe using a decorator? Such a decorator could get the session, invoke the method and then make sure to dispose the session properly. How would that pass the session to the decorated function?\n",
        "all_answers": [
            "\nYes, this is the right way.\nExample:\nThe Flask microframework with Flask-sqlalchemy extension does what you described. It also does .remove() automatically at the end of each HTTP request (\"view\" functions), so the session is released by the current thread. Calling just .commit() is not sufficient, you should use .remove().\nWhen not using Flask views, I usually use a \"with\" statement:\n@contextmanager\ndef get_db_session():\n    try:\n        yield session\n    finally:\n        session.remove()\n\nwith get_db_session() as session:\n    # do something with session\n\nYou can create a similar decorator.\nScoped session creates a DBMS connection pool, so this approach will be faster than opening/closing session at each HTTP request. It also works nice with greenlets (gevent or eventlet).\n",
            "\nYou don't need to create a scoped session if you create new session for each request and each request is handled by single thread.\nYou have to call s.commit() to make pending objects persistent, i.e. to save changes into database.\nYou may also want to close session by calling s.close().\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "multithreading",
            "session",
            "sqlalchemy"
        ]
    },
    {
        "question_id": "6623231",
        "question": "\n$(\"#topNav\" + $(\"#breadCrumb2nd\").text().replace(\" \", \"\")).addClass(\"current\");\n\nThis is a snippet from my code. I want to add a class to an ID after getting another ID's text property. The problem with this, is the ID holding the text I need, contains gaps between the letters. \nI would like the white spaces removed. I have tried TRIM()and REPLACE() but this only partially works. The REPLACE() only removes the 1st space.\n",
        "all_answers": [
            "\nYou have to tell replace() to repeat the regex:\n.replace(/ /g,'')\n\nThe g character makes it a \"global\" match, meaning it repeats the search through the entire string.  Read about this, and other RegEx modifiers available in JavaScript here.\nIf you want to match all whitespace, and not just the literal space character, use \\s instead:\n.replace(/\\s/g,'')\n\nYou can also use .replaceAll if you're using a sufficiently recent version of JavaScript, but there's not really any reason to for your specific use case, since catching all whitespace requires a regex, and when using a regex with .replaceAll, it must be global, so you just end up with extra typing:\n.replaceAll(/\\s/g,'')\n\n",
            "\n.replace(/\\s+/, \"\") \n\nWill replace the first whitespace only, this includes spaces, tabs and new lines.\nTo replace all whitespace in the string you need to use global mode\n.replace(/\\s/g, \"\")\n\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "jquery"
        ]
    },
    {
        "question_id": "38561",
        "question": "\nThe printf function takes an argument type, such as %d or %i for a signed int. However, I don't see anything for a long value.\n",
        "all_answers": [
            "\n%ld see printf reference on cplusplus.com\n",
            "\n\na) Can you explain to me the difference between int64_t and long (long int)? In my understanding, both are 64 bit integers. Is there any reason to choose one over the other?\n\nThe former is a signed integer type with exactly 64 bits. The latter is a signed integer type with at least 32 bits.\n\nb) I tried to look up the definition of int64_t on the web, without much success. Is there an authoritative source I need to consult for such questions?\n\nhttp://cppreference.com covers this here: http://en.cppreference.com/w/cpp/types/integer. The authoritative source, however, is the C++ standard (this particular bit can be found in §18.4 Integer types [cstdint]).\n\nc) For code using int64_t to compile, I am including <iostream>, which doesn't make much sense to me. Are there other includes that provide a declaration of int64_t?\n\nIt is declared in <cstdint> or <cinttypes> (under namespace std), or in <stdint.h> or <inttypes.h> (in the global namespace).\n",
            "\nPut an l (lowercased letter L) directly before the specifier.  \nunsigned long n;\nlong m;\n\nprintf(\"%lu %ld\", n, m);\n\n",
            "\nint64_t is typedef you can find that in <stdint.h> in C\n",
            "\nint64_t is guaranteed by the C99 standard to be exactly 64 bits wide on platforms that implement it, there's no such guarantee for a long which is at least 32 bits so it could be more.\n\n§7.18.1.3 Exact-width integer types 1 The typedef name intN_t\n  designates a signed integer type with width N , no padding  bits, and\n  a two’s complement representation. Thus, int8_t denotes a signed\n  integer   type with a width of exactly 8 bits.\n\n"
        ],
        "answer": "A3",
        "tags": [
            "c",
            "printf",
            "long-integer"
        ]
    },
    {
        "question_id": "600743",
        "question": "\nHow do I get a div to automatically adjust to the size of the background I set for it without setting a specific height (or min-height) for it?\n",
        "all_answers": [
            "\nThere is no way to auto adjust for background image size using CSS.\nYou can hack around it by measuring the background image on the server and then applying those attributes to the div, as others have mentioned.\nYou could also hack up some javascript to resize the div based on the image size (once the image has been downloaded) - this is basically the same thing.\nIf you need your div to auto-fit the image, I might ask why don't you just put an <img> tag inside your div?\n",
            "\nYou can do it server side: by measuring the image and then setting the div size, OR loading the image with JS, read it's attributes and then set the DIV size.\nAnd here is an idea, put the same image inside the div as an IMG tag, but give it visibility: hidden + play with position relative+ give this div the image as background.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nMaybe this can help, it's not exactly a background, but you get the idea:\n<style>\ndiv {\n    float: left;\n    position: relative;\n}\ndiv img {\n    position: relative;\n}\n\ndiv div {\n    position: absolute;\n    top:0;\n    left:0;\n}\n</style>\n\n<div>\n    <img src=\"http://antwrp.gsfc.nasa.gov/apod/image/0903/omegacen_davis.jpg\" />\n    <div>Hi there</div>\n</div>\n\n",
            "\nAnother, perhaps inefficient, solution would be to include the image under an img element set to visibility: hidden;.  Then make the background-image of the surrounding div the same as the image.\nThis will set the surrounding div to the size of the image in the img element but display it as a background. \n<div style=\"background-image: url(http://your-image.jpg);\">\n <img src=\"http://your-image.jpg\" style=\"visibility: hidden;\" />\n</div>\n\n"
        ],
        "answer": "A6",
        "tags": [
            "css",
            "html",
            "background",
            "height"
        ]
    },
    {
        "question_id": "25113672",
        "question": "\nI have a string \nlet stringPlusString = TextBoxCal.text\n\nI want to get the last character of stringPlusString. I do not want to use array.\nJava has charAt but I could not find something similar in Swift \n",
        "all_answers": [
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\n    let text = \"Muhammad Raza\"\n    println(\"\\(text[advance(text.endIndex, -1)])\")\n\nin Short !\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\n\"Without using Array on swift\"\nHere you go:\nvar text = \"Lorem ipsum\"\nvar lastChar = text.substringFromIndex(text.endIndex.predecessor())\n\n",
            "\nHere is another shorter way to get the last letter from string: \nlet text = \"some string\"\nlast(text) // returns {Some \"a\"}\n\nThe method last() returns an optional Character. \n",
            "\nUsing last to get the last Character\nFor Swift 4:\nlet str = \"hello world😍\"\nlet lastChar = str.last!   // lastChar is \"😍\"\n\nFor Swift 2 and Swift 3:\nlet str = \"hello world😍\"\nlet lastChar = str.characters.last!   // lastChar is \"😍\"\n\nFor Swift 1.2:\nlet str = \"hello world😍\"\nlet lastChar = last(str)!   // lastChar is \"😍\"\n\n\nSubscripting the String to get the last Character\nThis works for Swift 3 and Swift 4:\nlet str = \"hello world😍\"\nlet lastChar = str[str.index(before: str.endIndex)]   // lastChar is \"😍\"\n\nAnd for Swift 1.2 and Swift 2:\nlet str = \"hello world😍\"\nlet lastChar = str[str.endIndex.predecessor()]   // lastChar is \"😍\"\n\n"
        ],
        "answer": "A6",
        "tags": [
            "swift",
            "string"
        ]
    },
    {
        "question_id": "5931586",
        "question": "\nHow would I perform the following using raw SQL in views.py?\nfrom app.models import Picture\n\ndef results(request):\n    all = Picture.objects.all()\n    yes = Picture.objects.filter(vote='yes').count()\n    return render_to_response(\n        'results.html', \n        {'picture':picture, 'all':all, 'yes': yes}, \n        context_instance=RequestContext(request)\n    )\n\nWhat would this results function look like?\n",
        "all_answers": [
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nThe Django Documentation is really really good. You have basically two options to execute raw SQL. You can use Manager.raw() to perform raw queries which return model instances, or you can avoid the model layer and execute custom SQL directly.\nUsing the raw() manager:\n>>> for p in Person.objects.raw('SELECT * FROM myapp_person'):\n...     print p\nJohn Smith\nJane Jones\n\nIf you want to bypass the model layer directly you can use django.db.connection which represents the default database connection:\ndef my_custom_sql():\n    from django.db import connection, transaction\n    cursor = connection.cursor()\n\n    # Data modifying operation - commit required\n    cursor.execute(\"UPDATE bar SET foo = 1 WHERE baz = %s\", [self.baz])\n    transaction.commit_unless_managed()\n\n    # Data retrieval operation - no commit required\n    cursor.execute(\"SELECT foo FROM bar WHERE baz = %s\", [self.baz])\n    row = cursor.fetchone()\n\n    return row\n\n",
            "\n>>> from django.db import connection\n>>> cursor = connection.cursor()\n>>> cursor.execute('''SELECT count(*) FROM people_person''')\n1L\n>>> row = cursor.fetchone()\n>>> print row\n(12L,)\n>>> Person.objects.all().count()\n12\n\nuse WHERE clause to filter vote for yes:\n>>> cursor.execute('''SELECT count(*) FROM people_person WHERE vote = \"yes\"''')\n1L\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "sql",
            "django",
            "django-models",
            "django-views"
        ]
    },
    {
        "question_id": "1347779",
        "question": "\nHow can I navigate through all my text fields with the \"Next\" Button on the iPhone Keyboard?\nThe last text field should close the Keyboard.\nI've setup the IB the Buttons (Next / Done) but now I'm stuck.\nI implemented the textFieldShouldReturn action but now the Next and Done Buttons close the Keyboard.\n",
        "all_answers": [
            "\nAfter you exit from one text field, you call [otherTextField becomeFirstResponder] and the next field gets focus.\nThis can actually be a tricky problem to deal with since often you'll also want to scroll the screen or otherwise adjust the position of the text field so it's easy to see when editing.  Just make sure to do a lot of testing with coming into and out of the text fields in different ways and also leaving early (always give the user an option to dismiss the keyboard instead of going to the next field, usually with \"Done\" in the nav bar) \n",
            "\nin textFieldShouldReturn you should check that the textfield you are currently on is not the last one when they click next and if its n ot dont dismiss the keyboard..\n",
            "\nIn Cocoa for Mac OS X, you have the next responder chain, where you can ask the text field what control should have focus next. This is what makes tabbing between text fields work. But since iOS devices do not have a keyboard, only touch, this concept has not survived the transition to Cocoa Touch.\nThis can be easily done anyway, with two assumptions:\n\nAll \"tabbable\" UITextFields are on the same parent view.\nTheir \"tab-order\" is defined by the tag property.\n\nAssuming this you can override textFieldShouldReturn: as this:\n-(BOOL)textFieldShouldReturn:(UITextField*)textField\n{\n  NSInteger nextTag = textField.tag + 1;\n  // Try to find next responder\n  UIResponder* nextResponder = [textField.superview viewWithTag:nextTag];\n  if (nextResponder) {\n    // Found next responder, so set it.\n    [nextResponder becomeFirstResponder];\n  } else {\n    // Not found, so remove keyboard.\n    [textField resignFirstResponder];\n  }\n  return NO; // We do not want UITextField to insert line-breaks.\n}\n\nAdd some more code, and the assumptions can be ignored as well.\nSwift 4.0\n func textFieldShouldReturn(_ textField: UITextField) -> Bool {\n    let nextTag = textField.tag + 1\n    // Try to find next responder\n    let nextResponder = textField.superview?.viewWithTag(nextTag) as UIResponder!\n\n    if nextResponder != nil {\n        // Found next responder, so set it\n        nextResponder?.becomeFirstResponder()\n    } else {\n        // Not found, so remove keyboard\n        textField.resignFirstResponder()\n    }\n\n    return false\n}\n\nIf the superview of the text field will be a UITableViewCell then next responder will be\nlet nextResponder = textField.superview?.superview?.superview?.viewWithTag(nextTag) as UIResponder!\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "objective-c",
            "iphone"
        ]
    },
    {
        "question_id": "7974849",
        "question": "\n\n\n\nHow can I make one python file to run another?  \nFor example I have two .py files.  I want one file to be run, and then have it run the other .py file.\n",
        "all_answers": [
            "\nThere are more than a few ways. I'll list them in order of inverted preference (i.e., best first, worst last):\n\nTreat it like a module: import file. This is good because it's secure, fast, and maintainable. Code gets reused as it's supposed to be done. Most Python libraries run using multiple methods stretched over lots of files. Highly recommended. Note that if your file is called file.py, your import should not include the .py extension at the end.\nThe infamous (and unsafe) exec command: Insecure, hacky, usually the wrong answer. Avoid where possible.\n\n\nexecfile('file.py') in Python 2\nexec(open('file.py').read()) in Python 3\n\nSpawn a shell process: os.system('python file.py'). Use when desperate.\n\n",
            "\nYou'd treat one of the files as a python module and make the other one import it (just as you import standard python modules). The latter can then refer to objects (including classes and functions) defined in the imported module. The module can also run whatever initialization code it needs. See http://docs.python.org/tutorial/modules.html\n"
        ],
        "answer": "A1",
        "tags": [
            "python"
        ]
    },
    {
        "question_id": "31107040",
        "question": "\nI have been seeing the aria attribute all over while working with Angular Material. Can someone explain to me, what the aria prefix means? but most importantly what I'm trying to understand is the difference between aria-hidden and hidden attribute.\n",
        "all_answers": [
            "\nARIA (Accessible Rich Internet Applications) defines a way to make Web content and Web applications more accessible to people with disabilities.\nThe hidden attribute is new in HTML5 and tells browsers not to display the element. The aria-hidden property tells screen-readers if they should ignore the element. Have a look at the w3 docs for more details:\nhttps://www.w3.org/WAI/PF/aria/states_and_properties#aria-hidden\nUsing these standards can make it easier for disabled people to use the web.\n",
            "\nA hidden attribute is a boolean attribute (True/False). When this attribute is used on an element, it removes all relevance to that element. When a user views the html page, elements with the hidden attribute should not be visible.\nExample:\n    <p hidden>You can't see this</p>\n\nAria-hidden attributes indicate that the element and ALL of its descendants are still visible in the browser, but will be invisible to accessibility tools, such as screen readers.\nExample:\n    <p aria-hidden=\"true\">You can't see this</p>\n\nTake a look at this. It should answer all your questions.\nNote: ARIA stands for Accessible Rich Internet Applications\nSources: Paciello Group\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n"
        ],
        "answer": "A1",
        "tags": [
            "html",
            "wai-aria"
        ]
    },
    {
        "question_id": "65960211",
        "question": "\nI am trying to generate a Docker Image without using Visual Studio.  I am in the project folder and I execute from windows 10 admin command line  docker build .  I can't figure out how to make this work.\n[+] Building 1.3s (8/9)\n => [internal] load build definition from Dockerfile                                              0.0s\n => => transferring dockerfile: 753B                                                              0.0s\n => [internal] load .dockerignore                                                                 0.0s\n => => transferring context: 34B                                                                  0.0s\n => [internal] load metadata for mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim             0.0s\n => [base 1/2] FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim                          0.0s\n => ERROR FROM docker.io/publish/app:latest                                                       1.2s\n => => resolve docker.io/publish/app:latest                                                       1.2s\n => CACHED [base 2/2] WORKDIR /app                                                                0.0s\n => CACHED [final 1/2] WORKDIR /app                                                               0.0s\n => [auth] publish/app:pull token for registry-1.docker.io                                        0.0s\n------\n > FROM docker.io/publish/app:latest:\n------\nfailed to load cache key: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed\n\nThis is my dockerfile:\n#See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging.\nFROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n\nFROM mcr.microsoft.com/dotnet/core/sdk:3.1-buster AS build\nWORKDIR /src\nCOPY [\"src/App.Web/App.Web.csproj\", \"src/App.Web/\"]\nRUN dotnet restore \"App.Web.csproj\"\nCOPY . .\nWORKDIR \"/src/App.Web\"\nRUN dotnet build App.Web.csproj -c Debug -o /app\n\nFROM build as debug\nRUN dotnet publish \"App.Web.csproj\" -c Debug -o /app\n\nFROM base as final\nWORKDIR /app\nCOPY --from=publish/app /app .\nENTRYPOINT [\"dotnet\",\"App.Web.dll\"]\n\n",
        "all_answers": [
            "\nYou have stages called base, build, and debug. Then in the final stage you have:\nCOPY --from=publish/app /app .\n\nWhen docker can't find the stage with that name, publish/app, it tries to find that image, which doesn't exist. I'm guessing you want to copy from the build stage, e.g.\nCOPY --from=build /app .\n\n",
            "\nAre you logged in? Try with docker login and then execute docker build once again\nAs I can see here aspnet in docker hub the repository that you intent to use has been renamed. Use the following instead\nfrom mcr.microsoft.com/dotnet/aspnet:3.1-buster-slim\n\nRepositories have been renamed and a similar issue can be found here similar issue\n"
        ],
        "answer": "A1",
        "tags": [
            "windows",
            "docker",
            "dockerfile",
            "linux-containers"
        ]
    },
    {
        "question_id": "18991908",
        "question": "\nI know that the GitHub web interface lets you search all repositories for files with a particular pathname (e.g. searching for path:/app/models/user.rb yields > 109k results), but is there a way to search all repositories for filenames independent of their subdirectory location?  I tried using asterisks in the path argument, and that didn't seem to work.\n",
        "all_answers": [
            "\nDoes the search user.rb in:path do what you want to do? \nAlternatively there is also this search filename:user.rb\nFound on: https://help.github.com/articles/searching-code/\n",
            "\nGitHub introduced FileFinder in 2011.\n\nTry it out: just hit t on any repo's file or directory view.[1]\n\nSo, You're still restricted to repository.\n[1]https://github.com/blog/793-introducing-the-file-finder\nAnother approach to Your question:\nCan I use Git to search for matching filenames in a repository?\n",
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nI refined @andy-lester answer with intitle:, i.e. I want to find where's located the file simple_spinner_item.xml in Android's source code hosted on github, so I search on Google this string:\nsite:github.com intitle:simple_spinner_item.xml github.com/android\n\n^                       ^                       ^\n|                       |                       |\non github site          |                       |\n                        |                       |\nfilename I'm searching -+                       |\n                                                |\ngithub user ------------------------------------+\n\n",
            "\nYou can try Google.  Google for filename.txt site:github.com.\n"
        ],
        "answer": "A1",
        "tags": [
            "github",
            "search-engine"
        ]
    },
    {
        "question_id": "800368",
        "question": "\nIs it possible to declare a variable in c++ without instantiating it? I want to do something like this:\nAnimal a;\nif( happyDay() ) \n    a( \"puppies\" ); //constructor call\nelse\n    a( \"toads\" );\n\nBasially, I just want to declare a outside of the conditional so it gets the right scope.\nIs there any way to do this without using pointers and allocating a on the heap? Maybe something clever with references?\n",
        "all_answers": [
            "\nYou can't declare a variable without calling a constructor. However, in your example you could do the following:\nAnimal a(happyDay() ? \"puppies\" : \"toads\");\n\n",
            "\n{ and } will create a scope and if you define some variables in the scope you cannot access them from outside. But for already create that scope. So\n{for(int i = 0; i < count; ++i){}} \n\nis the same as\nfor(int i = 0; i < count; ++i){}\n\nbut if you define something between them, there is a difference\n{int a = 0; for(int i = 0; i < count; ++i){}}\n\nIn this example, a won't be accessible from outside scope.\n",
            "\nIt's a block scope marked by {} braces. It is usually used to mark the area of automatic storage. In your case it doesn't seem to do anything as the for loop has its own scope in standard C++.\n",
            "\nYou can't do this directly in C++ since the object is constructed when you define it with the default constructor.\nYou could, however, run a parameterized constructor to begin with:\nAnimal a(getAppropriateString());\n\nOr you could actually use something like the ?: operator to determine the correct string.\n(Update: @Greg gave the syntax for this. See that answer)\n",
            "\nOnce upon a time, many moons ago, VS6 existed and was popular.  It failed however to conform to a number of C++ standards; which was reasonable at the time as it was released just before (on the same year) the standard was officially released; it did however adhere to the draft of the standard as far as I'm aware.\nOne of the standards that changed between the draft and the official standard, was the lifetime of for loop variables created in the first section; leading to the following code failing to compile\n{\n    for (int i=0; i<1; ++i){}\n    for (int i=0; i<2; ++i){}\n}\n\nbecause i was redefined by the second for loop.\nWhile other compilers also suffered this bug; I highlight the VS6 one because it remained the only version of visual studio for a number of years after the release of the standard, but never released an update for this particular issue; meaning that it had a more significant impact.\nA solution to this is to force the whole for loop into its own scope as you have shown.\n",
            "\nIn your particular example there is no reason for them.\nSometimes you could want to create a scope for a variable:\nfloat average;\n// ...\n\n{\nint sum = 0;\nfor (int i = 0; i < count; ++i)\n{\n   sum += v[i];\n}\naverage = (float)sum / count;\n}\n\n// use average\n// sum not in scope here\n\nHowever I see this an anti-pattern. Usually if you find yourself in need of doing this then most likely the for should be its own function.\n"
        ],
        "answer": "A4",
        "tags": [
            "c++",
            "scope",
            "declaration",
            "instantiation"
        ]
    },
    {
        "question_id": "25826383",
        "question": "\nThere are two overloads for dequeueReusableCellWithIdentifier and I'm trying to determine when should I use one vs the other?\nThe apple docs regarding the forIndexPath function states, \"This method uses the index path to perform additional configuration based on the cell’s position in the table view.\" \nI'm not sure how to interpret that though?\n",
        "all_answers": [
            "\nI have never understood why Apple created the newer method, dequeueReusableCellWithIdentifier:forIndexPath:. Their documentation on them is not complete, and is somewhat misleading. The only difference I've been able to discern between the two methods, is that that older method can return nil, if it doesn't find a cell with the identifier passed in, while the newer method crashes, if it can't return a cell. Both methods are guaranteed to return a cell, if you have set the identifier correctly, and make the cell in a storyboard. Both methods are also guaranteed to return a cell if you register a class or xib, and make your cell in code or a xib file.\n",
            "\nThe most important difference is that the forIndexPath: version asserts (crashes) if you didn't register a class or nib for the identifier.  The older (non-forIndexPath:) version returns nil in that case.\nYou register a class for an identifier by sending registerClass:forCellReuseIdentifier: to the table view.  You register a nib for an identifier by sending registerNib:forCellReuseIdentifier: to the table view.\nIf you create your table view and your cell prototypes in a storyboard, the storyboard loader takes care of registering the cell prototypes that you defined in the storyboard.\nSession 200 - What's New in Cocoa Touch from WWDC 2012 discusses the (then-new) forIndexPath: version starting around 8m30s.  It says that “you will always get an initialized cell” (without mentioning that it will crash if you didn't register a class or nib).\nThe video also says that “it will be the right size for that index path”.  Presumably this means that it will set the cell's size before returning it, by looking at the table view's own width and calling your delegate's tableView:heightForRowAtIndexPath: method (if defined).  This is why it needs the index path.\n",
            "\ndequeueReusableCellWithIdentifier:forIndexPath: will always return a cell. It either re uses existing cells or creates a new one and returns if there are no cells.\nWhile, the traditional dequeueReusableCellWithIdentifier: will return a cell if it exists i.e if there is a cell which can be reused it returns that else it returns nil. So you would have to write a condition to check for nil value as well.\nTo answer your question use dequeueReusableCellWithIdentifier: when you want to support iOS 5 and lower versions since dequeueReusableCellWithIdentifier:forIndexPath is only available on iOS 6+\nReference : https://developer.apple.com/library/ios/documentation/uikit/reference/UITableView_Class/Reference/Reference.html#//apple_ref/occ/instm/UITableView/dequeueReusableCellWithIdentifier:forIndexPath:\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "objective-c",
            "swift"
        ]
    },
    {
        "question_id": "5631789",
        "question": "\nI have kernel driver. When installing on 32 bit systems and Windows XP and below, I had no problem and used SetupCopyOEMInf, but 64 bit drivers are required to be signed. I have signed it and I need to have a cat file with the driver copied somewhere on the computer, and this method of install doesn't work. How should I install it?\nEDIT: Clarified the question.\n",
        "all_answers": [
            "\nOn 64-bit JVM's you need the 64-bit SWT. Current versions can be downloaded here:\nhttp://archive.eclipse.org/eclipse/downloads/drops/R-3.6.1-201009090800/index.php#SWT\nNote the first two downloads, the first is for x32, the other for x64.\nNote: Even on 64bit Windows, if you use the 32bit JVM, you still need the 32bit SWT version!\n",
            "\nYou need to get an Authenticode signature, create a catalog file, and sign it with that. Microsoft decided that, for 64-bit systems, it will require the driver to come untampered from the vendor, by checking it signature.\n(Note: This is not the same as WHQL, which tests the quality of the driver. Authenticode merely indicates that the driver hasn't been tampered with by some malicious user or virus; it doesn't say anything about what the driver does, so it's a relatively easy -- although pricey -- signature to obtain.)\nAnother solution is test-signing, if you don't plan on redistributing your program.\nhttps://technet.microsoft.com/library/dd919230.aspx\n",
            "\nIn Windows Vista and Windows 7 there a new utility for handling drivers setup call PnPUtil. It handles exactly this kind of work. Just copy all your driver relevant files(*.inf, *.cat, *.sys) to a directory on the target computer and use PnPUtil -i -a <InfName>.inf\nNote: You will need to be in an administrator context to successfully use this tool.\n",
            "\nFor the latest link to SWT library downloads:\nSWT project page\n",
            "\nMy answer is more less compilation of above posted answers, especially the comment of the user @ClickUpvote who provided (by my opinion) the best answer. So here it is, I tested it just before posting it:\nIf your  application throws the exception below (On Windows 7 64 bit, with JVM 64)\nException in thread \"main\" java.lang.UnsatisfiedLinkError: Cannot load 32-bit SW T libraries on 64-bit JVM.\nThen the solution is as follows:\nOn 64-bit JVM's you need the 64-bit SWT. \nCurrent versions can be downloaded as described below - pretty well hidden:\n\nGo to: http://www.eclipse.org/swt/\nScroll down to Releases\nClick on more at: \n\n\nStable\nWindows, Linux, OS X, more...\n\n\nIn new page that opens just download this file (at the time of writing this post URL is \n( http://download.eclipse.org/eclipse/downloads/drops4/R-4.4-201406061215/#SWT )\n\nWindows (x86_64) (Supported Versions) (http)  6.3 MB swt-4.4-win32-win32-x86_64.zip\nAnd that is exactly the version  you need.\n",
            "\nI faced the same problems a couple of weeks ago.  We develop an RCP application that must use 32bit SWT, but we work on 64bit machines.\nWhat we had to do was to change Eclipse's configurations so it pointed to a 32bit JVM.  We did it on Window -> Preferences -> Java -> Installed JRE's.  On this preference page, we changed all references from \"Program Files\" to \"Program Files (x86)\".\nI hope it helps you somehow.\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "64-bit",
            "device-driver",
            "signed"
        ]
    },
    {
        "question_id": "26358422",
        "question": "\nHow do you get the class name of a UIViewController class in Swift?\nIn Objective-C, we can do something like this:\nself.appDelegate = (shAppDelegate *)[[UIApplication sharedApplication] delegate];\n    UIViewController *last_screen = self.appDelegate.popScreens.lastObject ;\n    \n    if(last_screen.class != self.navigationController.visibleViewController.class){\n\n    //.......\n}\n\nbut in Swift I tried:\nlet appDelegate = UIApplication.sharedApplication().delegate as AppDelegate\n    let last_screen = appDelegate.popScreens?.lastObject as UIViewController\n\nCan't do this.\nif last_screen.class != self.navigationController.visibleViewController.class {\n\n//....\n\n}\n\nno class method of UIViewController i.e last screen\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nTo know your class name you can call something like this:\nvar className = NSStringFromClass(yourClass.classForCoder)\n\n",
            "\nThe property is called dynamicType in Swift.\n",
            "\nYou actually don't need to use a web and app URL anymore. The web URL will automatically open in the app if the user has it. Instagram or other apps implement this on their end as a Universal Link\nSwift 4\nfunc openInstagram(instagramHandle: String) {\n    guard let url = URL(string: \"https://instagram.com/\\(instagramHandle)\")  else { return }\n    if UIApplication.shared.canOpenURL(url) {\n        if #available(iOS 10.0, *) {\n            UIApplication.shared.open(url, options: [:], completionHandler: nil)\n        } else {\n            UIApplication.shared.openURL(url)\n        }\n    }\n}\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "objective-c",
            "uiviewcontroller",
            "swift"
        ]
    },
    {
        "question_id": "26059111",
        "question": "\nIn order to stage python project within our corporation I need to make an installable distribution. \nThis should include:\n\nAn egg or whl for my project\nAn egg or whl for every dependency of the project\n(optionally) produce a requirements.txt file listing all the installable components for this release\n\nIs there an easy plug in, (e.g. an alternative to bdist_wheel) that will not only compile one wheel but also that project's components?\nObviously I can script this, but I was hoping that there might be a short-cut that builds the package + dependencies in fewer steps.\nThis needs to work on Python 2.7 on Windows + Linux.\n",
        "all_answers": [
            "\nYou will need to create a setup.py file for your package. Make sure you have the latest setuptools and pip installed. Then run the following:\npython setup.py bdist_wheel\n\nThis will create a wheel file for your package. This assumes you don't have C/C++ headers, DLLs, etc. If you do, then you'll probably have a lot more work to do.\nTo get dependencies, you will want to create a requirements.txt file and run the following:\npip wheel .\n\nIf your package isn't on PyPI, then you'll have to manually copy your package's wheel file into the wheel folder that this command creates. For more information see the following excellent article:\n\nhttp://lucumr.pocoo.org/2014/1/27/python-on-wheels/\n\n",
            "\nWith the latest pip and wheel, you can simply run\npip wheel .\n\nwithin your project folder, even if your application isn't on PyPi. All wheels will be stored in the current directory (.).  \nTo change the output directory (to for example, ./wheels), you may use the -w / --wheel-dir option:\npip wheel . -w wheels\n\nAll the options available are listed at the pip documentation.\n",
            "\nWith poetry you can define your dependencies and metadata about your project in a file in the root of your project, called pyproject.toml:\n[tool.poetry]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"some longer description\"\nauthors = [\"Some Author <[email protected]>\"]\n\n[tool.poetry.dependencies]\npython = \"*\"\n\n[tool.poetry.dev-dependencies]\npytest = \"^3.4\"\n\nTo build your project as a wheel, execute poetry build\n$ poetry build\n\nBuilding my-project (0.1.0)\n- Building sdist\n- Built my-project-0.1.0.tar.gz\n\n- Building wheel\n- Built my-project-0.1.0-py3-none-any.whl\n\na dist/ folder is created with a wheel for your project.\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "windows",
            "egg",
            "python-wheel"
        ]
    },
    {
        "question_id": "496277",
        "question": "\nI've got msysGit (Git on Windows) working just fine on my home machine, but at work, where we are behind a Microsoft ISA proxy, I get the following error when I do a git clone:\nH:\\>git clone git://github.com/akitaonrails/vimfiles.git\nInitialized empty Git repository in H:/vimfiles/.git/\ngithub.com[0: 65.74.177.129]: errno=Invalid argument\nfatal: unable to connect a socket (Invalid argument)\n\nI've tried setting the http_proxy environment variable to:\nhttp://our-proxy-server:8088\n\nI've set the git http.proxy configuration directive:\ngit config --global http.proxy http://our-proxy-server:8088\n\nNeither of the above makes a difference.\nDoing a git clone with http:// instead of git:// yields this:\nH:\\>git clone http://github.com/akitaonrails/vimfiles.git\nInitialized empty Git repository in H:/vimfiles/.git/\nfatal: http://github.com/akitaonrails/vimfiles.git/info/refs download error - The    requested URL returned error: 407\n\n407 is of course an authentication error.\nSo my question is: has anyone managed to get git working from behind a proxy, specifically an ISA proxy? I don't know if it's going to be worth pursing this. Any help very much appreciated.\nThanks!\n",
        "all_answers": [
            "\nHere's one for Mac: GitX\nScreenshot:\n\n",
            "\nTry Git Extensions.\nScreenshot:\n\n",
            "\nSource Tree (for MAC)\nScreenshot:\n\n",
            "\nI had the exact same error; but the ~/.gitconfig global config file was the key.\nIf you have a proxy with authentication you need to put in it:\ngit config --global http.proxy http://login:password@our-proxy-server:8088\n\nAnd it just works (with 'git clone http:')\nExample of a blog detailing the same setup: GIT clone over HTTP: who knew?\n\nIf it still fails in 407, it could be related to a problem with git-fetch losing authentication tokens on the second HTTP GET. A more recent version of libcurl might be needed.\n\nUpdate January 2011: jbustamovej mentions in his answer (upvoted) his blog post \"GitHub Behind Corporate Proxy\", which adds this:\n\nIt’s important to note that if your login has a backslash, as in domain\\login, you must escape the backslash, as in:\n\ngit config --global http.proxy http://domain\\\\\\login:password@our-proxy-server:8088\n\n",
            "\nWindows has TortoiseGit. It is not as mature as TortoiseSVN, but I've been using it and it works well enough for my purposes.\nScreenshot:\n\nEDIT [Dec 2014]: I'd also recommend looking at Dan's answer. Github's UI is probably the most mature/supported tool out there now (even if you don't use Github!)\n",
            "\nI'm surprised nobody has mentioned Tower for Mac OSX.\nHere is a screenshot:\n\n",
            "\nDo you have SOCKS proxy? If you have, you caould try FreeCap to socksify your git connection. I've been using git this way for a while.\nIf not, still try FreeCap. IIRC it might be able to use http proxies, but I haven't tried that.\nEDIT:\nI usualy socksify cmd.exe using FreeCap, and from then on (almost) all cmdline programs that I start from that session are socksified too. That's why I recommended Free Cap, since SocksCap (another alternative) doesn't work that way.\nAs for using http.proxy, it for some reason never worked for me with mingw version and my company http proxies.\n"
        ],
        "answer": "A4",
        "tags": [
            "windows",
            "git",
            "proxy",
            "msysgit"
        ]
    },
    {
        "question_id": "64736953",
        "question": "\nI just updated my iPhone to iOS 14.2.\nWhen I want to launch an app on the device from Xcode, I now keep seeing this:\n\nI also just updated Xcode to Version 12.1, hoping it would solve the problem, but it doesn't make any difference, I keep getting the same message.\nI tried disconnecting and reconnecting the device, but to no avail.\nI also removed all the data under ~/Library/Developer/Xcode/DerivedData/, but again with no effect.\nIt seems like some other people have had this issue before, but I didn't find any working solution for me.\nI hope someone with a recent similar experience can point me in the right direction for a proper way to solve this problem.\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nUpdate: Xcode 12.2, with support for iOS 14.2, is now available on the AppStore. If you find this problem with a newer version of iOS and Xcode, the answer is still the same, you can (probably) download the beta for the next Xcode version from the Apple Developer website, you can wait for the AppStore version to be updated, or you can (probably) find the symbols for the new iOS version and copy them to your current Xcode installation.\nOriginal answer. Applies to Xcode 12.1 and iOS 14.2\nThe latest version of Xcode in the AppStore doesn’t include support for 14.2. You can download a beta of the next version from the Apple Developer website that supports 14.2, or wait for the AppStore version to be updated.\n",
            "\n\nGo to my Github repo iOS 14.2 Device Support File and download 14.2.zip file directly and after unzip it\n\nAnd just copy and paste unzipped folder by path:\nApplications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/DeviceSupport/\n\n\nRestart the Xcode\n\n\nThat's all. You can build and go on your project.\nIf you need a visual solution, check out this answer: https://stackoverflow.com/a/64854525\n\nWhy we have done these steps?: Because Xcode 12.1 doesn’t include support for 14.2 so we implemented its device support files for 14.2.\nhttps://developer.apple.com/documentation/xcode-release-notes/xcode-12_1-release-notes\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "objective-c",
            "swift",
            "xcode",
            "swiftui"
        ]
    },
    {
        "question_id": "14368218",
        "question": "\na rails console output looks like this:\nUser.all\n=> [#<User id: 1, name: \"Michael Hartl\", email: \"[email protected]\",\ncreated_at: \"2011-12-05 00:57:46\", updated_at: \"2011-12-05 00:57:46\">,\n#<User id: 2, name: \"A Nother\", email: \"[email protected]\", created_at:\n\"2011-12-05 01:05:24\", updated_at: \"2011-12-05 01:05:24\">]\n\nI was wondering if there is command that can make it easier to read?  for example there was a .pretty command in MongoDB console that was formatting the output a little more eye friendly. But not sure if there is something similar in Rails or not.\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nYou could try the awesome_print gem :\nhttps://github.com/michaeldv/awesome_print\nOnce installed, you can pretty print any object using :\nap User.all\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nAlso you could use this incredible gem: \nAwesome Print\n"
        ],
        "answer": "A4",
        "tags": [
            "ruby-on-rails",
            "rails-activerecord"
        ]
    },
    {
        "question_id": "146",
        "question": "\nI have a website that plays mp3s in a flash player. If a user clicks 'play' the flash player automatically downloads an mp3 and starts playing it. \nIs there an easy way to track how many times a particular song clip (or any binary file) has been downloaded?\n\n\nIs the play link a link to the actual\n  mp3 file or to some javascript code\n  that pops up a player?\nIf the latter, you can easily add your\n  own logging code in there to track the\n  number of hits to it.\nIf the former, you'll need something\n  that can track the web server log\n  itself and make that distinction. My\n  hosting plan comes with Webalizer,\n  which does this nicely.\n\nIt's a javascript code so that answers that. \nHowever, it would be nice to know how to track downloads using the other method (without switching hosts).\n",
        "all_answers": [
            "\nIs the play link a link to the actual mp3 file or to some javascript code that pops up a player? \nIf the latter, you can easily add your own logging code in there to track the number of hits to it.\nIf the former, you'll need something that can track the web server log itself and make that distinction. My hosting plan comes with webalizer, which does this nicely.\n",
            "\nThe funny thing is I wrote a php media gallery for all my musics 2 days ago. I had a similar problem.  I'm using http://musicplayer.sourceforge.net/ for the player. And the playlist is built via php. All music requests go to a script called xfer.php?file=WHATEVER\n$filename = base64_url_decode($_REQUEST['file']);\nheader(\"Cache-Control: public\");\nheader('Content-disposition: attachment; filename='.basename($filename));\nheader(\"Content-Transfer-Encoding: binary\");\nheader('Content-Length: '. filesize($filename));\n\n//  Put either file counting code here, either a db or static files\n//\nreadfile($filename);  //and spit the user the file\n\nfunction base64_url_decode($input) {\n    return base64_decode(strtr($input, '-_,', '+/='));\n}\n\nAnd when you call files use something like:\nfunction base64_url_encode($input) {\n     return strtr(base64_encode($input), '+/=', '-_,');\n}\n\nhttp://us.php.net/manual/en/function.base64-encode.php\nIf you are using some JavaScript or a flash player (JW player for example) that requires the actual link of an mp3 file or whatever, you can append the text \"&type=.mp3\" so the final link becomes something like:\n\"www.example.com/xfer.php?file=34842ffjfjxfh&type=.mp3\". That way it looks like it ends with an mp3 extension without affecting the file link.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "apache",
            "logging",
            "download",
            "analytics"
        ]
    },
    {
        "question_id": "463677",
        "question": "\nWhen doing an ALTER TABLE statement in MySQL, the whole table is read-locked (allowing concurrent reads, but prohibiting concurrent writes) for the duration of the statement. If it's a big table, INSERT or UPDATE statements could be blocked for a looooong time. Is there a way to do a \"hot alter\", like adding a column in such a way that the table is still updatable throughout the process?\nMostly I'm interested in a solution for MySQL but I'd be interested in other RDBMS if MySQL can't do it.\nTo clarify, my purpose is simply to avoid downtime when a new feature that requires an extra table column is pushed to production. Any database schema will change over time, that's just a fact of life. I don't see why we should accept that these changes must inevitably result in downtime; that's just weak.\n",
        "all_answers": [
            "\nNope. If you are using MyISAM tables, to my best understanding they only do table locks - there are no record locks, they just try to keep everything hyperfast through simplicity. (Other MySQL tables operate differently.) In any case, you can copy the table to another table, alter it, and then switch them, updating for differences.\nThis is such a massive alteration that I doubt any DBMS would support it. It's considered a benefit to be able to do it with data in the table in the first place.\n",
            "\nThe only other option is to do manually what many RDBMS systems do anyway...\n- Create a new table  \nYou can then copy the contents of the old table over a chunk at a time.  Whilst always being cautious of any INSERT/UPDATE/DELETE on the source table.  (Could be managed by a trigger.  Although this would cause a slow down, it's not a lock...)\nOnce finished, change the name of the source table, then change the name of the new table.  Preferably in a transaction.\nOnce finished, recompile any stored procedures, etc that use that table.  The execution plans will likely no longer be valid.\nEDIT:\nSome comments have been made about this limitation being a bit poor.  So I thought I'd put a new perspective on it to show why it's how it is...\n\nAdding a new field is like changing one field on every row.  \nField Locks would be much harder than Row locks, never mind table locks.\n\nYou're actually changing the physical structure on the disk, every record moves.  \nThis really is like an UPDATE on the Whole table, but with more impact...  \n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "mysql",
            "ddl",
            "alter-table"
        ]
    },
    {
        "question_id": "18308535",
        "question": "\nIf someone deleted a remote branch because the work is over and I don't know, I won't do a git fetch --prune and eventually I will push back the deleted branch.\nIs there a viable solution for forcing Git to use the prune mode when fetching / pulling without having to specify it every time?\n",
        "all_answers": [
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nSince git 1.8.5 (Q4 2013):\n\n\"git fetch\" (hence \"git pull\" as well) learned to check \"fetch.prune\" and \"remote.*.prune\" configuration variables and to behave as if the \"--prune\" command line option was given.\n\nThat means that, if you set remote.origin.prune to true:\ngit config remote.origin.prune true\n\nAny git fetch or git pull will automatically prune.\nNote: Git 2.12 (Q1 2017) will fix a bug related to this configuration, which would make git remote rename misbehave.\nSee \"How do I rename a git remote?\".\n\nSee more at commit 737c5a9:\n\nWithout \"git fetch --prune\", remote-tracking branches for a branch the other side already has removed will stay forever.\n  Some people want to always run \"git fetch --prune\".\nTo accommodate users who want to either prune always or when fetching from a particular remote, add two new configuration variables \"fetch.prune\" and \"remote.<name>.prune\":\n\n\"fetch.prune\" allows to enable prune for all fetch operations.\n\"remote.<name>.prune\" allows to change the behaviour per remote.\n\nThe latter will naturally override the former, and the --[no-]prune option from the command line will override the configured default.\nSince --prune is a potentially destructive operation (Git doesn't keep reflogs for deleted references yet), we don't want to prune without users consent, so this configuration will not be on by default. \n\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIf you want to always prune when you fetch, I can suggest to use Aliases.\nJust type git config -e to open your editor and change the configuration for a specific project and add a section like\n[alias]\npfetch = fetch --prune   \n\nthe when you fetch with git pfetch the prune will be done automatically.      \n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n"
        ],
        "answer": "A3",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "8890524",
        "question": "\n\n\n\nI want to send an array as an Ajax request:\ninfo[0] = 'hi';\ninfo[1] = 'hello';\n\n$.ajax({\n  type: \"POST\",\n  url: \"index.php\",\n  success: function(msg){\n    $('.answer').html(msg);\n  }\n});\n\nHow can I do this?\n",
        "all_answers": [
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n",
            "\nvar array = new Array(); // or the shortcut: = []\narray.push ( {\"cool\":\"34.33\",\"also cool\":\"45454\"} );\narray.push (  {\"cool\":\"34.39\",\"also cool\":\"45459\"} );\n\nYour variable is a javascript object {} not an array [].\nYou could do:\nvar o = {}; // or the longer form: = new Object()\no.SomeNewProperty = \"something\";\no[\"SomeNewProperty\"] = \"something\";\n\nand\nvar o = { SomeNewProperty: \"something\" };\nvar o2 = { \"SomeNewProperty\": \"something\" };\n\nLater, you add those objects to your array: array.push (o, o2);\nAlso JSON is simply a string representation of a javascript object, thus:\nvar json = '{\"cool\":\"34.33\",\"alsocool\":\"45454\"}'; // is JSON\nvar o = JSON.parse(json); // is a javascript object\njson = JSON.stringify(o); // is JSON again\n\n",
            "\ninfo = [];\ninfo[0] = 'hi';\ninfo[1] = 'hello';\n\n\n$.ajax({\n   type: \"POST\",\n   data: {info:info},\n   url: \"index.php\",\n   success: function(msg){\n     $('.answer').html(msg);\n   }\n});\n\n",
            "\nJust use the JSON.stringify method and pass it through as the \"data\" parameter for the $.ajax function, like follows:\n$.ajax({\n    type: \"POST\",\n    url: \"index.php\",\n    dataType: \"json\",\n    data: JSON.stringify({ paramName: info }),\n    success: function(msg){\n        $('.answer').html(msg);\n    }\n});\n\nYou just need to make sure you include the JSON2.js file in your page...\n",
            "\nThat is an object, not an array. So you would do:\nvar json = { cool: 34.33, alsocool: 45454 };\njson.supercool = 3.14159;\nconsole.dir(json);\n\n",
            "\nobject[\"property\"] = value;\n\nor\nobject.property = value;\n\nObject and Array in JavaScript are different in terms of usage.  Its best if you understand them:  \nObject vs Array: JavaScript\n"
        ],
        "answer": "A3",
        "tags": [
            "jquery",
            "ajax",
            "arrays",
            "json"
        ]
    },
    {
        "question_id": "4186392",
        "question": "\nSay we usually it access via\nhttp://localhost/index.php?a=1&b=2&c=3\n\nHow do we execute the same on a Linux command prompt?\nphp -e index.php\n\nBut what about passing the $_GET variables? Maybe something like php -e index.php --a 1 --b 2 --c 3? I doubt that'll work.\n",
        "all_answers": [
            "\nTypically, for passing arguments to a command line script, you will use either the argv global variable or getopt:\n// Bash command:\n//   php -e myscript.php hello\necho $argv[1]; // Prints \"hello\"\n\n// Bash command:\n//   php -e myscript.php -f=world\n$opts = getopt('f:');\necho $opts['f']; // Prints \"world\"\n\n$_GET refers to the HTTP GET method parameters, which are unavailable on the command line, since they require a web server to populate.\nIf you really want to populate $_GET anyway, you can do this:\n// Bash command:\n//   export QUERY_STRING=\"var=value&arg=value\" ; php -e myscript.php\nparse_str($_SERVER['QUERY_STRING'], $_GET);\nprint_r($_GET);\n/* Outputs:\n     Array(\n        [var] => value\n        [arg] => value\n     )\n*/\n\nYou can also execute a given script, populate $_GET from the command line, without having to modify said script:\nexport QUERY_STRING=\"var=value&arg=value\" ; \\\nphp -e -r 'parse_str($_SERVER[\"QUERY_STRING\"], $_GET); include \"index.php\";'\n\nNote that you can do the same with $_POST and $_COOKIE as well.\n",
            "\nTry using WGET:\nWGET 'http://localhost/index.php?a=1&b=2&c=3'\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "linux"
        ]
    },
    {
        "question_id": "693788",
        "question": "\n\n\n\nWhat is better: void foo() or void foo(void)?\nWith void it looks ugly and inconsistent, but I've been told that it is good. Is this true?\nEdit: I know some old compilers do weird things, but if I'm using just GCC, is void foo() Ok? Will foo(bar); then be accepted?\n",
        "all_answers": [
            "\nFunctional programming is not about lambdas, it is all about pure functions.  So the following broadly promote functional style:\n\nOnly use function arguments, do not use global state.\nMinimise side effects i.e. printf, or any IO.  Return data describing IO which can be executed instead of causing the side effects directly in all functions.  \n\nThis can be achieved in plain c, no need for magic.\n",
            "\nvoid foo(void) is better because it explicitly says: no parameters allowed.\nvoid foo() means you could (under some compilers) send parameters, at least if this is the declaration of your function rather than its definition. \n",
            "\nvoid foo(void);\n\nThat is the correct way to say \"no parameters\" in C, and it also works in C++.\nBut:\nvoid foo();\n\nMeans different things in C and C++! In C it means \"could take any number of parameters of unknown types\", and in C++ it means the same as foo(void).\nVariable argument list functions are inherently un-typesafe and should be avoided where possible.\n",
            "\nHartel & Muller's book, Functional C, can nowadays (2012-01-02) be found at: http://eprints.eemcs.utwente.nl/1077/ (there is a link to PDF version).\n",
            "\nFFCALL lets you build closures in C -- callback = alloc_callback(&function, data) returns a function pointer such that callback(arg1, ...) is equivalent to calling function(data, arg1, ...).  You will have to handle garbage collection manually, though.\nRelatedly, blocks have been added to Apple's fork of GCC; they're not function pointers, but they let you pass around lambdas while avoiding the need to build and free storage for captured variables by hand (effectively, some copying and reference counting happens, hidden behind some syntactic sugar and runtime libraries).\n",
            "\nYou can use GCC's nested functions to simulate lambda expressions, in fact, I have a macro to do it for me:\n#define lambda(return_type, function_body) \\\n  ({ \\\n    return_type anon_func_name_ function_body \\\n    anon_func_name_; \\\n  })\n\nUse like this:\nint (*max)(int, int) = lambda (int, (int x, int y) { return x > y ? x : y; });\n\n"
        ],
        "answer": "A3",
        "tags": [
            "c",
            "void"
        ]
    },
    {
        "question_id": "6261910",
        "question": "\nI am reading Java Concurrency in Practice and kind of confused with the thread confinement concept. The book says that\n\nWhen an object is confined to a thread, such usage is automatically thread-safe even if the confined object itself is not\n\nSo when an object is confined to a thread, no other thread can have access to it? Is that what it means to be confined to a thread? How does one keep an object confined to a thread?\nEdit:\nBut what if I still want to share the object with another thread? Let's say that after thread A finishes with object O, thread B wants to access O. In this case, can O still be confined to B after A is done with it?\nUsing a local variable is one example for sure but that just means you don't share your object with other thread (AT ALL). In case of JDBC Connection pool, doesn't it pass one connection from one thread to another once a thread is done with that connection (totally clueless about this because I never used JDBC).\n",
        "all_answers": [
            "\n\nSo when an object is confined to a thread, no other thread can have access to it?\n\nNo, it's the other way around: if you ensure that no other thread has access to an object, then that object is said to be confined to a single thread.\nThere's no language- or JVM-level mechanism that confines an object to a single thread. You simply have to ensure that no reference to the object escapes to a place that could be accessed by another thread. There are tools that help avoid leaking references, such as the ThreadLocal class, but nothing that ensures that no reference is leaked anywhere.\nFor example: if the only reference to an object is from a local variable, then the object is definitely confined to a single thread, as other threads can never access local variables.\nSimilarly, if the only reference to an object is from another object that has already been proven to be confined to a single thread, then that first object is confined to the same thread.\nAd Edit: In practice you can have an object that's only accessed by a single thread at a time during its lifetime, but for which that single thread changes (a JDBC Connection object from a connection pool is a good example).\nProving that such an object is only ever accessed by a single thread is much harder than proving it for an object that's confined to a single thread during its entire life, however.\nAnd in my opinion those objects are never really \"confined to a single thread\" (which would imply a strong guarantee), but could be said to \"be used by a single thread at a time only\".\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nSee: http://codeidol.com/java/java-concurrency/Sharing-Objects/Thread-Confinement/\n\nA more formal means of maintaining\n  thread confinement is ThreadLocal,\n  which allows you to associate a\n  per-thread value with a value-holding\n  object. Thread-Local provides get and\n  set accessormethods that maintain a\n  separate copy of the value for each\n  thread that uses it, so a get returns\n  the most recent value passed to set\n  from the currently executing thread.\n\nIt holds a copy of object per one thread, thread A can't access copy of thread B and broke it's invariants if you will do it specially (for example, assign ThreadLocal value to static variable or expose it using other methods)\n"
        ],
        "answer": "A1",
        "tags": [
            "java",
            "multithreading",
            "concurrency",
            "thread-safety",
            "thread-confinement"
        ]
    },
    {
        "question_id": "3783525",
        "question": "\nBackground: I have a performance-critical query I'd like to run and I don't care about dirty reads.\nMy question is; If I'm using joins, do I have to specify the NOLOCK hint on those as well?\nFor instance; is:\nSELECT * FROM table1 a WITH (NOLOCK)\nINNER JOIN table2 b WITH (NOLOCK) ON a.ID = b.ID\n\nEquivalent to:\nSELECT * FROM table1 a WITH (NOLOCK)\nINNER JOIN table2 b ON a.ID = b.ID\n\nOr will I need to specify the (NOLOCK) hint on the join to ensure I'm not locking the joined table?\n",
        "all_answers": [
            "\nI was pretty sure that you need to specify the NOLOCK for each JOIN in the query. But my experience was limited to SQL Server 2005.\nWhen I looked up MSDN just to confirm, I couldn't find anything definite. The below statements do seem to make me think, that for 2008, your two statements above are equivalent though for 2005 it is not the case:\n\n[SQL Server 2008 R2]\nAll lock hints are propagated to all the tables and views that are accessed by the query plan, including tables and views referenced in a view. Also, SQL Server performs the corresponding lock consistency checks.\n[SQL Server 2005]\nIn SQL Server 2005, all lock hints are propagated to all the tables and views that are referenced in a view. Also, SQL Server performs the corresponding lock consistency checks.\n\nAdditionally, point to note - and this applies to both 2005 and 2008:\n\nThe table hints are ignored if the table is not accessed by the query plan. This may be caused by the optimizer choosing not to access the table at all, or because an indexed view is accessed instead. In the latter case, accessing an indexed view can be prevented by using the OPTION (EXPAND VIEWS) query hint.\n\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nI won't address the READ UNCOMMITTED argument, just your original question.\nYes, you need WITH(NOLOCK) on each table of the join.  No, your queries are not the same.\nTry this exercise.  Begin a transaction and insert a row into table1 and table2.  Don't commit or rollback the transaction yet.  At this point your first query will return successfully and include the uncommitted rows;  your second query won't return because table2 doesn't have the WITH(NOLOCK) hint on it.\n",
            "\nNeither. You set the isolation level to READ UNCOMMITTED which is always better than giving individual lock hints. Or, better still, if you care about details like consistency, use snapshot isolation.\n"
        ],
        "answer": "A3",
        "tags": [
            "sql",
            "sql-server",
            "nolock"
        ]
    },
    {
        "question_id": "1593051",
        "question": "\n\n\n\nIn a Unix or GNU scripting environment (e.g. a Linux distro, Cygwin, OSX), what is the best way to determine which Git branch is currently checked out in a working directory?\nOne use of this technique would be automatically labeling a release (like svnversion would do with Subversion).\nPlease also see my related question: How to programmatically determine whether a Git checkout is a tag, and if so what is the tag name?\n",
        "all_answers": [
            "\nThe correct solution is to take a peek at contrib/completions/git-completion.bash does that for bash prompt in __git_ps1.  Removing all extras like selecting how to describe detached HEAD situation, i.e. when we are on unnamed branch, it is:\nbranch_name=\"$(git symbolic-ref HEAD 2>/dev/null)\" ||\nbranch_name=\"(unnamed branch)\"     # detached HEAD\n\nbranch_name=${branch_name##refs/heads/}\n\ngit symbolic-ref is used to extract fully qualified branch name from symbolic reference; we use it for HEAD, which is currently checked out branch.\nAlternate solution could be:\nbranch_name=$(git symbolic-ref -q HEAD)\nbranch_name=${branch_name##refs/heads/}\nbranch_name=${branch_name:-HEAD}\n\nwhere in last line we deal with the detached HEAD situation, using simply \"HEAD\" to denote such situation.\n\nAdded 11-06-2013\nJunio C. Hamano (git maintainer) blog post, Checking the current branch programatically, from June 10, 2013 explains whys (and hows) in more detail.\n",
            "\nThat's one solution. If you add it to your .bashrc, it'll display the current branch in the console.\n# git branch\nparse_git_branch() {\n    git branch 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/(\\1) /'\n}\n$PS1=\"\\$(parse_git_branch)$PS1\"\n\nHowever it's pretty limited. But there is a great project called git sh, which is doing exactly that (and much more).\n",
            "\nThis one works for me. The --no-color part is, or can be, important if you want a plain string back.\ngit branch --no-color | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/\\1/'\n\n",
            "\nHere is what I do:\ngit branch | sed --quiet 's/* \\(.*\\)/\\1/p'\n\nThe output would look like this:\n$ git branch | sed --quiet 's/* \\(.*\\)/\\1/p'\nmaster\n$\n\n"
        ],
        "answer": "A1",
        "tags": [
            "git",
            "bash",
            "shell"
        ]
    },
    {
        "question_id": "6102948",
        "question": "\nI recently ran into an issue that could easily be solved using modulus division, but the input was a float:\n\nGiven a periodic function (e.g. sin) and a computer function that can only compute it within the period range (e.g. [-π, π]), make a function that can handle any input.\n\nThe \"obvious\" solution is something like:\n#include <cmath>\n\nfloat sin(float x){\n    return limited_sin((x + M_PI) % (2 *M_PI) - M_PI);\n}\n\nWhy doesn't this work? I get this error:\nerror: invalid operands of types double and double to binary operator %\n\nInterestingly, it does work in Python:\ndef sin(x):\n    return limited_sin((x + math.pi) % (2 * math.pi) - math.pi)\n\n",
        "all_answers": [
            "\nFor C/C++, this is only defined for integer operations.\nPython is a little broader and allows you to get the remainder of a floating point number for the remainder of how many times number can be divided into it:\n>>> 4 % math.pi\n0.85840734641020688\n>>> 4 - math.pi\n0.85840734641020688\n>>> \n\n",
            "\nYou can use GCC's nested functions to simulate lambda expressions, in fact, I have a macro to do it for me:\n#define lambda(return_type, function_body) \\\n  ({ \\\n    return_type anon_func_name_ function_body \\\n    anon_func_name_; \\\n  })\n\nUse like this:\nint (*max)(int, int) = lambda (int, (int x, int y) { return x > y ? x : y; });\n\n",
            "\ntry fmod\n",
            "\nBecause the normal mathematical notion of \"remainder\" is only applicable to integer division. i.e. division that is required to generate integer quotient.\nIn order to extend the concept of \"remainder\" to real numbers you have to introduce a new kind of \"hybrid\" operation that would generate integer quotient for real operands. Core C language does not support such operation, but it is provided as a standard library fmod function, as well as remainder function in C99. (Note that these functions are not the same and have some peculiarities. In particular, they do not follow the rounding rules of integer division.)\n",
            "\nYou're looking for fmod().\nI guess to more specifically answer your question, in older languages the % operator was just defined as integer modular division and in newer languages they decided to expand the definition of the operator.\nEDIT:  If I were to wager a guess why, I would say it's because the idea of modular arithmetic originates in number theory and deals specifically with integers.\n",
            "\nFunctional programming is not about lambdas, it is all about pure functions.  So the following broadly promote functional style:\n\nOnly use function arguments, do not use global state.\nMinimise side effects i.e. printf, or any IO.  Return data describing IO which can be executed instead of causing the side effects directly in all functions.  \n\nThis can be achieved in plain c, no need for magic.\n",
            "\nThe modulo operator % in C and C++ is defined for two integers, however, there is an fmod() function available for usage with doubles.\n",
            "\nFFCALL lets you build closures in C -- callback = alloc_callback(&function, data) returns a function pointer such that callback(arg1, ...) is equivalent to calling function(data, arg1, ...).  You will have to handle garbage collection manually, though.\nRelatedly, blocks have been added to Apple's fork of GCC; they're not function pointers, but they let you pass around lambdas while avoiding the need to build and free storage for captured variables by hand (effectively, some copying and reference counting happens, hidden behind some syntactic sugar and runtime libraries).\n"
        ],
        "answer": "A4",
        "tags": [
            "c++",
            "c"
        ]
    },
    {
        "question_id": "13597892",
        "question": "\nGitHub search allows filtering repositories by language. How can I set a repository to a specific language?\n",
        "all_answers": [
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nAs VonC mentioned in the comments, you can put your libraries under \"vendors\" or \"thirdparty\" and the files won't be analysed by linguist, the tool GitHub uses to analyse the language in your code.\n# Vendored dependencies\n- third[-_]?party/\n- 3rd[-_]?party/\n- vendors?/\n- extern(al)?/\n\nLater, they added more folder names.\n",
            "\nIt is purely deduced from the code content.\nAs Pedro mentions:\n\nPlease note that we count the total bytes of each language's file (we check the extension) to decide the percentages.\nThis means that if you see your project reported a JavaScript, but you swear you use Ruby, you probably have a JS lib somewhere that is bigger than your Ruby code\n\nAs detailed in \"GitHub changes repository to the wrong language\", you can add a .gitattributes file in which you can:\n\nignore part of your project (not considered for language detection)\n  static/* linguist-vendored\n\n\nconsider part of your project as documentation:\n  docs/* linguist-documentation\n\n\nindicate some files with specific extension (for instance *.rb) should be considered a specific language:\n  *.rb linguist-language=Java\n\n\n\n"
        ],
        "answer": "A2",
        "tags": [
            "github"
        ]
    },
    {
        "question_id": "18351951",
        "question": "\nWhat is the pythonic way of writing the following code?\nextensions = ['.mp3','.avi']\nfile_name = 'test.mp3'\n\nfor extension in extensions:\n    if file_name.endswith(extension):\n        #do stuff\n\nI have a vague memory that the explicit declaration of the for loop can be avoided and be written in the if condition. Is this true?\n",
        "all_answers": [
            "\nWhat happens when the string contains a duplicate character?\nfrom my experience with index() I saw that for duplicate you get back the same index.\nFor example:\ns = 'abccde'\nfor c in s:\n    print('%s, %d' % (c, s.index(c)))\n\nwould return:\na, 0\nb, 1\nc, 2\nc, 2\nd, 4\n\nIn that case you can do something like that:\nfor i, character in enumerate(my_string):\n   # i is the position of the character in the string\n\n",
            "\nstring.find(character)  \nstring.index(character)  \n\nPerhaps you'd like to have a look at the documentation to find out what the difference between the two is.\n",
            "\nJust for completion, in the case I want to find the extension in a file name in order to check it, I need to find the last '.', in this case use rfind:\npath = 'toto.titi.tata..xls'\npath.find('.')\n4\npath.rfind('.')\n15\n\nin my case, I use the following, which works whatever the complete file name is:\nfilename_without_extension = complete_name[:complete_name.rfind('.')]\n\n",
            "\nThough not widely known, str.endswith also accepts a tuple. You don't need to loop.\n>>> 'test.mp3'.endswith(('.mp3', '.avi'))\nTrue\n\n",
            "\nJust use:\nif file_name.endswith(tuple(extensions)):\n\n",
            "\nThere are two string methods for this, find() and index().  The difference between the two is what happens when the search string isn't found.  find() returns -1  and index() raises a ValueError.\nUsing find()\n>>> myString = 'Position of a character'\n>>> myString.find('s')\n2\n>>> myString.find('x')\n-1\n\n\nUsing index()\n>>> myString = 'Position of a character'\n>>> myString.index('s')\n2\n>>> myString.index('x')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: substring not found\n\n\nFrom the Python manual\n\nstring.find(s, sub[, start[, end]])\nReturn the lowest index in s where the substring sub is found such that sub is wholly contained in s[start:end]. Return -1 on failure. Defaults for start and end and interpretation of negative values is the same as for slices.\n\nAnd:\n\nstring.index(s, sub[, start[, end]])\nLike find() but raise ValueError when the substring is not found.\n\n",
            "\nJust for a sake of completeness, if you need to find all positions of a character in a string, you can do the following:\ns = 'shak#spea#e'\nc = '#'\nprint([pos for pos, char in enumerate(s) if char == c])\n\nwhich will print: [4, 9]\n",
            "\n>>> s=\"mystring\"\n>>> s.index(\"r\")\n4\n>>> s.find(\"r\")\n4\n\n\"Long winded\" way\n>>> for i,c in enumerate(s):\n...   if \"r\"==c: print i\n...\n4\n\nto get substring, \n>>> s=\"mystring\"\n>>> s[4:10]\n'ring'\n\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "string",
            "list"
        ]
    },
    {
        "question_id": "42694584",
        "question": "\nI was trying to push and create a pull-request from my local feature-branch, as usual, being in my feature-branch and right-clicking on the remote origin/develop -branch (I'm using Git Flow), and this error message popped out:\n\nCan't find anything with that error message. Any ideas?\n",
        "all_answers": [
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nMake sure that your user account is added to the repository as a collaborator.\nSetting --> Collaborators\n",
            "\nI had this problem as well when there was a HEAD tag at a commit behind the current local master or origin/master.\nTry double-clicking your local master (which eliminates HEAD) and then push your changes.\nNote that if you do not have a local master, right-click on remote origin master and choose 'Checkout origin/master'. Then pull, commit, push your changes.\n",
            "\nI had the same problem.  My branch name had an apostrophe in it (Richie'sVersion).  I created a new branch from the existing branch (essentially a copy of the existing branch) and gave it a name without an apostrophe (RichiesVersion) and this resolved the problem.  Pushing the new branch worked fine.\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nMy issue was that I used the clone https url widget provided by github. That URL doesn't work for private repositories as you need to add a username to the front of it.  \nExample: a private repo owned by john and named widget with collaborator sam the correct url would be: \nhttps://sam@github.com/john/widget.git\nThe github provided url: \nhttps://github.com/john/widget.git\nThe error message leaves much to be desired.\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nI got the same problem while using a github repository, and connecting to it via https, while using the OS X Keychain Credential helper.\nMy problem was that I had the wrong credentials stored in OS X's Keychain (I was using the email address that I used to sign up for github.com rather than the [username]@github.com address it provides you). I deleted the old account in the keychain and only left the @github.com one and it fixed the problem.\nNot sure if it is related, but when I checked the user.email local config:\ngit config -l\n\nit showed the incorrect email address as well, so I updated the local git user.email to use the correct account too:\ngit config user.email <username>@github.com\n\n"
        ],
        "answer": "A3",
        "tags": [
            "git",
            "github",
            "pull-request",
            "gitkraken"
        ]
    },
    {
        "question_id": "2154762",
        "question": "\nI would like to know how you upgrade PHP in Xampp for Windows? I tried to download the latest PHP version from the main PHP site but when I check (phpinfo) I still get that the previous version is still in use.\n",
        "all_answers": [
            "\nTake a backup of your htdocs and data folder (subfolder of MySQL folder), reinstall upgraded version and replace those folders.\nNote:\nIn case you have changed config files like PHP (php.ini), Apache (httpd.conf) or any other, please take back up of those files as well and replace them with newly installed version. \n",
            "\nI think you need to actually download and install XAMPP with the desired PHP version. I dont think you can just upgrade the components of XAMPP individually unless there is a facility provided for this within XAMPP itself.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "windows",
            "xampp"
        ]
    },
    {
        "question_id": "11039064",
        "question": "\nI have the following C# code in my application which works just fine.  It launches a new instance of Excel.\nprivate readonly Microsoft.Office.Interop.Excel.Application _application;\n_application = new Microsoft.Office.Interop.Excel.Application();\n_application.Visible = true;\n\nI only recently noticed that Application is an interface type.  What exactly is going on and how is it possible?\n",
        "all_answers": [
            "\nThe compiler allows you to instantiate interfaces if they’re decorated with a CoClass attribute identifying the concrete class that implements them (as well as a ComImport and a Guid). When you instantiate the interface, you would actually be instantiating this concrete class behind-the-scenes.\nThis “feature” is intended to be used as plumbing for COM imported types. Notice how the Outlook Application interface is backed by a concrete class named ApplicationClass:\n[GuidAttribute(\"00063001-0000-0000-C000-000000000046\")]\n[CoClassAttribute(typeof(ApplicationClass))]\npublic interface Application : _Application, ApplicationEvents_11_Event\n\nIn most circumstances, you should not go applying these attributes to your own interfaces. However, for the sake of demonstration, we can show that the compiler will allow you to take advantage of this possibility for instantiating interfaces in your code. Consider the following simple example (the GUID is random):\n[ComImport]\n[Guid(\"175EB158-B655-11E1-B477-02566188709B\")]\n[CoClass(typeof(Foo))]\ninterface IFoo\n{\n    string Bar();\n}\n\nclass Foo : IFoo\n{\n    public string Bar()\n    {\n        return \"Hello world\"; \n    }\n}\n\nUsing the above declarations, you can create an instance of your own IFoo interface:\nIFoo a = new IFoo();\nConsole.WriteLine(a.Bar());\n// Output: \"Hello world\"\n\nEdit: Although jonnyGold correctly notes that the Excel Application instance is not decorated with CoClass on MSDN, this appears to be an MSDN omission. The decompiled signature from the Microsoft.Office.Interop.Excel assembly is:\n[CoClass(typeof(ApplicationClass)), Guid(\"000208D5-0000-0000-C000-000000000046\")]\n[ComImport]\npublic interface Application : _Application, AppEvents_Event\n\n",
            "\nBecause MSDN says so:\n\nFor example, the following code uses the Excel Microsoft.Office.Interop.Excel.Application interface.\n  At run time, it uses the Application class to instantiate an Excel Application object and open a worksheet.\n\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "excel",
            "vsto"
        ]
    },
    {
        "question_id": "25214484",
        "question": "\nMy app has a protocol for detail view controllers, stating they must have a viewModel property:\nprotocol DetailViewController: class {\n    var viewModel: ViewModel? {get set}\n}\n\nI also have a few different classes that implement the protocol:\nclass FormViewController: UITableViewController, DetailViewController {\n    // ...\n}\n\nclass MapViewController: UIViewController, DetailViewController {\n    // ...\n}\n\nMy master view controller needs a property that can be set to any UIViewController subclass that implements the DetailViewController protocol.\nUnfortunately I can't find any documentation on how to do this. In Objective-C it would be trivial:\n@property (strong, nonatomic) UIViewController<DetailViewController>;\n\nIt appears that there isn't any syntax available in Swift to do this. The closest I've come is to declare a generic in my class definition:\nclass MasterViewController<T where T:UIViewController, T:DetailViewController>: UITableViewController {\n    var detailViewController: T?\n    // ...\n}\n\nBut then I get an error saying that \"Class 'MasterViewController' does not implement its superclass's required members\"\nThis seems like it should be as easy to do in Swift as it is in Objective-C, but I can't find anything anywhere that suggests how I might go about it. \n",
        "all_answers": [
            "\nI think you can get there by adding an (empty) extension to UIViewController and then specifying your detailViewController attribute using a composed protocol of the empty extension and your DetailViewController.  Like this:\nprotocol UIViewControllerInject {}\nextension UIViewController : UIViewControllerInject {}\n\nNow all subclasses of UIViewController satisfy protocol UIViewControllerInject.  Then with that, simply:\ntypealias DetailViewControllerComposed = protocol<DetailViewController, UIViewControllerInject>\n\nclass MasterViewController : UITableViewController {\n  var detailViewController : DetailViewControllerComposed?\n  // ...\n}\n\nBut, this is not particularly 'natural'.\n=== Edit, Addition ===\nActually, you could make it a bit better if you define your DetailViewController using my suggested UIViewControllerInject.  Like such:\nprotocol UIViewControllerInject {}\nextension UIViewController : UIViewControllerInject {}\n\nprotocol DetailViewController : UIViewControllerInject { /* ... */ }\n\nand now you don't need to explicitly compose something (my DetailViewControllerComposed) and can use DetailViewController? as the type for detailViewController.\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nAs of Swift 4, you can now do this.\nSwift 4 implemented SE-0156 (Class and Subtype existentials).\nThe equivalent of this Objective-C syntax:\n@property (strong, nonatomic) UIViewController<DetailViewController> * detailViewController;\n\nNow looks like this in Swift 4:\nvar detailViewController: UIViewController & DetailViewController\n\nEssentially you get to define one class that the variable conforms to, and N number of protocols it implements. See the linked document for more detailed information.\n",
            "\nAnother way would be to introduce intermediate base classes for the appropriate UIKit view controllers that implement the protocol:\nclass MyUIViewControler : UIViewController, DetailViewController ...\nclass MyUITableViewController : UITableViewController, DetailViewController ...\n\nThen you inherit your view controllers from these view controllers, not the UIKit ones. \nThis is not natural either, but it doesn't force all your UIViewControllers to satisfy the UIViewControllerInject protocol as GoZoner suggested.\n"
        ],
        "answer": "A3",
        "tags": [
            "swift",
            "protocols"
        ]
    },
    {
        "question_id": "2002610",
        "question": "\nWhat is the difference between these two function calls in PHP?\ninit_get($somevariable);\n\n@init_get($somevariable);\n\n",
        "all_answers": [
            "\nhttp://www.faqts.com/knowledge_base/view.phtml/aid/18068/fid/38\nAll PHP expressions can be called with the \"@\" prefix, which turns off \nerror reporting for that particular expression.\n",
            "\nthe \"@\" will silence any php errors your function could raise.\n",
            "\nIt silences errors and warnings. See Error Control Operators.\n"
        ],
        "answer": "A2",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "7298731",
        "question": "\nThere has been a lot of posting about what these two contexts are.. But I'm still not getting it quite right\nAs I understand it so far:\nEach is an instance of its class which means that some programmers recommend you to use this.getApplicationContext() as often as possible in order to not \"leak\" out any memory. This is because the other this (getting the Activity instance context) points to an Activity that is being destroyed each time the user tilts the phone or leave the app etc.. Which apparently the Garbage Collector (GC) doesn't catch and therefore uses too much memory.. \nBut can anyone please come up with some really good coding examples where it would be the right thing to use this (getting the context of the current Activity instance) and the application context will be useless/wrong?\n",
        "all_answers": [
            "\nTwo great examples of when you should use Activity context vs. the Application context are when displaying either a Toast message or a built-in Dialog message as using the Application context will cause an exception:\nProgressDialog.show(this, ....);\n\nor\nToast t = Toast.makeText(this,....);\n\nBoth of these need information from the Activity context that is not provided in the Application context.\n",
            "\ngetApplicationContext() is almost always wrong. Ms. Hackborn (among others) have been very explicit that you only use getApplicationContext() when you know why you are using getApplicationContext() and only when you need to use getApplicationContext().\nTo be blunt, \"some programmers\" use getApplicationContext() (or getBaseContext(), to a lesser extent) because their Java experience is limited. They implement an inner class (e.g., an OnClickListener for a Button in an Activity) and need a Context. Rather than using MyActivity.this to get at the outer class' this, they use getApplicationContext() or getBaseContext() to get a Context object.\nYou only use getApplicationContext() when you know you need a Context for something that may live longer than any other likely Context you have at your disposal. Scenarios include:\n\nUse getApplicationContext() if you need something tied to a Context that itself will have global scope. I use getApplicationContext(), for example, in WakefulIntentService, for the static WakeLock to be used for the service. Since that WakeLock is static, and I need a Context to get at PowerManager to create it, it is safest to use getApplicationContext().\nUse getApplicationContext() when you bind to a Service from an Activity, if you wish to pass the ServiceConnection (i.e., the handle to the binding) between Activity instances via onRetainNonConfigurationInstance(). Android internally tracks bindings via these ServiceConnections and holds references to the Contexts that create the bindings. If you bind from the Activity, then the new Activity instance will have a reference to the ServiceConnection which has an implicit reference to the old Activity, and the old Activity cannot be garbage collected.\n\nSome developers use custom subclasses of Application for their own global data, which they retrieve via getApplicationContext(). That's certainly possible. I prefer static data members, if for no other reason than you can only have one custom Application object. I built one app using a custom Application object and found it to be painful. Ms. Hackborn also agrees with this position.\nHere are reasons why not to use getApplicationContext() wherever you go:\n\nIt's not a complete Context, supporting everything that Activity does. Various things you will try to do with this Context will fail, mostly related to the GUI.\nIt can create memory leaks, if the Context from getApplicationContext() holds onto something created by your calls on it that you don't clean up. With an Activity, if it holds onto something, once the Activity gets garbage collected, everything else flushes out too. The Application object remains for the lifetime of your process.\n\n"
        ],
        "answer": "A2",
        "tags": [
            "android",
            "this",
            "android-context"
        ]
    },
    {
        "question_id": "49938266",
        "question": "\n\n\n\nHow can I return the value from an async function?\nI tried to like this\nconst axios = require('axios');\nasync function getData() {\n    const data = await axios.get('https://jsonplaceholder.typicode.com/posts');\n    return data;\n}\nconsole.log(getData());\n\nit returns me this,\nPromise { <pending> }\n\n",
        "all_answers": [
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nyour function getData will return a Promise.\nSo you can either:\n\nawait the function as well to get the result. However, to be able to use await, you need to be in an async function, so you need to 'wrap' this:\nasync function callAsync() {\n   var x = await getData();\n   console.log(x);\n}\ncallAsync();\n\n(I named the function for sake of clarity, but in this scenario, one would rather use an anonymous function call; see TheReason's answer.)\n\n\nor\n\nuse the result as a normal Promise, which is what an async function returns.\nYou have to use then with a callback:\ngetData().then(x => { \n    console.log(x); \n});\n\n\n\n",
            "\nUpdate 2020 - CLI\nAs @mix3d pointed out you can just run a command where file.js is your file and someFunction is your function optionally followed by parameters separated with spaces\nnpx run-func file.js someFunction \"just some parameter\"\n\nThat's it.\nfile.js called in the example above\nconst someFunction = (param) => console.log('Welcome, your param is', param)\n\n// exporting is crucial\nmodule.exports = { someFunction }\n\nMore detailed description\nRun directly from CLI (global)\nInstall\nnpm i -g run-func\n\nUsage i.e. run function \"init\", it must be exported, see the bottom\nrun-func db.js init\n\nor\nRun from package.json script (local)\nInstall\nnpm i -S run-func\n\nSetup\n\"scripts\": {\n   \"init\": \"run-func db.js init\"\n}\n\nUsage\nnpm run init\n\nParams\nAny following arguments will be passed as function parameters init(param1, param2)\nrun-func db.js init param1 param2\n\nImportant\nthe function (in this example init) must be exported in the file containing it\nmodule.exports = { init };\n\nor ES6 export\nexport { init };\n\n",
            "\nYou cant await something outside async scope. To get expected result you should wrap your console.log into async IIFE i.e\nasync function getData() {\n  return await axios.get('https://jsonplaceholder.typicode.com/posts');\n}\n\n(async () => {\n  console.log(await getData())\n})()\n\nWorking sample.\nMore information about async/await\nSince axios returns a promise the async/await can be omitted for the getData function like so:\nfunction getData() {\n  return axios.get('https://jsonplaceholder.typicode.com/posts');\n}\n\nand then do same as we did before\n(async () => {\n   console.log(await getData())\n})()\n\n"
        ],
        "answer": "A4",
        "tags": [
            "javascript",
            "node.js",
            "asynchronous",
            "async-await",
            "axios"
        ]
    },
    {
        "question_id": "23793062",
        "question": "\nStash enables automatic fork syncing if selected:\nhttps://confluence.atlassian.com/display/STASH/Keeping+forks+synchronized\nIt will update any branches in your fork that you haven't modified.\nI've been unable to find similar automatic functionality in GitHub; all google searches are turning up manual ways to sync forks via your local cache.\n",
        "all_answers": [
            "\nYou could define a webhook to listen to upstream (the original repo) changes, and update your fork.\nIn June 2016, you had the service backstroke.us which listens to those events for you. No need to write your own listener.\nSee 1egoman/backstroke\nBut, as commented by chriszo111, in 2020, that would be wei/pull\n\na GitHub App built with probot that keeps your forks up-to-date with upstream via automated pull requests.\n\n",
            "\nYou can create a Github App that use Github API to check the upstream repo periodically. Once an update is found, use Github API to create a pull request then call updateRef to update your branch to match master.\nOr, just install this Github App that does exactly that\nhttps://github.com/wei/pull\n🤖 a GitHub App that keeps your repository up-to-date with upstream changes.\n",
            "\nFor the record, recently I ran into this same problem and addressed it with Github Actions. The solution is rather easy: an scheduled action fetches the upstream repository and merges it into mine.\n# .github/workflows/example.yml\n\nname: Merge upstream branches\non:\n  schedule:\n     # actually, ~5 minutes is the highest\n     # effective frequency you will get\n    - cron:  '* * * * *'\njobs:\n  merge:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Merge upstream\n        run: |\n          git config --global user.name 'your-name'\n          git config --global user.email 'your-username@users.noreply.github.com'\n\n          # \"git checkout master\" is unnecessary, already here by default\n          git pull --unshallow  # this option is very important, you would get\n                                # complains about unrelated histories without it.\n                                # (but actions/checkout@v2 can also be instructed\n                                # to fetch all git depth right from the start)\n\n          git remote add upstream https://github.com/example/test.git\n          git fetch upstream\n\n          # Neither forget the -b opt,\n          # the feature/x ref is ambiguous at this stage\n          git checkout -b feature/x origin/feature/x\n          git merge --no-edit upstream/feature/x\n          git push origin feature/x\n\n          git checkout master\n          git merge --no-edit upstream/master\n          git push origin master\n\n          # etc\n\n\nI run it every Sunday which is more than enough for me. Just schedule this to whatever is fine for you.\nAlso, it is probably wiser to sync every branch in a different job since they will run in parallel and can independently succeed or fail if conflicts occur.\nIf you need to merge an arbitrary number of branches, you can refer to questions like How to fetch all Git branches to find shell tricks to do it.\nI noticed a public action exists to address this by rebasing. It looked promising but it was fairly undocumented so here is my snippet instead. Hope it helps!\n"
        ],
        "answer": "A3",
        "tags": [
            "github",
            "git-fork"
        ]
    },
    {
        "question_id": "18867824",
        "question": "\nI was just wondering what does the -u flag mean in this command? \ngit push -u origin master\n\n",
        "all_answers": [
            "\nIt's the same as --set-upstream\nIt's used to set origin as the upstream remote in your git config.\nIt may help if you don't want to manually specify the remote every time you run git push.\nAlso ...\nAs you're new to stackOverflow, take your time to read What types of questions should I avoid asking? section of the Help because sometimes you can find the answers by simply browsing the documentation.\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nMake sure that your user account is added to the repository as a collaborator.\nSetting --> Collaborators\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nThe -u option does the following:\nFor every branch that is up to date or successfully pushed, add an upstream (tracking) reference, used by argument-less, git-pull and other commands.\nSo, after pushing your local branch with the -u option, this local branch will be automatically linked with the remote branch, and you can use git pull without any arguments.\n",
            "\nI got the same problem while using a github repository, and connecting to it via https, while using the OS X Keychain Credential helper.\nMy problem was that I had the wrong credentials stored in OS X's Keychain (I was using the email address that I used to sign up for github.com rather than the [username]@github.com address it provides you). I deleted the old account in the keychain and only left the @github.com one and it fixed the problem.\nNot sure if it is related, but when I checked the user.email local config:\ngit config -l\n\nit showed the incorrect email address as well, so I updated the local git user.email to use the correct account too:\ngit config user.email <username>@github.com\n\n",
            "\nMy issue was that I used the clone https url widget provided by github. That URL doesn't work for private repositories as you need to add a username to the front of it.  \nExample: a private repo owned by john and named widget with collaborator sam the correct url would be: \nhttps://sam@github.com/john/widget.git\nThe github provided url: \nhttps://github.com/john/widget.git\nThe error message leaves much to be desired.\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n"
        ],
        "answer": "A8",
        "tags": [
            "git",
            "github",
            "push"
        ]
    },
    {
        "question_id": "1909441",
        "question": "\nI’ve got a search field. Right now it searches for every keyup. So if someone types “Windows”, it will make a search with AJAX for every keyup: “W”, “Wi”, “Win”, “Wind”, “Windo”, “Window”, “Windows”.\nI want to have a delay, so it only searches when the user stops typing for 200 ms.\nThere is no option for this in the keyup function, and I have tried setTimeout, but it didn’t work.\nHow can I do that?\n",
        "all_answers": [
            "\nTake a look at the autocomplete plugin.  I know that it allows you to specify a delay or a minimum number of characters.  Even if you don't end up using the plugin, looking through the code will give you some ideas on how to implement it yourself.\n",
            "\nIf you want to search after the type is done use a global variable to hold the timeout returned from your setTimout call and cancel it with a clearTimeout if it hasn't yet happend so that it won't fire the timeout except on the last keyup event\nvar globalTimeout = null;  \n$('#id').keyup(function(){\n  if(globalTimeout != null) clearTimeout(globalTimeout);  \n  globalTimeout =setTimeout(SearchFunc,200);  \n}   \nfunction SearchFunc(){  \n  globalTimeout = null;  \n  //ajax code\n}\n\nOr with an anonymous function :\nvar globalTimeout = null;  \n$('#id').keyup(function() {\n  if (globalTimeout != null) {\n    clearTimeout(globalTimeout);\n  }\n  globalTimeout = setTimeout(function() {\n    globalTimeout = null;  \n\n    //ajax code\n\n  }, 200);  \n}   \n\n",
            "\nI use this small function for the same purpose, executing a function after the user has stopped typing for a specified amount of time or in events that fire at a high rate, like resize:\n\n\nfunction delay(callback, ms) {\n  var timer = 0;\n  return function() {\n    var context = this, args = arguments;\n    clearTimeout(timer);\n    timer = setTimeout(function () {\n      callback.apply(context, args);\n    }, ms || 0);\n  };\n}\n\n\n// Example usage:\n\n$('#input').keyup(delay(function (e) {\n  console.log('Time elapsed!', this.value);\n}, 500));\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<label for=\"input\">Try it:\n<input id=\"input\" type=\"text\" placeholder=\"Type something here...\"/>\n</label>\n\n\n\nHow it works:\nThe delay function will return a wrapped function that internally handles an individual timer, in each execution the timer is restarted with the time delay provided, if multiple executions occur before this time passes, the timer will just reset and start again.\nWhen the timer finally ends, the callback function is executed, passing the original context and arguments (in this example, the jQuery's event object, and the DOM element as this).\nUPDATE 2019-05-16\nI have re-implemented the function using ES5 and ES6 features for modern environments:\nfunction delay(fn, ms) {\n  let timer = 0\n  return function(...args) {\n    clearTimeout(timer)\n    timer = setTimeout(fn.bind(this, ...args), ms || 0)\n  }\n}\n\nThe implementation is covered with a set of tests.\nFor something more sophisticated, give a look to the jQuery Typewatch plugin.\n",
            "\nUse \nmytimeout = setTimeout( expression, timeout );\n\nwhere expression is the script to run and timeout is the time to wait in milliseconds before it runs - this does NOT hault the script, but simply delays execution of that part until the timeout is done.\nclearTimeout(mytimeout);\n\nwill reset/clear the timeout so it does not run the script in expression (like a cancel) as long as it has not yet been executed.\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "jquery"
        ]
    },
    {
        "question_id": "1938735",
        "question": "\nTheoretically I can say that \nfree(ptr);\nfree(ptr); \n\nis a memory corruption since we are freeing the memory which has already been freed.\nBut what if \nfree(ptr);\nptr=NULL;\nfree(ptr); \n\nAs the OS will behave in an undefined manner I cannot get an actual theoretical analysis for this about what's happening.\nWhatever I am doing, is this memory corruption or not?\nIs freeing a NULL pointer valid?\n",
        "all_answers": [
            "\nThe difference is due to operator precedence.\nThe post-increment operator ++ has higher precedence than the dereference operator *. So *ptr++ is equivalent to *(ptr++). In other words, the post increment modifies the pointer, not what it points to.\nThe assignment operator += has lower precedence than the dereference operator *, so *ptr+=1 is equivalent to (*ptr)+=1. In other words, the assignment operator modifies the value that the pointer points to, and does not change the pointer itself. \n",
            "\nfree(ptr);\nptr=NULL;\nfree(ptr);/*This is perfectly safe */\n\nYou can safely delete a NULL pointer. No operation will be performed in that case.In other words  free() does nothing on a NULL pointer.\n",
            "\nThe order of precedence for the 3 operators involved in your question is the following :\npost-increment ++ > dereference * > assignment +=\nYou can check this page for further details on the subject.\n\nWhen parsing an expression, an operator which is listed on some row will be bound tighter (as if by parentheses) to its arguments than any operator that is listed on a row further below it. For example, the expression *p++ is parsed as *(p++), and not as (*p)++.\n\nLong story short, in order to express this assignment *ptr+=1 using the post-increment operator you need to add parentheses to the dereference operator to give that operation precedence over ++ as in this (*ptr)++\n",
            "\nfree(NULL) is perfectly legal in C as well as delete (void *)0 and delete[] (void *)0 are legal in C++.\nBTW, freeing memory twice usually causes some kind of runtime error, so it does not corrupt anything.\n",
            "\n\n7.20.3.2 The free function \nSynopsis \n#include <stdlib.h> \nvoid free(void *ptr); \n\nDescription\nThe free function causes the space pointed to by ptr to be deallocated, that is, made \n  available for further allocation. If ptr is a null pointer, no action occurs.\n\nSee ISO-IEC 9899.\nThat being said, when looking at different codebases in the wild, you'll notice people sometimes do:\nif (ptr)\n  free(ptr);\n\nThis is because some C runtimes (I for sure remember it was the case on PalmOS) would crash when freeing a NULL pointer.\nBut nowadays, I believe it's safe to assume free(NULL) is a nop as per instructed by the standard.\n",
            "\nnot memory corruption, but behavior depends on implementation.\nBy standard, it should be a legal code.\n",
            "\n\nIf ptr is NULL, no operation is performed.\n\nsays the documentation.\n"
        ],
        "answer": "A5",
        "tags": [
            "c",
            "pointers",
            "memory-management",
            "null",
            "free"
        ]
    },
    {
        "question_id": "8067338",
        "question": "\nI want know how I can add values to my vector of structs using the push_back method\nstruct subject\n{\n  string name;\n  int marks;\n  int credits;\n};\n\n\nvector<subject> sub;\n\nSo now how can I add elements to it?\nI have function that initializes string name(subject name to it)\nvoid setName(string s1, string s2, ...... string s6)\n{\n   // how can i set name too sub[0].name= \"english\", sub[1].name = \"math\" etc\n\n  sub[0].name = s1 // gives segmentation fault; so how do I use push_back method?\n\n  sub.name.push_back(s1);\n  sub.name.push_back(s2);\n  sub.name.push_back(s3);\n  sub.name.push_back(s4);\n\n  sub.name.push_back(s6);\n\n}\n\nFunction call\nsetName(\"english\", \"math\", \"physics\" ... \"economics\");\n\n",
        "all_answers": [
            "\nYou cannot access elements of an empty vector by subscript.\nAlways check that the vector is not empty & the index is valid while using the [] operator on std::vector.\n[] does not add elements if none exists, but it causes an Undefined Behavior if the index is invalid.\nYou should create a temporary object of your structure, fill it up and then add it to the vector, using vector::push_back()\nsubject subObj;\nsubObj.name = s1;\nsub.push_back(subObj);\n\n",
            "\nYou can also use vector::insert.\nstd::vector<int> v;\nint a[5] = {2, 5, 8, 11, 14};\n\nv.insert(v.end(), a, a+5);\n\nEdit:\nOf course, in real-world programming you should use:\nv.insert(v.end(), a, a+(sizeof(a)/sizeof(a[0])));  // C++03\nv.insert(v.end(), std::begin(a), std::end(a));     // C++11\n\n",
            "\nYou can do it with initializer list:\nstd::vector<unsigned int> array;\n\n// First argument is an iterator to the element BEFORE which you will insert:\n// In this case, you will insert before the end() iterator, which means appending value\n// at the end of the vector.\narray.insert(array.end(), { 1, 2, 3, 4, 5, 6 });\n\n",
            "\nCreate vector, push_back element, then modify it as so:\nstruct subject {\n    string name;\n    int marks;\n    int credits;\n};\n\n\nint main() {\n    vector<subject> sub;\n\n    //Push back new subject created with default constructor.\n    sub.push_back(subject());\n\n    //Vector now has 1 element @ index 0, so modify it.\n    sub[0].name = \"english\";\n\n    //Add a new element if you want another:\n    sub.push_back(subject());\n\n    //Modify its name and marks.\n    sub[1].name = \"math\";\n    sub[1].marks = 90;\n}\n\nYou cant access a vector with [#] until an element exists in the vector at that index. This example populates the [#] and then modifies it afterward.\n",
            "\nTry pass array to vector:\nint arr[] = {2,5,8,11,14};\nstd::vector<int> TestVector(arr, arr+5);\n\nYou could always call std::vector::assign to assign array to vector, call std::vector::insert to add multiple arrays.\nIf you use C++11, you can try:\nstd::vector<int> v{2,5,8,11,14};\n\nOr\nstd::vector<int> v = {2,5,8,11,14};\n\n"
        ],
        "answer": "A4",
        "tags": [
            "c++",
            "vector",
            "struct",
            "push-back"
        ]
    },
    {
        "question_id": "15108932",
        "question": "\nI have a small question.  I know that the %x format specifier can be used to read values from the stack in a format string attack.\nI found the following code:\n%08x%08x%08x%08x\n\nWhat does the 08 mean?  What is it doing exactly?  Thanks :)\n",
        "all_answers": [
            "\nBreak-down:\n\n8 says that you want to show 8 digits\n0 that you want to prefix with 0's instead of just blank spaces\nx that you want to print in lower-case hexadecimal.\n\nQuick example (thanks to Grijesh Chauhan):\n#include <stdio.h>\nint main() {\n    int data = 29;\n    printf(\"%x\\n\", data);    // just print data\n    printf(\"%0x\\n\", data);   // just print data ('0' on its own has no effect)\n    printf(\"%8x\\n\", data);   // print in 8 width and pad with blank spaces\n    printf(\"%08x\\n\", data);  // print in 8 width and pad with 0's\n\n    return 0;\n}\n\nOutput:  \n1d\n1d\n      1d\n0000001d\n\nAlso see http://www.cplusplus.com/reference/cstdio/printf/ for reference.\n",
            "\nWhy C++ doesn't have support for unsigned floats is because there is no equivalent machine code operations for the CPU to execute.  So it would be very inefficient to support it.  \nIf C++ did support it, then you would be sometimes using an unsigned float and not realizing that your performance has just been killed.  If C++ supported it then every floating point operation would need to be checked to see if it is signed or not.  And for programs that do millions of floating point operations, this is not acceptable. \nSo the question would be why don't hardware implementers support it.  And I think the answer to that is that there was no unsigned float standard defined originally.  Since languages like to be backwards compatible, even if it were added languages couldn't make use of it.  To see the floating point spec you should look at the IEEE standard 754 Floating-Point.\nYou can get around not having an unsigned floating point type though by creating a unsigned float class that encapsulates a float or double and throws warnings if you try to pass in a negative number.   This is less efficient, but probably if you aren't using them intensely you won't care about that slight performance loss.\nI definitely see the usefulness of having an unsigned float.  But C/C++ tends to chose efficiency that works best for everyone over safety. \n",
            "\n%08x means that every number should be printed at least 8 characters wide with filling all missing digits with zeros, e.g. for '1' output will be 00000001\n",
            "\nThat specifies the how many digits you want it to show.\n\ninteger value or * that specifies minimum field width. The result is padded with space characters (by default), if required, on the left when right-justified, or on the right if left-justified. In the case when * is used, the width is specified by an additional argument of type int. If the value of the argument is negative, it results with the - flag specified and positive field width. \n\n"
        ],
        "answer": "A1",
        "tags": [
            "c",
            "string",
            "security",
            "format"
        ]
    },
    {
        "question_id": "11285961",
        "question": "\nHow do I make the background of a Textview about 20% transparent (not fully transparent), where there is a color in the background (i.e. white)?\n",
        "all_answers": [
            "\nMake the color have 80% in the alpha channel. For example, for red use #CCFF0000:\n<TextView\n   ...\n   android:background=\"#CCFF0000\" />\n\nIn the example, CC is the hexadecimal number for 255 * 0.8 = 204. Note that the first two hexadecimal digits are for the alpha channel. The format is #AARRGGBB, where AA is the alpha channel, RR is the red channel, GG is the green channel and BB is the blue channel.\nI'm assuming that 20% transparent means 80% opaque. If you meant the other way, instead of CC use 33 which is the hexadecimal for 255 * 0.2 = 51.\nIn order to calculate the proper value for an alpha transparency value you can follow this procedure:\n\nGiven a transparency percentage, for example 20%, you know the opaque percentage value is 80% (this is 100-20=80)\nThe range for the alpha channel is 8 bits (2^8=256), meaning the range goes from 0 to 255.\nProject the opaque percentage into the alpha range, that is, multiply the range (255) by the percentage. In this example 255 * 0.8 = 204. Round to the nearest integer if needed.\nConvert the value obtained in 3., which is in base 10, to hexadecimal (base 16). You can use Google for this or any calculator. Using Google, type \"204 to hexa\" and it will give you the hexadecimal value. In this case it is 0xCC.\nPrepend the value obtained in 4. to the desired color. For example, for red, which is FF0000, you will have CCFF0000.\n\nYou can take a look at the Android documentation for colors.\n",
            "\nUse a color with an alpha value like #33------, and set it as background of your editText using the XML attribute android:background=\" \".\n\n0% (transparent) -> #00 in hex\n20% -> #33\n50% -> #80\n75% -> #C0\n100% (opaque) -> #FF\n\n255 * 0.2 = 51 → in hex 33\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "transparency",
            "textview"
        ]
    },
    {
        "question_id": "4283933",
        "question": "\nI have a model with a FileField. I want to unittest it. django test framework has great ways to manage database and emails. Is there something similar for FileFields?\nHow can I make sure that the unittests are not going to pollute the real application?\nThanks in advance\nPS: My question is almost a duplicate of Django test FileField using test fixtures but it doesn't have an accepted answer. Just want to re-ask if something new on this topic.\n",
        "all_answers": [
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nThere are several ways you could tackle this but they're all ugly since unit tests are supposed to be isolated but files are all about durable changes.\nMy unit tests don't run on a system with production data so it's been easy to simply reset the upload directory after each run with something like git reset --hard. This approach is in some ways the best simply because it involves no code changes and is guaranteed to work as long as you start with good test data. \nIf you don't actually need to do anything with that file after testing your model's save method, I'd recommend using python's excellent Mock library to completely fake the File instance (i.e. something like mock_file = Mock(spec=django.core.files.File); mock_file.read.return_value = \"fake file contents\") so you can completely avoid changes to your file handling logic. The Mock library has a couple of ways to globally patch Django's File class within a test method which is about as easy as this will get.\nIf you need to have a real file (i.e. for serving as part of a test, processing with an external script, etc.) you can use something similar to Mirko's example and create a File object after making sure it'll be stored somewhere appropriate - here are three ways to do that:\n\nHave your test settings.MEDIA_ROOT point to a temporary directory (see the Python tempfile module's mkdtemp function). This works fine as long as you have something like a separate STATIC_ROOT which you use for the media files which are part of your source code.\nUse a custom storage manager\nSet the file path manually on each File instance or have a custom upload_to function to point somewhere which your test setup/teardown process purges such as a test subdirectory under MEDIA_ROOT.\n\nEdit: mock object library is new in python version 3.3. For older python versions check Michael Foord's version\n",
            "\nI normally test filefields in models using doctest\n>>> from django.core.files import File\n>>> s = SimpleModel()\n>>> s.audio_file = File(open(\"media/testfiles/testaudio.wav\"))\n>>> s.save()\n>>> ...\n>>> s.delete()\n\nIf I need to I also test file uploads with test clients. \nAs for fixtures, I simply copy the files i need in a test folder, after modifying the paths in the fixture.\ne.g.\nIn a fixture containing models with filefiels pointing to a directory named \"audio\", you replace \"audio\": \"audio/audio.wav\" with \"audio\": \"audio/test/audio.wav\" .\nNow all you have to do is copy the test folder, with the necessary files, in \"audio\" in the test setUp and then delete it in tearDown.\nNot the cleanest way ever i think, but that's what i do.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django",
            "filefield",
            "django-unittest"
        ]
    },
    {
        "question_id": "1329291",
        "question": "\nI have a git repository that's used only to hold graphics and sound files used in several projects. They are all in one directory without sub-directories. Now I just created a script to copy these assets over from another, structured directory, with several levels of sub-directories.\nNow I only want the (source) hierarchical file structure to be tracked by git, and the (target) flat directory (with all the files in one pile) should be ignored.\nI've added the target directory to .gitignore, but git is still tracking changes in it. I thought if I commit the deletion of the old file in the target directory, git might stop tracking the new contents (copied in by the script), but it doesn't.\nHow do I make git forget about the target directory?\n",
        "all_answers": [
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nFor a subdirectory called blah/ added to git, both of the following seem to work to ignore new files in blah/. Added to .gitignore:\nblah \nblah/*\n\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nThis command will cause git to untrack your directory and all files under it without actually deleting them:\ngit rm -r --cached <your directory>\nThe -r option causes the removal of all files under your directory.  \nThe --cached option causes the files to only be removed from git's index, not your working copy. By default git rm <file> would delete <file>.\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n"
        ],
        "answer": "A6",
        "tags": [
            "git",
            "version-control"
        ]
    },
    {
        "question_id": "17095101",
        "question": "\nI am trying to highlight exactly what changed between two dataframes.\nSuppose I have two Python Pandas dataframes:\n\"StudentRoster Jan-1\":\nid   Name   score                    isEnrolled           Comment\n111  Jack   2.17                     True                 He was late to class\n112  Nick   1.11                     False                Graduated\n113  Zoe    4.12                     True       \n\n\"StudentRoster Jan-2\":\nid   Name   score                    isEnrolled           Comment\n111  Jack   2.17                     True                 He was late to class\n112  Nick   1.21                     False                Graduated\n113  Zoe    4.12                     False                On vacation\n\nMy goal is to output an HTML table that:\n\nIdentifies rows that have changed (could be int, float, boolean, string)\nOutputs rows with same, OLD and NEW values (ideally into an HTML table) so the consumer can clearly see what changed between two dataframes: \n\"StudentRoster Difference Jan-1 - Jan-2\":  \nid   Name   score                    isEnrolled           Comment\n112  Nick   was 1.11| now 1.21       False                Graduated\n113  Zoe    4.12                     was True | now False was \"\" | now   \"On   vacation\"\n\n\nI suppose I could do a row by row and column by column comparison, but is there an easier way?\n",
        "all_answers": [
            "\nIf your two dataframes have the same ids in them, then finding out what changed is actually pretty easy. Just doing frame1 != frame2 will give you a boolean DataFrame where each True is data that has changed. From that, you could easily get the index of each changed row by doing changedids = frame1.index[np.any(frame1 != frame2,axis=1)].\n",
            "\nThe first part is similar to Constantine, you can get the boolean of which rows are empty*:\nIn [21]: ne = (df1 != df2).any(1)\n\nIn [22]: ne\nOut[22]:\n0    False\n1     True\n2     True\ndtype: bool\n\nThen we can see which entries have changed:\nIn [23]: ne_stacked = (df1 != df2).stack()\n\nIn [24]: changed = ne_stacked[ne_stacked]\n\nIn [25]: changed.index.names = ['id', 'col']\n\nIn [26]: changed\nOut[26]:\nid  col\n1   score         True\n2   isEnrolled    True\n    Comment       True\ndtype: bool\n\nHere the first entry is the index and the second the columns which has been changed.\nIn [27]: difference_locations = np.where(df1 != df2)\n\nIn [28]: changed_from = df1.values[difference_locations]\n\nIn [29]: changed_to = df2.values[difference_locations]\n\nIn [30]: pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)\nOut[30]:\n               from           to\nid col\n1  score       1.11         1.21\n2  isEnrolled  True        False\n   Comment     None  On vacation\n\n* Note: it's important that df1 and df2 share the same index here. To overcome this ambiguity, you can ensure you only look at the shared labels using df1.index & df2.index, but I think I'll leave that as an exercise.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "pandas",
            "dataframe"
        ]
    },
    {
        "question_id": "4483886",
        "question": "\nHow can I get a count of the total number of digits of a number in C#? For example, the number 887979789 has 9 digits.\n",
        "all_answers": [
            "\nIn the comment to the accepted answer there is a distinction made which seems to be worth highlighting in a separate answer.\nThe correct code:\ndouble num3 = (double)num1/(double)num2;\n\nis not the same as casting the result of integer division:\ndouble num3 = (double)(num1/num2);\n\nGiven num1 = 7 and num2 = 12:\nThe correct code will result in num3 = 0.5833333\nCasting the result of integer division will result in num3 = 0.00\n",
            "\nThe easiest way to do that is adding decimal places to your integer.\nEx.:\nvar v1 = 1 / 30 //the result is 0\nvar v2 = 1.00 / 30.00 //the result is 0.033333333333333333\n\n",
            "\nstatic void Main(string[] args)\n{\n    long blah = 20948230498204;\n    Console.WriteLine(blah.ToString().Length);\n}\n\n",
            "\ndividing a number by 10 will give you the left most digit then doing a mod 10 on the number gives the number without the first digit and repeat that till you have all the digits\n",
            "\nYou want to cast the numbers:\ndouble num3 = (double)num1/(double)num2;\n\nNote: If any of the arguments in C# is a double, a double divide is used which results in a double. So, the following would work too:\ndouble num3 = (double)num1/num2;\n\nFor more information see: \nDot Net Perls\n",
            "\nWithout converting to a string you could try\nMath.Floor(Math.Log10(n) + 1);\n\n",
            "\nint i = 855865264;\nint NumLen = i.ToString().Length;\n\n",
            "\nI have went through most of the answers and im pretty sure that it's unachievable. Whatever you try to divide two int into double or float is not gonna happen.\nBut you have tons of methods to make the calculation happen, just cast them into float or double before the calculation will be fine.\n",
            "\nIt depends what exactly you want to do with the digits. You can iterate through the digits starting from the last to the first one like this:\nint tmp = number;\nint lastDigit = 0;\ndo\n{\n    lastDigit = tmp / 10;\n    doSomethingWithDigit(lastDigit);\n    tmp %= 10;\n} while (tmp != 0);\n\n",
            "\nComplementing the @NoahD's answer\nTo have a greater precision you can cast to decimal:\n(decimal)100/863\n//0.1158748551564310544611819235\n\nOr:\nDecimal.Divide(100, 863)\n//0.1158748551564310544611819235\n\nDouble are represented allocating 64 bits while decimal uses 128\n(double)100/863\n//0.11587485515643106\n\nIn depth explanation of \"precision\"\nFor more details about the floating point representation in binary and its precision take a look at this article from Jon Skeet where he talks about floats and doubles and this one where he talks about decimals.\n",
            "\nTry This:   \nmyint.ToString().Length\n\nDoes that work ?\n",
            "\nvar result = decimal.ToDouble(decimal.Divide(5, 2));\n\n",
            "\ncast the integers to doubles.\n",
            "\nvar firstNumber=5000,\nsecondeNumber=37;\n\nvar decimalResult = decimal.Divide(firstNumber,secondeNumber);\n\nConsole.WriteLine(decimalResult );\n\n",
            "\nConvert one of them to a double first.  This form works in many languages:\n real_result = (int_numerator + 0.0) / int_denominator\n\n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            "math",
            "numbers"
        ]
    },
    {
        "question_id": "1123718",
        "question": "\nI have an XML string as such:\n<?xml version='1.0'?><response><error code='1'> Success</error></response>\n\nThere are no lines between one element and another, and thus is very difficult to read. I want a function that formats the above string:\n<?xml version='1.0'?>\n<response>\n<error code='1'> Success</error>\n</response> \n\nWithout resorting to manually write the format function myself, is there any .Net library or code snippet that I can use offhand?\n",
        "all_answers": [
            "\nif you load up the XMLDoc I'm pretty sure the .ToString() function posses an overload for this.\nBut is this for debugging?  The reason that it is sent like that is to take up less space (i.e stripping unneccessary whitespace from the XML).\n",
            "\nUse XmlTextWriter...\npublic static string PrintXML(string xml)\n{\n    string result = \"\";\n\n    MemoryStream mStream = new MemoryStream();\n    XmlTextWriter writer = new XmlTextWriter(mStream, Encoding.Unicode);\n    XmlDocument document = new XmlDocument();\n\n    try\n    {\n        // Load the XmlDocument with the XML.\n        document.LoadXml(xml);\n\n        writer.Formatting = Formatting.Indented;\n\n        // Write the XML into a formatting XmlTextWriter\n        document.WriteContentTo(writer);\n        writer.Flush();\n        mStream.Flush();\n\n        // Have to rewind the MemoryStream in order to read\n        // its contents.\n        mStream.Position = 0;\n\n        // Read MemoryStream contents into a StreamReader.\n        StreamReader sReader = new StreamReader(mStream);\n\n        // Extract the text from the StreamReader.\n        string formattedXml = sReader.ReadToEnd();\n\n        result = formattedXml;\n    }\n    catch (XmlException)\n    {\n        // Handle the exception\n    }\n\n    mStream.Close();\n    writer.Close();\n\n    return result;\n}\n\n",
            "\nCheck the following link: How to pretty-print XML (Unfortunately, the link now returns 404 :()\nThe method in the link takes an XML string as an argument and returns a well-formed (indented) XML string. \nI just copied the sample code from the link to make this answer more comprehensive and convenient.  \npublic static String PrettyPrint(String XML)\n{\n    String Result = \"\";\n\n    MemoryStream MS = new MemoryStream();\n    XmlTextWriter W = new XmlTextWriter(MS, Encoding.Unicode);\n    XmlDocument D   = new XmlDocument();\n\n    try\n    {\n        // Load the XmlDocument with the XML.\n        D.LoadXml(XML);\n\n        W.Formatting = Formatting.Indented;\n\n        // Write the XML into a formatting XmlTextWriter\n        D.WriteContentTo(W);\n        W.Flush();\n        MS.Flush();\n\n        // Have to rewind the MemoryStream in order to read\n        // its contents.\n        MS.Position = 0;\n\n        // Read MemoryStream contents into a StreamReader.\n        StreamReader SR = new StreamReader(MS);\n\n        // Extract the text from the StreamReader.\n        String FormattedXML = SR.ReadToEnd();\n\n        Result = FormattedXML;\n    }\n    catch (XmlException)\n    {\n    }\n\n    MS.Close();\n    W.Close();\n\n    return Result;\n}\n\n",
            "\nYou will have to parse the content somehow ... I find using LINQ the most easy way to do it. Again, it all depends on your exact scenario. Here's a working example using LINQ to format an input XML string.\nstring FormatXml(string xml)\n{\n     try\n     {\n         XDocument doc = XDocument.Parse(xml);\n         return doc.ToString();\n     }\n     catch (Exception)\n     {\n         // Handle and throw if fatal exception here; don't just ignore them\n         return xml;\n     }\n }\n\n[using statements are ommitted for brevity]\n"
        ],
        "answer": "A4",
        "tags": [
            "c#",
            "xml",
            "formatting"
        ]
    },
    {
        "question_id": "14817051",
        "question": "\nI'm curious why GitHub calls submissions to merge, \"Pull requests.\"\nFrom my understanding, git pull will pull all changes, from a remote repository, into a current working branch.  Then merge those changes with FETCH_HEAD. (Git Pull)\nSo taking a look at git push... a push would actually push committed changes to a repository.  And isn't that what you are doing with a Git repo?  Submitting a \"request\" to merge your code? So why isn't it called a \"Push request\"?\n",
        "all_answers": [
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nThe term “pull requests” comes from the distributed nature of how many open source projects organize themselves. Instead of just pushing your changes into the repository (like you would do with a centralized repository, e.g. with Subversion), you are publishing your changes separately and ask the maintainer to pull in your changes. The maintainer then can look over the changes and do said pull.\n",
            "\nWhen you send your patch to someone else, you want that person to merge your change into his repository. Now, a pull is a fetch and a merge. So, if that person pulls your change, he will have merged it, too, which is what you want.\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nYou push commits from from your private repository to your public repository. You can't however, force changes on someone else's repository, so you request that they pull from your public repository to theirs.\n",
            "\nA pull request is when a contributor that does not have push access to a repository wants to submit code for inclusion in the project.  For instance, if you have a project on github and you are the only person with commit rights and I want to include code in your project what do I do?\nI'll fork your github repository and create a new branch for my work.  Once I'm happy with the current implementation I'll send you a request to git pull my branch into your repository (since I don't have rights to push directly).  When you do git pull you have the option of which branch to pull and where you want to pull to.  Perhaps you don't want to pull directly into your master branch but into some other branch to examine the code.\nThe git book has a nice section on different work flows like this.\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nWhen you submit a pull request, you ask the owner of the repo to pull your changes in their local repo (i.e. merge them). Then that repo will be published (via git push) to a public repo but this is implied. \nYou cannot call this \"push request\" because nobody pushes your changes, they pull them.\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n"
        ],
        "answer": "A2",
        "tags": [
            "git",
            "github",
            "terminology"
        ]
    },
    {
        "question_id": "427102",
        "question": "\nWhen I read Django code I often see in models what is called a \"slug\". I am not quite sure what this is, but I do know it has something to do with URLs. How and when is this slug-thing supposed to be used?\nI have read its definition below in this glossary:\n\nSlug\nA short label for something, containing only letters, numbers,\nunderscores or hyphens. They’re generally used in URLs. For example,\nin a typical blog entry URL:\nhttps://www.djangoproject.com/weblog/2008/apr/12/spring/ the last bit\n(spring) is the slug.\n\n",
        "all_answers": [
            "\nIt's a descriptive part of the URL that is there to make it more human descriptive, but without necessarily being required by the web server - in What is a \"slug\" in Django? the slug is 'in-django-what-is-a-slug', but the slug is not used to determine the page served (on this site at least)\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nA \"slug\" is a way of generating a valid URL, generally using data already obtained. For instance, a slug uses the title of an article to generate a URL. I advise to generate the slug by means of a function, given the title (or another piece of data), rather than setting it manually.\nAn example:\n<title> The 46 Year Old Virgin </title>\n<content> A silly comedy movie </content>\n<slug> the-46-year-old-virgin </slug>\n\nNow let's pretend that we have a Django model such as:\nclass Article(models.Model):\n    title = models.CharField(max_length=100)\n    content = models.TextField(max_length=1000)\n    slug = models.SlugField(max_length=40)\n\nHow would you reference this object with a URL and with a meaningful name? You could for instance use Article.id so the URL would look like this:\nwww.example.com/article/23\n\nOr, you might want to reference the title like this:\nwww.example.com/article/The 46 Year Old Virgin\n\nSince spaces aren't valid in URLs, they must be replaced by %20, which results in:\nwww.example.com/article/The%2046%20Year%20Old%20Virgin\n\nBoth attempts are not resulting in very meaningful, easy-to-read URL. This is better:\nwww.example.com/article/the-46-year-old-virgin\n\nIn this example, the-46-year-old-virgin is a slug: it is created from the title by down-casing all letters, and replacing spaces by hyphens -. \nAlso see the URL of this very web page for another example.\n",
            "\nFrom here.\n\n“Slug” is a newspaper term, but what\n  it means here is the final bit of the\n  URL. For example, a post with the\n  title, “A bit about Django” would\n  become, “bit-about-django”\n  automatically (you can, of course,\n  change it easily if you don’t like the\n  auto-generated slug).\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "django",
            "url",
            "django-models",
            "slug"
        ]
    },
    {
        "question_id": "12921658",
        "question": "\nI am using the Express framework in node.js with some middleware functions:\nvar app = express.createServer(options);\napp.use(User.checkUser);\n\nI can use the .use function with an additional parameter to use this middleware only on specific paths:\napp.use('/userdata', User.checkUser);\n\nIs it possible to use the path variable so that the middleware is used for all paths except a specific one, i.e. the root path?\nI am thinking about something like this:\napp.use('!/', User.checkUser);\n\nSo User.checkUser is always called except for the root path.\n",
        "all_answers": [
            "\nInstead of directly registering User.checkUser as middleware, register a new helper function, say checkUserFilter, that gets called on every URL, but passed execution to userFiled` only on given URLs. Example:\nvar checkUserFilter = function(req, res, next) {\n    if(req._parsedUrl.pathname === '/') {\n        next();\n    } else {\n        User.checkUser(req, res, next);\n    }\n}\n\napp.use(checkUserFilter);\n\nIn theory, you could provide regexp paths to app.use. For instance something like:\napp.use(/^\\/.+$/, checkUser);\n\nTried it on express 3.0.0rc5, but it doesn't work.\nMaybe we could open a new ticket and suggest this as a feature?\n",
            "\nYou can also set the path that static files will be served to the web from by specifying an additional (first) parameter to use() like so:\napp.use(\"/public\", express.static(__dirname + \"/public\"));\napp.use(\"/public2\", express.static(__dirname + \"/public2\"));\n\nThat way you get two different directories on the web that mirror your local directories, not one url path that fails over between two local directories.\nIn other words the URL pattern:\nhttp://your.server.com/public/*\n\nServes files from the local directory public while:\nhttp://your.server.com/public2/*\n\nServes files from the local directory public2.\nBTW this is also useful if you don't want static to serve the files from the root of your server but rather from a more qualified path.\nHTH\n",
            "\nI would add checkUser middleware to all my paths, except homepage.\napp.get('/', routes.index);\napp.get('/account', checkUser, routes.account);\n\nor\napp.all('*', checkUser);\n    \nfunction checkUser(req, res, next) {\n  if ( req.path == '/') return next();\n\n  //authenticate user\n  next();\n}\n\nYou could extend this to search for the req.path in an array of non-authenticated paths:\nfunction checkUser(req, res, next) {\n  const nonSecurePaths = ['/', '/about', '/contact'];\n  if (nonSecurePaths.includes(req.path)) return next();\n\n  //authenticate user\n  next();\n}\n\n",
            "\nYou can also \"merge\" directories into a single visible directory\nDirectory Structure\n\n/static\n/alternate_static\n\nCode\napp.use(\"/static\", express.static(__dirname + \"/static\"));\napp.use(\"/static\", express.static(__dirname + \"/alternate_static\"));\n\nBoth static and alternate_static will be served as if they were in the same directory. Watch out for filename clobbers, though. \n"
        ],
        "answer": "A3",
        "tags": [
            "node.js",
            "routes",
            "express",
            "middleware"
        ]
    },
    {
        "question_id": "1654960",
        "question": "\n\n\n\nIs there any guidelines on how to differentiate between .nil?, .blank? and .empty??\nI'm generally always confused as to when to use them in my application as they all seem to mean the same thing but have different meanings.\nDoes anyone have any cheat sheet on the gory details?\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\n\nnil? - checks to see if variable is referencing an object or not\nempty? - may be used to check on various object types like empty string \"\" or empty array []\nblank? - checks for nil? or empty?. \n\n",
            "\nI found a good explanation here:\n\nnil? tests whether the object is\n  exactly nil, that is whether it is the\n  one and only want instance of\n  NilClass.\nempty? is a method some objects\n  respond to. You need to check the\n  documentation for each case. For\n  example, and empty array is one that\n  is not nil (it is an array right?) and\n  has no elements. An empty string is\n  one that is not nil (it is a string\n  right?) and has no bytes, nothing.\nThe blank? method you ask for does not\n  belong to Ruby, it is a Rails\n  extension:\n  http://api.rubyonrails.com/classes/Object.html#M000011.\n\nIf you click through to the link at the end of that post you will find that the blank? method simply combines the nil? and empty? method calls.\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "ruby"
        ]
    },
    {
        "question_id": "2406537",
        "question": "\nThese formsets are exhibiting exactly the opposite behavior that I want.\nMy view is set up like this:\ndef post(request): # TODO: handle vehicle formset\n    VehicleFormSetFactory = formset_factory(VehicleForm, extra=1)\n    if request.POST:\n        vehicles_formset = VehicleFormSetFactory(request.POST)\n    else:\n        vehicles_formset = VehicleFormSetFactory()\n\nAnd my template looks like this:\n    <div id=\"vehicle_forms\">\n        {{ vehicles_formset.management_form }}\n        {% for form in vehicles_formset.forms %}\n            <h4>Vehicle {{forloop.counter}}</h4>\n            <table>\n                {% include \"form.html\" %}\n            </table>\n        {% endfor %}\n    </div>\n\nThat way it initially generates only 1 form, like I want. But I want that one form to be required!\nWhen I dynamically add blank forms with JavaScript and vehicles_formset.empty_form all those extra forms are required, which I don't want.\nFrom the docs:\n\nThe formset is smart enough to ignore extra forms that were not changed. \n\nThis is the behavior the first form is exhibiting (not what I want) but not the behavior that the extra forms are exhibiting (what I do want).\nIs there some attribute I can can change to at least make one form required?\n",
        "all_answers": [
            "\nOh I think I see. Try this:\nfrom django.forms.formsets import BaseFormSet, formset_factory\nclass OneExtraRequiredFormSet(BaseFormSet):\n    def initial_form_count(self):\n        return max(super(OneExtraRequiredFormSet,self).initial_form_count() - 1,0)\n\nVehicleFormSetFactory = formset_factory(VehicleForm, formset=OneExtraRequiredFormSet, extra=1)\n\n== Original answer below ==\nWhen you say \"at least make one form required\", I assume you mean \"make only one extra form required, regardless of how many have been added via javascript\".\nYou will need to have hidden input on your page which contains the number of forms that have been added via javascript, and then use that number, minus 1, as the value to pass in as the extra attribute to your formsets constructor.\n",
            "\nWell... this makes the first form required.\nclass RequiredFormSet(BaseFormSet):\n    def clean(self):\n        if any(self.errors):\n            return\n        if not self.forms[0].has_changed():\n            raise forms.ValidationError('Please add at least one vehicle.') \n\nOnly \"problem\" is that if there are 0 forms, then the clean method doesn't seem to get called at all, so I don't know how to check if there are 0. Really...this should never happen though (except that my JS has a bug in it, allowing you to remove all the forms).\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nFound a better solution:\nclass RequiredFormSet(BaseFormSet):\n    def __init__(self, *args, **kwargs):\n        super(RequiredFormSet, self).__init__(*args, **kwargs)\n        for form in self.forms:\n            form.empty_permitted = False\n\nThen create your formset like this:\nMyFormSet = formset_factory(MyForm, formset=RequiredFormSet)\n\nI really don't know why this wasn't an option to begin with... but, whatever. It only took a few hours of my life to figure out.\nThis will make all the forms required. You could make just the first one required by setting self.forms[0].empty_permitted to False.\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "django",
            "django-forms"
        ]
    },
    {
        "question_id": "2359895",
        "question": "\nI'm writing my first Android app for a small business that has some Droid phones. I set up an AVD for the phone with the right resolution: 854 pixels high. \nI'm working on a MacBook Pro with a max screen resolution 900 pixels high, so when the emulator starts up, the bottom is cut off. \nIs there a way to scale the emulator display down to 75% or something so that it fits on my screen? Any other solution (other than running everything on the phone itself)?\n",
        "all_answers": [
            "\nQuoting Streets of Boston from his adt-dev post:\n\nWhen upgrading, the 'Order and Export' of the new 'Android Private \n  Libraries' is not always checked. And the android-support-v4.jar is now in \n  this 'Android Private Libraries' section. \nTo fix this, go to 'Order and Export' and check 'Android Private \n  Libraries'. Then refresh/clean/rebuild. \nAfter you done this 'fix' for a library project, you may need to just close \n  and re-open any depending project, because they may not see this 'fix' \n  immediately. \n\nGive this a shot and with luck it will solve your problem.\n\n",
            "\nSimply checking Android Private Libraries was not enough, I also had to install Android SDK Build-tools in Android SDK Manager.\n",
            "\nFrom within Eclipse:\n\nGo to Window > Android SDK and AVD Manager > Virtual Devices\nSelect the AVD you want to launch and click Start\nCheck the Scale display to real size button\nEnter how big you want it to appear in inches and press Launch.  For this to work, you'll have to also enter a reasonable approximation of your mac's screen resolution.  I'm using 7 inches and 113 dpi for my 13\" Macbook Pro, but you may be able to get away with 8 or 9 inches.\n\n",
            "\nI had the same problem. It was because of the eclipse project.\nTo solve it I created a new project in eclipse, copy my existing project classes and resources into it and then launched eclipse again and added my custom includes.\n",
            "\nI had also the same problem and my adt was 22.0.1. And none of the solution above worked. Further when adding a external library project to a working project.I always check the gen folder of working project and if R of external library project is there (along with package name),then only external library project is exported. And on my gen folder no packagename of external library was shown.\nSo I checked  on project.properties file and there wasn't any external library link present android.library.reference.1= present. So I manually added the external library reference there ,even though I had added from project->properties->Java Build Path->Projects->Add. So manually editing the project.properties did all the work for me.\n\n",
            "\nI have encountered a similar problem, spent about 3 hours, but none of the proposed here decisions did not help... Finally I found a source of the problem: my project files & project.properties were read-only. Eclipse is simply silently ignoring any changes in library dependencies when I doing it in the GUI!\n",
            "\nI had the similar issue and my answer is slightly different from CommonsWare's. Here is my screenshot:\n\nAfter checking the libs back in my build started to work again.\n",
            "\nIf you launch your emulator outside of Eclipse, using the android command, you will be able to scale the screen as part of the launch process. Not sure how to do that in Eclipse, though.\n",
            "\nI had also the same problem,\ni) add gson lib as referecend librairies \nii) check it in java Build Path\n\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "eclipse",
            "emulation"
        ]
    },
    {
        "question_id": "2330840",
        "question": "\nI am using MySQL. Here is my schema:\nSuppliers(sid: integer, sname: string, address string)\nParts(pid: integer, pname: string, color: string)\nCatalog(sid: integer, pid: integer, cost: real)\n(primary keys are bolded)\nI am trying to write a query to select all parts that are made by at least two suppliers:\n-- Find the pids of parts supplied by at least two different suppliers.\nSELECT c1.pid                      -- select the pid\nFROM Catalog AS c1                 -- from the Catalog table\nWHERE c1.pid IN (                  -- where that pid is in the set:\n    SELECT c2.pid                  -- of pids\n    FROM Catalog AS c2             -- from catalog\n    WHERE c2.pid = c1.pid AND COUNT(c2.sid) >= 2 -- where there are at least two corresponding sids\n);\n\nFirst off, am I even going about this the right way?\nSecondly, I get this error: \n\n1111 - Invalid use of group function\n\nWhat am I doing wrong?\n",
        "all_answers": [
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n"
        ],
        "answer": "A4",
        "tags": [
            "mysql",
            "sql",
            "mysql-error-1111"
        ]
    },
    {
        "question_id": "10562915",
        "question": "\nLet's call this table terms_relation:\n+---------+----------+-------------+------------+------------+--+\n| term_id | taxonomy | description | created_at | updated_at |  |\n+---------+----------+-------------+------------+------------+--+\n|       1 | categ    | non         | 3434343434 |   34343433 |  |\n|       2 | categ    | non         | 3434343434 | 3434343434 |  |\n|       3 | tag      | non         | 3434343434 | 3434343434 |  |\n|       4 | tag      | non         | 3434343434 | 3434343434 |  |\n+---------+----------+-------------+------------+------------+--+\n\nAnd this is table terms:\n+----+-------------+-------------+\n| id |    name     |    slug     |\n+----+-------------+-------------+\n|  1 | hello       | hello       |\n|  2 | how are you | how-are-you |\n|  3 | tutorial    | tutorial    |\n|  4 | the end     | the-end     |\n+----+-------------+-------------+\n\nHow Do I select all rows in table terms and table terms_relation where it's taxonomy in table terms_relation is categ? Will I need two queries for this or I could use a join statement?\n",
        "all_answers": [
            "\nYou can use a subquery:\nSELECT *\nFROM terms\nWHERE id IN (SELECT term_id FROM terms_relation WHERE taxonomy='categ');\n\nand if you need to show all columns from both tables:\nSELECT t.*, tr.*\nFROM terms t, terms_relation tr\nWHERE t.id = tr.term_id\nAND tr.taxonomy='categ'\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nTry this (subquery):\nSELECT * FROM terms WHERE id IN \n   (SELECT term_id FROM terms_relation WHERE taxonomy = \"categ\")\n\nOr you can try this (JOIN):\nSELECT t.* FROM terms AS t \n   INNER JOIN terms_relation AS tr \n   ON t.id = tr.term_id AND tr.taxonomy = \"categ\"\n\nIf you want to receive all fields from two tables:\nSELECT t.id, t.name, t.slug, tr.description, tr.created_at, tr.updated_at \n  FROM terms AS t \n   INNER JOIN terms_relation AS tr \n   ON t.id = tr.term_id AND tr.taxonomy = \"categ\"\n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n"
        ],
        "answer": "A3",
        "tags": [
            "mysql",
            "sql",
            "database"
        ]
    },
    {
        "question_id": "29560805",
        "question": "\nI have 2 models as describes below.\nclass EmpGroup < ActiveRecord::Base\n  belongs_to :user\n  has_many :emp_group_members, dependent: :destroy\nend\n\nand \nclass EmpGroupMember < ActiveRecord::Base\n  belongs_to :emp_group\n  belongs_to :user\nend\n\nnow the problem is whenever I tried to destroy a group then I received a error as below.\nPG::ForeignKeyViolation: ERROR:  update or delete on table \"emp_groups\" violates foreign key constraint \"fk_rails_bd68440021\" on table \"emp_group_members\"\nDETAIL:  Key (id)=(1) is still referenced from table \"emp_group_members\".\n\nWhat I'm missing?\n",
        "all_answers": [
            "\nWhen you delete a group, are you using delete or destroy. - I've had this error before, and it was because I had a typo and was using .delete instead of .destroy\n",
            "\nAdd cascading delete to your EmpGroup model:\nclass EmpGroup < ActiveRecord::Base\n   has_many :emp_group_members, dependent: :delete_all\nend\n\nOr\nAre you calling delete method? you should call destroy instead.\nUse .destroy\n",
            "\n:dependent is one of the options available in belongs_to association\nIf you set the :dependent option to:\n\n:destroy, when the object is destroyed, destroy will be called on its associated objects.\n:delete, when the object is destroyed, all its associated objects will be deleted directly from the database without calling their destroy method.\n\nAdditionally, objects will be destroyed if they're associated with dependent: :destroy, and deleted if they're associated with dependent: :delete_all.\nin has_many associations:\n:destroy causes all the associated objects to also be destroyed\n:delete_all causes all the associated objects to be deleted directly from the database (so callbacks will not execute)\n\nyou can try\n emp_member_1= @emp_group.emp_group_members.first\n ##delete associated record\n @emp_group.emp_group_members.delete(emp_member_1)\n\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "ruby-on-rails-3",
            "ruby-on-rails-4",
            "ruby-on-rails-3.2"
        ]
    },
    {
        "question_id": "3452381",
        "question": "\nAs far as I know, they are absolute equal. However, browsing some django docs, I've\nfound this piece of code:\nHttpResponse.__init__(content='', mimetype=None, status=200, content_type='text/html')\nwhich surprise me the two getting along each other. The official docs was able to solve the issue in a practical manner:\n\ncontent_type is an alias for mimetype.\nHistorically, this parameter was only\ncalled mimetype, but since this is\nactually the value included in the\nHTTP Content-Type header, it can also\ninclude the character set encoding,\nwhich makes it more than just a MIME\ntype specification. If mimetype is\nspecified (not None), that value is\nused. Otherwise, content_type is used.\nIf neither is given, the\nDEFAULT_CONTENT_TYPE setting is used.\n\nHowever, I don't find it elucidating enough. Why we use 2 different naming for (almost the same) thing? Is \"Content-Type\" just a name used in browser requests, and with very little use outside it?\nWhat's the main difference between the each one, and when is right to call something mimetype as opposed to content-type ? Am I being petty and a grammar nazi?\n",
        "all_answers": [
            "\n\nWhy we use 2 different naming for (almost the same) thing?\n\nBackwards compatibility, based on your quote from the documentation.\n",
            "\n\nWhy we use 2 different naming for\n  (almost the same) thing? Is\n  \"Content-Type\" just a name used in\n  browser requests, and with very little\n  use outside it?\nWhat's the main difference between the\n  each one, and when is right to call\n  something mimetype as opposed to\n  content-type ? Am i being pitty and\n  grammar nazi?\n\nThe reason isn't only backward compatibility, and I'm afraid the usually excellent Django documentation is a bit hand-wavy about it. MIME (it's really worth reading at least the Wikipedia entry) has its origin in extending internet mail, and specifically SMTP. From there, the MIME and MIME-inspired extension design has found its way into a lot of other protocols (such as HTTP here), and is still being used when new kinds of metadata or data need to be transmitted in an existing protocol. There are dozens of RFCs that discuss MIME used for a plethora of purposes.\nSpecifically, Content-Type: is one among several MIME headers. \"Mimetype\" does indeed sound obsolete, but a reference to MIME itself isn't. Call that part backward-compatibility, if you will.\n[BTW, this is purely a terminology problem which has nothing whatsoever to do with grammar. Filing every usage question under \"grammar\" is a pet peeve of mine. Grrrr.]\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django",
            "content-type",
            "mime-types"
        ]
    },
    {
        "question_id": "4486926",
        "question": "\nI'm using the Mongoose Library for accessing MongoDB with node.js\nIs there a way to remove a key from a document?  i.e. not just set the value to null, but remove it?\nUser.findOne({}, function(err, user){\n  //correctly sets the key to null... but it's still present in the document\n  user.key_to_delete = null;\n\n  // doesn't seem to have any effect\n  delete user.key_to_delete;\n\n  user.save();\n});\n\n",
        "all_answers": [
            "\nIn early versions, you would have needed to drop down the node-mongodb-native driver. Each model has a collection object that contains all the methods that node-mongodb-native offers. So you can do the action in question by this:\nUser.collection.update({_id: user._id}, {$unset: {field: 1 }});\n\nSince version 2.0 you can do:\nUser.update({_id: user._id}, {$unset: {field: 1 }}, callback);\n\nAnd since version 2.4, if you have an instance of a model already you can do:\ndoc.field = undefined;\ndoc.save(callback);\n\n",
            "\nmongoose.connection.close(function(){\nconsole.log('Mongoose default connection disconnected through app termination');\nprocess.exit(0);\n});\n\nThis will close the mongoose connection and will also notify you by message in your console.\n",
            "\nCould this be a side problem like using\nfunction (user)\n\ninstead of\nfunction(err, user)\n\nfor the find's callback ? Just trying to help with this as I already had the case.\n",
            "\nYou will get an error if you try to close/disconnect outside of the method. The best solution is to close the connection in both callbacks in the method. The dummy code is here.\nconst newTodo = new Todo({text:'cook dinner'});\n\nnewTodo.save().then((docs) => {\n  console.log('todo saved',docs);\n  mongoose.connection.close();\n},(e) => {\n  console.log('unable to save');\n});\n\n",
            "\nYou'll want to do this:\nUser.findOne({}, function(err, user){\n  user.key_to_delete = undefined;\n  user.save();\n});\n\n",
            "\nAt mongo syntax to delete some key you need do following:\n{ $unset : { field : 1} }\n\nSeems at Mongoose the same. \nEdit\nCheck this example.\n",
            "\nYou can close the connection with\nmongoose.connection.close()\n\n",
            "\nJust as Jake Wilson said: You can set the connection to a variable then disconnect it when you are done:\nlet db;\nmongoose.connect('mongodb://localhost:27017/somedb').then((dbConnection)=>{\n    db = dbConnection;\n    afterwards();\n});\n\n\nfunction afterwards(){\n\n    //do stuff\n\n    db.disconnect();\n}\n\nor if inside Async function:\n(async ()=>{\n    const db = await mongoose.connect('mongodb://localhost:27017/somedb', { useMongoClient: \n                  true })\n\n    //do stuff\n\n    db.disconnect()\n})\n\notherwise when i was checking it in my environment it has an error.\n",
            "\nYou can set the connection to a variable then disconnect it when you are done:\nvar db = mongoose.connect('mongodb://localhost:27017/somedb');\n\n// Do some stuff\n\ndb.disconnect();\n\n",
            "\nThe other answer didn't work for me. I had to use mongoose.disconnect(); as stated in this answer. \n",
            "\nI'm using version 4.4.2 and none of the other answers worked for me. But adding useMongoClient to the options and putting it into a variable that you call close on seemed to work. \nvar db = mongoose.connect('mongodb://localhost:27017/somedb', { useMongoClient: true })\n\n//do stuff\n\ndb.close()\n\n"
        ],
        "answer": "A1",
        "tags": [
            "mongodb",
            "node.js",
            "mongoose",
            "document-database"
        ]
    },
    {
        "question_id": "1111980",
        "question": "\nMy program does some network activity in a background thread. Before starting, it pops up a progress dialog. The dialog is dismissed on the handler. This all works fine, except when screen orientation changes while the dialog is up (and the background thread is going). At this point the app either crashes, or deadlocks, or gets into a weird stage where the app does not work at all until all the threads have been killed.\nHow can I handle the screen orientation change gracefully?\nThe sample code below matches roughly what my real program does:\npublic class MyAct extends Activity implements Runnable {\n    public ProgressDialog mProgress;\n\n    // UI has a button that when pressed calls send\n\n    public void send() {\n         mProgress = ProgressDialog.show(this, \"Please wait\", \n                      \"Please wait\", \n                      true, true);\n        Thread thread = new Thread(this);\n        thread.start();\n    }\n\n    public void run() {\n        Thread.sleep(10000);\n        Message msg = new Message();\n        mHandler.sendMessage(msg);\n    }\n\n    private final Handler mHandler = new Handler() {\n        @Override\n        public void handleMessage(Message msg) {\n            mProgress.dismiss();\n        }\n    };\n}\n\nStack:\nE/WindowManager(  244): Activity MyAct has leaked window com.android.internal.policy.impl.PhoneWindow$DecorView@433b7150 that was originally added here\nE/WindowManager(  244): android.view.WindowLeaked: Activity MyAct has leaked window com.android.internal.policy.impl.PhoneWindow$DecorView@433b7150 that was originally added here\nE/WindowManager(  244):     at android.view.ViewRoot.<init>(ViewRoot.java:178)\nE/WindowManager(  244):     at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:147)\nE/WindowManager(  244):     at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:90)\nE/WindowManager(  244):     at android.view.Window$LocalWindowManager.addView(Window.java:393)\nE/WindowManager(  244):     at android.app.Dialog.show(Dialog.java:212)\nE/WindowManager(  244):     at android.app.ProgressDialog.show(ProgressDialog.java:103)\nE/WindowManager(  244):     at android.app.ProgressDialog.show(ProgressDialog.java:91)\nE/WindowManager(  244):     at MyAct.send(MyAct.java:294)\nE/WindowManager(  244):     at MyAct$4.onClick(MyAct.java:174)\nE/WindowManager(  244):     at android.view.View.performClick(View.java:2129)\nE/WindowManager(  244):     at android.view.View.onTouchEvent(View.java:3543)\nE/WindowManager(  244):     at android.widget.TextView.onTouchEvent(TextView.java:4664)\nE/WindowManager(  244):     at android.view.View.dispatchTouchEvent(View.java:3198)\n\nI have tried to dismiss the progress dialog in onSaveInstanceState, but that just prevents an immediate crash. The background thread is still going, and the UI is in partially drawn state. Need to kill the whole app before it starts working again.\n",
        "all_answers": [
            "\nWhen you switch orientations, Android will create a new View.  You're probably getting crashes because your background thread is trying to change the state on the old one.  (It may also be having trouble because your background thread isn't on the UI thread)\nI'd suggest making that mHandler volatile and updating it when the orientation changes.\n",
            "\nMove the long task to a seperate class. Implement it as a subject-observer pattern. Whenever the activity is created register and while closing unregister with the task class. Task class can use AsyncTask.\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "android-activity",
            "android-dialog"
        ]
    },
    {
        "question_id": "898307",
        "question": "\nI have a textbox with the .Multiline property set to true.  At regular intervals, I am adding new lines of text to it.  I would like the textbox to automatically scroll to the bottom-most entry (the newest one) whenever a new line is added.  How do I accomplish this?\n",
        "all_answers": [
            "\nTry to add the suggested code to the TextChanged event:\nprivate void textBox1_TextChanged(object sender, EventArgs e)\n{\n  textBox1.SelectionStart = textBox1.Text.Length;\n  textBox1.ScrollToCaret();\n}\n\n",
            "\nYou can use the following code snippet:\nmyTextBox.SelectionStart = myTextBox.Text.Length;\nmyTextBox.ScrollToCaret();\n\nwhich will automatically scroll to the end.\n",
            "\nIt seems the interface has changed in .NET 4.0.  There is the following method that achieves all of the above. As Tommy Engebretsen suggested, putting it in a TextChanged event handler makes it automatic.\ntextBox1.ScrollToEnd();\n\n",
            "\nI needed to add a refresh:\ntextBox1.SelectionStart = textBox1.Text.Length;\ntextBox1.ScrollToCaret();\ntextBox1.Refresh();\n\n",
            "\nYou can use Cursor.Current.\n// Set cursor as hourglass\nCursor.Current = Cursors.WaitCursor;\n\n// Execute your time-intensive hashing code here...\n\n// Set cursor as default arrow\nCursor.Current = Cursors.Default;\n\nHowever, if the hashing operation is really lengthy (MSDN defines this as more than 2-7 seconds), you should probably use a visual feedback indicator other than the cursor to notify the user of the progress. For a more in-depth set of guidelines, see this article.\nEdit:\nAs @Am pointed out, you may need to call Application.DoEvents(); after Cursor.Current = Cursors.WaitCursor; to ensure that the hourglass is actually displayed. \n",
            "\n\nAt regular intervals, I am adding new lines of text to it. I would like the textbox to automatically scroll to the bottom-most entry (the newest one) whenever a new line is added.\n\nIf you use TextBox.AppendText(string text), it will automatically scroll to the end of the newly appended text. It avoids the flickering scrollbar if you're calling it in a loop.\nIt also happens to be an order of magnitude faster than concatenating onto the .Text property. Though that might depend on how often you're calling it; I was testing with a tight loop.\n\nThis will not scroll if it is called before the textbox is shown, or if the textbox is otherwise not visible (e.g. in a different tab of a TabPanel). See TextBox.AppendText() not autoscrolling. This may or may not be important, depending on if you require autoscroll when the user can't see the textbox.\nIt seems that the alternative method from the other answers also don't work in this case. One way around it is to perform additional scrolling on the VisibleChanged event:\ntextBox.VisibleChanged += (sender, e) =>\n{\n    if (textBox.Visible)\n    {\n        textBox.SelectionStart = textBox.TextLength;\n        textBox.ScrollToCaret();\n    }\n};\n\n\nInternally, AppendText does something like this:\ntextBox.Select(textBox.TextLength + 1, 0);\ntextBox.SelectedText = textToAppend;\n\nBut there should be no reason to do it manually.\n(If you decompile it yourself, you'll see that it uses some possibly more efficient internal methods, and has what seems to be a minor special case.)\n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            "winforms",
            "textbox",
            "scroll"
        ]
    },
    {
        "question_id": "36788169",
        "question": "\nAre the two approaches the same or are there major differences/pitfalls to be aware of:\nclass MyClassSingleton {\n  static let sharedInstance = MyClassSingleton()\n  private init(){}\n\n  func helloClass() { print(\"hello from class Singleton\") }\n}\n\nstruct MyStructSingleton {\n  static let sharedInstance = MyStructSingleton()\n  private init() {}\n\n  func helloStruct() { print(\"hello from struct Singleton\") }\n}\n\n",
        "all_answers": [
            "\nThe main difference is that class-based mutable singleton works, while struct-based mutable \"singleton\" doesn't. Unless you want to make your singleton immutable (which is rare) you should stick to the class-based one.\nHere is an illustration of how mutable struct-based \"singleton\" does not work. Consider adding a mutable member state to both singletons, like this:\nclass MyClassSingleton {\n    static let sharedInstance = MyClassSingleton()\n    private init(){}\n    var state = 5\n    func helloClass() { print(\"hello from class Singleton: \\(state)\") }\n}\n\nstruct MyStructSingleton {\n    static let sharedInstance = MyStructSingleton()\n    private init() {}\n    var state = 5\n    func helloStruct() { print(\"hello from struct Singleton: \\(state)\") }\n}\n\nI made state a var, but I could expose it as a read-only property plus a mutating method; the essential thing is that both types are now mutable.\nIf I do this\nlet csi = MyClassSingleton.sharedInstance\ncsi.state = 42\nMyClassSingleton.sharedInstance.helloClass()\n\n42 gets printed, because csi is referencing the shared instance.\nHowever, when I do the same thing with struct-based singleton\nvar ssi = MyStructSingleton.sharedInstance\nssi.state = 42\nMyStructSingleton.sharedInstance.helloStruct()\n\n5 gets printed instead, because ssi is a copy of the sharedInstance, which is, of course, an indication that our singleton is not actually a singleton.\n",
            "\nThat depends on what you want to achieve and how you want to use your structure based on differences between class and struct. Most common thing that you will see is using class with singleton object.\nSingletons are pretty much the same, they are only created once, but you will get different behaviors from the class and from struct because:\n\nClasses are reference types, while structs are value types\nStructs are used to define simple structures\nStructs can't be inherited\n\nThere are several more differences but you get the idea from this.\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "9570237",
        "question": "\n\n\n\nI want to create an app that uses the internet and I'm trying to create a function that checks if a connection is available and if it isn't, go to an activity that has a retry button and an explanation.\nAttached is my code so far, but I'm getting the error Syntax error, insert \"}\" to complete MethodBody.\nNow I have been placing these in trying to get it to work, but so far no luck...\npublic class TheEvoStikLeagueActivity extends Activity {\n    private final int SPLASH_DISPLAY_LENGHT = 3000;\n     \n    /** Called when the activity is first created. */\n    @Override\n    public void onCreate(Bundle icicle) {\n        super.onCreate(icicle);\n        setContentView(R.layout.main);\n     \n        private boolean checkInternetConnection() {\n            ConnectivityManager conMgr = (ConnectivityManager) getSystemService (Context.CONNECTIVITY_SERVICE);\n            // ARE WE CONNECTED TO THE NET\n            if (conMgr.getActiveNetworkInfo() != null\n                    && conMgr.getActiveNetworkInfo().isAvailable()\n                    && conMgr.getActiveNetworkInfo().isConnected()) {\n\n                return true;\n\n                /* New Handler to start the Menu-Activity\n                 * and close this Splash-Screen after some seconds.*/\n                new Handler().postDelayed(new Runnable() {\n                    public void run() {\n                        /* Create an Intent that will start the Menu-Activity. */\n                        Intent mainIntent = new Intent(TheEvoStikLeagueActivity.this, IntroActivity.class);\n                        TheEvoStikLeagueActivity.this.startActivity(mainIntent);\n                        TheEvoStikLeagueActivity.this.finish();\n                    }\n                }, SPLASH_DISPLAY_LENGHT);\n            } else {\n                return false;\n                     \n                Intent connectionIntent = new Intent(TheEvoStikLeagueActivity.this, HomeActivity.class);\n                TheEvoStikLeagueActivity.this.startActivity(connectionIntent);\n                TheEvoStikLeagueActivity.this.finish();\n            }\n        }\n    }\n\n            \n\n",
        "all_answers": [
            "\nThis method checks whether mobile is connected to internet and returns true if connected:\nprivate boolean isNetworkConnected() {\n    ConnectivityManager cm = (ConnectivityManager) getSystemService(Context.CONNECTIVITY_SERVICE);\n\n    return cm.getActiveNetworkInfo() != null && cm.getActiveNetworkInfo().isConnected();\n}\n\nin manifest,\n<uses-permission android:name=\"android.permission.ACCESS_WIFI_STATE\" />\n<uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" />\n\nEdit:\nThis method actually checks if device is connected to internet(There is a possibility it's connected to a network but not to internet).\npublic boolean isInternetAvailable() {\n    try {\n        InetAddress ipAddr = InetAddress.getByName(\"google.com\"); \n        //You can replace it with your name\n            return !ipAddr.equals(\"\");\n\n        } catch (Exception e) {\n            return false;\n    }\n}\n\n",
            "\nYou cannot create a method inside another method, move private boolean checkInternetConnection() { method out of onCreate\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "networking",
            "android-networking"
        ]
    },
    {
        "question_id": "19169787",
        "question": "\nIs there a way to notify people on change of some certain files? Specifically, I would like to track change of *.sql files and and notify our developers on a change. How can I configure post commit hooks to notify?\n",
        "all_answers": [
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nMake sure that your user account is added to the repository as a collaborator.\nSetting --> Collaborators\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nIf you want folks to get notified via email, and you want them to manage their own notifications, then https://app.github-file-watcher.com/ should do the trick - it monitors any public repo, and will notify you via email of changes to any file, a specific file, or some files that match your criteria. \n",
            "\nI got the same problem while using a github repository, and connecting to it via https, while using the OS X Keychain Credential helper.\nMy problem was that I had the wrong credentials stored in OS X's Keychain (I was using the email address that I used to sign up for github.com rather than the [username]@github.com address it provides you). I deleted the old account in the keychain and only left the @github.com one and it fixed the problem.\nNot sure if it is related, but when I checked the user.email local config:\ngit config -l\n\nit showed the incorrect email address as well, so I updated the local git user.email to use the correct account too:\ngit config user.email <username>@github.com\n\n",
            "\nMy issue was that I used the clone https url widget provided by github. That URL doesn't work for private repositories as you need to add a username to the front of it.  \nExample: a private repo owned by john and named widget with collaborator sam the correct url would be: \nhttps://sam@github.com/john/widget.git\nThe github provided url: \nhttps://github.com/john/widget.git\nThe error message leaves much to be desired.\n",
            "\nUse git diff-tree in your post-receive hook:\n git diff-tree --name-status -rz\n\nYou can grep the result to check if certain files are modified (status 'M'), as described in this answer.\nyou can find many examples on gist.github.com, with this one using the --name-status option.\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n"
        ],
        "answer": "A7",
        "tags": [
            "git",
            "github",
            "post-commit-hook"
        ]
    },
    {
        "question_id": "11891593",
        "question": "\nMemory Limits for Windows Releases answers what is the maximum amount of memory any single process on Windows can address:\n\nOn 32-bit versions of Windows, a single process can map and address no\nmore than 3GB of virtual memory at time. In 64-bit versions of\nWindows, a 32-bit process can map and address no more than 4GB of\nvirtual memory at a time.\nFor 64-bit processes, the amount is difficult to calculate as there\nare numerous overlapping limits that could apply depending on all\nkinds of factors. It's typically around 7TB.\n\nMy question: How to verify the values such as \"3GB\", \"4GB\" etc.?\nCan a C# program be written to prove it? Is there a method for it?\n",
        "all_answers": [
            "\nYou could write some kind of a loop in a console app to test this.\nMaybe create a string that is exactly 1MB and loop through a concatenation process to increase it's size until you get a ... Stack Overflow error.\nOn each iteration WriteLine the size, or number of iterations.\nEDIT\nI would add, since STRING is immutable (despite technically being a reference type) to use OBJECT\nEdit Two\nTrisped points out that a string boxed in an Object is still immutable.\nCreating an Array of bytes [1024] should do the trick.\n",
            "\nMark Russinovich published a multipart series on windows memory resources really covers this very well. You can find it here: \nhttp://blogs.technet.com/b/markrussinovich/archive/2008/07/21/3092070.aspx\nHe covers the reasons why the limits are what they are, as well as tests. The code for the tests are floating around in the tubes somewhere.\nIf you want to know about memory resources and the problems you can see from leaking the various types, it is a good read.\nBut, in a nutshell, 32 bit on 32 bit OS: 2 GB, unless set to large address space aware, in which case 3 GB. 32 bit on 64 bit OS: 2 GB, unless set to large address space aware, in which case 4 GB.\n64 bit process: 2 GB, unless set to large address space aware, in which case it could address up to 8 TB, unless it is hosted on an Intel Itanium-based systems which is limited to 7 TB.\nMicrosoft states the various limits (by flavors and types) at:\nhttp://msdn.microsoft.com/en-us/library/aa366778.aspx\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "windows",
            "memory",
            "limit"
        ]
    },
    {
        "question_id": "753919",
        "question": "\nIs there an easy way to run a single migration? I don't want to migrate to a certain version I just want to run a specific one.\n",
        "all_answers": [
            "\nAssuming fairly recent version of Rails you can always run:\nrake db:migrate:up VERSION=20090408054532\n\nWhere version is the timestamp in the filename of the migration.\nEdit: At some point over the last 8 years (I'm not sure what version) Rails added checks that prevent this from running if it has already been run.  This is indicated by an entry in the schema_migrations table.  To re-run it, simply execute rake db:migrate:redo VERSION=20090408054532 instead.\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nYou can just run the code directly out of the ruby file:\nrails console\n>> require \"db/migrate/20090408054532_add_foos.rb\"\n>> AddFoos.new.up\n\nNote: Very old versions of rails may require AddFoos.up rather than AddFoos.new.up. If your migration has a \"change\" method, you need to run AddFoos.new.change.\nAn alternative way (without IRB) which relies on the fact that require returns an array of class names:\nscript/runner 'require(\"db/migrate/20090408054532_add_foos.rb\").first.constantize.up'\n\nNote that if you do this, it won't update the schema_migrations table, but it seems like that's what you want anyway.\nAdditionally, if it can't find the file you may need to use require(\"./db/...\" or try require_relative depending on your working directory\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "migration"
        ]
    },
    {
        "question_id": "3365766",
        "question": "\nI have an associative array and I need to find the numeric position of a key.\nI could loop through the array manually to find it, but is there a better way build into PHP?\n$a = array(\n  'blue'   => 'nice',\n  'car'    => 'fast',\n  'number' => 'none'\n);\n\n// echo (find numeric index of $a['car']); // output: 1\n\n",
        "all_answers": [
            "\necho array_search(\"car\",array_keys($a));\n\n",
            "\n$blue_keys = array_search(\"blue\", array_keys($a));\n\nhttp://php.net/manual/en/function.array-keys.php\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "arrays"
        ]
    },
    {
        "question_id": "5243665",
        "question": "\nWhat is difference between DisplayName attribute and Display attribute in ASP.NET MVC?\n",
        "all_answers": [
            "\nBy publishing your whole node_modules folder you are deploying far more files than you will actually need in production. \nInstead, use a task runner as part of your build process to package up those files you require, and deploy them to your wwwroot folder. This will also allow you to concat and minify your assets at the same time, rather than having to serve each individual library separately. \nYou can then also completely remove the FileServer configuration and rely on UseStaticFiles instead. \nCurrently, gulp is the VS task runner of choice. Add a gulpfile.js to the root of your project, and configure it to process your static files on publish. \nFor example, you can add the following scripts section to your project.json:\n \"scripts\": {\n    \"prepublish\": [ \"npm install\", \"bower install\", \"gulp clean\", \"gulp min\" ]\n  },\n\nWhich would work with the following gulpfile (the default when scaffolding with yo):\n/// <binding Clean='clean'/>\n\"use strict\";\n\nvar gulp = require(\"gulp\"),\n    rimraf = require(\"rimraf\"),\n    concat = require(\"gulp-concat\"),\n    cssmin = require(\"gulp-cssmin\"),\n    uglify = require(\"gulp-uglify\");\n\nvar webroot = \"./wwwroot/\";\n\nvar paths = {\n    js: webroot + \"js/**/*.js\",\n    minJs: webroot + \"js/**/*.min.js\",\n    css: webroot + \"css/**/*.css\",\n    minCss: webroot + \"css/**/*.min.css\",\n    concatJsDest: webroot + \"js/site.min.js\",\n    concatCssDest: webroot + \"css/site.min.css\"\n};\n\ngulp.task(\"clean:js\", function (cb) {\n    rimraf(paths.concatJsDest, cb);\n});\n\ngulp.task(\"clean:css\", function (cb) {\n    rimraf(paths.concatCssDest, cb);\n});\n\ngulp.task(\"clean\", [\"clean:js\", \"clean:css\"]);\n\ngulp.task(\"min:js\", function () {\n    return gulp.src([paths.js, \"!\" + paths.minJs], { base: \".\" })\n        .pipe(concat(paths.concatJsDest))\n        .pipe(uglify())\n        .pipe(gulp.dest(\".\"));\n});\n\ngulp.task(\"min:css\", function () {\n    return gulp.src([paths.css, \"!\" + paths.minCss])\n        .pipe(concat(paths.concatCssDest))\n        .pipe(cssmin())\n        .pipe(gulp.dest(\".\"));\n});\n\ngulp.task(\"min\", [\"min:js\", \"min:css\"]);\n\n",
            "\nThey both give you the same results but the key difference I see is that you cannot specify a ResourceType in DisplayName attribute. For an example in MVC 2, you had to subclass the DisplayName attribute to provide resource via localization. Display attribute (new in MVC3 and .NET4) supports ResourceType overload as an \"out of the box\" property.\n",
            "\nDisplayName sets the DisplayName in the model metadata. For example:\n[DisplayName(\"foo\")]\npublic string MyProperty { get; set; }\n\nand if you use in your view the following:\n@Html.LabelFor(x => x.MyProperty)\n\nit would generate:\n<label for=\"MyProperty\">foo</label>\n\nDisplay does the same, but also allows you to set other metadata properties such as Name, Description, ...\nBrad Wilson has a nice blog post covering those attributes.\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "asp.net-mvc",
            "data-annotations",
            "displayattribute",
            ".net-attributes"
        ]
    },
    {
        "question_id": "41750026",
        "question": "\nNode.js Alexa Task Issue\nI'm currently coding a Node.js Alexa Task via AWS Lambda, and I have been trying to code a function that receives information from the OpenWeather API and parses it into a variable called weather. The relevant code is as follows:\nvar request = require('request');\nvar weather = \"\";\nfunction isBadWeather(location) {\n      var endpoint = \"http://api.openweathermap.org/data/2.5/weather?q=\" + location + \"&APPID=205283d9c9211b776d3580d5de5d6338\";\n      var body = \"\";\n      request(endpoint, function (error, response, body) {\n            if (!error && response.statusCode == 200) {\n                  body = JSON.parse(body);\n                  weather = body.weather[0].id;\n            }\n      });\n}\n\nfunction testWeather()\n{\n      setTimeout(function() {\n      if (weather >= 200 && weather < 800)\n            weather = true;\n      else\n            weather = false;\n      console.log(weather);\n      generateResponse(buildSpeechletResponse(weather, true), {});\n      }, 500);\n}\n\nI ran this snippet countless times in Cloud9 and other IDEs, and it seems to be working flawlessly. However, when I zip it into a package and upload it to AWS Lambda, I get the following error:\n{\n    \"errorMessage\": \"Cannot find module '/var/task/index'\",\n    \"errorType\": \"Error\",\n    \"stackTrace\": [\n        \"Function.Module._load (module.js:276:25)\",\n        \"Module.require (module.js:353:17)\",\n        \"require (internal/module.js:12:17)\"\n    ]\n}\n\nI installed module-js, request, and many other Node modules that should make this code run, but nothing seems to fix this issue. Here is my directory, just in case:\n- planyr.zip\n   - index.js\n   - node_modules\n   - package.json\n\nDoes anyone know what the issue could be?\n",
        "all_answers": [
            "\nThis is probably a permissions issue with files inside your deployment zip.\nTry chmod 777 your files before packaging them in a zip file.\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nFixed it! My issue was that I tried to zip the file using my Mac's built-in compression function in Finder. \nIf you're a Mac user, like me, you should run the following script in terminal when you are in the root directory of your project (folder containing your index.js, node_modules, etc. files).\nzip -r ../yourfilename.zip *\n\nFor Windows:\nCompress-Archive -LiteralPath node_modules, index.js -DestinationPath yourfilename.zip\n\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "node.js",
            "amazon-web-services",
            "request",
            "aws-lambda"
        ]
    },
    {
        "question_id": "1485647",
        "question": "\nIs there any better way to rewrite this:\n$('element').removeClass('class1').removeClass('class2');\n\nI cannot use removeClass(); as it would remove ALL classes, which I don't want.\n",
        "all_answers": [
            "\njQuery .removeClass() documentation.\nOne or more CSS classes to remove from the elements, these are separated by spaces.\n",
            "\n$('element').removeClass('class1 class2');\n\nHere are the docs.\n",
            "\nYou've mixed different approaches how to include legacy vendor modules. This is how I'd tackle it:\n1. Prefer unminified CommonJS/AMD over dist\nMost modules link the dist version in the main field of their package.json. While this is useful for most developers, for webpack it is better to alias the src version because this way webpack is able to optimize dependencies better (e.g. when using the DedupePlugin).\n// webpack.config.js\n\nmodule.exports = {\n    ...\n    resolve: {\n        alias: {\n            jquery: \"jquery/src/jquery\"\n        }\n    }\n};\n\nHowever, in most cases the dist version works just fine as well.\n\n2. Use the ProvidePlugin to inject implicit globals\nMost legacy modules rely on the presence of specific globals, like jQuery plugins do on $ or jQuery. In this scenario you can configure webpack, to prepend var $ = require(\"jquery\") everytime it encounters the global $ identifier.\nvar webpack = require(\"webpack\");\n\n    ...\n    \n    plugins: [\n        new webpack.ProvidePlugin({\n            $: \"jquery\",\n            jQuery: \"jquery\"\n        })\n    ]\n\n\n3. Use the imports-loader to configure this\nSome legacy modules rely on this being the window object. This becomes a problem when the module is executed in a CommonJS context where this equals module.exports. In this case you can override this with the imports-loader.\nRun npm i imports-loader --save-dev and then\nmodule: {\n    loaders: [\n        {\n            test: /[\\/\\\\]node_modules[\\/\\\\]some-module[\\/\\\\]index\\.js$/,\n            loader: \"imports-loader?this=>window\"\n        }\n    ]\n}\n\nThe imports-loader can also be used to manually inject variables of all kinds. But most of the time the ProvidePlugin is more useful when it comes to implicit globals.\n\n4. Use the imports-loader to disable AMD\nThere are modules that support different module styles, like AMD, CommonJS and legacy. However, most of the time they first check for define and then use some quirky code to export properties. In these cases, it could help to force the CommonJS path by setting define = false.\nmodule: {\n    loaders: [\n        {\n            test: /[\\/\\\\]node_modules[\\/\\\\]some-module[\\/\\\\]index\\.js$/,\n            loader: \"imports-loader?define=>false\"\n        }\n    ]\n}\n\n\n5. Use the script-loader (no longer mantained) to globally import scripts\nIf you don't care about global variables and just want legacy scripts to work, you can also use the script-loader. It executes the module in a global context, just as if you had included them via the <script> tag.\n\n6. Use noParse to include large dists\nWhen there is no AMD/CommonJS version of the module and you want to include the dist, you can flag this module as noParse. Then webpack will just include the module without parsing it, which can be used to improve the build time. This means that any feature requiring the AST, like the ProvidePlugin, will not work.\nmodule: {\n    noParse: [\n        /[\\/\\\\]node_modules[\\/\\\\]angular[\\/\\\\]angular\\.js$/\n    ]\n}\n\n",
            "\n$(\"element\").removeClass(\"class1 class2\");\n\nFrom removeClass(), the class parameter:\n\nOne or more CSS classes to remove from\n  the elements, these are separated by\n  spaces.\n\n"
        ],
        "answer": "A4",
        "tags": [
            "jquery",
            "css"
        ]
    },
    {
        "question_id": "23076968",
        "question": "\nI have npm module with following package.json\n{\n  \"name\": \"my-app\",\n  \"version\": \"0.0.0\",\n  \"scripts\": {\n    \"prepublish\": \"bower install\",\n    \"build\": \"gulp\"\n  },\n  \"dependencies\": {\n    \"express\": \"~4.0.0\",\n    \"body-parser\": \"~1.0.1\"\n  },\n  \"devDependencies\": {\n    \"gulp\": \"~3.6.0\",\n    \"bower\": \"~1.3.2\"\n  }\n}\n\nWhen I deploy my app to production, I don't want install devDependecies, so, I run npm install --production. But in this case, prepublish script is called, but it doesn't need to, because I use CDN links in production.\nHow to call postinstall script only after npm install but not after npm install --production?\n",
        "all_answers": [
            "\nI work with windows, osx and linux so I use a NON environment specific solution to solve this problem:\nIn the postinstall handler i execute a js script that checks process.env.NODE_ENV variable and does the work.\nin my specific case I have to execute a gulp task only in development env:\npart of package.json\n\"scripts\": {\n  \"postinstall\": \"node postinstall\"\n}\n\nall postinstall.js script\nif (process.env.NODE_ENV === 'development') {\n  const gulp = require('./gulpfile');\n  gulp.start('taskname');\n}\n\nlast row of gulpfile.js\nmodule.exports = gulp;\n\nit's important to export gulp from the gulpfile.js because all tasks are in that specific gulp instance.\n",
            "\nSolution that is less dependent on unix nature of your shell:\n  \"scripts\": {\n    \"postinstall\": \"node -e \\\"process.env.NODE_ENV != 'production' && process.exit(1)\\\" || echo do dev stuff\"\n  },\n\n",
            "\nThis only works if you're on a unix-like environment: \nNPM sets an environment variable to \"true\" when install is run with --production. To only run the postinstall script if npm install was not run with --production, use the following code.\n\"postinstall\": \"if [ -z \\\"$npm_config_production\\\" ]; then node_modules/gulp/bin/gulp.js first-run; fi\",\n\n",
            "\nNewer npm (& Yarn) versions include support for the prepare script that is run after each install run but only in development mode. Also, the prepublish is deprecated. This should be enough:\n{\n  scripts: {\n    \"prepare\": \"bower install\"\n  }\n}\n\nDocs: https://docs.npmjs.com/misc/scripts\n",
            "\nI think you cannot choose what scripts are run based on the --production argument.  What you can do, however, is supply a script which tests the NODE_ENV variable and only runs bower install if it's not \"production\".\nIf you are always in a unix-y environment, you can do it like this:\n{ \n  scripts: {\n    \"prepublish\": \"[ \\\"$NODE_ENV\\\" = production ] && exit 0; bower install\"\n  }\n}\n\n",
            "\nI'm using if-env module. It's less verbose.\nPS: I didn't test it on windows yet.\nInstall with:\nnpm i if-env\n\nthan in package.json scripts:\n\"postinstall-production\": \"echo \\\"production, skipping...\\\"\",\n\"postinstall-dev\": \"echo \\\"doing dev exclusive stuff\\\"\",\n\"postinstall\": \"if-env NODE_ENV=production && npm run postinstall-production || npm run postinstall-dev\"\n\n"
        ],
        "answer": "A4",
        "tags": [
            "javascript",
            "node.js",
            "continuous-integration",
            "npm"
        ]
    },
    {
        "question_id": "28787457",
        "question": "\nI don't want type the extra arguments NODE_ENV='production' gulp every time I run gulp to set an environment variable.\nI would rather set the environment variable from within gulp via a task.\nWhat would be a good way to achieve this?\n",
        "all_answers": [
            "\ngulp.task('set-dev-node-env', function() {\n    return process.env.NODE_ENV = 'development';\n});\n\ngulp.task('set-prod-node-env', function() {\n    return process.env.NODE_ENV = 'production';\n});\n\nUse it like: \ngulp.task('build_for_prod', ['set-prod-node-env'], function() {\n    // maybe here manipulate config object  \n    config.paths.src.scripts = config.paths.deploy.scripts;\n    runSequence(\n        'build',\n        's3'\n    );\n});\n\n",
            "\nTry gulp-env\nQuick example on how to set some environment variables before running the nodemon task:\n// gulpfile.js\n\nvar gulp = require('gulp');\nvar nodemon = require('nodemon');\nvar env = require('gulp-env');\n\ngulp.task('nodemon', function() {\n    // nodemon server (just an example task)\n});\n\ngulp.task('set-env', function () {\n  env({\n    vars: {\n      MONGO_URI: \"mongodb://localhost:27017/testdb-for-british-eyes-only\",\n      PORT: 9001\n    }\n  })\n});\n\ngulp.task('default', ['set-env', 'nodemon'])\n\n"
        ],
        "answer": "A1",
        "tags": [
            "node.js",
            "gulp",
            "environment-variables"
        ]
    },
    {
        "question_id": "20871349",
        "question": "\nOn updating database in Entity Framework , Code first Migration, I am getting this error:\n\nThe ALTER TABLE statement conflicted with the FOREIGN KEY constraint \"FK_dbo.Clients_dbo.MedicalGroups_MedicalGroupId\". The conflict occurred in database \"hrbc\", table \"dbo.MedicalGroups\", column 'Id'.\n\nThis is my class:\npublic partial class Client\n{\n    [Key, DatabaseGenerated(DatabaseGeneratedOption.Identity)]\n    public int Id { get; set; }\n\n    public string FirstName { get; set; }\n    public string LastName { get; set; }\n    public int? MedicalGroupId { get; set; }\n    [ForeignKey(\"MedicalGroupId\")]\n    public virtual MedicalGroups MedicalGroup { get { return _MedicalGroup; } set { _MedicalGroup = value; } }\n}\n\nHere is my 2nd class:\npublic partial class MedicalGroups\n{\n    [Key]\n    public int Id { get; set; }\n    public string Name { get; set; }\n}\n\nAnd this is my migration which I am trying to apply:\npublic override void Up()\n{\n    AddForeignKey(\"dbo.Clients\", \"MedicalGroupId\", \"dbo.MedicalGroups\", \"Id\");\n    CreateIndex(\"dbo.Clients\", \"MedicalGroupId\");\n}\n\n",
        "all_answers": [
            "\nThis error is telling you that you are violating the foreign key constraint.  To resolve you have a few solutions\n\nFix your data - Somewhere there are records in the Clients table that have a MedicalGroupId that does not exist in the in the\nMedicalGroups table.  Write a query to find out what IDs do not\nexist in the MedicalGroups table and manually fix the data\nyourself.\nRemove the foreign key constraint - Obviously if you remove the foreign key constraint you will no longer be bothered by this message.  Unfortunately the database will no longer enforce this relationship and might make this problem worse in the future.\nCreate constraint using WITH NOCHECK - You can create your foreign key constraint using the WITH NOCHECK option.  This option tells SQL Server to not apply this constraint to existing data.  SQL Server WILL check this constraint in any future INSERTS/UPDATES/DELETES.\n\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nCheck that there is not existing data in the database that is conflicting with the FK constraint causing the creation to fail.\n",
            "\nI got the solution of my Problem. Problem is \"data\" which i have in my clients table. Because my client table have medicalgroupid values which are not actually exist that's why it is giving me error on foreign key constraint.\nUpdate Client set MedicalGroupId = NULL\n\n"
        ],
        "answer": "A4",
        "tags": [
            "c#",
            "sql",
            ".net",
            "sql-server",
            "entity-framework"
        ]
    },
    {
        "question_id": "546818",
        "question": "\nI want to allow my users to toggle the current user theme between Aero and Windows Classic(1). Is there a way that I can do this programatically?\nI don't want to pop up the \"Display properties\", and I'm dubious about just changing the registry. (This requires a log out and a log back in for the changes to take effect).\nApplication skinning (using the Codejock libraries) doesn't work either.\nIs there a way of doing this?\nThe application is hosted/run on a Windows Server 2008 over RDP.\n(1) The application in question is a hosted \"Remote App\", and I want users to be able to change the look of the displayed application to match their desktop.\n",
        "all_answers": [
            "\nI believe the best you can do is open your target .msstyles file (in c:\\windows\\resources\\themes), which will pop up the display properties box. At this point you could use window subclassing to programmatically click the right buttons.\n",
            "\nYou can set it using the following command:\nrundll32.exe %SystemRoot%\\system32\\shell32.dll,Control_RunDLL %SystemRoot%\\system32\\desk.cpl desk,@Themes /Action:OpenTheme /file:\"C:\\Windows\\Resources\\Themes\\aero.theme\"\n\nCaveat is that this will show the theme selector dialog. You could kill that dialog straight after.\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "themes"
        ]
    },
    {
        "question_id": "5256021",
        "question": "\nI forked a project on github and am successfully making changes to my local master and pushing to origin on github. I want to send a pull request, but only want to include the last commit.  The pull request UI on github.com shows the last 9 commits and I don't know how to filter that down.\nI was trying to understand if I should create a new local branch, check that out and somehow reset or rebase to upstream?  Then apply my last commit from my master by id to the new local branch and use that for the pull request?\nI'm trying to get the concepts right and figure out the right command lines to do what I need.\n",
        "all_answers": [
            "\nCreate a new branch starting from the latest commit, which is also in the origin repository:\ngit branch new-branch origin/master\ngit checkout new-branch\n\nThen use git cherry-pick to get the single commit you want the pull request for. If the branch with this commit is called feature and the commit you want is the latest commit in this branch, this will be\ngit cherry-pick feature\n\nAssuming this patch applies without conflict, you got now a branch for which you can do your pull request.\nIn a second step, you now need to decide what to do with your feature branch. If you haven't published your changes on this branch yet, the best procedure is probably rebasing this branch upon new-branch (and removing the last commit, if this is not done automatically by git rebase).\n",
            "\nYou didn't add the changes. Either specifically add them via\ngit add filename1 filename2\n\nor add all changes (from root path of the project)\ngit add .\n\nor use the shorthand -a while commiting:\ngit commit -a -m \"message\".\n\n",
            "\nAs the message says:\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nGit has a \"staging area\" where files need to be added before being committed, you can read an explanation of it here.\n\nFor your specific example, you can use:\ngit commit -am \"save arezzo files\"\n\n(note the extra a in the flags, can also be written as git commit -a -m \"message\" - both do the same thing)\nAlternatively, if you want to be more selective about what you add to the commit, you use the git add command to add the appropriate files to the staging area, and git status to preview what is about to be added (remembering to pay attention to the wording used).\nYou can also find general documentation and tutorials for how to use git on the git documentation page which will give more detail about the concept of staging/adding files.\n\nOne other thing worth knowing about is interactive staging - this allows you to add parts of a file to the staging area, so if you've made three distinct code changes (for related but different functionality), you can use interactive mode to split the changes and add/commit each part in turn. Having smaller specific commits like this can be helpful.\n",
            "\nYou need to basically create a new branch & cherry-pick the commits you want to add to it.\n\nNote: you might need these before the checkout/cherry-pick commands\ngit remote add upstream <git repository>\ngit remote update\n\ngit checkout -b <new-branch-name> upstream/master\n\ngit cherry-pick <SHA hash of commit>\n\ngit push origin <new-branch-name>\n\nAfterwards, you will see <new-branch-name> branch on github, switch to it and can submit the pull request with the changes you want.\n",
            "\nYou should do:\ngit commit . -m \"save arezzo files\"\n\n"
        ],
        "answer": "A4",
        "tags": [
            "git",
            "github",
            "pull-request"
        ]
    },
    {
        "question_id": "31785966",
        "question": "\nI have a ViewSet like this one to list users' data:\nclass Foo(viewsets.ViewSet):\n\n    def list(self, request):\n        queryset = User.objects.all()\n        serializer = UserSerializer(queryset, many=True)\n        return Response(serializer.data)\n\nI want to turn on pagination like the default pagination for ModelViewSet:\n{\n    \"count\": 55,\n    \"next\": \"http://myUrl/?page=2\",\n    \"previous\": null,\n    \"results\": [{...},{...},...,{...}]\n}\n\nThe official doc says: \n\nPagination is only performed automatically if you're using the generic views or viewsets\n\n...but my resultset is not paginated at all. How can I paginate it?\n",
        "all_answers": [
            "\n\nPagination is only performed automatically if you're using the generic\n  views or viewsets\n\nThe first roadblock is translating the docs to english. What they intended to convey is that you desire a generic viewset. The generic viewsets extend from generic ApiViews which have extra class methods for paginating querysets and responses.\nAdditionally,  you're providing your own list method, but the default pagination process is actually handled by the mixin:\nclass ListModelMixin(object):\n    \"\"\"\n    List a queryset.\n    \"\"\"\n    def list(self, request, *args, **kwargs):\n        queryset = self.filter_queryset(self.get_queryset())\n\n        page = self.paginate_queryset(queryset)\n        if page is not None:\n            serializer = self.get_serializer(page, many=True)\n            return self.get_paginated_response(serializer.data)\n\n        serializer = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)\n\nThe easy solution, use the framework code:\nclass Foo(mixins.ListModelMixin, viewsets.GenericViewSet):\n    queryset = User.objects.all()\n    serializer = UserSerializer\n\nThe more complex solution would be if you need a custom list method, then you should write it as you see fit but in the style of the above mixin code snippet.\n",
            "\nTry providing a class variable\npaginate_by = 10 #This will paginate by 10 results per page.\n\nCreate a Custom ViewSet which performs only list operation as your case for here currently.\nclass ListModelViewSet(mixins.ListModelMixin, viewsets.GenericViewSet):\n    pass\n\nNow inherit your class Foo with this custom made viewset\nclass Foo(ListModelViewSet):\n\n    paginate_by = 10\n\n    def list(self, request):\n        queryset = User.objects.all()\n        serializer = UserSerializer(queryset, many=True)\n        return Response(serializer.data)\n\nThis should help you get the pagination working.\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django",
            "django-rest-framework"
        ]
    },
    {
        "question_id": "6993780",
        "question": "\nI've set my Model field to null=True, which allows NULL in MySQL, but I can't seem to assign NULL to the field through Django Admin. I've tried also setting blank=True, but that just sets the field to an empty string. Following this didn't work either, as the field value was set to \"None\", the string.\nAny ideas?\n",
        "all_answers": [
            "\nsettings.py\nALLOWED_HOSTS = ['*'] // if you are in dev or docker\n\nEdited\nOk guys, dont do this in production if you are not using docker, just put the IP addr.\nGrettings\n",
            "\nUsually, when you pass both null=True and blank=True, if you leave the field blank in the admin, Django will use NULL for its value.\nEDIT: \nas agf explains in his answer, this is true for all types except CharField and TextField.\n",
            "\nThis section in the docs makes it sound like you can't set a string-based field to NULL through the admin; it will use the empty string. This is just the way Django does it. It will work for other types of fields.\nYou'll either have to hack on the admin script or else decide it doesn't really need to be NULL in the database; an empty string is OK.\n",
            "\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['62.63.141.41', 'namjoosadr.com']\n\nand then restart your apache. in ubuntu:\n/etc/init.d/apache2 restart\n\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nTry to overwrite the save() method of the Model, to check for empty values:\nclass MyModel(models.Model):\n\n    my_nullable_string = models.CharField(max_length=15, null=True, blank=True)\n\n    def save(self, *args, **kwargs):\n         if not self.my_nullable_string:\n              self.my_nullable_string = None\n         super(MyModel, self).save(*args, **kwargs)\n\n",
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n"
        ],
        "answer": "A8",
        "tags": [
            "python",
            "mysql",
            "sql",
            "django",
            "django-admin"
        ]
    },
    {
        "question_id": "969285",
        "question": "\n\n\n\nI'm getting a datetime string in a format like \"2009-05-28T16:15:00\" (this is ISO 8601, I believe). One hackish option seems to be to parse the string using time.strptime and passing the first six elements of the tuple into the datetime constructor, like:\ndatetime.datetime(*time.strptime(\"2007-03-04T21:08:12\", \"%Y-%m-%dT%H:%M:%S\")[:6])\n\nI haven't been able to find a \"cleaner\" way of doing this. Is there one?\n",
        "all_answers": [
            "\nSince Python 3.7 and no external libraries, you can use the fromisoformat function from the datetime module:\ndatetime.datetime.fromisoformat('2019-01-04T16:41:24+02:00')\n\nPython 2 doesn't support the %z format specifier, so it's best to explicitly use Zulu time everywhere if possible:\ndatetime.datetime.strptime(\"2007-03-04T21:08:12Z\", \"%Y-%m-%dT%H:%M:%SZ\")\n\n",
            "\nI haven't tried it yet, but pyiso8601 promises to support this.\n",
            "\nI prefer using the dateutil library for timezone handling and generally solid date parsing. If you were to get an ISO 8601 string like: 2010-05-08T23:41:54.000Z you'd have a fun time parsing that with strptime, especially if you didn't know up front whether or not the timezone was included. pyiso8601 has a couple of issues (check their tracker) that I ran into during my usage and it hasn't been updated in a few years. dateutil, by contrast, has been active and worked for me:\nfrom dateutil import parser\nyourdate = parser.parse(datestring)\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "datetime",
            "iso8601",
            "datetime-parsing"
        ]
    },
    {
        "question_id": "26686948",
        "question": "\nSuppose I have String like :\nvar abc : NSString = \"ABC\"\n\nand I want to check that it is nil or not and for that I try :\nif abc == nil{\n\n        //TODO:\n\n    }\n\nBut this is not working and giving me an error. Error Says :\nCan not invoke '=='with an argument list of type '(@|value NSString , NilLiteralConvertible)' \n\nAny solution for this?\n",
        "all_answers": [
            "\nIf abc is an optional, then the usual way to do this would be to attempt to unwrap it in an if statement:\nif let variableName = abc { // If casting, use, eg, if let var = abc as? NSString\n    // variableName will be abc, unwrapped\n} else {\n    // abc is nil\n}\n\n\nHowever, to answer your actual question, your problem is that you're typing the variable such that it can never be optional.\nRemember that in Swift, nil is a value which can only apply to optionals.\nSince you've declared your variable as:\nvar abc: NSString ...\n\nit is not optional, and cannot be nil.\nTry declaring it as:\nvar abc: NSString? ...\n\nor alternatively letting the compiler infer the type.\n",
            "\nif (MyUnknownClassOrType is nil) {\n    println(\"No class or object to see here\")\n}\n\nApple also recommends that you use this to check for depreciated and removed classes from previous frameworks.\nHere's an exact quote from a developer at Apple:\n\nYes. If the currently running OS doesn’t implement the class then the class method will return nil.\n\nHope this helps :)\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n"
        ],
        "answer": "A1",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "2264072",
        "question": "\nHow can you detect that a user swiped his finger in some direction over a web page with JavaScript?\nI was wondering if there was one solution that would work for websites on both the iPhone and an Android phone.\n",
        "all_answers": [
            "\nwhat i've used before is you have to detect the mousedown event, record its x,y location (whichever is relevant) then detect the mouseup event, and subtract the two values. \n",
            "\npublic void run(final String scriptSrc) { \n        webView.post(new Runnable() {\n            @Override\n            public void run() { \n                webView.loadUrl(\"javascript:\" + scriptSrc); \n            }\n        }); \n    }\n\n",
            "\nI've repackaged TouchWipe as a short jquery plugin: detectSwipe\n",
            "\nFrom kitkat onwards use evaluateJavascript method instead loadUrl to call the javascript functions like below\n    if (android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.KITKAT) {\n        webView.evaluateJavascript(\"enable();\", null);\n    } else {\n        webView.loadUrl(\"javascript:enable();\");\n    }\n\n",
            "\nSimple vanilla JS code sample:\ndocument.addEventListener('touchstart', handleTouchStart, false);        \ndocument.addEventListener('touchmove', handleTouchMove, false);\n\nvar xDown = null;                                                        \nvar yDown = null;\n\nfunction getTouches(evt) {\n  return evt.touches ||             // browser API\n         evt.originalEvent.touches; // jQuery\n}                                                     \n                                                                         \nfunction handleTouchStart(evt) {\n    const firstTouch = getTouches(evt)[0];                                      \n    xDown = firstTouch.clientX;                                      \n    yDown = firstTouch.clientY;                                      \n};                                                \n                                                                         \nfunction handleTouchMove(evt) {\n    if ( ! xDown || ! yDown ) {\n        return;\n    }\n\n    var xUp = evt.touches[0].clientX;                                    \n    var yUp = evt.touches[0].clientY;\n\n    var xDiff = xDown - xUp;\n    var yDiff = yDown - yUp;\n                                                                         \n    if ( Math.abs( xDiff ) > Math.abs( yDiff ) ) {/*most significant*/\n        if ( xDiff > 0 ) {\n            /* right swipe */ \n        } else {\n            /* left swipe */\n        }                       \n    } else {\n        if ( yDiff > 0 ) {\n            /* down swipe */ \n        } else { \n            /* up swipe */\n        }                                                                 \n    }\n    /* reset values */\n    xDown = null;\n    yDown = null;                                             \n};\n\nTested in Android.\n",
            "\nI figured out what the issue was : missing quotes in the testEcho() parameter.  This is how I got the call to work:\nmyWebView.loadUrl(\"javascript:testEcho('Hello World!')\");\n\n",
            "\njQuery Mobile also includes swipe support: http://api.jquerymobile.com/swipe/\nExample\n$(\"#divId\").on(\"swipe\", function(event) {\n    alert(\"It's a swipe!\");\n});\n\n"
        ],
        "answer": "A5",
        "tags": [
            "javascript",
            "iphone",
            "android",
            "swipe"
        ]
    },
    {
        "question_id": "2409836",
        "question": "\nI have a lot of <a> html tags without the href attribute for making onclick javascript calls. These links do not have a pointer style of cursor. They have text style cursor.\nHow can I set the cursor style to pointer for links without using the href attribute?\nI know I can add href=\"#\". I have this in a lot of places in the html document, and would like to know how to make cursor style pointer for links without using the href attribute.\n",
        "all_answers": [
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nin your css file add this....\na:hover {\n cursor:pointer;\n}\n\nif you don't have a css file, add this to the HEAD of your HTML page\n<style type=\"text/css\">\n a:hover {\n  cursor:pointer;\n }\n</style>\n\nalso you can use the href=\"\" attribute by returning false at the end of your javascript.\n<a href=\"\" onclick=\"doSomething(); return false;\">a link</a>\n\nthis is good for many reasons. SEO or if people don't have javascript, the href=\"\" will work. e.g.\n<a href=\"nojavascriptpage.html\" onclick=\"doSomething(); return false;\">a link</a>\n\n@see http://www.alistapart.com/articles/behavioralseparation\nEdit: Worth noting @BalusC's answer where he mentions :hover is not necessary for the OP's use case. Although other style can be add with the :hover selector.\n",
            "\nUse CSS cursor: pointer if I remember correctly.\nEither in your CSS file:\n.link_cursor\n{\n    cursor: pointer;\n}\n\nThen just add the following HTML to any elements you want to have the link cursor: class=\"link_cursor\" (the preferred method.)\nOr use inline CSS:\n<a style=\"cursor: pointer;\">\n\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\n\nstyle=\"cursor: pointer;\"\n\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "html",
            "css",
            "hyperlink",
            "mouse-cursor"
        ]
    },
    {
        "question_id": "4967448",
        "question": "\nI want to send a sms with Android.\nWhat is the intent for SMS sending?\nI want to show the compose sms view with my pre-define text passing over in message field.\n",
        "all_answers": [
            "\nIn Android , we have the class SmsManager which manages SMS operations such as sending data, text, and pdu SMS messages. Get this object by calling the static method SmsManager.getDefault(). \nSmsManager Javadoc\nCheck the following link to get the sample code for sending SMS:\narticle on sending and receiving SMS messages in Android\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nTry the below code and then call, sendSMS(\"99999999999\", \"message\"); to send sms in desired number.\n//---sends an SMS message to another device---\n@SuppressWarnings(\"deprecation\")\nprivate void sendSMS(String phoneNumber, String message)\n{        \n    Log.v(\"phoneNumber\",phoneNumber);\n    Log.v(\"MEssage\",message);\n    PendingIntent pi = PendingIntent.getActivity(this, 0,\n    new Intent(this, **DummyClasshere.class**), 0);                \n    SmsManager sms = SmsManager.getDefault();\n    sms.sendTextMessage(phoneNumber, null, message, pi, null);        \n}\n\nPlease place the following permission into AndroidManifest.xml file.\n<uses-permission android:name=\"android.permission.SEND_SMS\"/>\n\nHope this might help.\nUpdate\nFrom the comment: \nDummyClasshere.class  is an activity without doing any process or the class in which u need to navigate. \n\nYou can use Object.class in place of DummyClasshere.class.\n\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nYou can use the following code:\nstartActivity(new Intent(Intent.ACTION_VIEW, Uri.parse(\"sms:\"\n                        + phoneNumber)));\n\nMake sure you set phoneNumber to the phone number that you want to send the message to\nYou can add a message to the SMS with (from comments):\nIntent intent = new Intent(Intent.ACTION_VIEW, Uri.parse(\"sms:\" + phoneNumber));     \nintent.putExtra(\"sms_body\", message); \nstartActivity(intent);\n\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n"
        ],
        "answer": "A6",
        "tags": [
            "android",
            "sms"
        ]
    },
    {
        "question_id": "22981673",
        "question": "\nI faced the following code in our project:\nsynchronized (Thread.currentThread()){\n    //some code\n}\n\nI don't understand the reason to use synchronized  on currentThread.\nIs there any difference between \nsynchronized (Thread.currentThread()){\n    //some code\n}\n\nand just\n//some code\n\nCan you provide an example which shows the difference?\nUPDATE\nmore in details this code as follows:\nsynchronized (Thread.currentThread()) {\n       Thread.currentThread().wait(timeInterval);\n}\n\nIt looks like just Thread.sleep(timeInterval).  Is it truth?\n",
        "all_answers": [
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nconsider this\n    Thread t = new Thread() {\n        public void run() { // A\n            synchronized (Thread.currentThread()) {\n                System.out.println(\"A\");\n                try {\n                    Thread.sleep(5000);\n                } catch (InterruptedException e) {\n                }\n            }\n        }\n    };\n    t.start();\n    synchronized (t) { // B\n        System.out.println(\"B\");\n        Thread.sleep(5000);\n    }\n\nblocks A and B cannot run simultaneously, so in the given test either \"A\" or \"B\" output will be delayed by 5 secs, which one will come first is undefined\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nBetter alternatives to join() method have been evolved over a period of time.\nExecutorService.html#invokeAll is one alternative.\n\nExecutes the given tasks, returning a list of Futures holding their status and results when all complete. Future.isDone() is true for each element of the returned list. \n\nNote that a completed task could have terminated either normally or by throwing an exception. The results of this method are undefined if the given collection is modified while this operation is in progress.\nForkJoinPool or Executors.html#newWorkStealingPool provides other alternatives to achieve the same purpose. \nExample code snippet:\n\nimport java.util.concurrent.*;\n\nimport java.util.*;\n\npublic class InvokeAllDemo{\n    public InvokeAllDemo(){\n        System.out.println(\"creating service\");\n        ExecutorService service = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\n\n        List<MyCallable> futureList = new ArrayList<MyCallable>();\n        for ( int i=0; i<10; i++){\n            MyCallable myCallable = new MyCallable((long)i);\n            futureList.add(myCallable);\n        }\n        System.out.println(\"Start\");\n        try{\n            List<Future<Long>> futures = service.invokeAll(futureList);  \n        }catch(Exception err){\n            err.printStackTrace();\n        }\n        System.out.println(\"Completed\");\n        service.shutdown();\n    }\n    public static void main(String args[]){\n        InvokeAllDemo demo = new InvokeAllDemo();\n    }\n    class MyCallable implements Callable<Long>{\n        Long id = 0L;\n        public MyCallable(Long val){\n            this.id = val;\n        }\n        public Long call(){\n            // Add your business logic\n            return id;\n        }\n    }\n}\n\n",
            "\nYou are implementing a recursive mutex.\ni.e. the same thread can enter the synchronisation block, but not other threads.\n"
        ],
        "answer": "A2",
        "tags": [
            "java",
            "multithreading",
            "concurrency",
            "synchronization",
            "thread-safety"
        ]
    },
    {
        "question_id": "11444164",
        "question": "\nI have set the time zone in /config/application.rb, and I expect all times generated in my app to be in this time zone by default, yet when I create a new DateTime object (using .new), it creates it in GMT. How can I get it to be in my app's time zone?\nconfig/application.rb\nconfig.time_zone = 'Pacific Time (US & Canada)'\n\nirb\nDateTime.now\n# => Wed, 11 Jul 2012 19:04:56 -0700 \n\nmydate = DateTime.new(2012, 07, 11, 20, 10, 0)\n# => Wed, 11 Jul 2012 20:10:00 +0000                    # GMT, but I want PDT\n\nUsing in_time_zone doesn't work because that just converts the GMT time to PDT time, which is the wrong time:\nmydate.in_time_zone('Pacific Time (US & Canada)')\n# => Wed, 11 Jul 2012 13:10:00 PDT -07:00               # wrong time (I want 20:10)\n\n",
        "all_answers": [
            "\nDo require 'sass/plugin' and make sure it's at the bottom after your Application.initialize! call. \n",
            "\nYou can use ActiveSupport's TimeWithZone (Time.zone) object to create and parse dates in the time zone of your application:\n1.9.3p0 :001 > Time.zone.now\n => Wed, 11 Jul 2012 19:47:03 PDT -07:00 \n1.9.3p0 :002 > Time.zone.parse('2012-07-11 21:00')\n => Wed, 11 Jul 2012 21:00:00 PDT -07:00 \n\n",
            "\nI do the following in ApplicationController to set the timezone to the user's time.\nI'm not sure if this is what you want.\nclass ApplicationController < ActionController::Base\n  before_filter :set_timezone\n  def set_timezone\n    # current_user.time_zone #=> 'London'\n    Time.zone = current_user.time_zone if current_user && current_user.time_zone\n  end\n\nend\n\n",
            "\nFor rails 3.1.rc4, you could set the config:\nconfig.sass.preferred_syntax = :sass\n\nin the application.rb file\n",
            "\nI added the following to config/environments/development.rb:\nconfig.sass.preferred_syntax = :sass\n\nThat did the trick.\n",
            "\nI definitely prefer sass to scss too - have you considered just using the compass gem for all your CSS, and adding preferred_syntax = :sass to config/compass.rb\nI haven't tested this out yet on rails 3.1 yet but it works in 3.0.7\nEDIT\nAs a troubleshooting step, what happens when you remove just the first line of code from sass_config.rb so that it just has the second one? Do both these lines cause the error?\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "datetime",
            "timezone",
            "ruby-on-rails-3.1",
            "activesupport"
        ]
    },
    {
        "question_id": "5643496",
        "question": "\nI was digging through some code, and I found some calls to mySQL_fetch_array. Is PHP case sensitive about function names? I recall reading this somewhere but can't seem to find any reference to it.\n",
        "all_answers": [
            "\nTry This\n<script>\n  var phpadd= <?php echo add(1,2);?> //call the php add function\n  var phpmult= <?php echo mult(1,2);?> //call the php mult function\n  var phpdivide= <?php echo divide(1,2);?> //call the php divide function\n</script>\n\n",
            "\nYes, you can do ajax request to server with your data in request parameters, like this (very simple):\nNote that the following code uses jQuery\njQuery.ajax({\n    type: \"POST\",\n    url: 'your_functions_address.php',\n    dataType: 'json',\n    data: {functionname: 'add', arguments: [1, 2]},\n\n    success: function (obj, textstatus) {\n                  if( !('error' in obj) ) {\n                      yourVariable = obj.result;\n                  }\n                  else {\n                      console.log(obj.error);\n                  }\n            }\n});\n\nand your_functions_address.php like this:\n    <?php\n    header('Content-Type: application/json');\n\n    $aResult = array();\n\n    if( !isset($_POST['functionname']) ) { $aResult['error'] = 'No function name!'; }\n\n    if( !isset($_POST['arguments']) ) { $aResult['error'] = 'No function arguments!'; }\n\n    if( !isset($aResult['error']) ) {\n\n        switch($_POST['functionname']) {\n            case 'add':\n               if( !is_array($_POST['arguments']) || (count($_POST['arguments']) < 2) ) {\n                   $aResult['error'] = 'Error in arguments!';\n               }\n               else {\n                   $aResult['result'] = add(floatval($_POST['arguments'][0]), floatval($_POST['arguments'][1]));\n               }\n               break;\n\n            default:\n               $aResult['error'] = 'Not found function '.$_POST['functionname'].'!';\n               break;\n        }\n\n    }\n\n    echo json_encode($aResult);\n\n?>\n\n",
            "\nuse document.write\nfor example,\n<script>\n  document.write(' <?php add(1,2); ?> ');\n  document.write(' <?php milt(1,2); ?> ');\n  document.write(' <?php divide(1,2); ?> ');\n</script>\n\n",
            "\nI am quoting from this:\n\nNote: Function names are\n  case-insensitive, though it is usually\n  good form to call functions as they\n  appear in their declaration.\n\nSo, its looks like user-defined functions are not case-sensitive, there was a vote for making functions/objects under PHP5 case-sensitive.\n",
            "\nNo. \nPHP functions are not case sensitive.\n",
            "\nNo, they are not case sensitive, however, you should always use the case that is in the manual, for consistency.\nHowever, variables are case sensitive.\n",
            "\nYou need to create an API :\nYour js functions execute AJAX requests on your web service\n  var mult = function(arg1, arg2)\n    $.ajax({\n      url: \"webservice.php?action=mult&arg1=\"+arg1+\"&arg2=\"+arg2\n    }).done(function(data) {\n      console.log(data);\n    });\n  }\n\non the php side, you'll have to check the action parameter in order to execute the propre function (basically a switch statement on the $_GET[\"action\"] variable)\n"
        ],
        "answer": "A4",
        "tags": [
            "php",
            "function",
            "case-sensitive"
        ]
    },
    {
        "question_id": "1838476",
        "question": "\nWhat is the difference in Dictionary.add(key, value) and Dictionary[key] = value?\nI've noticed that the last version does not throw an ArgumentException when inserting a duplicate key, but is there any reason to prefer the first version?\nEdit: Does anyone have an authoritative source of information about this? I've tried MSDN, but it is as always a wild goose chase :(\n",
        "all_answers": [
            "\nThe performance is almost a 100% identical. You can check this out by opening the class in Reflector.net\nThis is the This indexer:\npublic TValue this[TKey key]\n{\n    get\n    {\n        int index = this.FindEntry(key);\n        if (index >= 0)\n        {\n            return this.entries[index].value;\n        }\n        ThrowHelper.ThrowKeyNotFoundException();\n        return default(TValue);\n    }\n    set\n    {\n        this.Insert(key, value, false);\n    }\n}\n\nAnd this is the Add method:\npublic void Add(TKey key, TValue value)\n{\n    this.Insert(key, value, true);\n}\n\nI won't post the entire Insert method as it's rather long, however the method declaration is this:\nprivate void Insert(TKey key, TValue value, bool add)\n\nAnd further down in the function, this happens:\nif ((this.entries[i].hashCode == num) && this.comparer.Equals(this.entries[i].key, key))\n{\n    if (add)\n    {\n        ThrowHelper.ThrowArgumentException(ExceptionResource.Argument_AddingDuplicate);\n    }\n\nWhich checks if the key already exists, and if it does and the parameter add is true, it throws the exception.\nSo for all purposes and intents the performance is the same.\nLike a few other mentions, it's all about whether you need the check, for attempts at adding the same key twice.\nSorry for the lengthy post, I hope it's okay.\n",
            "\nDictionary.Add(key, value) and Dictionary[key] = value have different purposes:\n\nUse the Add method to add new key/value pair, existing keys will not be replaced (an ArgumentException is thrown).\nUse the indexer if you don't care whether the key already exists in the dictionary, in other words: add the key/value pair if the the key is not in the dictionary or replace the value for the specified key if the key is already in the dictionary.\n\n",
            "\nYes, that is the difference, the Add method throws an exception if the key already exists.\nThe reason to use the Add method is exactly this. If the dictionary is not supposed to contain the key already, you usually want the exception so that you are made aware of the problem.\n",
            "\nThe first version will add a new KeyValuePair to the dictionary, throwing if key is already in the dictionary. The second, using the indexer, will add a new pair if the key doesn't exist, but overwrite the value of the key if it already exists in the dictionary.\nIDictionary<string, string> strings = new Dictionary<string, string>();\n\nstrings[\"foo\"] = \"bar\";          //strings[\"foo\"] == \"bar\"\nstrings[\"foo\"] = string.Empty;   //strings[\"foo\"] == string.empty\nstrings.Add(\"foo\", \"bar\");       //throws     \n\n",
            "\nGiven the, most than probable similarities in performance, use whatever feel more correct and readable to the piece of code you're using.\nI feel an operation that describes an addition, being the presence of the key already a really rare exception is best represented with the add. Semantically it makes more sense.\nThe dict[key] = value represents better a substitution. If I see that code I half expect the key to already be in the dictionary anyway.\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "optimization",
            "dictionary"
        ]
    },
    {
        "question_id": "4282413",
        "question": "\nHow can I sort this array of objects by one of its fields, like name or count?\nArray\n(\n    [0] => stdClass Object\n        (\n            [ID] => 1\n            [name] => Mary Jane\n            [count] => 420\n        )\n\n    [1] => stdClass Object\n        (\n            [ID] => 2\n            [name] => Johnny\n            [count] => 234\n        )\n\n    [2] => stdClass Object\n        (\n            [ID] => 3\n            [name] => Kathy\n            [count] => 4354\n        )\n\n   ....\n\n",
        "all_answers": [
            "\n$arraysAreEqual = ($a == $b); // TRUE if $a and $b have the same key/value pairs.\n$arraysAreEqual = ($a === $b); // TRUE if $a and $b have the same key/value pairs in the same order and of the same types.\n\nSee Array Operators.\nEDIT\nThe inequality operator is != while the non-identity operator is !== to match the equality \noperator == and the identity operator ===.\n",
            "\nUse usort, here's an example adapted from the manual:\nfunction cmp($a, $b) {\n    return strcmp($a->name, $b->name);\n}\n\nusort($your_data, \"cmp\");\n\nYou can also use any callable as the second argument. Here are some examples:\n\nUsing anonymous functions (from PHP 5.3)\n  usort($your_data, function($a, $b) {return strcmp($a->name, $b->name);});\n\n\nFrom inside a class\n  usort($your_data, array($this, \"cmp\")); // \"cmp\" should be a method in the class\n\n\nUsing arrow functions (from PHP 7.4)\n  usort($your_data, fn($a, $b) => strcmp($a->name, $b->name));\n\n\n\nAlso, if you're comparing numeric values, fn($a, $b) => $a->count - $b->count as the \"compare\" function should do the trick, or, if you want yet another way of doing the same thing, starting from PHP 7 you can use the Spaceship operator, like this: fn($a, $b) => $a->count <=> $b->count.\n",
            "\nusort($array, 'my_sort_function');\n\nvar_dump($array);\n\nfunction my_sort_function($a, $b)\n{\n    return $a->name < $b->name;\n}\n\nThe same code will be with the count field.\nMore details about usort: http://ru2.php.net/usort\nBtw, where did you get that array from? I hope that not from database?\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "arrays",
            "sorting",
            "object",
            "multidimensional-array"
        ]
    },
    {
        "question_id": "9581745",
        "question": "\n\n\n\n\nPossible Duplicate:\nwhat is “=null” and “ IS NULL”\nIs there any difference between IS NULL and =NULL \n\nWhat is the difference between\nwhere x is null\n\nand \nwhere x = null\n\nand why does the latter not work?\n",
        "all_answers": [
            "\nIn SQL, a comparison between a null value and any other value (including another null) using a comparison operator (eg =, !=, <, etc) will result in a null, which is considered as false for the purposes of a where clause (strictly speaking, it's \"not true\", rather than \"false\", but the effect is the same).\nThe reasoning is that a null means \"unknown\", so the result of any comparison to a null is also \"unknown\". So you'll get no hit on rows by coding where my_column = null.\nSQL provides the special syntax for testing if a column is null, via is null and is not null, which is a special condition to test for a null (or not a null).\nHere's some SQL showing a variety of conditions and and their effect as per above.\ncreate table t (x int, y int);\ninsert into t values (null, null), (null, 1), (1, 1);\n\nselect 'x = null' as test , x, y from t where x = null\nunion all\nselect 'x != null', x, y from t where x != null\nunion all\nselect 'not (x = null)', x, y from t where not (x = null)\nunion all\nselect 'x = y', x, y from t where x = y\nunion all\nselect 'not (x = y)', x, y from t where not (x = y);\n\nreturns only 1 row (as expected):\nTEST    X   Y\nx = y   1   1\n\nSee this running on SQLFiddle\n",
            "\nFirst is correct way of checking whether a field value is null while later won't work the way you expect it to because null is special value which does not equal anything, so you can't use equality comparison using = for it.\nSo when you need to check if a field value is null or not, use:\nwhere x is null\n\ninstead of:\nwhere x = null\n\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n"
        ],
        "answer": "A1",
        "tags": [
            "sql",
            "null"
        ]
    },
    {
        "question_id": "30260076",
        "question": "\nI am following this documentation\nto implement export to Excel in my laravel 4 project.\nSo am trying to generate excel file from array like this:\n//$results is taken with db query\n\n$data = array();\nforeach ($results as $result) {\n   $result->filed1 = 'some modification';\n   $result->filed2 = 'some modification2';\n   $data[] = $result;\n}\nExcel::create('Filename', function($excel) use($data) {\n\n$excel->sheet('Sheetname', function($sheet) use($data) {\n\n    $sheet->fromArray($data);\n\n      });\n\n})->export('xls');\n\nBut this raises exception:\n  Object of class stdClass could not be converted to string\n\nWhat am I doing wrong ?\nUPDATE:\nTried this:\n$data = get_object_vars($data);\n\nwhich results in:\nget_object_vars() expects parameter 1 to be object, array given\n\nThis:\n$data = (array)$data;\n\nResults in the initial error.\n",
        "all_answers": [
            "\nThere is some class that generates PHP Excel files (real excel files, not that .csv thing).\nI use (DEPRICATED) See edit 2:  \nhttps://github.com/PHPOffice/PHPExcel\nBUT: I have had a problem when trying to read these generated excel files with the java excel READER, so there might be bugs in this PHP script.\n\nEDIT: Nice one: http://www.phpclasses.org/package/2037-PHP-Generate-spreadsheet-files-Excel-xls-XML-format.html\n\nPhpSpreadsheet is the next version of PHPExcel. It breaks compatibility to dramatically improve the code base quality (namespaces, PSR compliance, use of latest PHP language features, etc.). https://github.com/PHPOffice/PhpSpreadsheet\n\n\n",
            "\nThere is a PHP Excel extension: http://ilia.ws/archives/222-PHP-Excel-Extension.html\n",
            "\nYou might need to change your object to an array first. I dont know what export does, but I assume its expecting an array.\nYou can either use\nget_object_vars()\nOr if its a simple object, you can just typecast it.\n$arr =  (array) $Object;\n",
            "\n$data is indeed an array, but it's made up of objects.\nConvert its content to array before creating it:\n$data = array();\nforeach ($results as $result) {\n   $result->filed1 = 'some modification';\n   $result->filed2 = 'some modification2';\n   $data[] = (array)$result;  \n   #or first convert it and then change its properties using \n   #an array syntax, it's up to you\n}\nExcel::create(....\n\n",
            "\nSome applications generate an HTML table or a CSV file instead of a real Excel file, and pretend it is an Excel file so that Excel opens it. With HTML tables, this works surprisingly well and it even supports some formatting. With the newest Excel versions, however, you get a message asking you whether you really want to open the file.\n"
        ],
        "answer": "A4",
        "tags": [
            "php",
            "excel",
            "laravel"
        ]
    },
    {
        "question_id": "31182637",
        "question": "\nI am trying to write a test case using the new UI Testing available in Xcode 7 beta 2. The App has a login screen where it makes a call to the server to login. There is a delay associated with this as it is an asynchronous operation.\nIs there a way to cause a delay or wait mechanism in the XCTestCase before proceeding to further steps?\nThere is no proper documentation available and I went through the Header files of the classes. Was not able to find anything related to this.\nAny ideas/suggestions?\n",
        "all_answers": [
            "\nHere are the settings visually:\n\n",
            "\nAsynchronous UI Testing was introduced in Xcode 7 Beta 4. To wait for a label with the text \"Hello, world!\" to appear you can do the following:\nlet app = XCUIApplication()\napp.launch()\n\nlet label = app.staticTexts[\"Hello, world!\"]\nlet exists = NSPredicate(format: \"exists == 1\")\n\nexpectationForPredicate(exists, evaluatedWithObject: label, handler: nil)\nwaitForExpectationsWithTimeout(5, handler: nil)\n\nMore details about UI Testing can be found on my blog.\n",
            "\nIf you are using Xcode 8.0+ and Swift 2.2+ or even Objective C:\n\nIf you want to allow HTTP connections to any site, you can use this keys:\n<key>NSAppTransportSecurity</key>\n<dict>\n    <key>NSAllowsArbitraryLoads</key>\n    <true/>\n</dict>\n\nIf you know which domains you will connect to add:\n<key>NSAppTransportSecurity</key>\n<dict>\n    <key>NSExceptionDomains</key>\n    <dict>\n        <key>example.com</key>\n        <dict>\n            <key>NSExceptionAllowsInsecureHTTPLoads</key>\n            <true/>\n            <key>NSIncludesSubdomains</key>\n            <true/>\n        </dict>\n    </dict>\n</dict>\n\n",
            "\nEdit:\nIt actually just occurred to me that in Xcode 7b4, UI testing now has \nexpectationForPredicate:evaluatedWithObject:handler: \nOriginal:\nAnother way is to spin the run loop for a set amount of time.  Really only useful if you know how much (estimated) time you'll need to wait for\nObj-C:\n[[NSRunLoop currentRunLoop] runMode:NSDefaultRunLoopMode beforeDate:[NSDate dateWithTimeIntervalSinceNow: <<time to wait in seconds>>]]\nSwift:\nNSRunLoop.currentRunLoop().runMode(NSDefaultRunLoopMode, beforeDate: NSDate(timeIntervalSinceNow: <<time to wait in seconds>>))\nThis is not super useful if you need to test some conditions in order to continue your test.  To run conditional checks, use a while loop.\n",
            "\nUse NSAppTransportSecurity:\n\nYou have to set the NSAllowsArbitraryLoads key to YES under NSAppTransportSecurity dictionary in your info.plist file.\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "ios9",
            "xcode-ui-testing",
            "xcode7-beta2",
            "xctwaiter"
        ]
    },
    {
        "question_id": "1097522",
        "question": "\nI have a collection of checkboxes with generated ids and some of them have an extra attribute. Is it possible to use JQuery to check if an element has a specific attribute?\nFor example, can I verify if the following element has the attribute \"myattr\"? The value of the attribute can vary.\n<input type=\"checkbox\" id=\"A\" myattr=\"val_attr\">A</input>\n\nFor example how can I get a collection of all checkboxes that have this attribute without checking one by one? Is this possible?\n",
        "all_answers": [
            "\nif ($('#A').attr('myattr')) {\n    // attribute exists\n} else {\n    // attribute does not exist\n}\n\nEDIT:\nThe above will fall into the else-branch when myattr exists but is an empty string or \"0\". If that's a problem you should explicitly test on undefined:\nif ($('#A').attr('myattr') !== undefined) {\n    // attribute exists\n} else {\n    // attribute does not exist\n}\n\n",
            "\nDo you mean can you select them? If so, then yes:\n$(\":checkbox[myattr]\")\n\n"
        ],
        "answer": "A2",
        "tags": [
            "jquery",
            "attributes"
        ]
    },
    {
        "question_id": "2650041",
        "question": "\nWould anyone have any pointers on getting PNG images to display in Emacs 23 under Win32?..  I have installed the gnuwin32 set of utilities, including libpng and zlib; C:\\Program Files\\GnuWin32\\bin is in path.  JPG files started working but not PNGs.  I'd appreciate any hints on getting this to work.\nEDIT: PNG thumbnails actually display fine (e.g. in dired via C-t C-t).  However, opening them fails (opens as garbage in fundamental mode, and M-x image-mode says \"invalid image specification\").\n",
        "all_answers": [
            "\nYou have to copy one of these dlls \"libpng12d.dll\" \"libpng12.dll\" \"libpng.dll\" \"libpng13d.dll\" \"libpng13.dll\" to your emacs-23.1/bin/ directory. They require zlib1.dll which you have to copy as well. I did the same thing for jpeg62.dll and giflib4.dll and now my emacs supports jpg, gif and png files. For some reason it does not work if I simply put these dlls in the path.\nYou can check (image-type-available-p 'png) to see if png is supported. image-library-alist maps image type to a list of dlls which support it.\n",
            "\nAccording to the official manual:\n3.3 How do I get image support?\nEmacs has built in support for XBM and PBM/PGM/PPM images. This is sufficient to see the monochrome splash screen and tool-bar icons. Since 22.2, the official precompiled binaries for Windows have bundled libXpm, which is required to display the color versions of those images.\nEmacs is compiled to recognize JPEG, PNG, GIF and TIFF images also, but displaying these image types require external DLLs which are not bundled with Emacs. See Other useful ports.\nThose dlls for the various image formats are (as far as I know) - XPM (xpm4.dll), PNG (libpng13.dll, zlib1.dll), JPEG (jpeg62.dll), TIFF (libtiff3.dll) and GIF (giflib4.dll);\n"
        ],
        "answer": "A1",
        "tags": [
            "windows",
            "emacs"
        ]
    },
    {
        "question_id": "7575627",
        "question": "\nNpm sounds like a great platform to use within an organization, curious if a private repo is possible, like with Nexus/Maven.  Nothing comes up on Google :(\n",
        "all_answers": [
            "\nForgive me if I don't understand your question well, but here's my answer:\nYou can create a private npm module and use npm's normal commands to install it. Most node.js users use git as their repository, but you can use whatever repository works for you.\n\nIn your project, you'll want the skeleton of an NPM package. Most\nnode modules have git repositories where you can look at how they\nintegrate with NPM (the package.json file, I believe is part of\nthis and NPM's website shows you how to make a npm package)\nUse something akin to Make to make and tarball your package to be\navailable from the internet or your network to stage it for npm\ninstall downloads.\nOnce your package is made, then use\n\nnpm install *tarball_url*\n\n\n",
            "\nI don't think there is an easy way to do this.\nA look at the npm documentation tells us, that it is possible:\n\nCan I run my own private registry?\nYes!\nThe easiest way is to replicate the couch database, and use the same (or similar) design doc to implement the APIs.\nIf you set up continuous replication from the official CouchDB, and then set your internal CouchDB as the registry config, then you'll be able to read any published packages, in addition to your private ones, and by default will only publish internally. If you then want to publish a package for the whole world to see, you can simply override the --registry config for that command.\n\nThere's also an excellent tutorial on how to create a private npm repository in the clock blog.\nEDIT (2017-02-26):\nNot really new, but there are now paid plans to host private packages on npm.\nOver the years, npm has become a factor for many non-Node.js companies, too, through the huge frontend ecosystem that's built upon npm. If your company is already running Sonatype Nexus for hosting Java projects internally, you can also use it for hosting internal npm packages.\nOther options include JFrog Artifactory and Inedo ProGet, but I haven't used those.\n"
        ],
        "answer": "A2",
        "tags": [
            "node.js",
            "repository",
            "npm"
        ]
    },
    {
        "question_id": "4724980",
        "question": "\nHow can the iPhone be set to vibrate once?\nFor example, when a player loses a life or the game is over, the iPhone should vibrate.\n",
        "all_answers": [
            "\nin viewDidLoad, add this line:\nself.tableView.separatorColor = [UIColor clearColor];\n\nand in cellForRowAtIndexPath:  \nfor iOS lower versions \nif(indexPath.row != self.newCarArray.count-1){\n    UIImageView *line = [[UIImageView alloc] initWithFrame:CGRectMake(0, 44, 320, 2)];\n    line.backgroundColor = [UIColor redColor];\n    [cell addSubview:line];\n}\n\nfor iOS 7 upper versions (including iOS 8)\nif (indexPath.row == self.newCarArray.count-1) {\n    cell.separatorInset = UIEdgeInsetsMake(0.f, cell.bounds.size.width, 0.f, 0.f);\n}\n\n",
            "\nA simple way to do so is with Audio Services:\n#import <AudioToolbox/AudioToolbox.h> \n...    \nAudioServicesPlaySystemSound(kSystemSoundID_Vibrate);\n\n",
            "\nFrom \"iPhone Tutorial: Better way to check capabilities of iOS devices\":\nThere are two seemingly similar functions that take a parameter kSystemSoundID_Vibrate:\n1) AudioServicesPlayAlertSound(kSystemSoundID_Vibrate);\n2) AudioServicesPlaySystemSound(kSystemSoundID_Vibrate);\n\n\nBoth of the functions vibrate the iPhone. But, when you use the first\n  function on devices that don’t support vibration, it plays a beep\n  sound. The second function, on the other hand, does nothing on\n  unsupported devices. So if you are going to vibrate the device\n  continuously, as an alert, common sense says, use function 2.\n\nFirst, add the AudioToolbox framework AudioToolbox.framework to your target in Build Phases.\nThen, import this header file:\n#import <AudioToolbox/AudioServices.h>\n\n",
            "\nIn the UITableViewDataSource cellForRowAtIndexPath method\nSwift :\nif indexPath.row == {your row number} {\n    cell.separatorInset = UIEdgeInsets(top: 0, left: 0, bottom: 0, right: .greatestFiniteMagnitude)\n}\n\nor :\ncell.separatorInset = UIEdgeInsetsMake(0, 0, 0, UIScreen.main.bounds.width)\n\nfor default Margin:\ncell.separatorInset = UIEdgeInsetsMake(0, tCell.layoutMargins.left, 0, 0)\n\nto show separator end-to-end\ncell.separatorInset = .zero\n\nObjective-C:\nif (indexPath.row == {your row number}) {\n    cell.separatorInset = UIEdgeInsetsMake(0.0f, 0.0f, 0.0f, CGFLOAT_MAX);\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "cocoa-touch",
            "avfoundation",
            "vibration"
        ]
    },
    {
        "question_id": "888533",
        "question": "\nWhen building a Windows Console App in C#, is it possible to write to the console without having to extend a current line or go to a new line?  For example, if I want to show a percentage representing how close a process is to completion, I'd just like to update the value on the same line as the cursor, and not have to put each percentage on a new line.\nCan this be done with a \"standard\" C# console app?\n",
        "all_answers": [
            "\nAfter I tried algirdas' solution, my Windows crashed (Win 7 Pro 64bit) so I decided to try a different solution:\n\nStart Run (Win+R)\nType cmd /K chcp 65001\n\nYou will get mostly what you want. To start it from the taskbar or anywhere else, make a shortcut (you can name it cmd.unicode.exe or whatever you like) and change its Target to C:\\Windows\\System32\\cmd.exe /K chcp 65001.\n",
            "\nIf you print only \"\\r\" to the console the cursor goes back to the beginning of the current line and then you can rewrite it. This should do the trick:\nfor(int i = 0; i < 100; ++i)\n{\n    Console.Write(\"\\r{0}%   \", i);\n}\n\nNotice the few spaces after the number to make sure that whatever was there before is erased.\nAlso notice the use of Write() instead of WriteLine() since you don't want to add an \"\\n\" at the end of the line.\n",
            "\nYou can use Console.SetCursorPosition to set the position of the cursor and then write at the current position.\nHere is an example showing a simple \"spinner\":\nstatic void Main(string[] args)\n{\n    var spin = new ConsoleSpinner();\n    Console.Write(\"Working....\");\n    while (true) \n    {\n        spin.Turn();\n    }\n}\n\npublic class ConsoleSpinner\n{\n    int counter;\n\n    public void Turn()\n    {\n        counter++;        \n        switch (counter % 4)\n        {\n            case 0: Console.Write(\"/\"); counter = 0; break;\n            case 1: Console.Write(\"-\"); break;\n            case 2: Console.Write(\"\\\\\"); break;\n            case 3: Console.Write(\"|\"); break;\n        }\n        Thread.Sleep(100);\n        Console.SetCursorPosition(Console.CursorLeft - 1, Console.CursorTop);\n    }\n}\n\nNote that you will have to make sure to overwrite any existing output with new output or blanks.\nUpdate: As it has been criticized that the example moves the cursor only back by one character, I will add this for clarification: Using SetCursorPosition you may set the cursor to any position in the console window. \nConsole.SetCursorPosition(0, Console.CursorTop);\n\nwill set the cursor to the beginning of the current line (or you can use Console.CursorLeft = 0 directly).\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "windows",
            "console"
        ]
    },
    {
        "question_id": "5406368",
        "question": "\nIs it possible to use CSS/CSS3 to mirror text?\nSpecifically, I have this scissors char “✂” (&#9986;) that I'd like to display pointing left and not right.\n",
        "all_answers": [
            "\nyou can use 'transform' to achieve this. \nhttp://jsfiddle.net/aRcQ8/\ncss:\n-moz-transform: rotate(-180deg);\n-webkit-transform: rotate(-180deg);\ntransform: rotate(-180deg);\n\n",
            "\nYou can use CSS transformations to achieve this. A horizontal flip would involve scaling the div like this:\n-moz-transform: scale(-1, 1);\n-webkit-transform: scale(-1, 1);\n-o-transform: scale(-1, 1);\n-ms-transform: scale(-1, 1);\ntransform: scale(-1, 1);\n\nAnd a vertical flip would involve scaling the div like this:\n-moz-transform: scale(1, -1);\n-webkit-transform: scale(1, -1);\n-o-transform: scale(1, -1);\n-ms-transform: scale(1, -1);\ntransform: scale(1, -1);\n\n\nDEMO:\n\n\nspan{ display: inline-block; margin:1em; } \r\n.flip_H{ transform: scale(-1, 1); color:red; }\r\n.flip_V{ transform: scale(1, -1); color:green; }\n<span class='flip_H'>Demo text &#9986;</span>\r\n<span class='flip_V'>Demo text &#9986;</span>\n\n\n\n",
            "\n-moz-transform: scale(-1, 1);\n-webkit-transform: scale(-1, 1);\n-o-transform: scale(-1, 1);\n-ms-transform: scale(-1, 1);\ntransform: scale(-1, 1);\n\nThe two parameters are X axis, and Y axis, -1 will be a mirror, but you can scale to any size you like to suit your needs. Upside down and backwards would be (-1, -1).\nIf you're interested in the best option available for cross browser support back in 2011, see my older answer.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n"
        ],
        "answer": "A2",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "6376113",
        "question": "\nHow can I use spaces in the Windows Command Line?\ncmd /C C:\\Program Files (x86)\\WinRar\\Rar.exe a D:\\Hello 2\\File.rar D:\\Hello 2\\*.*\n\n",
        "all_answers": [
            "\nSingle quotation marks won't do in that case. You have to add quotation marks around each path and also enclose the whole command in quotation marks:\ncmd /C \"\"C:\\Program Files (x86)\\WinRar\\Rar.exe\" a \"D:\\Hello 2\\File.rar\" \"D:\\Hello 2\\*.*\"\"\n\nSee also the cmd.exe remarks section.\n",
            "\nAs others have already said, parameters passed through the command line can be accessed in batch files with the notation %1 to %9. There are also two other tokens that you can use:\n\n%0 is the executable (batch file) name as specified in the command line.\n%* is all parameters specified in the command line -- this is very useful if you want to forward the parameters to another program.\n\nThere are also lots of important techniques to be aware of in addition to simply how to access the parameters.\nChecking if a parameter was passed\nThis is done with constructs like IF \"%~1\"==\"\", which is true if and only if no arguments were passed at all. Note the tilde character which causes any surrounding quotes to be removed from the value of %1; without a tilde you will get unexpected results if that value includes double quotes, including the possibility of syntax errors.\nHandling more than 9 arguments (or just making life easier)\nIf you need to access more than 9 arguments you have to use the command SHIFT. This command shifts the values of all arguments one place, so that %0 takes the value of %1, %1 takes the value of %2, etc. %9 takes the value of the tenth argument (if one is present), which was not available through any variable before calling SHIFT (enter command SHIFT /? for more options).\nSHIFT is also useful when you want to easily process parameters without requiring that they are presented in a specific order. For example, a script may recognize the flags -a and -b in any order. A good way to parse the command line in such cases is\n:parse\nIF \"%~1\"==\"\" GOTO endparse\nIF \"%~1\"==\"-a\" REM do something\nIF \"%~1\"==\"-b\" REM do something else\nSHIFT\nGOTO parse\n:endparse\nREM ready for action!\n\nThis scheme allows you to parse pretty complex command lines without going insane.\nSubstitution of batch parameters\nFor parameters that represent file names the shell provides lots of functionality related to working with files that is not accessible in any other way. This functionality is accessed with constructs that begin with %~.\nFor example, to get the size of the file passed in as an argument use\nECHO %~z1\n\nTo get the path of the directory where the batch file was launched from (very useful!) you can use\nECHO %~dp0\n\nYou can view the full range of these capabilities by typing CALL /? in the command prompt.\n",
            "\nEnclose the paths containing spaces with double quotes.\ncmd /C \"C:\\Program Files (x86)\\WinRar\\Rar.exe\" a \"D:\\Hello 2\\File.rar\" \"D:\\Hello 2\\*.*\"\n\n",
            "\nYou should try using quotes.\ncmd /C \"C:\\Program Files (x86)\\WinRar\\Rar.exe\" a \"D:\\Hello 2\\File.rar\" \"D:\\Hello 2\\*.*\"\n\n"
        ],
        "answer": "A1",
        "tags": [
            "windows",
            "cmd",
            "escaping"
        ]
    },
    {
        "question_id": "13999432",
        "question": "\nAs per This Question, I'm using a thread to terminate a function on user input.  My code looks something like:\nbool stopper = false;\nthread stopThread(userStop, &stopper);      // start thread looking for user input\nfor(int i = 0; i < 1000; i++) {\n    if(stopper) { break; }                  // break if desired\n    // Do stuff\n}\nreturn 0;\n\nwhere,\nuserStop(bool *st) {\n    char chChar = getchar();\n    if(chChar == '\\n') {\n        *st = true;\n    }\n}\n\nWhen I run this, I get the error terminate called without an active exception.  Based on these questions: thread terminate called without an active exception, C++ terminate called without an active exception; it looks like its because I'm not 'join'ing the thread again.\nThe problem is, I don't want to 'join' the thread -- because then the user will need to provide input for userStop()to terminate, but I only want the user to provide input if the for-loop is to be broken (which it isn't necessarily).\nThanks!\n",
        "all_answers": [
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nTerminating a thread is a bad idea -- you should make your thread exit gracefully. If you did terminate the thread, you'd end up causing code in the getch() function to end unexpectedly. What if that code was in the middle of managing a data structure, allocating or freeing memory, or doing some other work that had to execute until completion? You'd end up leaving something in an invalid state, and you'd eventually crash when that invalid state was exercised.\n",
            "\nThe trouble you are encountering is a result of the stopThread going out of scope on the stack. The C++ standard has the following to say about this:\n\n30.3.1.3    thread destructor    [thread.thread.destr]\n~thread();\n\nIf joinable() then terminate(), otherwise no effects. [ Note: Either\n    implicitly detaching or joining a joinable() thread in its destructor\n    could result in difficult to debug correctness (for detach) or\n    performance (for join) bugs encountered only when an exception is\n    raised. Thus the programmer must ensure that the destructor is never\n    executed while the thread is still joinable. — end note ]\n\n\nWhat this means is that you should not let threads go out of scope without first calling either join() or detach().\nThe way you describe it, you want the thread to go out of scope without joining so it will continue to run as your application runs. That requires a call to detach(). From there, I can only offer a little wisdom...\n\nThat thread is now completely responsible for its own lifetime. If it doesn't return on its own, it will run forever (until the process terminates).\nYou are getting user input, presumably from something like cin or getch(). If these are accessed from multiple threads, you do not have much assurance that there are not race conditions in their library implementations. Tread lightly.\n\n",
            "\nIn your standard input thread, you'll want to asynchronously read from input.  And wake up on both a demand to stop reading, and new input.\nTerminating a thread without joining is not a reasonable thing to do.  So what you need to be able to do is say \"yo thread, finish up right now\", then be able to expect that the join will finish promptly.  This can even be via a two-step handshake (\"yo thread, finish up\", followed by \"ok ok, I managed to clean up, join me now\") in some cases.\nNote that your loop to 1000 looks really ridiculous: user input timeouts should generally be based on actual time passing, or some other event occurring that makes the user input non-useful.\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "multithreading"
        ]
    },
    {
        "question_id": "7666863",
        "question": "\nTo a UIScrollView *toScrollView (which is the width of the screen), I want to add a gray bottom border (exactly like that of the to-field of the compose view of the iPhone's native Messages app).\nTo achieve this, I followed Cocoa Touch: How To Change UIView's Border Color And Thickness? and just covered the top border with  the custom UINavigationBar and made the toScrollView's x-coordinate -1 & width 322 so that the left & right borders are just off screen.\nThis looks fine, but it's sort of a hack, and I was wondering if there's a better way to do this.\n- (void)viewDidLoad {\n    [super viewDidLoad];\n\n    // Add UINavigationBar *navigationBar at top.\n    self.navigationItem.leftBarButtonItem = [[UIBarButtonItem alloc]\n                                             initWithBarButtonSystemItem:UIBarButtonSystemItemCancel\n                                             target:self action:@selector(cancelAction)];\n    UINavigationBar *navigationBar = [[UINavigationBar alloc]\n                                      initWithFrame:CGRectMake(0.0f, 0.0f, 320.0f, 44.0f)];\n    navigationBar.items = [NSArray arrayWithObject:self.navigationItem];\n\n    // Add UIScrollView *toScrollView below navigationBar.\n    UIScrollView *toScrollView = [[UIScrollView alloc]\n                                  initWithFrame:CGRectMake(-1.0f, 43.0f, 322.0f, 45.0f)];\n    toScrollView.backgroundColor = [UIColor whiteColor];\n    toScrollView.layer.borderColor = [UIColor colorWithWhite:0.8f alpha:1.0f].CGColor;\n    toScrollView.layer.borderWidth = 1.0f;\n    [self.view addSubview:toScrollView];\n    [self.view addSubview:navigationBar]; // covers top of toScrollView\n}\n\n",
        "all_answers": [
            "\nYou can add a separate UIView with 1 point height and gray background color to self.view and position it right below toScrollView.\n\nEDIT: Unless you have a good reason (want to use some services of UIView which are not offered by CALayer), you should use CALayer as @MattDiPasquale suggests. UIView has a greater overhead, which might not be a problem in most cases, but still, the other solution is more elegant.\n\n",
            "\nInstead of using a UIView, as @ImreKelényi suggests, you can use a CALayer:\n// Add a bottomBorder.\nCALayer *bottomBorder = [CALayer layer];\n\nbottomBorder.frame = CGRectMake(0.0f, 43.0f, toScrollView.frame.size.width, 1.0f);\n\nbottomBorder.backgroundColor = [UIColor colorWithWhite:0.8f \n                                                 alpha:1.0f].CGColor;\n\n[toScrollView.layer addSublayer:bottomBorder];\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "uiview",
            "border"
        ]
    },
    {
        "question_id": "43243732",
        "question": "\nI try to find out why my env() helper always returns null. This causes trouble especially in app.php file, where are env() helpers widely used by default. Perhaps any mysterious server setting?\nMy env file:\nAPP_ENV=production\nAPP_KEY=base64:mymagickey=\nAPP_DEBUG=false\nAPP_LOG_LEVEL=info\nAPP_URL=http://www.example.com\n\netc...\n\nEDIT - I tried following:\nphp artisan cache:clear\nphp artisan view:clear\nphp artisan config:cache\n\nand ofcourse, i am using env helper like this: env('APP_ENV')\nBut still no success. The wierd part is, that $_ENV php variable contains every single variable from .env file.\n",
        "all_answers": [
            "\nSince Laravel 5.2, the env(...) function will not work after you cached the config.\nThe Laravel documentation says\n\nIf you are using the config:cache command during deployment, you must make sure that you are only calling the env function from within your configuration files, and not from anywhere else in your application.\n\nSo the correct answer would be to\n\nIf you are calling env from within your application, it is strongly recommended you add proper configuration values to your configuration files and call env from that location instead, allowing you to convert your env calls to config calls.\n\nAnd I quoted it from the same documentation\nFor a quick fix this will do:\n php artisan config:clear\n\nBut it will fail again as soon as configuration is cached, as should always be the case in production environments.\nAnd now it should be clear why, when you tried config:cache, it did not help, even though it clears the config prior to caching.\n",
            "\nUse \\Config::get('app.env'); instead of env(APP_ENV); because you're going to get the same error eventually and that's not good for a live website.\nIf you want to add custom variables from your ENV, go into your config app and find this:\n/*\n    |--------------------------------------------------------------------------\n    | Application Environment\n    |--------------------------------------------------------------------------\n    |\n    | This value determines the \"environment\" your application is currently\n    | running in. This may determine how you prefer to configure various\n    | services your application utilizes. Set this in your \".env\" file.\n    |\n    */\n\n'env' => env('APP_ENV', 'production'),\n\nadd a new line under \"'env' => env('APP_ENV', 'production'),\", so for example, it could be the following:\n/*\n    |--------------------------------------------------------------------------\n    | Application Environment\n    |--------------------------------------------------------------------------\n    |\n    | This value determines the \"environment\" your application is currently\n    | running in. This may determine how you prefer to configure various\n    | services your application utilizes. Set this in your \".env\" file.\n    |\n    */\n\n'env' => env('APP_ENV', 'production'),\n'key' => env('APP_KEY'),\n\nYou can call the \"key\" variable like this:\n\\Config::get('app.key');\n\nWhenever you add a new variable like \"key\" to the app env, you'll need to use config:cache to reset the cache.\n",
            "\nIt is a \".env\" known bug which can be solved with:\nphp artisan config:cache\n\n",
            "\nIt looks like you have everything correct according to Laravel docs, but you have a typo\n$item->push($product);\n\nShould be\n$items->push($product);\n\npush method appends an item to the end of the collection:\nI also want to think the actual method you're looking for is put\n$items->put('products', $product);\n\nput method sets the given key and value in the collection\n",
            "\nHope this command will save you\n\nphp artisan config:clear\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "laravel",
            "environment-variables",
            "phpdotenv"
        ]
    },
    {
        "question_id": "812437",
        "question": "\nI am working in PHP.\nPlease what's the proper way of inserting new records into the DB, which has unique field.\nI am inserting lot of records in a batch and I just want the new ones to be inserted and I don't want any error for the duplicate entry.\nIs there only way to first make a SELECT and to see if the entry is already there before the INSERT - and to INSERT only when SELECT returns no records? I hope not.\nI would like to somehow tell MySQL to ignore these inserts without any error.\nThank you\n",
        "all_answers": [
            "\nYou can use INSERT... IGNORE syntax if you want to take no action when there's a duplicate record.\nYou can use REPLACE INTO syntax if you want to overwrite an old record with a new one with the same key.\nOr, you can use INSERT... ON DUPLICATE KEY UPDATE syntax if you want to perform an update to the record instead when you encounter a duplicate.\nEdit:  Thought I'd add some examples.\nExamples\nSay you have a table named tbl with two columns, id and value.  There is one entry, id=1 and value=1.  If you run the following statements:\nREPLACE INTO tbl VALUES(1,50);\n\nYou still have one record, with id=1 value=50.  Note that the whole record was DELETED first however, and then re-inserted.  Then:\nINSERT IGNORE INTO tbl VALUES (1,10);\n\nThe operation executes successfully, but nothing is inserted.  You still have id=1 and value=50.  Finally:\nINSERT INTO tbl VALUES (1,200) ON DUPLICATE KEY UPDATE value=200;\n\nYou now have a single record with id=1 and value=200.\n",
            "\nYou can use triggers.\nAlso check this introduction guide to triggers.\n",
            "\nYou can make sure that you do not insert duplicate information by using the EXISTS condition.\nFor example, if you had a table named clients with a primary key of client_id, you could use the following statement:\nINSERT INTO clients\n(client_id, client_name, client_type)\nSELECT supplier_id, supplier_name, 'advertising'\nFROM suppliers\nWHERE not exists (select * from clients\nwhere clients.client_id = suppliers.supplier_id);\n\nThis statement inserts multiple records with a subselect.\nIf you wanted to insert a single record, you could use the following statement:\nINSERT INTO clients\n(client_id, client_name, client_type)\nSELECT 10345, 'IBM', 'advertising'\nFROM dual\nWHERE not exists (select * from clients\nwhere clients.client_id = 10345);\n\nThe use of the dual table allows you to enter your values in a select statement, even though the values are not currently stored in a table.\nfrom http://www.techonthenet.com/sql/insert.php\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "mysql",
            "insert"
        ]
    },
    {
        "question_id": "41385059",
        "question": "\nSay I have the following type:\ntype Event = {\n   name: string;\n   dateCreated: string;\n   type: string;\n}\n\nI now want to extend this type, i.e.\ntype UserEvent extends Event = {\n   UserId: string; \n}\n\nThis doesn't work. How can I do this?\n",
        "all_answers": [
            "\nWhat you are trying to achieve is equivalent to\ninterface Event {\n   name: string;\n   dateCreated: string;\n   type: string;\n}\n\ninterface UserEvent extends Event {\n   UserId: string; \n}\n\nThe way you defined the types does not allow for specifying inheritance, however you can achieve something similar using intersection types, as artem pointed out.\n",
            "\nThe keyword extends can be used for interfaces and classes only.\nIf you just want to declare a type that has additional properties, you can use intersection type:\ntype UserEvent = Event & {UserId: string}\n\nUPDATE for TypeScript 2.2, it's now possible to have an interface that extends object-like type, if the type satisfies some restrictions:\ntype Event = {\n   name: string;\n   dateCreated: string;\n   type: string;\n}\n\ninterface UserEvent extends Event {\n   UserId: string; \n}\n\nIt does not work the other way round - UserEvent must be declared as interface, not a type if you want to use extends syntax.\nAnd it's still impossible to use extend with arbitrary types - for example, it does not work if Event is a type parameter without any constraints.\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "typescript"
        ]
    },
    {
        "question_id": "58270901",
        "question": "\nI'm receiving the following error running npm start:\nES2015 module syntax is preferred over custom TypeScript modules and namespaces  @typescript-eslint/no-namespace\n    namespace InternalThings {...}\n\nI tried to research this but it's very confusing.\nWhy does this is happening?\nHow to fix it?\nI tried to put some flags on my tsconfig.json but so far no success;\n",
        "all_answers": [
            "\nThe error is coming from eslint. You have to either ignore '@typescript-eslint/no-namespace' rule in the config or rewrite your code using ES6.\n\nCustom TypeScript modules (module foo {}) and namespaces (namespace\n  foo {}) are considered outdated ways to organize TypeScript code.\n  ES2015 module syntax is now preferred (import/export)\n\nRefer https://github.com/typescript-eslint/typescript-eslint/blob/master/packages/eslint-plugin/docs/rules/no-namespace.md\n",
            "\nThis is a lint error, caused by this lint rule: https://github.com/typescript-eslint/typescript-eslint/blob/master/packages/eslint-plugin/docs/rules/no-namespace.md\nIf you find the rule useful and want to keep it, then you'll need to modify your code to use import and export instead of namespace. See the documentation of the rule for what counts as a fix.\nIf you like the rule, but want to disable the rule for this line, add the following just above it:\n// eslint-disable-next-line @typescript-eslint/no-namespace\n\nIf you don't like the rule and want to disable it entirely, then edit your .eslintrc file to have the following line:\nrules: {\n  \"@typescript-eslint/no-namespace\": \"off\"\n}\n\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nUpdate 2020 - CLI\nAs @mix3d pointed out you can just run a command where file.js is your file and someFunction is your function optionally followed by parameters separated with spaces\nnpx run-func file.js someFunction \"just some parameter\"\n\nThat's it.\nfile.js called in the example above\nconst someFunction = (param) => console.log('Welcome, your param is', param)\n\n// exporting is crucial\nmodule.exports = { someFunction }\n\nMore detailed description\nRun directly from CLI (global)\nInstall\nnpm i -g run-func\n\nUsage i.e. run function \"init\", it must be exported, see the bottom\nrun-func db.js init\n\nor\nRun from package.json script (local)\nInstall\nnpm i -S run-func\n\nSetup\n\"scripts\": {\n   \"init\": \"run-func db.js init\"\n}\n\nUsage\nnpm run init\n\nParams\nAny following arguments will be passed as function parameters init(param1, param2)\nrun-func db.js init param1 param2\n\nImportant\nthe function (in this example init) must be exported in the file containing it\nmodule.exports = { init };\n\nor ES6 export\nexport { init };\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "node.js",
            "reactjs",
            "typescript"
        ]
    },
    {
        "question_id": "330836",
        "question": "\nHow do I uninstall a Windows Service when there is no executable for it left on the system? I can not run installutil -u since there is not executable left on the system. I can still see an entry for the service in the Services console. \nThe reason for this state is probably because of a problem in the msi package that does not remove the service correctly, but how do I fix it once the service is in this state?\n",
        "all_answers": [
            "\nThere's a built in windows cmd to do this: sc create. Not as fancy as nssm, but you don't have to download an additional piece of software.\nsc create \"ServiceName\" start= demand displayname= \"DisplayName\" binpath= [path to .bat file]\n\nNote\n\nstart=demand means you must start the service yourself. Options include: boot, system, auto, demand, disabled, delayed-auto\nwhitespace is required after =\nI did encounter an error on service start that the service did not respond in a timely manner, but it was clear the service had run the .bat successfully. Haven't dug into this yet but this thread experienced the same thing and solved it using nssm to install the service.\n\n",
            "\nCreate a copy of executables of same service and paste it on the same path of the existing service and then uninstall.\n",
            "\nNSSM is totally free and hyper-easy, running command prompt / terminal as administrator:\nnssm install \"YourCoolServiceNameLabel\"\n\nthen a dialog will appear so you can choose where is the file you want to run.\nto uninstall\nnssm remove \"YourCoolServiceNameLabel\"\n\n",
            "\nfound here\nI just tried on windows XP, it worked\nlocal computer:\nsc \\\\. delete [service-name]\n  Deleting services in Windows Server 2003\n\n  We can use sc.exe in the Windows Server 2003 to control services, create services and delete services. Since some people thought they must directly modify the registry to delete a service, I would like to share how to use sc.exe to delete a service without directly modifying the registry so that decreased the possibility for system failures.\n\n  To delete a service: \n\n  Click “start“ - “run“, and then enter “cmd“ to open Microsoft Command Console.\n\n  Enter command:\n\n  sc servername delete servicename\n\n  For instance, sc \\\\dc delete myservice\n\n  (Note: In this example, dc is my Domain Controller Server name, which is not the local machine, myservice is the name of the service I want to delete on the DC server.)\n\n  Below is the official help of all sc functions:\n\n  DESCRIPTION:\n    SC is a command line program used for communicating with the\n    NT Service Controller and services. \n  USAGE:\n          sc\n\n",
            "\nYou should be able to uninstall it using sc.exe (I think it is included in the Windows Resource Kit) by running the following in an \"administrator\" command prompt:\nsc.exe delete <service name>\n\nwhere <service name> is the name of the service itself as you see it in the service management console, not of the exe.\nYou can find sc.exe in the System folder and it needs Administrative privileges to run. More information in this Microsoft KB article.\nAlternatively, you can directly call the DeleteService() api. That way is a little more complex, since you need to get a handle to the service control manager via OpenSCManager() and so on, but on the other hand it gives you more control over what is happening.\n"
        ],
        "answer": "A5",
        "tags": [
            "windows",
            "windows-services",
            "uninstallation"
        ]
    },
    {
        "question_id": "2496901",
        "question": "\nOne of my apps has an \"opening screen\" (basically a menu) that has an EditText followed by several Buttons. The problem is that several of my users are reporting that when they open the app it's automatically popping up the on-screen keyboard without them even touching the EditText. As far as I can tell, all of these users are using the HTC Hero. \nIs this a bug in 1.5? Is there anything I can do about it?\n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nYou can use the following line of code in the activity's onCreate method to make sure the keyboard only pops up when a user clicks into an EditText\nthis.getWindow().setSoftInputMode(WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_HIDDEN); \n\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nIn that version of Android, when a view is inflated, the focus will be set to the first focusable control by default - and if there's no physical keyboard, the on-screen keyboard will pop up.\nTo fix this, explicitly set focus somewhere else. If focus is set to anything other than an EditText, the on-screen keyboard will not appear.\nHave you tried testing this by running Android 1.5 in the emulator?\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "android-softkeyboard"
        ]
    },
    {
        "question_id": "25783282",
        "question": "\nXcode6 has removed the Empty Application template when creating a new project. How can we create an empty application (without Storyboard) in Xcode6 and above, like in earlier versions?\n",
        "all_answers": [
            "\nThere is no option in XCode6 and above versions for directly creating an Empty Application as in XCode5 and earlier. But still we can create an application without Storyboard by following these steps:\n\nCreate a Single View Application.\nRemove Main.storyboard and LaunchScreen.xib (select them, right-click, and choose to either\nremove them from the project, or delete them completely).\nRemove \"Main storyboard file base name\" and \"Launch screen interface\nfile base name\" entries in Info.plist file.\nOpen AppDelegate.m, and edit applicationDidFinishLaunchingWithOptions so that it looks like this:\n\nSwift 3 and above:\n    func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplicationLaunchOptionsKey: Any]?) -> Bool \n    {\n        self.window = UIWindow(frame: UIScreen.main.bounds)\n        self.window?.backgroundColor = UIColor.white\n        self.window?.makeKeyAndVisible()\n        return true\n    }\n\nSwift 2.x:\n    func application(application: UIApplication, didFinishLaunchingWithOptions launchOptions: [NSObject: AnyObject]?) -> Bool \n    {\n        self.window = UIWindow(frame: UIScreen.mainScreen().bounds)\n        self.window?.backgroundColor = UIColor.whiteColor()\n        self.window?.makeKeyAndVisible()\n        return true\n    }\n\nObjective-C:\n    - (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions\n    {\n        self.window = [[UIWindow alloc] initWithFrame:[[UIScreen mainScreen] bounds]];\n        // Override point for customization after application launch.\n        self.window.rootViewController = [[ViewController alloc] init];\n        self.window.backgroundColor = [UIColor whiteColor];\n        [self.window makeKeyAndVisible];\n        return YES;\n    }\n\n",
            "\nYes, Or just use one of the previous Beta to create it, and continue on the latest version after.\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "xcode",
            "storyboard",
            "xcode6"
        ]
    },
    {
        "question_id": "17894688",
        "question": "\nI have a User model and a Task model. I have not mentioned any relation between them while creating them. \nI need to establish that User has_many Tasks and a Task belongs_to User through a migration  \nWhat would be the migration generation command for establishing that relationship?\n",
        "all_answers": [
            "\nSteps : \n\n\nbundle config --delete bin         # Turn off Bundler's stub generator\nrake rails:update:bin               # Use the new Rails 4 executables\ngit add bin or git add bin -f      # Add bin/ to source control\ngit commit -a -m \"you commit message\"\ngit push heroku master\nheroku open\n\n\n",
            "\nI had this problem also since I upgraded to rails 4.0.0\nRun this command\nrake rails:update:bin\n\nYou can go here for more info\nhttps://devcenter.heroku.com/articles/rails4\n",
            "\nI had this issue because the permissions on my ~/bin directory were 644 instead of 755.  Running rake rails:update:bin locally (on Mac/*nix) and then pushing the changes fixed the problem.\n",
            "\nAfter struggling with this for a bit, I noticed that my Rails 4 project had a /bin directory, unlike some older Rails 3 projects I had cloned.  /bin contains 3 files, bundle, rails, and rake, but these weren't making it to Heroku because I had bin in my global .gitignore file.  \nThis is a pretty common ignore rule if you work with Git and other languages (Java, etc.), so to fix this:\n\nRemove bin from ~/.gitignore\nRun bundle install\nCommit your\nchanges with git add . and git commit -m \"Add bin back\"\nPush your changes to Heroku with git push heroku master\n\n",
            "\nThere is no special migration command that would be used.\nIn your User model you will put \nclass User < ActiveRecord::Base\n  has_many :tasks\nend\n\nclass Task < ActiveRecord::Base\n  belongs_to :user\nend\n\nIn the corresponding migration file for the tasks you have the following field added     user_id\nTake a look at this guide\n",
            "\nYou could call:\nrails g model task user:references\n\nwhich will generates an user_id column in the tasks table and will modify the task.rb model to add a belongs_to :user relatonship. Please note, you must to put manually the has_many :tasks or  has_one :task relationship to the user.rb model.\nIf you already have the model generated, you could create a migration with the following:\nrails g migration AddUserToTask user:belongs_to\n\nwhich will generate:\nclass AddUserToTask < ActiveRecord::Migration\n  def change\n    add_reference :tasks, :user, index: true\n  end\nend\n\nthe only difference with this approach is, the belongs_to :user relationship in the task.rb model won't be created automatically, so you must create it for your own.\n",
            "\nThe Relationship in Rails is taken care by model not by Rails.\nSo you just need to define this relationship in your model:\nclass User < ActiveRecord::Base\n  has_many :tasks\nend\n\nclass Task < ActiveRecord::Base\n  belongs_to :user\nend\n\nAnd just make sure that a user_id field is present in the migration for creating the \"tasks\" table.\n",
            "\nI had the very same problem that you did. The issue lied in the fact that the bin folder was never pushed to the heroku repository. \nI looked, I looked, and then I looked again, there was no rule in the .gitignore file for the bin/ folder...\nThen, after a lot of pain and anguish, I realized that a couple of months before I had created a global .gitignore that would ignore all bin folders of all my repositories (why lord, why??).\nI deleted the global .gitignore, and everything worked fine.\n"
        ],
        "answer": "A6",
        "tags": [
            "ruby-on-rails",
            "rails-activerecord",
            "ruby-on-rails-4",
            "rails-migrations"
        ]
    },
    {
        "question_id": "4708645",
        "question": "\nUsing Windows XP I accidentally typed git commit -a instead of git commit -am \"My commit message\", and now I'm viewing my CMD prompt filled with the file version of my commit message (\"Please enter the commit message for your...\"). I've added my message to the top, but now I can't figure out how to save and leave. I tried to press Ctrl + W + Q, but it doesn't do anything, but add ^ where the cursor is.\nI also tried Esc first, and then Ctrl + W + Q, but it says No write since last change (add ! to override).\n",
        "all_answers": [
            "\nPress ESC to make sure you are out of the edit mode and then type:\n:wq\n\n",
            "\nEsc to make sure you exit insert mode, then :wq (colon w q) or ZZ (shift-Z shift-Z).\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nRemove the last commit before push\ngit reset --soft HEAD~1\n1 means the last commit, if you want to remove two last use 2, and so forth*\n",
            "\nI have experienced the same situation I did the below as this much easier.\nBy passing commit-Id you can reach to the particular commit you want to go:\ngit reset --hard {commit-id}\n\nAs you want to remove your last commit so you need to pass the commit-Id where you need to move your pointer:\ngit reset --hard db0c078d5286b837532ff5e276dcf91885df2296\n\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n"
        ],
        "answer": "A1",
        "tags": [
            "git",
            "vim",
            "windows-xp",
            "git-commit"
        ]
    },
    {
        "question_id": "1020890",
        "question": "\n\n\n\nThe \"joke\" question Joel asked during podcast #58 made me all nostalgic for Logo, which was the second language I ever programmed in, after Basic, and which is why I never had any trouble with recursion in college.\nAre there any implementations of Logo for Windows or Linux (the platforms I can use) or Mac (because I know I'm not alone in this world)?  How can I get the Logo programming language for my computer?\n",
        "all_answers": [
            "\nThere is a pure-Python version of Logo available at http://pylogo.org/\n",
            "\nUCBLogo is my favorite LOGO implementation, and happens to be available for Windows, UNIX (with X11 support for turtle drawing), and Mac OS X, with outdated ports for DOS and Mac OS 9 as well.\nMost Linux distros already have it packaged.\nIt is also still maintained (thanks to cheap labor students at Berkeley), open-source, and very portable (I've run it on various flavors of UNIX, including Linux, and various processor architectures as well).\nUCBLogo comes with a fairly comprehensive standard library and good documentation; the source code for the examples in Brian Harvey's \"Computer Science Logo Style\" books are also included.\n\nAddendum:\npapert - logo in your browser is surprisingly featureful, and seems to work in any modern browser.\n",
            "\nI'm surprised nobody has mentioned Tower for Mac OSX.\nHere is a screenshot:\n\n",
            "\nFor OSX I don't like Tower. I have had too many crashes and problems. On the other hand, Source Tree works very well. Albeit it requires a bit more understanding of git itself. IMO Tower is no Cornerstone. I wish Cornerstone would support GIT.\n",
            "\nGitGui comes with git. It has always worked great for me. Is there some problem you have with it?\nScreenshot:\n\n",
            "\nI'm teaching my kids LOGO successfully on Windows using Elica LOGO.  (Kids ages are presently 12 and 10.)\nThe package's strengths include many \"advanced\" extensions, beyond the basic 2-dimensional turtle.  These include 3-D graphics and simple hooks into the Windows widget world.  (You can create Windows forms with buttons, etc., from within your LOGO code.)\nLacks sound/music capability, at least in version 5.5, and the built-in documentation is extensive, with many advanced examples, but it's not very useful in my opinion--due to its incompleteness, and its having many coding examples that contain errors.   (But my kids learn more by finding the errors in the programing samples.)\n",
            "\nHere's one for Mac: GitX\nScreenshot:\n\n",
            "\nIn the vein of teaching how to fish: take a look at https://git.wiki.kernel.org/index.php/InterfacesFrontendsAndTools page on Git Wiki, which has section about GUIs.\nGit Homepage also has section about GUIs: http://git-scm.com/downloads/guis\n",
            "\nCross-platform versions:\nhttp://www.mathcats.com/gallery/logodownloadinfo.html\nMacOS X specific:\nhttp://www.alancsmith.co.uk/\nOpen-source Logo:\nhttp://sourceforge.net/projects/fmslogo\nhttp://www.rz.uni-augsburg.de/~micheler/en/\n",
            "\nWindows has TortoiseGit. It is not as mature as TortoiseSVN, but I've been using it and it works well enough for my purposes.\nScreenshot:\n\nEDIT [Dec 2014]: I'd also recommend looking at Dan's answer. Github's UI is probably the most mature/supported tool out there now (even if you don't use Github!)\n",
            "\nTo really recreate the nostalgia, you might try running Logo on an emulated Apple II.  You can get images of Apple II disks for Logo here and the AppleWin emulator here.\n",
            "\nSource Tree (for MAC)\nScreenshot:\n\n",
            "\nTry Git Extensions.\nScreenshot:\n\n"
        ],
        "answer": "A6",
        "tags": [
            "linux",
            "windows",
            "macos",
            "logo-lang"
        ]
    },
    {
        "question_id": "1312885",
        "question": "\nI am trying to figure out which I should be using.  On closing my WinForm app fires of a Form in Dialog mode.  That form runs a Background worker that Syncs the DB with the remote DB and displays it's progress on the \"Splash Form.\"  \nI have a method like so:\nprivate void CloseMyApp()\n{\n    SaveUserSettings();\n\n    splashForm = new SplashForm();\n    splashForm.ShowDialog();\n\n    Application.ExitThread();\n    //Application.Exit();\n}\n\nwhich is what I call to close my app from Menu --> Exit and in the Form_FormClosing() event.  Application.Exit() gives the following error -->\n\nCollection was modified; enumeration operation may not execute.\n\nNow I read that Environment.Exit() is brutal and means there is probably something wrong with your app (see here).\nApplication.ExitThread() works but I am concered that it may only be APPEARING to work and as I have never used it before I am not sure when it is normally appropriate to do so.\n",
        "all_answers": [
            "\nUnfortunately, the problem isn't caused by any of these, and really exists (even if you don't get the message) in all of these scenarios.\nYour problem is this:\n\nOn closing my WinForm App fires of a Form in Dialog mode. That form runs a Background worker that Syncs the DB with the remote DB and displays it's progress on the \"Splash Form.\"\n\nSince you're not actually shutting down when you request a shutdown, all of the \"Exit\" functions are trying to tear down your background thread.  Unfortunately, this is probably happening in the middle of your DB sync, and an enumeration working in the save logic is probably providing that error.\nI would recommend not using any of these - just call myMainForm.Close() instead.  That should close your main form, which will fire your closing logic appropriately.  Once the main form in your application closes, it will shut down gracefully.\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nEnvironment.Exit() is used for console apps.\nYou want to use: System.Windows.Forms.Application.Exit()\nBy exiting thread, you are only exiting the current thread context, while leaving any started foreground threads running. I suspect the thread that is causing the error is still running, so you've essentially masked the problem, not worked around it. I would try and figure out why you are getting this error \"Collection was modified; enumeration operation may not execute.\" on exit. It's being exposed by Application.Exit(), but it's not caused by it.\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            ".net",
            "winforms",
            "multithreading",
            "exit"
        ]
    },
    {
        "question_id": "1858195",
        "question": "\nHow could I convert an XLS file to a CSV file on the windows command line.\nThe machine has Microsoft Office 2000 installed. I'm open to installing OpenOffice if it's not possible using Microsoft Office.\n",
        "all_answers": [
            "\nWhy not write your own?\nI see from your profile you have at least some C#/.NET experience.  I'd create a Windows console application and use a free Excel reader to read in your Excel file(s).  I've used Excel Data Reader available from CodePlex without any problem (one nice thing: this reader doesn't require Excel to be installed).  You can call your console application from the command line.\nIf you find yourself stuck post here and I'm sure you'll get help.\n",
            "\nThere's an Excel OLEDB data provider built into Windows; you can use this to 'query' the Excel sheet via ADO.NET and write the results to a CSV file. There's a small amount of coding required, but you shouldn't need to install anything on the machine.\n",
            "\nFor second accuracy, yyyy-MM-dd HH:mm:ss should do the trick.\nI believe Excel is not very good with fractions of a second (loses them when interacting with COM object IIRC).\n",
            "\nOpen Notepad, create a file called XlsToCsv.vbs and paste this in:\nif WScript.Arguments.Count < 2 Then\n    WScript.Echo \"Error! Please specify the source path and the destination. Usage: XlsToCsv SourcePath.xls Destination.csv\"\n    Wscript.Quit\nEnd If\nDim oExcel\nSet oExcel = CreateObject(\"Excel.Application\")\nDim oBook\nSet oBook = oExcel.Workbooks.Open(Wscript.Arguments.Item(0))\noBook.SaveAs WScript.Arguments.Item(1), 6\noBook.Close False\noExcel.Quit\nWScript.Echo \"Done\"\n\nThen from a command line, go to the folder you saved the .vbs file in and run: \nXlsToCsv.vbs [sourcexlsFile].xls [destinationcsvfile].csv\n\nThis requires Excel to be installed on the machine you are on though.\n",
            "\nHow about with PowerShell?\nCode should be looks like this, not tested though\n$xlCSV = 6\n$Excel = New-Object -Com Excel.Application \n$Excel.visible = $False \n$Excel.displayalerts=$False \n$WorkBook = $Excel.Workbooks.Open(\"YOUDOC.XLS\") \n$Workbook.SaveAs(\"YOURDOC.csv\",$xlCSV) \n$Excel.quit()\n\nHere is a post explaining how to use it\nHow Can I Use Windows PowerShell to Automate Microsoft Excel?\n"
        ],
        "answer": "A4",
        "tags": [
            "windows",
            "excel",
            "csv"
        ]
    },
    {
        "question_id": "22974765",
        "question": "\nWhenever I read a csv file in R (read.csv(\"file_name.csv\")) that was exported using toad, the first column name is preceded by the following characters \"ï..\". Also, opening the csv file in excel or notepad++ shows up correctly (without the preceding characters). This is a hassle as my workaround has been to rename the column after each read. \nThanks for any fix to this issue! \nEdit:\nThe export was created in Toad by right-clicking on the result set of a query and selecting  'Quick Export -> File -> CSV File'\nMore details per comment:\nhead(readLines('test_file.csv'),n=3)`<br>\n[1] \"ï»¿ID,LOCATION\" \"12021,1204\" \"12281,1204\"\n\n",
        "all_answers": [
            "\nAfter researching this further, it has to do with BOM (Byte Order Mark) added characters. Apparently cannot use Quick Export, but the Data Export Wizard instead as it allows setting the file encoding. It worked for my by setting it to Western European(Windows) instead of unicode utf-8.\nSee How do I remove ï»¿ from the beginning of a file?\n",
            "\nIt might be easiest to try the RCurl package. Install the package and try the following:\n# install.packages(\"RCurl\")\nlibrary(RCurl)\nURL <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv\"\nx <- getURL(URL)\n## Or \n## x <- getURL(URL, ssl.verifypeer = FALSE)\nout <- read.csv(textConnection(x))\nhead(out[1:6])\n#   RT SERIALNO DIVISION PUMA REGION ST\n# 1  H      186        8  700      4 16\n# 2  H      306        8  700      4 16\n# 3  H      395        8  100      4 16\n# 4  H      506        8  700      4 16\n# 5  H      835        8  800      4 16\n# 6  H      989        8  700      4 16\ndim(out)\n# [1] 6496  188\n\ndownload.file(\"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv\",destfile=\"reviews.csv\",method=\"libcurl\")\n\n",
            "\nHere's an update as of Nov 2014. I find that setting method='curl' did the trick for me (while method='auto', does not).\nFor example:\n# does not work\ndownload.file(url='https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip',\n              destfile='localfile.zip')\n\n# does not work. this appears to be the default anyway\ndownload.file(url='https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip',\n              destfile='localfile.zip', method='auto')\n\n# works!\ndownload.file(url='https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip',\n              destfile='localfile.zip', method='curl')\n\n",
            "\nTry this:\nd <- read.csv(\"test_file.csv\", fileEncoding=\"UTF-8-BOM\")\n\nThis works in R 3.0.0+ and removes the BOM if present in the file (common for files generated from Microsoft applications: Excel, SQL server)\n"
        ],
        "answer": "A4",
        "tags": [
            "r",
            "csv",
            "toad"
        ]
    },
    {
        "question_id": "36683726",
        "question": "\nI am trying to build my first app with react-native.\nI am following these 2 tutorial:\n\nhttps://facebook.github.io/react-native/docs/getting-started.html#content\nhttps://facebook.github.io/react-native/docs/android-setup.html\n\nI am sure that I installed all the requirements from the second link but when I try running my app with react-native run-android, I get the following error:\n\nI executed this command while running genymotion.\nThis is all that I have installed in Android SDK:\n\n\nI tried to install Android build tools 23.0.1 but I get this error:\n\nWhat should I do?\n",
        "all_answers": [
            "\nI've renamed the project' subfolder from: \"android/app/src/main/java/MY/APP/OLD_ID/\" to: \"android/app/src/main/java/MY/APP/NEW_ID/\"\nThen manually switched the old and new package ids:\nIn:\nandroid/app/src/main/java/MY/APP/NEW_ID/MainActivity.java:\npackage MY.APP.NEW_ID;\n\nIn android/app/src/main/java/MY/APP/NEW_ID/MainApplication.java:\npackage MY.APP.NEW_ID;\n\nIn android/app/src/main/AndroidManifest.xml:\npackage=\"MY.APP.NEW_ID\"\n\nAnd in android/app/build.gradle:\napplicationId \"MY.APP.NEW_ID\"\n\nIn android/app/BUCK:\nandroid_build_config(\n  package=\"MY.APP.NEW_ID\"\n)\nandroid_resource(\n  package=\"MY.APP.NEW_ID\"\n)\n\nGradle' cleaning in the end (in /android folder):\n./gradlew clean\n\n",
            "\nTo change the package name from com.myapp to: com.mycompany.myapp (for example), \n\nFor iOS app of the react app, use xcode - under general.\nFor the android app, open the build.gradle at module level. The one in the android/app folder. You will find \n\n// ...\ndefaultConfig {\n     applicationId com.myapp\n     // ...\n}\n// ...\n\nChange the com.myapp to whatever you need.\nHope this helps. \n",
            "\nI use the react-native-rename* npm package. Install it via\nnpm install react-native-rename -g\n\nThen, from the root of your React Native project, execute the following:\nreact-native-rename \"MyApp\" -b com.mycompany.myapp\n\n",
            "\nEither install v23.0.1 of the build tools (the fifth row in your screenshot), or change your code to use the build tools version you already have installed (v23.0.3). This can be specified in your app's build.gradle file:\nandroid {\n    compileSdkVersion 23\n    buildToolsVersion \"23.0.3\"\n\n    defaultConfig {\n        ...\n    }\n}\n\nAs per duncanc4's comment below, \n\nThe build.gradle file you want to edit is in the android/app folder\n  within your project directory.\n\n",
            "\nThe error you're getting seems to be related to system's permissions, since it's not able to create a folder.\nTry running the sdk-manager using root (with su or sudo commands).\n",
            "\nI faced the same problem and I solved it doing the following:\nGo to /home/[USER]/Android/Sdk/tools\nand execute:\n\n$android list sdk -a\n\nWhich will show a list like:\n\nAndroid SDK Tools, revision 24.0.2\nAndroid SDK Platform-tools, revision 23.0.2\nAndroid SDK Platform-tools, revision 23.0.1\n\n... and many more\nThen, execute the command (attention! at your computer the third option may be different):\n\n$android update sdk -a -u -t 3\n\nIt will install the 23.0.1 SDK Platform-tools components.\nTry to build your project again.\n"
        ],
        "answer": "A6",
        "tags": [
            "android",
            "linux",
            "react-native"
        ]
    },
    {
        "question_id": "11372177",
        "question": "\nI have the following dictionary passed to a render function, with sources being a list of strings and title being a string potentially equal to one of the strings in sources:\n{'title':title, 'sources':sources})\n\nIn the HTML template I'd like to accomplish something among the lines of the following:\n{% for source in sources %}\n  <tr>\n    <td>{{ source }}</td>\n    <td>\n      {% if title == {{ source }} %}\n        Just now!\n      {% endif %}\n    </td>\n  </tr>\n{% endfor %}\n\nHowever, the following block of text results in an error:\nTemplateSyntaxError at /admin/start/\nCould not parse the remainder: '{{' from '{{'\n\n...with {% if title == {{ source }} %} being highlighted in red.\n",
        "all_answers": [
            "\nA quick look at django.contib.admin.options' change_view method shows the original object is included as a context variable called original. So if you're simply overriding change_form.html itself you can get to the object being edited via {{ original }}. \n",
            "\n{% for source in sources %}\n  <tr>\n    <td>{{ source }}</td>\n    <td>\n      {% ifequal title source %}\n        Just now!\n      {% endifequal %}\n    </td>\n  </tr>\n{% endfor %}\n\n                or\n\n\n{% for source in sources %}\n      <tr>\n        <td>{{ source }}</td>\n        <td>\n          {% if title == source %}\n            Just now!\n          {% endif %}\n        </td>\n      </tr>\n    {% endfor %}\n\nSee Django Doc\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nYou shouldn't use the double-bracket {{ }} syntax within if or ifequal statements, you can simply access the variable there like you would in normal python:\n{% if title == source %}\n   ...\n{% endif %}\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n"
        ],
        "answer": "A5",
        "tags": [
            "django",
            "templates",
            "django-templates"
        ]
    },
    {
        "question_id": "11849562",
        "question": "\nI tried using JSON.stringify(object), but it doesn't go down on the whole structure and hierarchy.\nOn the other hand console.log(object) does that but I cannot save it. \nIn the console.log output I can expand one by one all the children and select and copy/paste but the structure is to big for that.\n",
        "all_answers": [
            "\nThat is an object, not an array. So you would do:\nvar json = { cool: 34.33, alsocool: 45454 };\njson.supercool = 3.14159;\nconsole.dir(json);\n\n",
            "\nvar array = new Array(); // or the shortcut: = []\narray.push ( {\"cool\":\"34.33\",\"also cool\":\"45454\"} );\narray.push (  {\"cool\":\"34.39\",\"also cool\":\"45459\"} );\n\nYour variable is a javascript object {} not an array [].\nYou could do:\nvar o = {}; // or the longer form: = new Object()\no.SomeNewProperty = \"something\";\no[\"SomeNewProperty\"] = \"something\";\n\nand\nvar o = { SomeNewProperty: \"something\" };\nvar o2 = { \"SomeNewProperty\": \"something\" };\n\nLater, you add those objects to your array: array.push (o, o2);\nAlso JSON is simply a string representation of a javascript object, thus:\nvar json = '{\"cool\":\"34.33\",\"alsocool\":\"45454\"}'; // is JSON\nvar o = JSON.parse(json); // is a javascript object\njson = JSON.stringify(o); // is JSON again\n\n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n",
            "\nYou can use the Chrome DevTools Utilities API copy() command for copying the string representation of the specified object to the clipboard.\nIf you have lots of objects then you can actually JSON.stringify() all your objects and keep on appending them to a string. Now use copy() method to copy the complete string to clipboard.\n",
            "\nUpdate:\nYou can now just right click\n\nRight click > Save as in the Console panel to save the logged messages to a file.\n\nOriginal Answer:\nYou can use this devtools snippet shown below to create a console.save method. It creates a FileBlob from the input, and then automatically downloads it.\n(function(console){\n\nconsole.save = function(data, filename){\n\n    if(!data) {\n        console.error('Console.save: No data')\n        return;\n    }\n\n    if(!filename) filename = 'console.json'\n\n    if(typeof data === \"object\"){\n        data = JSON.stringify(data, undefined, 4)\n    }\n\n    var blob = new Blob([data], {type: 'text/json'}),\n        e    = document.createEvent('MouseEvents'),\n        a    = document.createElement('a')\n\n    a.download = filename\n    a.href = window.URL.createObjectURL(blob)\n    a.dataset.downloadurl =  ['text/json', a.download, a.href].join(':')\n    e.initMouseEvent('click', true, false, window, 0, 0, 0, 0, 0, false, false, false, false, 0, null)\n    a.dispatchEvent(e)\n }\n})(console)\n\nSource: http://bgrins.github.io/devtools-snippets/#console-save\n"
        ],
        "answer": "A5",
        "tags": [
            "javascript",
            "json",
            "google-chrome"
        ]
    },
    {
        "question_id": "35907642",
        "question": "\nHow do I add a custom header to a HttpClient request? I am using PostAsJsonAsync method to post the JSON. The custom header that I would  need to be added is \n\"X-Version: 1\"\n\nThis is what I have done so far:\nusing (var client = new HttpClient()) {\n    client.BaseAddress = new Uri(\"https://api.clickatell.com/\");\n    client.DefaultRequestHeaders.Accept.Clear();\n    client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", \"xxxxxxxxxxxxxxxxxxxx\");\n    client.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue(\"application/json\"));\n    var response = client.PostAsJsonAsync(\"rest/message\", svm).Result;\n}\n\n",
        "all_answers": [
            "\nvar request = new HttpRequestMessage {\n    RequestUri = new Uri(\"[your request url string]\"),\n    Method = HttpMethod.Post,\n    Headers = {\n        { \"X-Version\", \"1\" } // HERE IS HOW TO ADD HEADERS,\n        { HttpRequestHeader.Authorization.ToString(), \"[your authorization token]\" },\n        { HttpRequestHeader.ContentType.ToString(), \"multipart/mixed\" },//use this content type if you want to send more than one content type\n    },\n    Content = new MultipartContent { // Just example of request sending multipart request\n        new ObjectContent<[YOUR JSON OBJECT TYPE]>(\n            new [YOUR JSON OBJECT TYPE INSTANCE](...){...}, \n            new JsonMediaTypeFormatter(), \n            \"application/json\"), // this will add 'Content-Type' header for the first part of request\n        new ByteArrayContent([BINARY DATA]) {\n            Headers = { // this will add headers for the second part of request\n                { \"Content-Type\", \"application/Executable\" },\n                { \"Content-Disposition\", \"form-data; filename=\\\"test.pdf\\\"\" },\n            },\n        },\n    },\n};\n\n",
            "\nI have found the answer to my question.\nclient.DefaultRequestHeaders.Add(\"X-Version\",\"1\");\n\nThat should add a custom header to your request\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "asp.net",
            "http-headers",
            "dotnet-httpclient"
        ]
    },
    {
        "question_id": "308",
        "question": "\nI often run into the following problem.\nI work on some changes to a project that require new tables or columns in the database. I make the database modifications and continue my work. Usually, I remember to write down the changes so that they can be replicated on the live system. However, I don't always remember what I've changed and I don't always remember to write it down.\nSo, I make a push to the live system and get a big, obvious error that there is no NewColumnX, ugh.\nRegardless of the fact that this may not be the best practice for this situation, is there a version control system for databases? I don't care about the specific database technology. I just want to know if one exists. If it happens to work with MS SQL Server, then great.\n",
        "all_answers": [
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nMost database engines should support dumping your database into a file. I know MySQL does, anyway. This will just be a text file, so you could submit that to Subversion, or whatever you use. It'd be easy to run a diff on the files too.\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nFor Oracle, I use Toad, which can dump a schema to a number of discrete files (e.g., one file per table).  I have some scripts that manage this collection in Perforce, but I think it should be easily doable in just about any revision control system.\n",
            "\nIn Ruby on Rails, there's a concept of a migration -- a quick script to change the database.\nYou generate a migration file, which has rules to increase the db version (such as adding a column) and rules to downgrade the version (such as removing a column). Each migration is numbered, and a table keeps track of your current db version.\nTo migrate up, you run a command called \"db:migrate\" which looks at your version and applies the needed scripts. You can migrate down in a similar way.\nThe migration scripts themselves are kept in a version control system -- whenever you change the database you check in a new script, and any developer can apply it to bring their local db to the latest version.\n"
        ],
        "answer": "A6",
        "tags": [
            "sql",
            "database",
            "oracle",
            "version-control"
        ]
    },
    {
        "question_id": "24395105",
        "question": "\nIn Swift, I am trying to create an array of 64 SKSpriteNode. I want first to initialize it empty, then I would put Sprites in the first 16 cells, and the last 16 cells (simulating an chess game).\nFrom what I understood in the doc, I would have expect something like:\nvar sprites = SKSpriteNode()[64];\nor\nvar sprites4 : SKSpriteNode[64];\nBut it doesn't work. \nIn the second case, I get an error saying: \"Fixed-length arrays are not yet supported\". Can that be real? To me that sounds like a basic feature.\nI need to access the element directly by their index.\n",
        "all_answers": [
            "\nFixed-length arrays are not yet supported. What does that actually mean? Not that you can't create an array of n many things — obviously you can just do let a = [ 1, 2, 3 ] to get an array of three Ints. It means simply that array size is not something that you can declare as type information.\nIf you want an array of nils, you'll first need an array of an optional type — [SKSpriteNode?], not [SKSpriteNode] — if you declare a variable of non-optional type, whether it's an array or a single value, it cannot be nil. (Also note that [SKSpriteNode?] is different from [SKSpriteNode]?... you want an array of optionals, not an optional array.)\nSwift is very explicit by design about requiring that variables be initialized, because assumptions about the content of uninitialized references are one of the ways that programs in C (and some other languages) can become buggy. So, you need to explicitly ask for an [SKSpriteNode?] array that contains 64 nils:\nvar sprites = [SKSpriteNode?](repeating: nil, count: 64)\n\n",
            "\nThe best you are going to be able to do for now is create an array with an initial count repeating nil:\nvar sprites = [SKSpriteNode?](count: 64, repeatedValue: nil)\n\nYou can then fill in whatever values you want.\n\nIn Swift 3.0 :\nvar sprites = [SKSpriteNode?](repeating: nil, count: 64)\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "1895059",
        "question": "\n\n\n\nI'm not clear on how git revert works. For example, I want to revert to a commit six commits behind the head, reverting all the changes in the intermediary commits in between.\nSay its SHA hash is 56e05fced214c44a37759efa2dfc25a65d8ae98d. Then why can't I just do something like:\ngit revert 56e05fced214c44a37759efa2dfc25a65d8ae98d\n\n",
        "all_answers": [
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nIf you want to commit on top of the current HEAD with the exact state at a different commit, undoing all the intermediate commits, then you can use reset to create the correct state of the index to make the commit.\n# Reset the index and working tree to the desired tree\n# Ensure you have no uncommitted changes that you want to keep\ngit reset --hard 56e05fced\n\n# Move the branch pointer back to the previous HEAD\ngit reset --soft \"HEAD@{1}\"\n\ngit commit -m \"Revert to 56e05fced\"\n\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIt reverts the said commit, that is, adds the commit opposite to it. If you want to checkout an earlier revision, you do:\ngit checkout 56e05fced214c44a37759efa2dfc25a65d8ae98d\n\n"
        ],
        "answer": "A6",
        "tags": [
            "git",
            "git-revert"
        ]
    },
    {
        "question_id": "487073",
        "question": "\nI'm loading elements via AJAX. Some of them are only visible if you scroll down the page. Is there any way I can know if an element is now in the visible part of the page?\n",
        "all_answers": [
            "\nThis should do the trick:\nfunction isScrolledIntoView(elem)\n{\n    var docViewTop = $(window).scrollTop();\n    var docViewBottom = docViewTop + $(window).height();\n\n    var elemTop = $(elem).offset().top;\n    var elemBottom = elemTop + $(elem).height();\n\n    return ((elemBottom <= docViewBottom) && (elemTop >= docViewTop));\n}\n\nSimple Utility Function\nThis will allow you to call a utility function that accepts the element you're looking for and if you want the element to be fully in view or partially.\nfunction Utils() {\n\n}\n\nUtils.prototype = {\n    constructor: Utils,\n    isElementInView: function (element, fullyInView) {\n        var pageTop = $(window).scrollTop();\n        var pageBottom = pageTop + $(window).height();\n        var elementTop = $(element).offset().top;\n        var elementBottom = elementTop + $(element).height();\n\n        if (fullyInView === true) {\n            return ((pageTop < elementTop) && (pageBottom > elementBottom));\n        } else {\n            return ((elementTop <= pageBottom) && (elementBottom >= pageTop));\n        }\n    }\n};\n\nvar Utils = new Utils();\n\nUsage\nvar isElementInView = Utils.isElementInView($('#flyout-left-container'), false);\n\nif (isElementInView) {\n    console.log('in view');\n} else {\n    console.log('out of view');\n}\n\n",
            "\nWebResourcesDepot wrote a script to load while scrolling that uses jQuery some time ago. You can view their Live Demo Here. The beef of their functionality was this:\n$(window).scroll(function(){\n  if  ($(window).scrollTop() == $(document).height() - $(window).height()){\n    lastAddedLiveFunc();\n  }\n});\n\nfunction lastAddedLiveFunc() { \n  $('div#lastPostsLoader').html('<img src=\"images/bigLoader.gif\">');\n  $.post(\"default.asp?action=getLastPosts&lastPostID=\"+$(\".wrdLatest:last\").attr(\"id\"),\n    function(data){\n        if (data != \"\") {\n          $(\".wrdLatest:last\").after(data);         \n        }\n      $('div#lastPostsLoader').empty();\n    });\n};\n\n",
            "\nI have such a method in my application, but it does not use jQuery:\n/* Get the TOP position of a given element. */\nfunction getPositionTop(element){\n    var offset = 0;\n    while(element) {\n        offset += element[\"offsetTop\"];\n        element = element.offsetParent;\n    }\n    return offset;\n}\n\n/* Is a given element is visible or not? */\nfunction isElementVisible(eltId) {\n    var elt = document.getElementById(eltId);\n    if (!elt) {\n        // Element not found.\n        return false;\n    }\n    // Get the top and bottom position of the given element.\n    var posTop = getPositionTop(elt);\n    var posBottom = posTop + elt.offsetHeight;\n    // Get the top and bottom position of the *visible* part of the window.\n    var visibleTop = document.body.scrollTop;\n    var visibleBottom = visibleTop + document.documentElement.offsetHeight;\n    return ((posBottom >= visibleTop) && (posTop <= visibleBottom));\n}\n\nEdit : This method works well for I.E. (at least version 6). Read the comments for compatibility with FF.\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "jquery",
            "scroll"
        ]
    },
    {
        "question_id": "4032676",
        "question": "\ntext = text + CepVizyon.getPhoneCode() + \"\\n\\n\"\n            + getText(R.string.currentversion) + CepVizyon.getLicenseText();\n    activationText.setText(text);   \nmyTextView.setText(text);\n\nI want to change color for CepVizyon.getPhoneCode()'s string.  How can I do this?\n",
        "all_answers": [
            "\nWith regards to Maneesh's answer, this will work but you need to add and escape the quotes for the color attribute.\nmyTextView.setText(Html.fromHtml(text + \"<font color=\\\"#FFFFFF\\\">\" + CepVizyon.getPhoneCode() + \"</font><br><br>\"\n            + getText(R.string.currentversion) + CepVizyon.getLicenseText()));\n\n",
            "\nSpannable is more flexible:\nString text2 = text + CepVizyon.getPhoneCode() + \"\\n\\n\"\n            + getText(R.string.currentversion) + CepVizyon.getLicenseText();\n\nSpannable spannable = new SpannableString(text2);\n\nspannable.setSpan(new ForegroundColorSpan(Color.WHITE), text.length(), (text + CepVizyon.getPhoneCode()).length(), Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);\n\nmyTextView.setText(spannable, TextView.BufferType.SPANNABLE);\n\n",
            "\nJust in case anybody finds this, there's a nicer alternative that's not documented (I tripped over it after searching for hours, and finally found it in the bug list for the Android SDK itself). You CAN include raw HTML in strings.xml, as long as you wrap it in\n<![CDATA[ ...raw html... ]]>\n\nEdge Cases:\n\nCharacters like apostrophe ('), double-quote (\"), and ampersand (&) only need to be escaped if you want them to appear in the rendered text AS themselves, but they COULD be plausibly interpreted as HTML.\n\n' and \" can be represented as\\' and \\\", or &apos; and &quot;.\n< and > always need to be escaped as &lt; and &gt; if you literally want them to render as '<' and '>' in the text.\nAmpersand (&) is a little more complicated.\n\nAmpersand followed by whitespace renders as ampersand.\nAmpersand followed by one or more characters that don't form a valid HTML entity code render as Ampersand followed by those characters. So... &qqq; renders as &qqq;, but &lt;1 renders as <1.\n\n\n\n\n\nExample:\n<string name=\"nice_html\">\n<![CDATA[\n<p>This is a html-formatted \\\"string\\\" with <b>bold</b> and <i>italic</i> text</p>\n<p>This is another paragraph from the same \\'string\\'.</p>\n<p>To be clear, 0 &lt; 1, & 10 &gt; 1<p>\n]]>\n</string>\n\nThen, in your code:\nTextView foo = (TextView)findViewById(R.id.foo);\nfoo.setText(Html.fromHtml(getString(R.string.nice_html), FROM_HTML_MODE_LEGACY));\n\nIMHO, this is several orders of magnitude nicer to work with :-)\n\nAugust 2021 update: My original answer used Html.fromHtml(String), which was deprecated in API 24. The alternative fromHtml(String,int) form is suggested as its replacement.\nFROM_HTML_MODE_LEGACY is likely to work... but one of the other flags might be a better choice for what you want to do.\nOn a final note, if you'd prefer to render Android Spanned text suitable for use in a TextView using Markdown syntax instead of HTML, there are now multiple thirdparty libraries to make it easy including https://noties.io/Markwon.\n",
            "\nmyTextView.setText(Html.fromHtml(text + \"<font color=white>\" + CepVizyon.getPhoneCode() + \"</font><br><br>\"\n            + getText(R.string.currentversion) + CepVizyon.getLicenseText()));\n\n"
        ],
        "answer": "A2",
        "tags": [
            "android",
            "uitextview",
            "textview"
        ]
    },
    {
        "question_id": "6025367",
        "question": "\n\n\n\nI have a table with a very large amount of rows. Duplicates are not allowed but due to a problem with how the rows were created I know there are some duplicates in this table.\nI need to eliminate the extra rows from the perspective of the key columns. Some other columns may have slightly different data but I do not care about that. I still need to keep one of these rows however. SELECT DISTINCT won't work because it operates on all columns and I need to suppress duplicates based on the key columns.\nHow can I delete the extra rows but still keep one efficiently?\n",
        "all_answers": [
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nYou didn't say what version you were using, but in SQL 2005 and above, you can use a common table expression with the OVER Clause.  It goes a little something like this:\nWITH cte AS (\n  SELECT[foo], [bar], \n     row_number() OVER(PARTITION BY foo, bar ORDER BY baz) AS [rn]\n  FROM TABLE\n)\nDELETE cte WHERE [rn] > 1\n\nPlay around with it and see what you get.\n(Edit: In an attempt to be helpful, someone edited the ORDER BY clause within the CTE. To be clear, you can order by anything you want here, it needn't be one of the columns returned by the cte. In fact, a common use-case here is that \"foo, bar\" are the group identifier and \"baz\" is some sort of time stamp. In order to keep the latest, you'd do ORDER BY baz desc)\n",
            "\nExample query:\nDELETE FROM Table\nWHERE ID NOT IN\n(\nSELECT MIN(ID)\nFROM Table\nGROUP BY Field1, Field2, Field3, ...\n)\n\nHere fields are column on which you want to group the duplicate rows.\n",
            "\nHere's my twist on it, with a runnable example. Note this will only work in the situation where Id is unique, and you have duplicate values in other columns.\nDECLARE @SampleData AS TABLE (Id int, Duplicate varchar(20))\n\nINSERT INTO @SampleData\nSELECT 1, 'ABC' UNION ALL\nSELECT 2, 'ABC' UNION ALL\nSELECT 3, 'LMN' UNION ALL\nSELECT 4, 'XYZ' UNION ALL\nSELECT 5, 'XYZ'\n\nDELETE FROM @SampleData WHERE Id IN (\n    SELECT Id FROM (\n        SELECT \n            Id\n            ,ROW_NUMBER() OVER (PARTITION BY [Duplicate] ORDER BY Id) AS [ItemNumber]\n            -- Change the partition columns to include the ones that make the row distinct\n        FROM \n            @SampleData\n    ) a WHERE ItemNumber > 1 -- Keep only the first unique item\n)\n\nSELECT * FROM @SampleData\n\nAnd the results:\nId          Duplicate\n----------- ---------\n1           ABC\n3           LMN\n4           XYZ\n\nNot sure why that's what I thought of first... definitely not the simplest way to go but it works.\n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "sql-server",
            "t-sql"
        ]
    },
    {
        "question_id": "11195692",
        "question": "\nI have the following array in PHP:\nArray\n(\n    [0] => Array\n        (\n            [id] => 0\n            [name] => name1\n            [short_name] => n1\n        )\n\n    [2] => Array\n        (\n            [id] => 2\n            [name] => name2\n            [short_name] => n2\n        )\n)\n\nI want to JSON encode it as a JSON array, producing a string like the following:\n[  \n    {  \n        \"id\":0,\n        \"name\":\"name1\",\n        \"short_name\":\"n1\"\n    },\n    {  \n        \"id\":2,\n        \"name\":\"name2\",\n        \"short_name\":\"n2\"\n    }\n]\n\nBut when I call json_encode on this array, I get the following:\n{  \n    \"0\":{  \n        \"id\":0,\n        \"name\":\"name1\",\n        \"short_name\":\"n1\"\n    },\n    \"2\":{  \n        \"id\":2,\n        \"name\":\"name2\",\n        \"short_name\":\"n2\"\n    }\n}\n\nWhich is an object instead of an array.\nHow can I get json_encode to encode my array as an array, instead?\n",
        "all_answers": [
            "\nSee Arrays in RFC 8259 The JavaScript Object Notation (JSON) Data Interchange Format:\n\nAn array structure is represented as square brackets surrounding zero\nor more values (or elements).  Elements are separated by commas.\narray = begin-array [ value *( value-separator value ) ] end-array\n\nYou are observing this behaviour because your array is not sequential - it has keys 0 and 2, but doesn't have 1 as a key.\nJust having numeric indexes isn't enough. json_encode will only encode your PHP array as a JSON array if your PHP array is sequential - that is, if its keys are 0, 1, 2, 3, ...\nYou can reindex your array sequentially using the array_values function to get the behaviour you want. For example, the code below works successfully in your use case:\necho json_encode(array_values($input)).\n\n",
            "\nArray in JSON are indexed array only, so the structure you're trying to get is not valid Json/Javascript.\nPHP Associatives array are objects in JSON, so unless you don't need the index, you can't do such conversions.\nIf you want to get such structure you can do:\n$indexedOnly = array();\n\nforeach ($associative as $row) {\n    $indexedOnly[] = array_values($row);\n}\n\njson_encode($indexedOnly);\n\nWill returns something like:\n[\n     [0, \"name1\", \"n1\"],\n     [1, \"name2\", \"n2\"],\n]\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "json"
        ]
    },
    {
        "question_id": "2563918",
        "question": "\nI have a table that looks like this:\nid   count\n1    100\n2    50\n3    10\n\nI want to add a new column called cumulative_sum, so the table would look like this:\nid   count  cumulative_sum\n1    100    100\n2    50     150\n3    10     160\n\nIs there a MySQL update statement that can do this easily? What's the best way to accomplish this?\n",
        "all_answers": [
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nUsing a correlated query:\n\n  SELECT t.id,\n         t.count,\n         (SELECT SUM(x.count)\n            FROM TABLE x\n           WHERE x.id <= t.id) AS cumulative_sum\n    FROM TABLE t\nORDER BY t.id\n\nUsing MySQL variables:\n\n  SELECT t.id,\n         t.count,\n         @running_total := @running_total + t.count AS cumulative_sum\n    FROM TABLE t\n    JOIN (SELECT @running_total := 0) r\nORDER BY t.id\n\nNote:\n\nThe JOIN (SELECT @running_total := 0) r is a cross join, and allows for variable declaration without requiring a separate SET command.  \nThe table alias, r, is required by MySQL for any subquery/derived table/inline view \n\nCaveats:\n\nMySQL specific; not portable to other databases\nThe ORDER BY is important; it ensures the order matches the OP and can have larger implications for more complicated variable usage (IE: psuedo ROW_NUMBER/RANK functionality, which MySQL lacks)\n\n",
            "\nIf performance is an issue, you could use a MySQL variable:\nset @csum := 0;\nupdate YourTable\nset cumulative_sum = (@csum := @csum + count)\norder by id;\n\nAlternatively, you could remove the cumulative_sum column and calculate it on each query:\nset @csum := 0;\nselect id, count, (@csum := @csum + count) as cumulative_sum\nfrom YourTable\norder by id;\n\nThis calculates the running sum in a running way :)\n",
            "\nUPDATE t\nSET cumulative_sum = (\n SELECT SUM(x.count)\n FROM t x\n WHERE x.id <= t.id\n)\n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nYou could also create a trigger that will calculate the sum before each insert \ndelimiter |\n\nCREATE TRIGGER calCumluativeSum  BEFORE INSERT ON someTable\n  FOR EACH ROW BEGIN\n\n  SET cumulative_sum = (\n     SELECT SUM(x.count)\n        FROM someTable x\n        WHERE x.id <= NEW.id\n    )\n\n    set  NEW.cumulative_sum = cumulative_sum;\n  END;\n|\n\nI have not tested this\n"
        ],
        "answer": "A3",
        "tags": [
            "mysql",
            "sql",
            "cumulative-sum"
        ]
    },
    {
        "question_id": "7020659",
        "question": "\nSay I have:\n<form method=\"get\" action=\"something.php\">\n    <input type=\"text\" name=\"name\" />\n</form>\n\n<input type=\"submit\" />\n\nHow do I go about submitting that form with that submit button outside of the form, I think in HTML5 theres an action attribute for the submit but I'm not sure if thats fully cross-browser and if it isn't is there anyway to do this?\n",
        "all_answers": [
            "\nUpdate: In modern browsers you can use the form attribute to do this. \n\nAs far as I know, you cannot do this without javascript.\nHere's what the spec says \n\nThe elements used to create controls generally appear inside a FORM\n  element, but may also appear outside of a FORM element declaration\n  when they are used to build user interfaces. This is discussed in the\n  section on intrinsic events. Note that controls outside a form cannot\n  be successful controls.\n\nThat's my bold\nA submit button is considered a control.\nhttp://www.w3.org/TR/html4/interact/forms.html#h-17.2.1\nFrom the comments\n\nI have a multi tabbed settings area with a button to update all, due\n  to the design of it the button would be outside of the form.\n\nWhy not place the input inside the form, but use CSS to position it elsewhere on the page?\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nTry this:\n<input type=\"submit\" onclick=\"document.forms[0].submit();\" />\n\nAlthough I would suggest adding an id to the form and accessing by that instead of document.forms[index].\n"
        ],
        "answer": "A1",
        "tags": [
            "html"
        ]
    },
    {
        "question_id": "61177995",
        "question": "\nI'm just trying to deploy my application and I just ran composer update on my server and I got the following error: \nIn PackageManifest.php line 122:\nUndefined index: name\nHow can I fix this issue?\n",
        "all_answers": [
            "\nI had a problem like this, and also tried composer self-update --stable, but there was no result. So, I found that this file belongs to the Laravel framework. So the following command resolved this issue:\n$ composer update laravel/framework\n",
            "\nRunning the following command fixed it for us\ncomposer self-update --stable\n\n",
            "\nAs a temporary fix, try this, it worked for me, in the following file:\nvendor/laravel/framework/src/Illuminate/Foundation/PackageManifest.php\n\nFind line 116 and comment it:\n$packages = json_decode($this->files->get($path), true);\n\nAdd two new lines after the above commented line:\n$installed = json_decode($this->files->get($path), true);\n$packages = $installed['packages'] ?? $installed;\n\n",
            "\nI had the same problem.\nIn my case downgrading the composer version fixed the problem.\nThey updated Composer 4 times within 2 days - I think they had a problem with their newest updates.\nIn my case version 1.10.1 was the version to go with.\nsudo composer self-update --1\n\nI hope it'll work.\n"
        ],
        "answer": "A3",
        "tags": [
            "php",
            "laravel"
        ]
    },
    {
        "question_id": "2941517",
        "question": "\nI just made a perfectly good commit to the wrong branch.\nHow do I undo the last commit in my master branch and then take those same changes and get them into my upgrade branch?\n",
        "all_answers": [
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\nIf you have a clean (un-modified) working copy\nTo rollback one commit (make sure you note the commit's hash for the next step):\ngit reset --hard HEAD^\n\nTo pull that commit into a different branch:\ngit checkout other-branch\ngit cherry-pick COMMIT-HASH\n\nIf you have modified or untracked changes\nAlso note that git reset --hard will kill any untracked and modified changes you might have, so if you have those you might prefer:\ngit reset HEAD^\ngit checkout .\n\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIf you haven't yet pushed your changes, you can also do a soft reset:\ngit reset --soft HEAD^\n\nThis will revert the commit, but put the committed changes back into your index. Assuming the branches are relatively up-to-date with regard to each other, git will let you do a checkout into the other branch, whereupon you can simply commit:\ngit checkout branch\ngit commit -c ORIG_HEAD\n\nThe -c ORIG_HEAD part is useful to not type commit message again.\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\nRemove the last commit before push\ngit reset --soft HEAD~1\n1 means the last commit, if you want to remove two last use 2, and so forth*\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n"
        ],
        "answer": "A4",
        "tags": [
            "git",
            "git-commit"
        ]
    },
    {
        "question_id": "8213",
        "question": "\nI need to import a csv file into Firebird and I've spent a couple of hours trying out some tools and none fit my needs.\nThe main problem is that all the tools I've been trying like EMS Data Import and Firebird Data Wizard expect that my CSV file contains all the information needed by my Table.\nI need to write some custom SQL in the insert statement, for example, I have a CSV file with the city name, but as my database already has all the cities in another table (normalized), I need to write a subselect in the insert statement to lookup for the city and write its ID, also I have a stored procedure to cread GUIDS.\nMy insert statement would be something like this:\nINSERT INTO PERSON (ID, NAME, CITY_ID) VALUES((SELECT NEW_GUID FROM CREATE_GUID), :NAME, (SELECT CITY_ID FROM CITY WHERE NAME = :CITY_NAME)\n\nHow can I approach this?\n",
        "all_answers": [
            "\nAccording to MSDN, timestamp\n\nIs a data type that exposes automatically generated, unique binary\n  numbers within a database. timestamp is generally used as a mechanism\n  for version-stamping table rows. The storage size is 8 bytes. The\n  timestamp data type is just an incrementing number and does not\n  preserve a date or a time. To record a date or time, use a datetime\n  data type.\n\nYou're probably looking for the datetime data type instead.\n",
            "\nWell, if it's a CSV, and it this is a one time process, open up the file in Excel, and then write formulas to populate your data in any way you desire, and then write a simple Concat formula to construct your SQL, and then copy that formula for every row. You will get a large number of SQL statements which you can execute anywhere you want.\n",
            "\nIf you have a need to copy the exact same timestamp data, change the data type in the destination table from timestamp to binary(8) -- i used varbinary(8) and it worked fine.\nThis obviously breaks any timestamp functionality in the destination table, so make sure you're ok with that first.\n",
            "\nIt's a bit crude - but for one off jobs, I sometimes use Excel.\nIf you import the CSV file into Excel, you can create a formula which creates an INSERT statement by using string concatenation in the formula. So - if your CSV file has 3 columns that appear in columns A, B, and C in Excel, you could write a formula like...\n=\"INSERT INTO MyTable (Col1, Col2, Col3) VALUES (\" & A1 & \", \" & B1 & \", \" & C1 & \")\"\n\nThen you can replicate the formula down all of your rows, and copy, and paste the answer into a text file to run against your database.\nLike I say - it's crude - but it can be quite a 'quick and dirty' way of getting a job done!\n",
            "\nYou can't insert the values into timestamp column explicitly. It is auto-generated. Do not use this column in your insert statement. Refer http://msdn.microsoft.com/en-us/library/ms182776(SQL.90).aspx for more details.\nYou could use a datetime instead of a timestamp like this:\ncreate table demo (\n    ts datetime\n)\n\ninsert into demo select current_timestamp\n\nselect ts from demo\n\nReturns:\n2014-04-04 09:20:01.153\n\n"
        ],
        "answer": "A4",
        "tags": [
            "sql",
            "csv",
            "insert",
            "firebird"
        ]
    },
    {
        "question_id": "7841610",
        "question": "\nI have a problem with Xcode 4.2 debugging in an iOS 5 simulator/device. The following code crashes, as expected:\nNSArray *arr=[NSArray array];\n[arr objectAtIndex:100];\n\nIn iOS 4, I get a useful stack trace of hex numbers. But in iOS 5, it just gives me:\n*** First throw call stack:\n(0x16b4052 0x1845d0a 0x16a0674 0x294c 0x6f89d6 0x6f98a6 0x708743 0x7091f8 0x7fcaa9 0x2257fa9 0x16881c5 0x15ed022 0x15eb90a 0x15eadb4 0x15eaccb 0x6f02a7 0x6faa93 0x2889 0x2805)\n\nThanks.\n",
        "all_answers": [
            "\nThis is a common problem, not getting stack traces in 4.2. You can try swapping between LLDB and GDB to see if you get better results.\nFile a bug report here.\nhttp://developer.apple.com/bugreporter/\nEDIT:\nI believe that if you swap back to LLVM GCC 4.2 you'll not see this happen. You may lose features you need though.\n",
            "\nNothing I tried would fix this (tried both compilers, both debuggers, etc.)\nAfter upgrading XCode for the iOS 5 update, no stack traces seemed to work.\nHowever, I have found an effective work-around - creating my own exception handler (which is also useful for other reasons). First, create a function that will handle the error and output it to the console (as well as whatever else you want to do with it):\nvoid uncaughtExceptionHandler(NSException *exception) {\n    NSLog(@\"CRASH: %@\", exception);\n    NSLog(@\"Stack Trace: %@\", [exception callStackSymbols]);\n    // Internal error reporting\n}\n\nNext, add the exception handler to your app delegate:\n- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions\n{   \n    NSSetUncaughtExceptionHandler(&uncaughtExceptionHandler);\n    // Normal launch stuff\n}\n\nThat's it!\nIf this doesn't work, then there are only two possible reasons:\n\nSomething is overwriting your NSSetUncaughtExceptionHandler call (there can be only one handler for your entire app). For example, some 3rd party libraries set their own uncaughtExceptionHandler. So, try setting it at the END of your didFinishLaunchingWithOptions function (or selectively disabling 3rd party libraries). Or better yet, set a symbolic break point on NSSetUncaughtExceptionHandler to quickly see who is calling it. What you may want to do is to modify your current one rather than adding another one.\nYou're not actually encountering an exception (for example, EXC_BAD_ACCESS is not an exception; credit to @Erik B's comments, below)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "xcode",
            "debug-symbols"
        ]
    },
    {
        "question_id": "1581895",
        "question": "\nI'm writing a simple crawler in Python using the threading and Queue modules. I fetch a page, check links and put them into a queue, when a certain thread has finished processing page, it grabs the next one from the queue. I'm using an array for the pages I've already visited to filter the links I add to the queue, but if there are more than one threads and they get the same links on different pages, they put duplicate links to the queue. So how can I find out whether some url is already in the queue to avoid putting it there again?\n",
        "all_answers": [
            "\nuse:\nurl in q.queue\n\nwhich returns True iff url is in the queue\n",
            "\nIf you don't care about the order in which items are processed, I'd try a subclass of Queue that uses set internally:\nclass SetQueue(Queue):\n\n    def _init(self, maxsize):\n        self.maxsize = maxsize\n        self.queue = set()\n\n    def _put(self, item):\n        self.queue.add(item)\n\n    def _get(self):\n        return self.queue.pop()\n\nAs Paul McGuire pointed out, this would allow adding a duplicate item after it's been removed from the \"to-be-processed\" set and not yet added to the \"processed\" set. To solve this, you can store both sets in the Queue instance, but since you are using the larger set for checking if the item has been processed, you can just as well go back to queue which will order requests properly.\nclass SetQueue(Queue):\n\n    def _init(self, maxsize):\n        Queue._init(self, maxsize) \n        self.all_items = set()\n\n    def _put(self, item):\n        if item not in self.all_items:\n            Queue._put(self, item) \n            self.all_items.add(item)\n\nThe advantage of this, as opposed to using a set separately, is that the Queue's methods are thread-safe, so that you don't need additional locking for checking the other set.\n",
            "\nWhy only use the array (ideally, a dictionary would be even better) to filter things you've already visited? Add things to your array/dictionary as soon as you queue them up, and only add them to the queue if they're not already in the array/dict. Then you have 3 simple separate things:\n\nLinks not yet seen (neither in queue nor array/dict)\nLinks scheduled to be visited (in both queue and array/dict)\nLinks already visited (in array/dict, not in queue)\n\n",
            "\nSQLite is so simple to use and would fit perfectly... just a suggestion.\n",
            "\nThe way I solved this (actually I did this in Scala, not Python) was to use both a Set and a Queue, only adding links to the queue (and set) if they did not already exist in the set.\nBoth the set and queue were encapsulated in a single thread, exposing only a queue-like interface to the consumer threads.\nEdit: someone else suggested SQLite and that is also something I am considering, if the set of visited URLs needs to grow large. (Currently each crawl is only a few hundred pages so it easily fits in memory.) But the database is something that can also be encapsulated within the set itself, so the consumer threads need not be aware of it.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "multithreading",
            "queue"
        ]
    },
    {
        "question_id": "4730600",
        "question": "\nif I have a variable in the context of unknown length, for example;\nlist=[{'key':'A'},{'key':'B'},{'key':'C'}]\nHow can I get the last object? {{ list.0.key }} works for the first, but {{ list.-1.key }} gives;\nCould not parse the remainder: '-1.key' from 'list.-1.key'\n",
        "all_answers": [
            "\nThanks everyone for you help, it lead me to the realisation that I can use the with tag.\n{% with list|last as last %}\n    {{ last.key }}\n{% endwith %}\n\n",
            "\nUse the last template tag:\n{{ value|last }}\n\n\nIf value is the list ['a', 'b', 'c', 'd'], the output will be the string \"d\".\n\n",
            "\nAnother way to avoid the SerializerMethodField solution and therefore still allow writing to the serializer as well would be to subclass the RelatedField and do the filtering there.\nTo only allow active users as values for the field, the example would look like:\nclass ActiveUsersPrimaryKeyField(serializers.PrimaryKeyRelatedField):\n    def get_queryset(self):\n        return super().get_queryset().filter(active=True)\n\nclass MySerializer(serializers.ModelSerializer):\n    users = ActiveUsersPrimaryKeyField(many=True)\n    class Meta:\n        model = MyModel\n        fields = ('users',)\n\nAlso see this response.\nNote that this only restricts the set of input values to active users, though, i.e. only when creating or updating model instances, inactive users will be disallowed.\n\nIf you also use your serializer for reading and MyModel already has a relation to a user that has become inactive in the meantime, it will still be serialized. To prevent this, one way is to filter the relation using django's Prefetch objects. Basically, you'll filter out inactive users before they even get into the serializer:\nfrom django.db.models import Prefetch\n\n# Fetch a model instance, eagerly prefetching only those users that are active\nmodel_with_active_users = MyModel.objects.prefetch_related(\n    Prefetch(\"users\", queryset=User.objects.filter(active=True))\n).first()\n\n# serialize the data with the serializer defined above and see that only active users are returned\ndata = MyModelSerializer(model_with_active_users).data\n\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n"
        ],
        "answer": "A1",
        "tags": [
            "django",
            "django-templates"
        ]
    },
    {
        "question_id": "803616",
        "question": "\n\n\n\nIs it possible to pass functions with arguments to another function in Python?\nSay for something like:\ndef perform(function):\n    return function()\n\nBut the functions to be passed will have arguments like:\naction1()\naction2(p)\naction3(p,r)\n\n",
        "all_answers": [
            "\nThis is what lambda is for:\ndef perform(f):\n    f()\n\nperform(lambda: action1())\nperform(lambda: action2(p))\nperform(lambda: action3(p, r))\n\n",
            "\nDo you mean this?\ndef perform(fun, *args):\n    fun(*args)\n\ndef action1(args):\n    # something\n\ndef action2(args):\n    # something\n\nperform(action1)\nperform(action2, p)\nperform(action3, p, r)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "function"
        ]
    },
    {
        "question_id": "10563644",
        "question": "\nI have tried:\napp.get('/', function(req, res, next) {\n    var e = new Error('error message');\n    e.status = 400;\n    next(e);\n});\n\nand:\napp.get('/', function(req, res, next) {\n    res.statusCode = 400;\n    var e = new Error('error message');\n    next(e);\n});\n\nbut always an error code of 500 is announced.\n",
        "all_answers": [
            "\nOld question, but still coming up on Google. In the current version of Express (3.4.0), you can alter res.statusCode before calling next(err):\nres.statusCode = 404;\nnext(new Error('File not found'));\n\n",
            "\nYou can also \"merge\" directories into a single visible directory\nDirectory Structure\n\n/static\n/alternate_static\n\nCode\napp.use(\"/static\", express.static(__dirname + \"/static\"));\napp.use(\"/static\", express.static(__dirname + \"/alternate_static\"));\n\nBoth static and alternate_static will be served as if they were in the same directory. Watch out for filename clobbers, though. \n",
            "\nThe version of the errorHandler middleware bundled with some (perhaps older?) versions of express seems to have the status code hardcoded. The version documented here: http://www.senchalabs.org/connect/errorHandler.html on the other hand lets you do what you are trying to do. So, perhaps trying upgrading to the latest version of express/connect.\n",
            "\nYou can also set the path that static files will be served to the web from by specifying an additional (first) parameter to use() like so:\napp.use(\"/public\", express.static(__dirname + \"/public\"));\napp.use(\"/public2\", express.static(__dirname + \"/public2\"));\n\nThat way you get two different directories on the web that mirror your local directories, not one url path that fails over between two local directories.\nIn other words the URL pattern:\nhttp://your.server.com/public/*\n\nServes files from the local directory public while:\nhttp://your.server.com/public2/*\n\nServes files from the local directory public2.\nBTW this is also useful if you don't want static to serve the files from the root of your server but rather from a more qualified path.\nHTH\n",
            "\nPer the Express (Version 4+) docs, you can use:\nres.status(400);\nres.send('None shall pass');\n\nhttp://expressjs.com/4x/api.html#res.status\n<=3.8\nres.statusCode = 401;\nres.send('None shall pass');\n\n",
            "\nIt's not possible by one middleware injection, but you can inject static middleware multiple times:\napp.configure('development', function(){\n    app.use(express.static(__dirname + '/public1'));\n    app.use(express.static(__dirname + '/public2'));\n});\n\nExplanation\nLook at connect/lib/middleware/static.js#143:\npath = normalize(join(root, path));\n\nThere is options.root is static root, which you define in express.static or connect.static call, and path is request path.\nLook more at connect/lib/middleware/static.js#154:\n  fs.stat(path, function(err, stat){\n    // ignore ENOENT\n    if (err) {\n      if (fn) return fn(err);\n     return ('ENOENT' == err.code || 'ENAMETOOLONG' == err.code)\n       ? next()\n       : next(err);\n\nPath checked only once, and if file not found request passed to next middleware.\nUpdate for Connect 2.x\nLinks to code are inactual for Connect 2.x, but multiple static middleware usage are still posible as before.\n",
            "\nYou can use res.send('OMG :(', 404); just res.send(404);\n"
        ],
        "answer": "A5",
        "tags": [
            "node.js",
            "express",
            "http-status-codes"
        ]
    },
    {
        "question_id": "6123378",
        "question": "\nI have a series of CSV files where numbers are formatted in the european style using commas instead of decimal points, i.e. 0,5 instead of 0.5.\nThere are too many of these files to edit them before importing to R. I was hoping there is an easy parameter for the read.csv() function, or a method to apply to the extracted dataset in order for R to treat the data as a number rather than a string.\n",
        "all_answers": [
            "\nmaybe\nas.is=T\n\nthis also prevents to convert the character columns into factors\n",
            "\nWhen you check ?read.table you will probably find all the answer that you need.\nThere are two issues with (continental) European csv files:\n\nWhat does the c in csv stand for? For standard csv this is a ,, for European csv this is a ;\nsep is the corresponding argument in read.table\nWhat is the character for the decimal point? For standard csv this is a ., for European csv this is a ,\ndec is the corresponding argument in read.table\n\nTo read standard csv use read.csv, to read European csv use read.csv2. These two functions are just wrappers to read.table that set the appropriate arguments.\nIf your file does not follow either of these standards set the arguments manually.\n",
            "\nFrom ?read.table:\ndec     the character used in the file for decimal points.\n\nAnd yes, you can use that for read.csv as well. (to me: no stupid, you cannot!) \nAlternatively, you can also use \nread.csv2\n\nwhich assumes a \",\" decimal separator and a \";\" for column separators. \n",
            "\nHere's an update as of Nov 2014. I find that setting method='curl' did the trick for me (while method='auto', does not).\nFor example:\n# does not work\ndownload.file(url='https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip',\n              destfile='localfile.zip')\n\n# does not work. this appears to be the default anyway\ndownload.file(url='https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip',\n              destfile='localfile.zip', method='auto')\n\n# works!\ndownload.file(url='https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip',\n              destfile='localfile.zip', method='curl')\n\n",
            "\nIt might be easiest to try the RCurl package. Install the package and try the following:\n# install.packages(\"RCurl\")\nlibrary(RCurl)\nURL <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv\"\nx <- getURL(URL)\n## Or \n## x <- getURL(URL, ssl.verifypeer = FALSE)\nout <- read.csv(textConnection(x))\nhead(out[1:6])\n#   RT SERIALNO DIVISION PUMA REGION ST\n# 1  H      186        8  700      4 16\n# 2  H      306        8  700      4 16\n# 3  H      395        8  100      4 16\n# 4  H      506        8  700      4 16\n# 5  H      835        8  800      4 16\n# 6  H      989        8  700      4 16\ndim(out)\n# [1] 6496  188\n\ndownload.file(\"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv\",destfile=\"reviews.csv\",method=\"libcurl\")\n\n"
        ],
        "answer": "A2",
        "tags": [
            "r",
            "csv",
            "number-formatting"
        ]
    },
    {
        "question_id": "578904",
        "question": "\nIf I have a util class with static methods that will call Hibernate functions to accomplish basic data access. I am wondering if making the method synchronized is the right approach to ensure thread-safety.\nI want this to prevent access of info to the same DB instance. However, I'm now sure if the following code are preventing getObjectById being called for all Classes when it is called by a particular class. \npublic class Utils {\n     public static synchronized Object getObjectById (Class objclass, Long id) {\n           // call hibernate class\n         Session session = new Configuration().configure().buildSessionFactory().openSession();\n         Object obj = session.load(objclass, id);\n         session.close();\n         return obj;\n     }\n\n     // other static methods\n}\n\n",
        "all_answers": [
            "\nTo answer your question, yes it does: your synchronized method cannot be executed by more than one thread at a time.\n",
            "\nWhy do you want to enforce that only a single thread can access the DB at any one time? \nIt is the job of the database driver to implement any necessary locking, assuming a Connection is only used by one thread at a time!\nMost likely, your database is perfectly capable of handling multiple, parallel access\n",
            "\nIf it is something to do with the data in your database, why not utilize database isolation locking to achieve?\n",
            "\nBy using synchronized on a static method lock you will synchronize the class methods and attributes ( as opposed to instance methods and attributes )\nSo your assumption is correct.\n\nI am wondering if making the method synchronized is the right approach to ensure thread-safety.\n\nNot really. You should let your RDBMS do that work instead. They are good at this kind of stuff.\nThe only thing you will get by synchronizing the access to the database is to make your application terribly slow.  Further more, in the code you posted you're building a Session Factory each time, that way, your application will spend more time accessing the DB than performing the actual job.\nImagine the following scenario:\nClient A and B attempt to insert different information into record X of table T.\nWith your approach the only thing you're getting is to make sure one is called after the other, when this would happen anyway in the DB, because the RDBMS will prevent them from inserting half information from A and half from B at the same time. The result will be the same but only 5 times ( or more )  slower.\nProbably it could be better to take a look at the \"Transactions and Concurrency\" chapter in the Hibernate documentation.  Most of the times the problems you're trying to solve, have been solved already and a much better way.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nStatic methods use the class as the object for locking, which is Utils.class for your example. So yes, it is OK.\n"
        ],
        "answer": "A4",
        "tags": [
            "java",
            "multithreading",
            "hibernate",
            "concurrency",
            "synchronization"
        ]
    },
    {
        "question_id": "44611526",
        "question": "\nI generated Angular 4 app 3 weeks ago using the @angular/cli. After 2 weeks, I tried to run it with the command line ng serve but I am prompted an error below:\nCannot find module 'typescript'\nError: Cannot find module 'typescript'\n    at Function.Module._resolveFilename (module.js:469:15)\n    at Function.Module._load (module.js:417:25)\n    at Module.require (module.js:497:17)\n    at require (internal/module.js:20:19)\n    at Object.<anonymous> (C:\\Users\\mypc\\Documents\\Angular Projects\\my-angular-app\\node_modules\\@angular\\cli\\models\\config\\config.js:5:12)\n    at Module._compile (module.js:570:32)\n    at Object.Module._extensions..js (module.js:579:10)\n    at Module.load (module.js:487:32)\n    at tryModuleLoad (module.js:446:12)\n    at Function.Module._load (module.js:438:3)\n\nDo you have any idea how to fix this? Thanks.\n",
        "all_answers": [
            "\nThis should do the trick,\nnpm install -g typescript\n\n",
            "\nI was able to solve this problem by removing node_modules then running npm install\n",
            "\nAs per the other answers, add the following to someFile.js\nmodule.exports.someFunction = function () {\n  console.log('hi');\n};\n\nYou can then add the following to package.json\n\"scripts\": {\n   \"myScript\": \"node -e 'require(\\\"./someFile\\\").someFunction()'\"\n}\n\nFrom the terminal, you can then call\nnpm run myScript\n\nI find this a much easier way to remember the commands and use them\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n",
            "\nUpdate 2020 - CLI\nAs @mix3d pointed out you can just run a command where file.js is your file and someFunction is your function optionally followed by parameters separated with spaces\nnpx run-func file.js someFunction \"just some parameter\"\n\nThat's it.\nfile.js called in the example above\nconst someFunction = (param) => console.log('Welcome, your param is', param)\n\n// exporting is crucial\nmodule.exports = { someFunction }\n\nMore detailed description\nRun directly from CLI (global)\nInstall\nnpm i -g run-func\n\nUsage i.e. run function \"init\", it must be exported, see the bottom\nrun-func db.js init\n\nor\nRun from package.json script (local)\nInstall\nnpm i -S run-func\n\nSetup\n\"scripts\": {\n   \"init\": \"run-func db.js init\"\n}\n\nUsage\nnpm run init\n\nParams\nAny following arguments will be passed as function parameters init(param1, param2)\nrun-func db.js init param1 param2\n\nImportant\nthe function (in this example init) must be exported in the file containing it\nmodule.exports = { init };\n\nor ES6 export\nexport { init };\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "node.js",
            "angular"
        ]
    },
    {
        "question_id": "6438061",
        "question": "\nIs there any way to scroll a ScrollView programmatically to a certain position?\nI have created dynamic TableLayout which is placed in a ScrollView. So I want that on a specific action (like clicking a Button, etc.) the particular row should scroll automatically to a top position.\nIs it possible?\n",
        "all_answers": [
            "\nAnswer to your first question: Your broadcast receiver is being called two times because\nYou have added two <intent-filter>\n\nChange in network connection :\n<action android:name=\"android.net.conn.CONNECTIVITY_CHANGE\" />\n\nChange in WiFi state:\n<action android:name=\"android.net.wifi.WIFI_STATE_CHANGED\" />\n\n\nJust use one:\n<action android:name=\"android.net.conn.CONNECTIVITY_CHANGE\" />.\nIt will respond to only one action instead of two. See here for more information.\nAnswer to your second question (you want the receiver to call only one time if an internet connection is available):\nYour code is perfect; you notify only when the internet is available.\nUPDATE\nYou can use this method to check your connectivity if you want just to check whether your mobile is connected to the internet or not.\npublic boolean isOnline(Context context) {\n  \n    ConnectivityManager cm = (ConnectivityManager) context.getSystemService(Context.CONNECTIVITY_SERVICE);\n    NetworkInfo netInfo = cm.getActiveNetworkInfo();\n    //should check null because in airplane mode it will be a null\n    return (netInfo != null && netInfo.isConnected());\n}\n\n",
            "\npublic class NetworkChangeReceiver extends BroadcastReceiver {\n\n    @Override\n    public void onReceive(final Context context, final Intent intent) {\n        if (checkInternet(context)) {\n            Toast.makeText(context, \"Network Available Do operations\", Toast.LENGTH_LONG).show();\n        }\n    }\n\n    boolean checkInternet(Context context) {\n        ServiceManager serviceManager = new ServiceManager(context);\n        return serviceManager.isNetworkAvailable()\n    }\n}\n\nServiceManager.java\npublic class ServiceManager {\n\n    Context context;\n\n    public ServiceManager(Context base) {\n        context = base;\n    }\n\n    public boolean isNetworkAvailable() {\n        ConnectivityManager cm = (ConnectivityManager) context.getSystemService(Context.CONNECTIVITY_SERVICE);\n        NetworkInfo networkInfo = cm.getActiveNetworkInfo();\n        return networkInfo != null && networkInfo.isConnected();\n    }\n}\n\npermissions:\n <uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" />\n <uses-permission android:name=\"android.permission.INTERNET\" />\n\n",
            "\nTry using scrollTo method More Info\n",
            "\nScrollView sv = (ScrollView)findViewById(R.id.scrl);\nsv.scrollTo(0, sv.getBottom());\n\nor\nsv.scrollTo(5, 10);\n",
            "\nUse something like this:\nmScrollView.scrollBy(10, 10);\n\nor\nmScrollView.scrollTo(10, 10);\n\n"
        ],
        "answer": "A4",
        "tags": [
            "java",
            "android",
            "scrollview",
            "android-scrollview"
        ]
    },
    {
        "question_id": "6983400",
        "question": "\nI want to change my UILabel's text after 2 seconds.\nI tried setting my UILabel's text to \"A text\", and use sleep(2) and finally changing the text to \"Another text\".\nBut sleep(2) only freezes the app and \"Another text\" is set without displaying \"A text\" for 2 seconds.\nHow may I display \"A text\" for 2 seconds and then show \"Another text\"?\n",
        "all_answers": [
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nYou can use NSTimer, like so - \n[NSTimer scheduledTimerWithTimeInterval:0.5 \n                                 target:self \n                               selector:@selector(updateLabel:) \n                               userInfo:nil \n                                repeats:YES];\n\nDefine another method updateLabel and do the updation there. Define your timeInterval to suite your needs... \nAlso setting repeats to YES makes sure that this selector is executed every 0.5 seconds (in the above case).\n",
            "\nYou need to use a timer. Using sleep will halt your entire program. Check NSTimer\n",
            "\nYou can accomplish this with a timer, e.g.\nNSTimer *timer = [NSTimer scheduledTimerWithTimeInterval:4.0 target:self selector:@selector(eventToFire:) userInfo:nil repeats:YES]; // Fire every 4 seconds.\n   \n...\n\n- (void)eventToFire:(NSTimer*)timer {\n  // Do Something\n}\n\n",
            "\nYou can use \n[self performSelector:@selector(changeText:) withObject:text afterDelay:2.0];\n\nor if you want to display it periodically, check the NSTimer class.\n",
            "\nThis is because the view isn't updated until the end of the runloop. Instead of using sleeps try using NSTimer to set a specific time to update the view.\n"
        ],
        "answer": "A6",
        "tags": [
            "ios",
            "objective-c",
            "swift",
            "wait",
            "performselector"
        ]
    },
    {
        "question_id": "3395236",
        "question": "\nI'm using Django with an sqlite backend, and write performance is a problem.  I may graduate to a \"proper\" db at some stage, but for the moment I'm stuck with sqlite.  I think that my write performance problems are probably related to the fact that I'm creating a large number of rows, and presumably each time I save() one it's locking, unlocking and syncing the DB on disk.\nHow can I aggregate a large number of save() calls into a single database operation?\n",
        "all_answers": [
            "\nEDITED: commit_on_success is deprecated and was removed in Django 1.8. Use transaction.atomic instead. See Fraser Harris's answer.\nActually this is easier to do than you think.  You can use transactions in Django.  These batch database operations (specifically save, insert and delete) into one operation.  I've found the easiest one to use is commit_on_success.  Essentially you wrap your database save operations into a function and then use the commit_on_success decorator.\nfrom django.db.transaction import commit_on_success\n\n@commit_on_success\ndef lot_of_saves(queryset):\n    for item in queryset:\n        modify_item(item)\n        item.save()\n\nThis will have a huge speed increase.  You'll also get the benefit of having roll-backs if any of the items fail.  If you have millions of save operations then you may have to commit them in blocks using the commit_manually and transaction.commit() but I've rarely needed that.\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\n\n\"How can I aggregate a large number of save() calls into a single database operation?\"\n\nYou don't need to.  Django already manages a cache for you.   You can't improve it's DB caching by trying to fuss around with saves. \n\n\"write performance problems are probably related to the fact that I'm creating a large number of rows\"\n\nCorrect.\nSQLite is pretty slow.  That's the way it is.  Queries are faster than most other DB's.  Writes are pretty slow.\nConsider more serious architecture change.  Are you loading rows during a web transaction (i.e., bulk uploading files and loading the DB from those files)?\nIf you're doing bulk loading inside a web transaction, stop.  You need to do something smarter.  Use celery or use some other \"batch\" facility to do your loads in the background.\nWe try to limit ourself to file validation in a web transaction and do the loads when the user's not waiting for their page of HTML.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "sql",
            "django",
            "sqlite"
        ]
    },
    {
        "question_id": "17983068",
        "question": "\nI want to have my local and remote repositories always in sync in terms of branches.\nAfter a Pull Request review on GitHub, I merge and remove my branch there (remote).\nHow could I fetch this information in my local repository and get Git to remove my local version of the branch as well?\n",
        "all_answers": [
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nThe quick way\ngit branch --merged | grep -v \"\\*\" | xargs -n 1 git branch -d\n\nNB: if you're not on master, this has the potential to delete the branch. Keep reading for the \"better way\".\nMake sure we keep master\nYou can ensure that master, or any other branch for that matter, doesn't get removed by greping for more. In that case you would go:\ngit branch --merged | grep -v \"\\*\" | grep -v \"YOUR_BRANCH_TO_KEEP\" | xargs -n 1 git branch -d\n\nSo if we wanted to keep master, develop and staging for instance, we would go:\ngit branch --merged | grep -v \"\\*\" | grep -Ev \"(\\*|master|develop|staging)\" | xargs -n 1 git branch -d\n\nMake this an alias\nSince it's a bit long, you might want to add an alias to your .zshrc or .bashrc. Mine is called gbpurge (for git branches purge):\nalias gbpurge='git branch --merged | grep -Ev \"(\\*|master|develop|staging)\" | xargs -n 1 git branch -d'\n\nThen reload your .bashrc or .zshrc:\n. ~/.bashrc\n\nor\n. ~/.zshrc\n\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\ntry:\n\ngit pull --prune\n\nwhich deletes your local branch, if its corresponding remote branch is deleted.\nUpdated:\nThe statement above is not that correct.\nIn fact, running git pull --prune will only REMOVE the remote-tracking branches such like\n\nremotes/origin/fff\nremotes/origin/dev\nremotes/origin/master\n\nThen, you can run git branch -r to check the remote-tracking branches left on your machine. Suppose the left branches are:\n\norigin/dev\norigin/master\n\nwhich means the branch origin/fff is deleted.\nSo, after running git pull --prune, just run:\ngit branch --merged | grep -vFf <(git branch -r | cut -d'/' -f2-)\nyou can find out all the local branches which:\n\nhave no correspoding remote branches any more;\ncan be removed safely.\n\nthen, <the command above> | xargs git branch -d can delete all of them.\n"
        ],
        "answer": "A4",
        "tags": [
            "git",
            "github",
            "branch",
            "pull",
            "repository"
        ]
    },
    {
        "question_id": "5641997",
        "question": "\nIs it necessary to write <html>, <head> and <body> tags?\nFor example, I can make such a page:\n<!DOCTYPE html>\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\">\n    <title>Page Title</title>\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"css/reset.css\">\n    <script src=\"js/head_script.js\"></script><!-- this script will be in head //-->\n\n\n<div>Some html</div> <!-- here body starts //-->\n\n    <script src=\"js/body_script.js\"></script>\n\nAnd Firebug correctly separates head and body:\n\nThe W3C validator says it's valid.\nBut I rarely see this practice on the web.\nIs there a reason to write these tags?\n",
        "all_answers": [
            "\nOmitting the html, head, and body tags is certainly allowed by the HTML specifications. The underlying reason is that browsers have always sought to be consistent with existing web pages, and the very early versions of HTML didn't define those elements. When HTML first did, it was done in a way that the tags would be inferred when missing.\nI often find it convenient to omit the tags when prototyping and especially when writing test cases as it helps keep the markup focused on the test in question. The inference process should create the elements in exactly the manner that you see in Firebug, and browsers are pretty consistent in doing that.\nBut...\nInternet Explorer has at least one known bug in this area. Even Internet Explorer 9 exhibits this. Suppose the markup is this:\n<!DOCTYPE html>\n<title>Test case</title>\n<form action='#'>\n   <input name=\"var1\">\n</form>\n\nYou should (and do in other browsers) get a DOM that looks like this:\nHTML\n    HEAD\n        TITLE\n    BODY\n        FORM action=\"#\"\n            INPUT name=\"var1\"\n\nBut in Internet Explorer you get this:\nHTML\n    HEAD\n       TITLE\n       FORM action=\"#\"\n           BODY\n               INPUT name=\"var1\"\n    BODY\n\nSee it for yourself.\nThis bug seems limited to the form start tag preceding any text content and any body start tag.\n",
            "\nIt's valid to omit them in HTML 4:\n\n7.3 The HTML element \nstart tag: optional, End tag: optional \n\n7.4.1 The HEAD element \nstart tag: optional, End tag: optional\n\nFrom 7 The global structure of an HTML document.\nIn HTML5, there are no \"required\" or \"optional\" elements exactly, as HTML5 syntax is more loosely defined.  For example, title:\n\nThe title element is a required child in most situations, but when a higher-level protocol provides title information, e.g. in the Subject line of an e-mail when HTML is used as an e-mail authoring format, the title element can be omitted.\n\nFrom 4.2.2 The title element.\nIt's not valid to omit them in true XHTML5, though that is almost never used (versus XHTML-acting-like-HTML5).\nHowever, from a practical standpoint you often want browsers to run in \"standards mode,\" for predictability in rendering HTML and CSS.  Providing a DOCTYPE and a more structured HTML tree will guarantee more predictable cross-browser results.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n"
        ],
        "answer": "A1",
        "tags": [
            "html",
            "tags"
        ]
    },
    {
        "question_id": "1496682",
        "question": "\nHow can I add all the columnar values by associative key? Note that key sets are dynamic.  \nInput array:\nArray\n(\n    [0] => Array\n        (\n            [gozhi] => 2\n            [uzorong] => 1\n            [ngangla] => 4\n            [langthel] => 5\n        )\n\n    [1] => Array\n        (\n            [gozhi] => 5\n            [uzorong] => 0\n            [ngangla] => 3\n            [langthel] => 2\n        )\n\n    [2] => Array\n        (\n            [gozhi] => 3\n            [uzorong] => 0\n            [ngangla] => 1\n            [langthel] => 3\n        )\n)\n\nDesired result:\nArray\n(\n    [gozhi] => 10\n    [uzorong] => 1\n    [ngangla] => 8\n    [langthel] => 10\n)\n\n",
        "all_answers": [
            "\nTry serialize. This will check nested subarrays as well.\n$foo =serialize($array_foo);\n$bar =serialize($array_bar);\nif ($foo == $bar) echo \"Foo and bar are equal\";\n\n",
            "\n$sumArray = array();\n\nforeach ($myArray as $k=>$subArray) {\n  foreach ($subArray as $id=>$value) {\n    isset($sumArray[$id]) || $sumArray[$id] = 0;\n    $sumArray[$id]+=$value;\n  }\n}\n\nprint_r($sumArray);\n\n",
            "\n$newarr=array();\nforeach($arrs as $value)\n{\n  foreach($value as $key=>$secondValue)\n   {\n       if(!isset($newarr[$key]))\n        {\n           $newarr[$key]=0;\n        }\n       $newarr[$key]+=$secondValue;\n   }\n}\n\n",
            "\n$arraysAreEqual = ($a == $b); // TRUE if $a and $b have the same key/value pairs.\n$arraysAreEqual = ($a === $b); // TRUE if $a and $b have the same key/value pairs in the same order and of the same types.\n\nSee Array Operators.\nEDIT\nThe inequality operator is != while the non-identity operator is !== to match the equality \noperator == and the identity operator ===.\n",
            "\nAccording to this page.\nNOTE: The accepted answer works for associative arrays, but it will not work as expected with indexed arrays (explained below). If you want to compare either of them, then use this solution. Also, this function may not works with multidimensional arrays (due to the nature of array_diff function).\nTesting two indexed arrays, which elements are in different order, using $a == $b or $a === $b fails, for example:\n<?php\n    (array(\"x\",\"y\") == array(\"y\",\"x\")) === false;\n?>\n\nThat is because the above means:\narray(0 => \"x\", 1 => \"y\") vs. array(0 => \"y\", 1 => \"x\").\nTo solve that issue, use:\n<?php\nfunction array_equal($a, $b) {\n    return (\n         is_array($a) \n         && is_array($b) \n         && count($a) == count($b) \n         && array_diff($a, $b) === array_diff($b, $a)\n    );\n}\n?>\n\nComparing array sizes was added (suggested by super_ton) as it may improve speed.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "arrays",
            "multidimensional-array",
            "sum"
        ]
    },
    {
        "question_id": "4675728",
        "question": "\nHow do I redirect stdout to an arbitrary file in Python?\nWhen a long-running Python script (e.g, web application) is started from within the ssh session and backgounded, and the ssh session is closed, the application will raise IOError and fail the moment it tries to write to stdout. I needed to find a way to make the application and modules output to a file rather than stdout to prevent failure due to IOError. Currently, I employ nohup to redirect output to a file, and that gets the job done, but I was wondering if there was a way to do it without using nohup, out of curiosity.\nI have already tried sys.stdout = open('somefile', 'w'), but this does not seem to prevent some external modules from still outputting to terminal (or maybe the sys.stdout = ... line did not fire at all). I know it should work from simpler scripts I've tested on, but I also didn't have time yet to test on a web application yet.\n",
        "all_answers": [
            "\nIf you want to do the redirection within the Python script, setting sys.stdout to a file object does the trick:\n# for python3\nimport sys\nwith open('file', 'w') as sys.stdout:\n    print('test')\n\nA far more common method is to use shell redirection when executing (same on Windows and Linux):\n$ python3 foo.py > file\n\n",
            "\nimport sys\nsys.stdout = open('stdout.txt', 'w')\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "stdout"
        ]
    },
    {
        "question_id": "4337217",
        "question": "\n\n\n\nSo I know that the difference between a signed int and unsigned int is that a bit is used to signify if the number if positive or negative, but how does this apply to a char? How can a character be positive or negative?\n",
        "all_answers": [
            "\nThere are three char types: (plain) char, signed char and unsigned char.  Any char is usually an 8-bit integer* and in that sense, a signed and unsigned char have a useful meaning (generally equivalent to uint8_t and int8_t).  When used as a character in the sense of text, use a char (also referred to as a plain char).  This is typically a signed char but can be implemented either way by the compiler.\n* Technically, a char can be any size as long as sizeof(char) is 1, but it is usually an 8-bit integer.\n",
            "\nThere's no dedicated \"character type\" in C language. char is an integer type, same (in that regard) as int, short and other integer types. char just happens to be the smallest integer type. So, just like any other integer type, it can be signed or unsigned.\nIt is true that (as the name suggests) char is mostly intended to be used to represent characters. But characters in C are represented by their integer \"codes\", so there's nothing unusual in the fact that an integer type char is used to serve that purpose.\nThe only general difference between char and other integer types is that plain char is not synonymous with signed char, while with other integer types the signed modifier is optional/implied.\n",
            "\nWhy C++ doesn't have support for unsigned floats is because there is no equivalent machine code operations for the CPU to execute.  So it would be very inefficient to support it.  \nIf C++ did support it, then you would be sometimes using an unsigned float and not realizing that your performance has just been killed.  If C++ supported it then every floating point operation would need to be checked to see if it is signed or not.  And for programs that do millions of floating point operations, this is not acceptable. \nSo the question would be why don't hardware implementers support it.  And I think the answer to that is that there was no unsigned float standard defined originally.  Since languages like to be backwards compatible, even if it were added languages couldn't make use of it.  To see the floating point spec you should look at the IEEE standard 754 Floating-Point.\nYou can get around not having an unsigned floating point type though by creating a unsigned float class that encapsulates a float or double and throws warnings if you try to pass in a negative number.   This is less efficient, but probably if you aren't using them intensely you won't care about that slight performance loss.\nI definitely see the usefulness of having an unsigned float.  But C/C++ tends to chose efficiency that works best for everyone over safety. \n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "types",
            "unsigned"
        ]
    },
    {
        "question_id": "6167994",
        "question": "\nrails generate migration AddRetweetsCountToTweet retweets_count:integer \n\nOk I use above line to create migration file that automatically generates code in the generated file to add a column to a model Tweet with datatype integer. Now I want to add default value to the added column while generating the migration file. Is that possible? I googled it but couldn't find. Guys need help. \n",
        "all_answers": [
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nDefault migration generator does not handle default values (column modifiers are supported but do not include default or null), but you could create your own generator.\nYou can also manually update the migration file prior to running rake db:migrate by adding the options to add_column:\nadd_column :tweet, :retweets_count, :integer, :null => false, :default => 0\n... and read Rails API\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nt.integer :retweets_count, :default => 0\n\n... should work.\nSee the Rails guide on migrations\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "migration"
        ]
    },
    {
        "question_id": "413477",
        "question": "\n\n\n\nI was looking into Valgrind to help improve my C coding/debugging when I discovered it is only for Linux - I have no other need or interest in moving my OS to Linux so I was wondering if there is a equally good program for Windows.\n",
        "all_answers": [
            "\nSome more good commercial tools:\n\nPurify\nInsure++\n\n",
            "\nI had the chance to use Compuware DevPartner Studio in the past and that was really good, but it's quite expensive.\nA cheaper solution could be GlowCode, i just worked with a 5.x version and, despite some problems in attaching to a process i needed to debug, it worked quite well.\n",
            "\nMinGW is a suite of development tools that contains GCC (among others), and GCC is a C compiler within that suite.\n",
            "\nSee the \"Source Test Tools\" link on the Software QA Testing and Test Tool Resources page for a list of similar tools.\nI've used BoundsChecker,DevPartner Studio and Intel V-Tune in the past for profiling. I liked V-Tune the best; you could emulate various Intel chipsets and it would give you hints on how to optimize for that platform.\n",
            "\nPerhaps CodeSnitch would be something you're after? http://www.entrek.com/codesnitch.html\n",
            "\nDevelopment environment for Windows you are using may contain its own tools. Visual Studio, for example, lets you detect and isolate memory leaks in your programs\n",
            "\nTo compile C program you need a C implementation for your specific computer.\nC implementations consist, basically, of a compiler (its preprocesser and headers) and a library (the ready-made executable code).\nOn a computer with Windows installed, the library that contains most ready-made executable code is not compatible with gcc compiler ... so to use this compiler in Windows you need a different library: that's where MinGW enters. MinGW provides, among other things, the library(ies) needed for making a C implementation together with gcc.\n\nThe Windows library and MSVC together make a different implementation.\n",
            "\nI've been loving Memory Validator, from a company called Software Verification.\n",
            "\nMinGW is a complete GCC toolchain (including half a dozen frontends, such as C, C++, Ada, Go, and whatnot) for the Windows platform which compiles for and links to the Windows OS component C Runtime Library in msvcrt.dll. Rather it tries to be minimal (hence the name).\nThis means, unlike Cygwin, MinGW does not attempt to offer a complete POSIX layer on top of Windows, but on the other hand it does not require you to link with a special compatibility library.\nIt therefore also does not have any GPL-license implications for the programs you write (notable exception: profiling libraries, but you will not normally distribute those so that does not matter).\nThe newer MinGW-w64 comes with a roughly 99% complete Windows API binding (excluding ATL and such) including x64 support and experimental ARM implementations. You may occasionally find some exotic constant undefined, but for what 99% of the people use 99% of the time, it just works perfectly well.\nYou can also use the bigger part of what's in POSIX, as long as it is implemented in some form under Windows. The one major POSIX thing that does not work with MinGW is fork, simply because there is no such thing under Windows (Cygwin goes through a lot of pain to implement it).\nThere are a few other minor things, but all in all, most things kind of work anyway.\nSo, in a very very simplified sentence: MinGW(-w64) is a \"no-frills compiler thingie\" that lets you write native binary executables for Windows, not only in C and C++, but also other languages.\n"
        ],
        "answer": "A1",
        "tags": [
            "c",
            "windows",
            "debugging",
            "memory-leaks",
            "valgrind"
        ]
    },
    {
        "question_id": "33819757",
        "question": "\nI'm not 100% sure, but I believe I installed node v5 from the windows installer on both my home and office PCs.\nOn my home PC global installs happen under %APPDATA%:\n(dev) go|c:\\srv> which lessc\nc:\\users\\bjorn\\appdata\\roaming\\npm\\lessc\nc:\\users\\bjorn\\appdata\\roaming\\npm\\lessc.cmd\n\nwhile on my office PC, they go under program files:\n(dev) go|w:\\srv> which lessc\nc:\\program files\\nodejs\\lessc\nc:\\program files\\nodejs\\lessc.cmd\n\nI need to provide the full path to a number of these global tools to PyCharm's file watcher, and since the project file i shared it would make sense to not have global resources under a user folder.\nWhy would the global installs end up in different folders, and how can I force them to a location that is common to all team members?\n",
        "all_answers": [
            "\nThese are typical npm paths if you install a package globally:\nWindows XP -             %USERPROFILE%\\Application Data\\npm\\node_modules\nNewer Windows Versions - %AppData%\\npm\\node_modules\nor -                     %AppData%\\roaming\\npm\\node_modules\n\n",
            "\nAccording to: https://docs.npmjs.com/files/folders\n\n\nLocal install (default): puts stuff in ./node_modules of the current    package root.\nGlobal install (with -g): puts stuff in /usr/local or wherever node is    installed.\nInstall it locally if you're going to require() it.\nInstall it globally if you're going to run it on the command line.  -> If you need both, then install it in both places, or use npm link.\n\nprefix Configuration\nThe prefix config defaults to the location where node is installed. On\nmost systems, this is /usr/local. On windows, this is the exact\nlocation of the node.exe binary.\n\nThe docs might be a little outdated, but they explain why global installs can end up in different directories:\n(dev) go|c:\\srv> npm config ls -l | grep prefix\n; prefix = \"C:\\\\Program Files\\\\nodejs\" (overridden)\nprefix = \"C:\\\\Users\\\\bjorn\\\\AppData\\\\Roaming\\\\npm\"\n\nBased on the other answers, it may seem like the override is now the default location on Windows, and that I may have installed my office version prior to this override being implemented.\nThis also suggests a solution for getting all team members to have globals stored in the same absolute path relative to their PC, i.e. (run as Administrator):\n(Run this in cmd, not in PowerShell!)\nmkdir %PROGRAMDATA%\\npm\nsetx PATH \"%PROGRAMDATA%\\npm;%PATH%\" /M\nnpm config set prefix %PROGRAMDATA%\\npm\n\nopen a new cmd.exe window and reinstall all global packages.\nExplanation (by lineno.):\n\nCreate a folder in a sensible location to hold the globals (Microsoft is\nadamant that you shouldn't write to ProgramFiles, so %PROGRAMDATA% seems\nlike the next logical place.\nThe directory needs to be on the path, so use setx .. /M to set the\nsystem path (under HKEY_LOCAL_MACHINE).  This is what requires you to run\nthis in a shell with administrator permissions.\nTell npm to use this new path. (Note: folder isn't visible in %PATH% in\nthis shell, so you must open a new window).\n\n",
            "\nJust press windows button and type %APPDATA% and type enter.\nAbove is the location where you can find \\npm\\node_modules folder. This is where global modules sit in your system.\n"
        ],
        "answer": "A2",
        "tags": [
            "node.js",
            "windows",
            "npm",
            "pycharm"
        ]
    },
    {
        "question_id": "35978550",
        "question": "\nHow do I show uncommitted changes in Git?\nI STFW'ed, and these commands are not working:\nteyan@TEYAN-THINK MINGW64 /d/nano/repos/PSTools/psservice (teyan/psservice)\n$ git status\nOn branch teyan/psservice\nYour branch is up-to-date with 'origin/teyan/psservice'.\nChanges to be committed:\n  (use \"git reset HEAD <file>...\" to unstage)\n\n        modified:   psservice.c\n        modified:   psservice.vcxproj.filters\n\n\nteyan@TEYAN-THINK MINGW64 /d/nano/repos/PSTools/psservice (teyan/psservice)\n$ git diff\n\nteyan@TEYAN-THINK MINGW64 /d/nano/repos/PSTools/psservice (teyan/psservice)\n$ git diff master\nfatal: ambiguous argument 'master': unknown revision or path not in the working tree.\nUse '--' to separate paths from revisions, like this:\n'git <command> [<revision>...] -- [<file>...]'\n\n",
        "all_answers": [
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\n\nHow to show uncommitted changes in Git\n\nThe command you are looking for is git diff.\n\ngit diff - Show changes between commits, commit and working tree, etc\n\n\nHere are some of the options it expose which you can use\ngit diff (no parameters)\nPrint out differences between your working directory and the index.\ngit diff --cached:\nPrint out differences between the index and HEAD (current commit).\ngit diff HEAD:\nPrint out differences between your working directory and the HEAD.\ngit diff --name-only\nShow only names of changed files.\ngit diff --name-status\nShow only names and status of changed files.\ngit diff --color-words\nWord by word diff instead of line by line.\nHere is a sample of the output for git diff --color-words:\n\n",
            "\nYou have already staged the changes (presumably by running git add), so in order to get their diff, you need to run:\ngit diff --cached\n\n(A plain git diff will only show unstaged changes.)\nFor example:\n\n"
        ],
        "answer": "A5",
        "tags": [
            "git",
            "git-diff"
        ]
    },
    {
        "question_id": "3677753",
        "question": "\nIn my view I want to display the current date in \"mm/dd/yyyy\" format.\n",
        "all_answers": [
            "\n<%= Time.now.strftime(\"%m/%d/%Y\") %>\n\n",
            "\nYou could simply do (substitute in Time for DateTime if using straight Ruby -- i.e. no Rails):\nDateTime.now.strftime('%m/%d/%Y')\n\nIf you're using that format a lot, you might want to create a date_time_formats initializer in your RAILS_ROOT/config/initializers folder (assuming Rails 2), something like this:\n# File: date_time_formats.rb\nActiveSupport::CoreExtensions::Time::Conversions::DATE_FORMATS.merge!(\n  :human => \"%m/%d/%Y\"\n)\n\nWhich will then let you use the more friendly version of DateTime.now.to_s(:human) in your code.\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "date"
        ]
    },
    {
        "question_id": "2051744",
        "question": "\nI have a scatter plot graph with a bunch of random x, y coordinates. Currently the Y-Axis starts at 0 and goes up to the max value. I would like the Y-Axis to start at the max value and go up to 0.\npoints = [(10,5), (5,11), (24,13), (7,8)]    \nx_arr = []\ny_arr = []\nfor x,y in points:\n    x_arr.append(x)\n    y_arr.append(y)\nplt.scatter(x_arr,y_arr)\n\n",
        "all_answers": [
            "\nThere is a better, and simpler, solution than the one given by John Vinyard. Use NullLocator:\nimport matplotlib.pyplot as plt\n\nplt.plot(range(10))\nplt.gca().xaxis.set_major_locator(plt.NullLocator())\nplt.show()\nplt.savefig('plot')\n\n",
            "\nThe plt.tick_params method is very useful for stuff like this.  This code turns off major and minor ticks and removes the labels from the x-axis.\nNote that there is also ax.tick_params for matplotlib.axes.Axes objects.\nfrom matplotlib import pyplot as plt\nplt.plot(range(10))\nplt.tick_params(\n    axis='x',          # changes apply to the x-axis\n    which='both',      # both major and minor ticks are affected\n    bottom=False,      # ticks along the bottom edge are off\n    top=False,         # ticks along the top edge are off\n    labelbottom=False) # labels along the bottom edge are off\nplt.show()\nplt.savefig('plot')\nplt.clf()\n\n\n",
            "\nNot exactly what the OP was asking for, but a simple way to disable all axes lines, ticks and labels is to simply call:\nplt.axis('off')\n\n",
            "\nAlternatively, you can pass an empty tick position and label as\n# for matplotlib.pyplot\n# ---------------------\nplt.xticks([], [])\n# for axis object\n# ---------------\n# from Anakhand May 5 at 13:08\n# for major ticks\nax.set_xticks([])\n# for minor ticks\nax.set_xticks([], minor=True)\n\n",
            "\nUse matplotlib.pyplot.axis()\naxis([xmin, xmax, ymin, ymax])\nSo you could add something like this at the end:\nplt.axis([min(x_arr), max(x_arr), max(y_arr), 0])\n\nAlthough you might want padding at each end so that the extreme points don't sit on the border.\n",
            "\nDisplacedAussie's answer is correct, but usually a shorter method is just to reverse the single axis in question:\nplt.scatter(x_arr, y_arr)\nax = plt.gca()\nax.set_ylim(ax.get_ylim()[::-1])\n\nwhere the gca() function returns the current Axes instance and the [::-1] reverses the list.\n",
            "\nHere is an alternative solution that I found on the matplotlib mailing list:\nimport matplotlib.pylab as plt\n\nx = range(1000)\nax = plt.axes()\nax.semilogx(x, x)\nax.xaxis.set_ticks_position('none') \n\n\n",
            "\nThere is a new API that makes this even simpler.\nplt.gca().invert_xaxis()\n\nand/or\nplt.gca().invert_yaxis()\n\n",
            "\nTry this to remove the labels (but not the ticks):\nimport matplotlib.pyplot as plt\n\nplt.setp( ax.get_xticklabels(), visible=False)\n\nexample\n",
            "\nThis snippet might help in removing the xticks only.\nfrom matplotlib import pyplot as plt    \nplt.xticks([])\n\nThis snippet might help in removing the xticks and yticks both.\nfrom matplotlib import pyplot as plt    \nplt.xticks([]),plt.yticks([])\n\n"
        ],
        "answer": "A8",
        "tags": [
            "python",
            "pandas",
            "matplotlib",
            "seaborn"
        ]
    },
    {
        "question_id": "20379311",
        "question": "\nI have a form that is an update user form where several of the elements are checkboxes.  I want true to pass to the params if checked (this is working) and false to pass to the params if unchecked (not working).  The unchecked items are not even being sent to the params.  How can i make an unchecked item pass through as false?  \nForm\n<%= form_tag user_url(@user), class: \"form-signin\", method: 'patch' do %>\n <h4>Please confirm your email.  We'll only email you if you have notifications.</h4>\n  <%= email_field_tag :email, current_user.email %>\n <h4>Want to be notified when someone needs a player?  Choose which sports below.</h4>\n  <%= check_box_tag :basketball, checked = true %> Basketball</br></br>\n  <%= check_box_tag :indoor_volleyball, checked = true %> Indoor Volleyball</br></br>\n  <%= check_box_tag :beach_volleyball, checked = true %> Beach Volleyball</br></br>\n  <%= check_box_tag :soccer, checked = true %> Soccer</br></br>\n  <%= check_box_tag :flag_football, checked = true %> Flag Football</br></br>\n  <%= check_box_tag :hockey, checked = true %> Hockey</br></br>\n  <%= check_box_tag :kickball, checked = true %> Kickball</br></br>\n  <%= check_box_tag :softball, checked = true %> Softball\n  <%= hidden_field_tag :user_id, :value => current_user.id %>\n  <%= hidden_field_tag :user, :value => current_user %>\n <div>\n  </br>\n  <%= submit_tag \"Submit\", class:\"btn btn-large btn-success\" %>\n </div>\n\nController\n  def update\n   respond_to do |format|\n   if @user.update(update_params)\n     format.html { redirect_to @user, notice: 'Updates were successful.' }\n     format.json { head :no_content }\n    else\n     format.html { render action: 'edit' }\n     format.json { render json: @user.errors, status: :unprocessable_entity }\n    end\n   end\n  end\n\n  def update_params\n    params.permit(:email, :soccer, :softball, :beach_volleyball, :indoor_volleyball, :flag_football, :basketball, :hockey, :kickball)\n  end\n\n",
        "all_answers": [
            "\nLook at it\nThe main idea to place hidden field before checkbox. When a form is submitted fields will be parsed: if checkbox is checked - its value will be passed, else the value of hidden field\nFor example smth like this (NOT testes)\n<%= hidden_field_tag :basketball, false %>\n<%= check_box_tag :basketball, checked = true %> Basketball</br></br>\n\n",
            "\nYou need to place a hidden field tag before each checkbox with an empty value, for example:\n<%= hidden_field_tag :basketball, '' %>\n<%= check_box_tag :basketball, checked = true %> Basketball</br></br>\n\nThen the form is aware it needs to populate that field with an empty value if nothing is selected.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "checkbox",
            "ruby-on-rails-4"
        ]
    },
    {
        "question_id": "22451973",
        "question": "\nI made a script that opens a .xls file, writes a few new values in it, then saves the file.\nLater, the script opens it again, and wants to find the answers in some cells which contain formulas.\nIf I call that cell with openpyxl, I get the formula (ie: \"=A1*B1\").\nAnd if I activate data_only, I get nothing.\nIs there a way to let Python calculate the .xls file? (or should I try PyXll?)\n",
        "all_answers": [
            "\nNo, and in openpyxl there will never be. I think there is a Python library that purports to implements an engine for such formualae which you can use.\n",
            "\nThere is actually a project that takes Excel formulas and evaluates them using Python:  Pycel.  Pycel uses Excel itself (via COM) to extract the formulas, so in your case you would skip that part.  The project probably has something useful that you can use, but I can't vouch for its maturity or completeness.  It was not really developed for the general public.\nThere is also a newer project called Koala which builds on both Pycel and OpenPyXL.\nAnother approach, if you can't use Excel but you can calculate the results of the formulas yourself (in your Python code), is to write both the value and the formula into a cell (so that when you read the file, you can just pull the value, and not worry about the formula at all).  As of this writing, I haven't found a way to do it in OpenPyXL, but XlsxWriter can do it.  From the documentation:\n\nXlsxWriter doesn’t calculate the value of a formula and instead stores the value 0 as the formula result. It then sets a global flag in the XLSX file to say that all formulas and functions should be recalculated when the file is opened. This is the method recommended in the Excel documentation and in general it works fine with spreadsheet applications. However, applications that don’t have a facility to calculate formulas, such as Excel Viewer, or some mobile applications will only display the 0 results.\n\nIf required, it is also possible to specify the calculated result of the formula using the options value parameter. This is occasionally necessary when working with non-Excel applications that don’t calculate the value of the formula. The calculated value is added at the end of the argument list:\n\nworksheet.write_formula('A1', '=2+2', num_format, 4)\n\nWith this approach, when it's time to read the value, you would use OpenPyXL's data_only option. (For other people reading this answer: If you use xlrd, then only the value is available anyway.)\nFinally, if you do have Excel, then perhaps the most straightforward and reliable thing you can do is automate the opening and resaving of your file in Excel (so that it will calculate and write the values of the formulas for you). xlwings is an easy way to do this from either Windows or Mac.\n",
            "\nThere is a way to make it more pythonic (works with three or more letters and uses less magic numbers):\ndef col2num(col):\n    num = 0\n    for c in col:\n        if c in string.ascii_letters:\n            num = num * 26 + (ord(c.upper()) - ord('A')) + 1\n    return num\n\nAnd as a one-liner using reduce (does not check input and is less readable so I don't recommend it):\ncol2num = lambda col: reduce(lambda x, y: x*26 + y, [ord(c.upper()) - ord('A') + 1 for c in col])\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "excel",
            "xlwt",
            "openpyxl",
            "pyxll"
        ]
    },
    {
        "question_id": "24196689",
        "question": "\nI'm learning swift recently, but I have a basic problem that can't find an answer\nI want to get something like \nvar a:Int = 3\nvar b:Int = 3 \nprintln( pow(a,b) ) // 27\n\nbut the pow function can work with double number only, it doesn't work with integer, and I can't even cast the int to double by something like Double(a) or a.double()...\nWhy it doesn't supply the power of integer? it will definitely return an integer without ambiguity !\nand Why I can't cast a integer to a double? it just change 3 to 3.0 (or 3.00000... whatever)\nif I got two integer and I want to do the power operation, how can I do it smoothly?\nThanks!\n",
        "all_answers": [
            "\nIf you really want an 'Int only' implementation and don't want to coerce to/from Double, you'll need to implement it.  Here is a trivial implementation; there are faster algorithms but this will work:\nfunc pow (_ base:Int, _ power:UInt) -> Int {\n  var answer : Int = 1\n  for _ in 0..<power { answer *= base }\n  return answer\n}\n\n> pow (2, 4)\n$R3: Int = 16\n> pow (2, 8)\n$R4: Int = 256\n> pow (3,3)\n$R5: Int = 27\n\nIn a real implementation you'd probably want some error checking.\n",
            "\nIf you like, you could declare an infix operator to do it.\n// Put this at file level anywhere in your project\ninfix operator ^^ { associativity left precedence 160 }\nfunc ^^ (radix: Int, power: Int) -> Int {\n    return Int(pow(Double(radix), Double(power)))\n}\n\n// ...\n// Then you can do this...\nlet i = 2 ^^ 3\n// ... or\nprintln(\"2³ = \\(2 ^^ 3)\") // Prints 2³ = 8\n\nI used two carets so you can still use the XOR operator.\nUpdate for Swift 3\nIn Swift 3 the \"magic number\" precedence is replaced by precedencegroups:\nprecedencegroup PowerPrecedence { higherThan: MultiplicationPrecedence }\ninfix operator ^^ : PowerPrecedence\nfunc ^^ (radix: Int, power: Int) -> Int {\n    return Int(pow(Double(radix), Double(power)))\n}\n\n// ...\n// Then you can do this...\nlet i2 = 2 ^^ 3\n// ... or\nprint(\"2³ = \\(2 ^^ 3)\") // Prints 2³ = 8\n\n",
            "\nOther than that your variable declarations have syntax errors, this works exactly how you expected it to. All you have to do is cast a and b to Double and pass the values to pow. Then, if you're working with 2 Ints and you want an Int back on the other side of the operation, just cast back to Int.\nimport Darwin \n\nlet a: Int = 3\nlet b: Int = 3\n\nlet x: Int = Int(pow(Double(a),Double(b)))\n\n"
        ],
        "answer": "A2",
        "tags": [
            "integer",
            "double",
            "swift",
            "pow"
        ]
    },
    {
        "question_id": "3347847",
        "question": "\nIn PHP, CGI, or in RoR's View, we can easily print out debug information.  How about in the Controller, how can we just say, print \"hello world\" (to the webpage output) and return to continue with the view, or stop the controller right there?\n",
        "all_answers": [
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nIn the controller you can:\nrender :text => @some_object.inspect\n\nBut your view won't be rendered.\nYou could also:\nRails.logger.debug(\"My object: #{@some_object.inspect}\")\n\nand run tail on log/development.log to see the output.\nIn the view the recommeneded way is:\n<%= debug(@some_object) %>\n\n",
            "\nYou can debug in the view: <%= debug @post %>. More info: http://guides.rubyonrails.org/debugging_rails_applications.html\n",
            "\nDon't know about print, but puts never failed me. Your hello world will be in console and logs and normal flow will continue.\nDid I understand you correctly?\n"
        ],
        "answer": "A4",
        "tags": [
            "ruby-on-rails",
            "debugging"
        ]
    },
    {
        "question_id": "23081263",
        "question": "\nSince I reinstalled Eclipse (simply deleted and downloaded it again) I can't debug my applications on Samsung Galaxy i9001 (with CyanogenMod - Android 4.4.2). It worked fine before reinstallation.\nUnplug/plug, Uncheck/check \"Debug Enabled\", adb kill-server/adb start-server, restart phone/computer doesn't work for me. On the device authorize dialog never appears (but I remember that dialog appeared before reinstallation). I have no idea how to force this authorize dialog to display. There is no abd_key.pub file in .android directory.\nWhen i try read cpu info DDMS says:\n[2014-04-15 12:47:06 - DDMS] device unauthorized. Please check the confirmation dialog on your device.\n\nAny ideas? Is it possible to generate keys manually without confirmation dialog?\nUSB Connection\n\nWireless Connection\n\n",
        "all_answers": [
            "\nI run into the same issues with nexus7.\nFollowing worked for fixing this.\n\nOpen Developer option in the Settings menu on your device.\nSwitch off the button on the upper right of the screen.\nDelete all debug permission from the list of the menu.\nSwitch on the button on the upper right of the screen. \n\nnow reconnect your device to your PC and everything should be fine.\nSorry for my poor english and some name of the menus(buttons) can be incorrect in your language because mine is Japanese.\n",
            "\nOhhh finally I figured it out!\nAfter removing Eclipse directory I installed it into another directory.\necho %ANDROID_SDK_HOME%\n\nhas displayed wrong path to sdk directory.\n\nset ANDROID_SDK_HOME \"E:\\adt-bundle-windows-x86_64-20140321\\sdk\"\nunplug device\nadb kill-server\nadb start-server\nplug device\n\nAfter these steps, I was able to see confirmation dialog with RSA fingerprint on my phone :)\n",
            "\n\nAs the message have stated, you need to allow the adb access on your phone. \n\nYou need to first connect the phone to your PC with USB cables, then the authorization message will pop out on the screen. Tick remember your choice, then allow it.\nIF your device doesnt shows any messages when connected to the PC.Just do this.\n\nRemove /data/misc/adb/adb_key, reboot your phone and try connect\n  again. The message should come up.\n\n",
            "\nIt's likely that the device is no longer authorized on ADB for whatever reason.\n1. Check if authorized:\n<ANDROID_SDK_HOME>\\platform-tools>adb devices\nList of devices attached\n4df798d76f98cf6d        unauthorized\n\n2. Revoke USB Debugging on phone\nIf the device is shown as unauthorized, go to the developer options on the phone and click \"Revoke USB debugging authorization\" (tested with JellyBean & Samsung GalaxyIII).\n3. Restart ADB Server:\nThen restarted adb server\nadb kill-server\nadb start-server\n\n4. Reconnect the device\nThe device will ask if you are agree to connect the computer id.\nYou need to confirm it.\n5. Now Check the device\nIt is now authorized!\nadb devices\n<ANDROID_SDK_HOME>\\platform-tools>adb devices\nList of devices attached\n4df798d76f98cf6d        device\n\n"
        ],
        "answer": "A4",
        "tags": [
            "android",
            "adb",
            "unauthorized"
        ]
    },
    {
        "question_id": "34156938",
        "question": "\nI am generating a self-signed SSL certificate with OpenSSL (not makecert), for use in IIS.\nopenssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 -nodes -subj '//CN=myhost'\n\n(The double slash is correct. The command above does not work without that.)\nopenssl pkcs12 -export -out key.pfx -inkey key.pem -in cert.pem -name 'myhost'\n\nThe first command runs completes successfully. However the second get stuck with \n\nLoading 'screen' into random state -\n\nI am using OpenSSL (1.0.2d) that comes with Git for Windows (2.6.3).\nAnyone experiences the same issue?\nClarification: Question How to fix \"unable to write 'random state' \" in openssl describes different -- problem with writing the the .rnd file. Here the problem seems to be generating the random state. (And only in the second command.)\n",
        "all_answers": [
            "\nI have done it earlier.\nHope this helps, if this is exactly what you are looking for.\n\nLoad your certificate (in PCCERT_CONTEXT structure) from Windows Cert store using Crypto APIs.\nGet encrypted content of it in binary format as it is. [PCCERT_CONTEXT->pbCertEncoded].\nParse this binary buffer into X509 certificate Object using OpenSSL's d2i_X509() method.\nGet handle to OpenSSL's trust store using SSL_CTX_get_cert_store() method.\nLoad above parsed X509 certificate into this trust store using X509_STORE_add_cert() method.\nYou are done!\n\n",
            "\nPlease try to add winpty before oppenssl:  \nwinpty openssl ...\n\nor you can run a new bash wrapped by winpty:\nwinpty bash\n\nIn the windows console, there is some problem with terminal input/output so winpty can help if some software requires unix terminal behavior.\nwinpty helped me to run openssl in this environment:\ngit version 2.7.3.windows.1\nOpenSSL 1.0.2g  1 Mar 2016\n\n",
            "\nI found that I needed to specify the PFX password on the command line using -passout pass:SomePassword - e.g.:\nopenssl pkcs12 -export -out foo_example_com.pfx -inkey foo_example_com.key -in foo_example_com.crt -passout pass:Pa55w0rd\n\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "ssl",
            "openssl",
            "git-bash"
        ]
    },
    {
        "question_id": "50973048",
        "question": "\nSuppose that I would like to implement a fix to a project of someone else. That project resides on GitHub.\nI could create a fork on GitHub and implement the fix.\nHowever, I would like to create my fork on GitLab rather than on GitHub.\nIs that possible? How?\nI have read this article:\nhttps://about.gitlab.com/2016/12/01/how-to-keep-your-fork-up-to-date-with-its-origin/\nAnyway, I am not sure what should I do in my case.\n\nShould I just create a fork on GitLab of the project from GitHub somehow?\nOr should I create a mirror on GitLab of the project from GitHub?\nOr should I create a mirror on GitLab and then fork the mirror?\nOr should I do  something completely different?\n\nWhat is the correct approach.\nThanks.\nUPDATE\nRepository mirroring on GitLab does not make sense probably. I can create a mirror of MY GitHub repository on GitLab but I cannot create a mirror of a repository of someone else.\nhttps://docs.gitlab.com/ee/workflow/repository_mirroring.html\nThis is what I have done so far:\nI have cloned the original GitHub project to my local machine. I have commited the fix to a new branch in my local repository. I have created an empty project on GitLab. I have set origin in my local repository to that empty project on GitLab and pushed both branches to GitLab. I have set upstream in my local repository to the GitHub repository.\nWhen I want to get new commits from the original GitHub repository to the repository on GitLab (i.e. sync the repositories), I can do this using my local repo as an intermediate step. However, there is no direct connection between the repo on GitHub and the repo on GitLab. Is my setup correct? Is there any difference if I make a fork on GitHub?\n",
        "all_answers": [
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nForking a private github repository is possible.\n\nClick new project\nSelect Import\nSelect github\nOAuth2 used to authenticate and auto create gitlab app\nSelect project to fork\n\n^ I've just done this with a private repo on github, imported successfully (inc branches etc). Imported project is automatically kept private ;)\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nIf you just want to track changes, first make an empty repository in GitLab (or whatever else you may be using) and clone it to your computer.\nThen add the GitHub project as the \"upstream\" remote with:\ngit remote add upstream https://github.com/user/repo\n\nNow you can fetch and pull from the upstream should there be any changes. (You can also push or merge to it if you have access rights.)\ngit pull upstream master\n\nFinally, push back to your own GitLab repository:\ngit push origin master\n\nIf you don't want to manually pull upstream/push origin, GitLab offers a mirroring ability in Settings => Repository => Mirroring repositories.\n"
        ],
        "answer": "A7",
        "tags": [
            "git",
            "github",
            "gitlab",
            "git-fork"
        ]
    },
    {
        "question_id": "2035645",
        "question": "\nI have been under the impression for that JavaScript was always asynchronous.  However, I have learned that there are situations where it is not (ie DOM manipulations).  Is there a good reference anywhere about when it will be synchronous and when it will be asynchronous?  Does jQuery affect this at all?\n",
        "all_answers": [
            "\nJavaScript is always synchronous and single-threaded. If you're executing a JavaScript block of code on a page then no other JavaScript on that page will currently be executed.\nJavaScript is only asynchronous in the sense that it can make, for example, Ajax calls. The Ajax call will stop executing and other code will be able to execute until the call returns (successfully or otherwise), at which point the callback will run synchronously. No other code will be running at this point. It won't interrupt any other code that's currently running.\nJavaScript timers operate with this same kind of callback.\nDescribing JavaScript as asynchronous is perhaps misleading. It's more accurate to say that JavaScript is synchronous and single-threaded with various callback mechanisms.\njQuery has an option on Ajax calls to make them synchronously (with the async: false option). Beginners might be tempted to use this incorrectly because it allows a more traditional programming model that one might be more used to. The reason it's problematic is that this option will block all JavaScript on the page until it finishes, including all event handlers and timers.\n",
            "\nJavaScript is single-threaded, and all the time you work on a normal synchronous code-flow execution.\nGood examples of the asynchronous behavior that JavaScript can have are events (user interaction, Ajax request results, etc) and timers, basically actions that might happen at any time.\nI would recommend you to give a look to the following article:\n\nHow JavaScript Timers Work\n\nThat article will help you to understand the single-threaded nature of JavaScript and how timers work internally and how asynchronous JavaScript execution works.\n\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "jquery"
        ]
    },
    {
        "question_id": "5513075",
        "question": "\nI am sending NSString and UIImage using bluetooth. I decided to store both in a NSDictionary and then convert the dictionary to NSData.\nMy question is how to convert NSDictionary to NSData and visa versa?\n",
        "all_answers": [
            "\nNSDictionary -> NSData:\nNSMutableData *data = [[NSMutableData alloc] init];\nNSKeyedArchiver *archiver = [[NSKeyedArchiver alloc] initForWritingWithMutableData:data];\n[archiver encodeObject:yourDictionary forKey:@\"Some Key Value\"];\n[archiver finishEncoding];\n[archiver release];\n\n// Here, data holds the serialized version of your dictionary\n// do what you need to do with it before you:\n[data release];\n\nNSData -> NSDictionary\nNSData *data = [[NSMutableData alloc] initWithContentsOfFile:[self dataFilePath]];\nNSKeyedUnarchiver *unarchiver = [[NSKeyedUnarchiver alloc] initForReadingWithData:data];\nNSDictionary *myDictionary = [[unarchiver decodeObjectForKey:@\"Some Key Value\"] retain];\n[unarchiver finishDecoding];\n[unarchiver release];\n[data release];\n\nYou can do that with any class that conforms to NSCoding.\nsource\n",
            "\nNSDictionary -> NSData: \nNSData *myData = [NSKeyedArchiver archivedDataWithRootObject:myDictionary];\n\nNSData -> NSDictionary:\nNSDictionary *myDictionary = (NSDictionary*) [NSKeyedUnarchiver unarchiveObjectWithData:myData];\n\n",
            "\nNSDictionary from NSData\nhttp://www.cocoanetics.com/2009/09/nsdictionary-from-nsdata/\nNSDictionary to NSData\nYou can use NSPropertyListSerialization class for that. Have a look at its method:\n+ (NSData *)dataFromPropertyList:(id)plist format:(NSPropertyListFormat)format\n                              errorDescription:(NSString **)errorString\n\nReturns an NSData object containing a given property list in a specified format.\n"
        ],
        "answer": "A2",
        "tags": [
            "iphone",
            "objective-c",
            "ios",
            "nsdictionary"
        ]
    },
    {
        "question_id": "31594549",
        "question": "\nHow do I change the size of my image so it's suitable for printing?\nFor example, I'd like to use to A4 paper, whose dimensions are 11.7 inches by 8.27 inches in landscape orientation.\n",
        "all_answers": [
            "\nThere is a better, and simpler, solution than the one given by John Vinyard. Use NullLocator:\nimport matplotlib.pyplot as plt\n\nplt.plot(range(10))\nplt.gca().xaxis.set_major_locator(plt.NullLocator())\nplt.show()\nplt.savefig('plot')\n\n",
            "\nYou need to create the matplotlib Figure and Axes objects ahead of time, specifying how big the figure is:\nfrom matplotlib import pyplot\nimport seaborn\n\nimport mylib\n\na4_dims = (11.7, 8.27)\ndf = mylib.load_data()\nfig, ax = pyplot.subplots(figsize=a4_dims)\nseaborn.violinplot(ax=ax, data=df, **violin_options)\n\n",
            "\nAlternatively, you can pass an empty tick position and label as\n# for matplotlib.pyplot\n# ---------------------\nplt.xticks([], [])\n# for axis object\n# ---------------\n# from Anakhand May 5 at 13:08\n# for major ticks\nax.set_xticks([])\n# for minor ticks\nax.set_xticks([], minor=True)\n\n",
            "\nYou can set the context to be poster or manually set fig_size.\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nnp.random.seed(0)\nn, p = 40, 8\nd = np.random.normal(0, 2, (n, p))\nd += np.log(np.arange(1, p + 1)) * -5 + 10\n\n\n# plot\nsns.set_style('ticks')\nfig, ax = plt.subplots()\n# the size of A4 paper\nfig.set_size_inches(11.7, 8.27)\nsns.violinplot(data=d, inner=\"points\", ax=ax)    \nsns.despine()\n\nfig.savefig('example.png')\n\n\n",
            "\nThe plt.tick_params method is very useful for stuff like this.  This code turns off major and minor ticks and removes the labels from the x-axis.\nNote that there is also ax.tick_params for matplotlib.axes.Axes objects.\nfrom matplotlib import pyplot as plt\nplt.plot(range(10))\nplt.tick_params(\n    axis='x',          # changes apply to the x-axis\n    which='both',      # both major and minor ticks are affected\n    bottom=False,      # ticks along the bottom edge are off\n    top=False,         # ticks along the top edge are off\n    labelbottom=False) # labels along the bottom edge are off\nplt.show()\nplt.savefig('plot')\nplt.clf()\n\n\n",
            "\nNot exactly what the OP was asking for, but a simple way to disable all axes lines, ticks and labels is to simply call:\nplt.axis('off')\n\n",
            "\nThis snippet might help in removing the xticks only.\nfrom matplotlib import pyplot as plt    \nplt.xticks([])\n\nThis snippet might help in removing the xticks and yticks both.\nfrom matplotlib import pyplot as plt    \nplt.xticks([]),plt.yticks([])\n\n",
            "\nTry this to remove the labels (but not the ticks):\nimport matplotlib.pyplot as plt\n\nplt.setp( ax.get_xticklabels(), visible=False)\n\nexample\n",
            "\nHere is an alternative solution that I found on the matplotlib mailing list:\nimport matplotlib.pylab as plt\n\nx = range(1000)\nax = plt.axes()\nax.semilogx(x, x)\nax.xaxis.set_ticks_position('none') \n\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "matplotlib",
            "seaborn",
            "figsize"
        ]
    },
    {
        "question_id": "749711",
        "question": "\n\n\n\nBasically I want to get a handle of the python interpreter so I can pass a script file to execute (from an external application).\n",
        "all_answers": [
            "\nI think it depends on how you installed python. Note that you can have multiple installs of python, I do on my machine. However, if you install via an msi of a version of python 2.2 or above, I believe it creates a registry key like so:\nHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\App Paths\\Python.exe\n\nwhich gives this value on my machine:\nC:\\Python25\\Python.exe\n\nYou just read the registry key to get the location.\nHowever, you can install python via an xcopy like model that you can have in an arbitrary place, and you just have to know where it is installed.\n",
            "\nThis works in Linux & Windows:\nPython 3.x\n>>> import sys\n>>> print(sys.executable)\nC:\\path\\to\\python.exe\n\nPython 2.x\n>>> import sys\n>>> print sys.executable\n/usr/bin/python\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python"
        ]
    },
    {
        "question_id": "45688522",
        "question": "\nI'm using VS 15.3, which supports integrated CMake 3.8. How can I target C++17 without writing flags for each specific compilers? My current global settings don't work:\n# https://cmake.org/cmake/help/latest/prop_tgt/CXX_STANDARD.html\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nset(CMAKE_CXX_EXTENSIONS OFF)\n\n# expected behaviour\n#set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /std:c++latest\")\n\nI expected CMake to add \"/std:c++lastest\" or equivalents when generating VS solution files, but no c++17 flags was found, resulted in compiler error:\nC1189 #error: class template optional is only available with C++17.\n\n",
        "all_answers": [
            "\nYour approach is the correct one, but it will not work for MSVC on versions of CMake prior to 3.10.\nFrom the CMake 3.9 documentation:\n\nFor compilers that have no notion of a standard level, such as MSVC, this has no effect.\n\nIn short, CMake haven't been updated to accommodate for the standard flags added to VC++ 2017.\nYou have to detect if VC++ 2017 (or later) is used and add the corresponding flags yourself for now.\n\nIn CMake 3.10 (and later) this have been fixed for newer version of VC++. See the 3.10 documentation.\n",
            "\nSettings for compiler\nIn the project where you want to #include the header file from another project, you will need to add the path of the header file into the Additional Include Directories section in the project configuration.\nTo access the project configuration:\n\nRight-click on the project, and select Properties.\nSelect Configuration Properties->C/C++->General.\nSet the path under Additional Include Directories.\n\nHow to include\nTo include the header file, simply write the following in your code:\n#include \"filename.h\"\n\nNote that you don't need to specify the path here, because you include the directory in the Additional Include Directories already, so Visual Studio will know where to look for it.\nIf you don't want to add every header file location in the project settings, you could just include a directory up to a point, and then #include relative to that point:\n// In project settings\nAdditional Include Directories    ..\\..\\libroot\n\n// In code\n#include \"lib1/lib1.h\"    // path is relative to libroot\n#include \"lib2/lib2.h\"    // path is relative to libroot\n\nSetting for linker\nIf using static libraries (i.e. .lib file), you will also need to add the library to the linker input, so that at linkage time the symbols can be linked against (otherwise you'll get an unresolved symbol):\n\nRight-click on the project, and select Properties.\nSelect Configuration Properties->Linker->Input\nEnter the library under Additional Dependencies.\n\n",
            "\nYou can keep that set(CMAKE_CXX_STANDARD 17) for other compilers, like Clang and GCC. But for Visual Studio, it's useless.\nIf CMake still doesn't support this, you can do the following for Visual Studio:\nif(MSVC)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /std:c++17\")\nendif(MSVC)\n\nEDIT: As the question title doesn't mention the compiler, let me add that for gcc, clang and similar compilers, this is the command to enable C++17:\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++17\")\n\n"
        ],
        "answer": "A1",
        "tags": [
            "c++",
            "visual-studio",
            "cmake",
            "c++17"
        ]
    },
    {
        "question_id": "1655065",
        "question": "\nMy problem is that I want to redirect via JavaScript to a directory above.\nMy code:\nlocation.href = (location.href).substr(0, (location.href).lastIndexOf('folder'))\n\nThe URL looks like this:\nexample.com/path/folder/index.php?file=abc&test=123&lol=cool\nThe redirect affect just this:\nexample.com/path/&test=123&lol=cool\nBut want to have this:\nexample.com/path/\nHow can I do it?\n",
        "all_answers": [
            "\nredirect to ../\n",
            "\nvar getLocation = function(href) {\n    var l = document.createElement(\"a\");\n    l.href = href;\n    return l;\n};\nvar l = getLocation(\"http://example.com/path\");\nconsole.debug(l.hostname)\n>> \"example.com\"\nconsole.debug(l.pathname)\n>> \"/path\"\n\n",
            "\n<a href=\"..\">no JS needed</a>\n.. means parent directory.\n",
            "\nThe modern way:\nnew URL(\"http://example.com/aa/bb/\")\n\nReturns an object with properties hostname and pathname, along with a few others.\nThe first argument is a relative or absolute URL; if it's relative, then you need to specify the second argument (the base URL). For example, for a URL relative to the current page:\nnew URL(\"/aa/bb/\", location)\n\nIn addition to browsers, this API is also available in Node.js since v7, through require('url').URL.\n",
            "\nIf you use location.hostname you will get your domain.com part. Then location.pathname will give you /path/folder. I would split location.pathname by / and reassemble the URL. But unless you need the querystring, you can just redirect to .. to go a directory above.\n",
            "\nYou can do a relative redirect:\nwindow.location.href = '../'; //one level up\n\nor\nwindow.location.href = '/path'; //relative to domain\n\n",
            "\nfound here: https://gist.github.com/jlong/2428561\nvar parser = document.createElement('a');\nparser.href = \"http://example.com:3000/pathname/?search=test#hash\";\n\nparser.protocol; // => \"http:\"\nparser.host;     // => \"example.com:3000\"\nparser.hostname; // => \"example.com\"\nparser.port;     // => \"3000\"\nparser.pathname; // => \"/pathname/\"\nparser.hash;     // => \"#hash\"\nparser.search;   // => \"?search=test\"\nparser.origin;   // => \"http://example.com:3000\"\n\n"
        ],
        "answer": "A6",
        "tags": [
            "javascript",
            "url",
            "redirect"
        ]
    },
    {
        "question_id": "5619202",
        "question": "\nHow can I convert a string to a Date object in JavaScript?\nvar st = \"date in some format\"\nvar dt = new Date();\n\nvar dt_st = // st in Date format, same as dt.\n\n",
        "all_answers": [
            "\nAs an alternative to duck typing via\ntypeof date.getMonth === 'function'\n\nyou can use the instanceof operator, i.e. But it will return true for invalid dates too, e.g. new Date('random_string') is also instance of Date\ndate instanceof Date\n\nThis will fail if objects are passed across frame boundaries.\nA work-around for this is to check the object's class via\nObject.prototype.toString.call(date) === '[object Date]'\n\n",
            "\nnew Date(2000, 10, 1) will give you \"Wed Nov 01 2000 00:00:00 GMT+0100 (CET)\" \nSee that 0 for month gives you January\n",
            "\nDate.parse almost gets you what you want.  It chokes on the am/pm part, but with some hacking you can get it to work:\nvar str = 'Sun Apr 25, 2010 3:30pm',\n    timestamp;\n\ntimestamp = Date.parse(str.replace(/[ap]m$/i, ''));\n\nif(str.match(/pm$/i) >= 0) {\n    timestamp += 12 * 60 * 60 * 1000;\n}\n\n",
            "\nThe best string format for string parsing is the date ISO format together with the JavaScript Date object constructor. \nExamples of ISO format: YYYY-MM-DD or YYYY-MM-DDTHH:MM:SS.\nBut wait!  Just using the \"ISO format\" doesn't work reliably by itself. String are sometimes parsed as UTC and sometimes as localtime (based on browser vendor and version). The best practice should always be to store dates as UTC and make computations as UTC.\nTo parse a date as UTC, append a Z - e.g.: new Date('2011-04-11T10:20:30Z').\nTo display a date in UTC, use .toUTCString(),\nto display a date in user's local time, use .toString().\nMore info on MDN | Date and this answer.\nFor old Internet Explorer compatibility (IE versions less than 9 do not support ISO format in Date constructor), you should split datetime string representation to it's parts and then you can use constructor using datetime parts, e.g.:  new Date('2011', '04' - 1, '11', '11', '51', '00'). Note that the number of the month must be 1 less.\n\nAlternate method - use an appropriate library:\nYou can also take advantage of the library Moment.js that allows parsing date with the specified time zone.\n",
            "\nPass it as an argument to Date():\nvar st = \"date in some format\"\nvar dt = new Date(st);\n\nYou can access the date, month, year using, for example: dt.getMonth().\n",
            "\nYou can use the following code:\n(myvar instanceof Date) // returns true or false\n\n",
            "\nJust new Date(st);\nAssuming that it's the proper format.\n"
        ],
        "answer": "A4",
        "tags": [
            "javascript",
            "date",
            "date-parsing"
        ]
    },
    {
        "question_id": "8291366",
        "question": "\nI want to know what is the best way to benchmark my PHP scripts. Does not matter if a cron job, or webpage or web service.\nI know i can use microtime but is it really giving me the real time of a PHP script?\nI want to test and benchmark different functions in PHP that do the same thing. For example, preg_match vs strpos or domdocument vs preg_match or preg_replace vs str_replace`\nExample of a webpage:\n<?php\n// login.php\n\n$start_time = microtime(TRUE);\n\nsession_start(); \n// do all my logic etc...\n\n$end_time = microtime(TRUE);\n\necho $end_time - $start_time;\n\nThis will output: 0.0146126717 (varies all the time - but that is the last one I got). This means it took 0.015 or so to execute the PHP script.\nIs there a better way?\n",
        "all_answers": [
            "\nPut it in a for loop to do each thing 1,000,000 times to get a more realistic number. And only start the timer just before the code you actually want to benchmark, then record the end time just after (i.e. don't start the timer before the session_start().\nAlso make sure the code is identical for each function you want to benchmark, with the exception of the function you are timing.\nHow the script is executed (cronjob, php from commandline, Apache, etc.) should not make a difference since you are only timing the relative difference between the speed of the different functions. So this ratio should remain the same.\nIf the computer on which you are running the benchmark has many other things going on, this could affect the benchmark results if there happens to be a spike in CPU or memory usage from another application while your benchmark is running. But as long as you have a lot of resources to spare on the computer then I don't think this will be a problem.\n",
            "\nIf you actually want to benchmark real world code, use tools like Xdebug and XHProf.\nXdebug is great for when you're working in dev/staging, and XHProf is a great tool for production and it's safe to run it there (as long as you read the instructions). The results of any one single page load aren't going to be as relevant as seeing how your code performs while the server is getting hammered to do a million other things as well and resources become scarce. This raises another question: are you bottlenecking on CPU? RAM? I/O?\nYou also need to look beyond just the code you are running in your scripts to how your scripts/pages are being served. What web server are you using? As an example, I can make nginx + PHP-FPM seriously out perform mod_php + Apache, which in turn gets trounced for serving static content by using a good CDN.\nThe next thing to consider is what you are trying to optimise for?  \n\nIs the speed with which the page renders in the users browser the\nnumber one priority?\nIs getting each request to the server thrown back out as quickly as\npossible with smallest CPU consumption the goal?\n\nThe former can be helped by doing things like gzipping all resources sent to the browser, yet doing so could (in some circumstances) push you further away from the achieving the latter.\nHopefully all of the above can help show that carefully isolated 'lab' testing will not reflect the variables and problems that you will encounter in production, and that you must identify what your high level goal is and then what you can do to get there, before heading off down the micro/premature-optimisation route to hell.\n",
            "\nYou can use the PHP function apc_clear_cache.\nCalling apc_clear_cache() will clear the system cache and calling apc_clear_cache('user') will clear the user cache.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "performance",
            "benchmarking",
            "microtime"
        ]
    },
    {
        "question_id": "1972259",
        "question": "\nI'm trying to install mysql-python in a virtualenv using pip on windows.  At first, I was getting the same error reported here, but the answer there worked for me too.  Now I'm getting this following error:\n_mysql.c(34) : Fatal error C1083: Cannot open include file: 'config-win.h': No such file or directory\n\nIf I symlink (Win7) to my regular (not the virtualenv's) python's site-packages/MySQLdb dir I get \nError loading MySQLdb module: No module named _mysql\n\nI'm rather at a loss here.  Any pointers?\n",
        "all_answers": [
            "\nUpdate for mysql 5.5 and config-win.h not visible issue\nIn 5.5 config-win. has actually moved to Connector separate folder in windows. i.e. smth like:\nC:\\Program Files\\MySQL\\Connector C 6.0.2\\include\nTo overcome the problem one need not only to download \"dev bits\" (which actually connects the connector) but also to modify mysqldb install scripts to add the include folder. I've done a quick dirty fix as that. \nsite.cfg:\n# Windows connector libs for MySQL.\nconnector = C:\\Program Files\\MySQL\\Connector C 6.0.2\n\nin setup_windows.py locate the line \ninclude_dirs = [ os.path.join(mysql_root, r'include') ]:\n\nand add:\ninclude_dirs = [ os.path.join(options['connector'], r'include') ]\n\nafter it.\nUgly but works until mysqldb authors will change the behaviour.\n\nAlmost forgot to mention. In the same manner one needs to add similar additional entry for libs:\nlibrary_dirs = [ os.path.join(options['connector'], r'lib\\opt') ]\n\ni.e. your setup_windows.py looks pretty much like:\n...\nlibrary_dirs = [ os.path.join(mysql_root, r'lib\\opt') ]\nlibrary_dirs = [ os.path.join(options['connector'], r'lib\\opt') ]\nlibraries = [ 'kernel32', 'advapi32', 'wsock32', client ]\ninclude_dirs = [ os.path.join(mysql_root, r'include') ]\ninclude_dirs = [ os.path.join(options['connector'], r'include') ]\nextra_compile_args = [ '/Zl' ]\n...\n\n",
            "\nTry ActivePython,\npypm -E C:\\myvirtualenv install mysql-python\n\n",
            "\nMost probably the answer is to install MySQL Developer Build and selecting \"C headers\\libs\" option during configuration. (as reported in this entry: Building MySQLdb for Python on Windows on rationalpie.wordpress.com)\nMaybe even better solution is to install a precompiled build: http://www.technicalbard.com/files/MySQL-python-1.2.2.win32-py2.6.exe\n",
            "\nInstalling dev bits for mysql got rid of the config-win.h error I was having, and threw another. Failed to load and parse the manifest. The system cannot find the file specified. I found the answer to my problem in this post: http://www.fuyun.org/2009/12/install-mysql-for-python-on-windows/.\nI copied the file 'C:\\Python26\\Lib\\distutils\\msvc9compiler.py` into my virtualenv, made the edit suggested in the above link, and things are working fine.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "windows",
            "virtualenv",
            "pip",
            "mysql-python"
        ]
    },
    {
        "question_id": "73129574",
        "question": "\nCannot update my app in Google Play since it says:\n\nThis release includes the com.google.android.gms.permission.AD_ID\npermission but your declaration on Play Console says your app doesn't\nuse advertising ID.\nYou must update your advertising ID declaration.\n\nFirst thing is that the app not using ads.\nThe library which is injecting the permission is -> jetified-play-services-ads-identifier-18.0.0 but i don't know where it is coming from.\nAlso to be sure that this permission(no matter what) is deleted, added in my app manifest:\n<uses-permission android:name=\"com.google.android.gms.permission.AD_ID\" tools:node=\"remove\" />\n\nBut it is still saying that my app cannot be updated because it is containing that permission. I have checked the manifest via APK analyzer just to be sure, and it doesn't have the permission in the manifest file(i don't know why it is still saying that the permission is there)...\nAlso updated the Advertising Setting on Play Store:\n\nBut still the same is happening :(\nUPDATE\nFound where this permissions are coming from and disabed those modules:\nimplementation (\"com.google.firebase:firebase-analytics-ktx:21.1.0\") {\n        exclude module: \"play-services-ads-identifier\"\n        exclude module: \"play-services-measurement\"\n        exclude module: \"play-services-measurement-sdk\"\n        exclude module: \"play-services-measurement-api\"\n    }\n\nAfter that change the merged manifest doesn't contains anymore that permission also tested via APK Analyzer too but unfortunately Google Play still says that the app contains the permissions (WEIRD)...\nAny help is appreciated :)\n",
        "all_answers": [
            "\nIf you use firebase-analytics you should answer the questions like the following:\ndoes your app use Ad ID?: Yes\nCollected: Yes\nShared: Yes\nProcessed ephemerally?: No\nRequired or Optional?: Optional(Given you implement consent/Opt-Out)\nNote: firebase analytics can NOT work without Identifying the unique user, and they use Ad ID to do this.\n",
            "\nThe same problem happened with me. The solution was as following:\n1-Firstly I have added this line to AndroidManifest.xml file:\n    <uses-permission\n    android:name=\"com.google.android.gms.permission.AD_ID\"\n    tools:node=\"remove\" />\n\n2-Secondly I have disabled the Firebase Analytics AD ID collection by adding this line in the AndroidManifest.xml inside the application tag:\n        <meta-data\n        android:name=\"google_analytics_adid_collection_enabled\"\n        android:value=\"false\" />\n\n3-Then I went to the Google play console App Content -> Advertising ID -> Choose Yes and mark the Analytics option and check Turn off release errors check box.\n4-After that I have rebuild the app, generated a new bundle and uploaded to the google play console but still when I submit it shows the same error then I have pressed Shift+F5 in chrome to reload the page without cache and then it worked and the error disappeared.\n",
            "\nAfter contacting Google Play support they replied and said that if you use analytics we need to choose YES on The AD_ID permission for an analytics use case on the Advertising ID section.\nYou should not remove permission manually or remove analytics sub-modules that contain AD_ID permission since it can break things...\nSo just need to choose YES even if the app is not using Ads.\n\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "android-studio",
            "google-play",
            "android-manifest",
            "google-advertising-id"
        ]
    },
    {
        "question_id": "9017521",
        "question": "\nI have found different articles about this exception but none of them was my case.\nHere is the source code:\nclass Program\n{\n\n    private static Mutex mutex;\n    private static bool mutexIsLocked = false;\n    static void Main(string[] args)\n    {\n\n        ICrmService crmService = \n            new ArmenianSoftware.Crm.Common.CrmServiceWrapper(GetCrmService(\"Armsoft\", \"crmserver\"));\n        //Lock mutex for concurrent access to workflow\n        mutex = new Mutex(true, \"ArmenianSoftware.Crm.Common.FilterCtiCallLogActivity\");\n        mutexIsLocked = true;\n\n        //Create object for updating filtered cti call log\n        ArmenianSoftware.Crm.Common.FilterCtiCallLog filterCtiCallLog =\n            new ArmenianSoftware.Crm.Common.FilterCtiCallLog(crmService);\n        //Bind events\n        filterCtiCallLog.CtiCallsRetrieved += new EventHandler<ArmenianSoftware.Crm.Common.CtiCallsRetrievedEventArgs>(filterCtiCallLog_CtiCallsRetrieved);\n\n        //Execute filter\n        try\n        {\n            filterCtiCallLog.CreateFilteredCtiCallLogSync();\n        }\n        catch (Exception ex)\n        {\n            throw ex;\n        }\n        finally\n        {\n            if (mutexIsLocked)\n            {\n                mutexIsLocked = false;\n                mutex.ReleaseMutex();\n            }\n        }\n    }\n\n    static void filterCtiCallLog_CtiCallsRetrieved(object sender,\n         ArmenianSoftware.Crm.Common.CtiCallsRetrievedEventArgs e)\n    {\n        tryasasas\n        {\n            if (mutexIsLocked)\n            {\n                mutexIsLocked = false;\n                mutex.ReleaseMutex();\n            }\n        }\n        catch (Exception ex)\n        {\n            throw ex;\n        }\n    }\n}\n\nfilterCtiCallLog.CreateFilteredCtiCallLogSync(); function executes requests to server, and raises some events, one of which is CtiCallsRetrieve event. And I need to release the mutex when this event is fired. But on calling the mutex.Release() function exception is thrown.  CreateFilteredCtiCallLogSync works synchronously. What is the problem?\n",
        "all_answers": [
            "\nKeeping a bool around that indicates that the mutex is owned is a grave mistake.  You are not making the bool thread-safe.  You got into this pickle because you are using the wrong synchronization object.  A mutex has thread-affinity, the owner of a mutex is a thread.  The thread that acquired it must also be the one that calls ReleaseMutex().  Which is why your code bombs.\nYou in all likelihood need an event here, use AutoResetEvent.  Create it in the main thread, call Set() in the worker, WaitOne() in the main thread to wait for the worker to complete its job.  And dispose it afterwards.  Also note that using a thread to perform a job and having your main thread wait for its completion is not productive.  You might as well have the main thread do the job.\nIf you are actually doing this to protect access to an object that's not thread-safe (it isn't clear) then use the lock statement.\n",
            "\nI only had this one once or twice, and in every case it came about by trying to release a mutex I didn't own.\nAre you sure the events are raised on the same thread the mutex was acquired on? \nAlthough you mention that filterCtiCallLog.CreateFilteredCtiCallLogSync() is a blocking call, perhaps  it spawns of worker threads that raise the event?\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            ".net",
            "multithreading",
            "mutex"
        ]
    },
    {
        "question_id": "194157",
        "question": "\nI'm using:\nFileInfo(\n    System.Environment.GetFolderPath(\n        System.Environment.SpecialFolder.ProgramFiles) \n    + @\"\\MyInstalledApp\"\n\nIn order to determine if a program is detected on a users machine (it's not ideal, but the program I'm looking for is a right old kludge of a MS-DOS application, and I couldn't think of another method).\nOn Windows XP and 32-bit versions of Windows Vista this works fine. However, on x64 Windows Vista the code returns the x64 Program Files folder, whereas the application is installed in Program Files x86. Is there a way to programatically return the path to Program Files x86 without hard wiring \"C:\\Program Files (x86)\"?\n",
        "all_answers": [
            "\nOn 64-bit JVM's you need the 64-bit SWT. Current versions can be downloaded here:\nhttp://archive.eclipse.org/eclipse/downloads/drops/R-3.6.1-201009090800/index.php#SWT\nNote the first two downloads, the first is for x32, the other for x64.\nNote: Even on 64bit Windows, if you use the 32bit JVM, you still need the 32bit SWT version!\n",
            "\nI faced the same problems a couple of weeks ago.  We develop an RCP application that must use 32bit SWT, but we work on 64bit machines.\nWhat we had to do was to change Eclipse's configurations so it pointed to a 32bit JVM.  We did it on Window -> Preferences -> Java -> Installed JRE's.  On this preference page, we changed all references from \"Program Files\" to \"Program Files (x86)\".\nI hope it helps you somehow.\n",
            "\nThe function below will return the x86 Program Files directory in all of these three Windows configurations:\n\n32 bit Windows\n32 bit program running on 64 bit Windows\n64 bit program running on 64 bit windows\n\n \nstatic string ProgramFilesx86()\n{\n    if( 8 == IntPtr.Size \n        || (!String.IsNullOrEmpty(Environment.GetEnvironmentVariable(\"PROCESSOR_ARCHITEW6432\"))))\n    {\n        return Environment.GetEnvironmentVariable(\"ProgramFiles(x86)\");\n    }\n\n    return Environment.GetEnvironmentVariable(\"ProgramFiles\");\n}\n\n",
            "\nOne way would be to look for the \"ProgramFiles(x86)\" environment variable:\nString x86folder = Environment.GetEnvironmentVariable(\"ProgramFiles(x86)\");\n\n",
            "\nFor the latest link to SWT library downloads:\nSWT project page\n",
            "\nNote, however, that the ProgramFiles(x86) environment variable is only available if your application is running 64-bit.\nIf your application is running 32-bit, you can just use the ProgramFiles environment variable whose value will actually be \"Program Files (x86)\".\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "windows",
            "file",
            "64-bit"
        ]
    },
    {
        "question_id": "34959038",
        "question": "\nI am stuck with this error no matter what directory I am in, and what I type after \"npm\" in cmd.exe. Here is the npm-debug.log: \n0 info it worked if it ends with ok\n1 verbose cli [ 'C:\\\\Program Files\\\\nodejs\\\\node.exe',\n1 verbose cli   'C:\\\\Program Files\\\\nodejs\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js' ]\n2 info using [email protected]\n3 info using [email protected]\n4 verbose stack Error: EISDIR: illegal operation on a directory, read\n4 verbose stack     at Error (native)\n5 verbose cwd C:\\Users\\me\n6 error Windows_NT 6.1.7601\n7 error argv \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Program Files\\\\nodejs\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\"\n8 error node v4.2.6\n9 error npm  v2.14.12\n10 error code EISDIR\n11 error errno -4068\n12 error syscall read\n13 error eisdir EISDIR: illegal operation on a directory, read\n13 error eisdir This is most likely not a problem with npm itself\n13 error eisdir and is related to npm not being able to find a package.json in\n13 error eisdir a package you are trying to install.\n14 verbose exit [ -4068, true ]\n\nI have tried and uninstalling/reinstalling nodejs multiple times, I even deleted npm and npm-cache folders in C:\\Users\\me\\AppData\\Roaming. I'm not sure what went wrong to cause this. One second it was working fine, and now I can't get rid of this error. The explanation in the log does not make sense, as it gives this error in any directory. I should note that running a command prompt as administrator does not give this error. I'm pulling my hair out this Friday evening trying to get this fixed, any help would be greatly appreciated!\n",
        "all_answers": [
            "\nDoing a complete uninstall, including removing paths, etc and reinstalling has solved the problem, very strange problem though.\nHow to completely remove node.js from Windows\n",
            "\nI ran into the same problem while I was changing some npm settings. I did a mistake with one npm config set command and this added a line referring to a non-existing directory to C:\\Users\\{User}\\.npmrc. After I deleted that line manually from .npmrc, the problem was gone.\n"
        ],
        "answer": "A2",
        "tags": [
            "node.js",
            "windows",
            "cmd",
            "npm",
            "file-permissions"
        ]
    },
    {
        "question_id": "4411213",
        "question": "\nI’ve got a Django model with two custom manager methods. Each returns a different subset of the model’s objects, based on a different property of the object.\nclass FeatureManager(models.Manager):\n\n    def without_test_cases(self):\n        return self.get_query_set().annotate(num_test_cases=models.Count('testcase_set')).filter(num_test_cases=0)\n\n    def standardised(self):\n        return self.get_query_set().annotate(standardised=Count('documentation_set__standard')).filter(standardised__gt=0)\n\n(Both testcase_set and documentation_set refer to ManyToManyFields on other models.)\nIs there any way to get a queryset, or just a list of objects, that’s the intersectiond of the querysets returned by each manager method?\n",
        "all_answers": [
            "\nIn most cases you can just write (exploiting the \"Set\" part of QuerySet) :\nintersection = Model.objects.filter(...) & Model.objects.filter(...)\n\nThis isn't very well documented, but should behave almost exactly like using AND conditions on conditions from both queries. Relevant code: https://github.com/django/django/blob/1.8c1/django/db/models/query.py#L203\n",
            "\nRefactor\nclass FeatureManager(models.Manager):\n\n    @staticmethod\n    def _test_cases_eq_0( qs ):\n       return qs.annotate( num_test_cases=models.Count('testcase_set') ).filter(num_test_cases=0)\n\n    @staticmethod\n    def _standardized_gt_0( qs ):\n        return qs.annotate( standardised=Count('documentation_set__standard') ).filter(standardised__gt=0)\n\n    def without_test_cases(self):\n        return self._test_cases_eq_0( self.get_query_set() )\n\n    def standardised(self):\n        return self._standardized_gt_0( self.get_query_set() )\n\n    def intersection( self ):\n        return self._test_cases_eq_0( self._standardized_gt_0( self.get_query_set() ) )\n\n",
            "\nOne way may be to use the python sets module and just do an intersection:\nmake a couple of query sets that overlap at id=5:\nIn [42]: first = Location.objects.filter(id__lt=6)\nIn [43]: last = Location.objects.filter(id__gt=4)\n\n\"import sets\" first (gets a deprecation warning... ummm... oh well). Now build and intersect them - we get one element in the set:\nIn [44]: sets.Set(first).intersection(sets.Set(last))\nOut[44]: Set([<Location: Location object>])\n\nNow get the id of the intersection elements to check it really is 5:\nIn [48]: [s.id for s in sets.Set(first).intersection(sets.Set(last))]\nOut[48]: [5]\n\nThis obviously hits the database twice and returns all the elements of the query set - better way would be to chain the filters on your managers and that should be able to do it in one DB hit and at the SQL level. I cant see a QuerySet.and/or(QuerySet) method.\n",
            "\nIf you want to do it in python, not in the database:\nintersection = set(queryset1) & set(queryset2)\n\nThe problems is that if you use different annotations in the queriesdue to the added annotations the objects might look different...\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django",
            "django-models"
        ]
    },
    {
        "question_id": "8507798",
        "question": "\nSo Rails 3.1 comes with a little-known handy \"rails g plugin new\" generator, which gives you a skeleton suitable for a rails gem plugin. [http://guides.rubyonrails.org/plugins.html#or-generate-a-gemified-plugin]\nOne of the useful things this does, is set things up conveniently for testing with Test::Unit. It gives you a basic dummy Rails app that your tests can run in the context of, to test 'engine' behavior that only functions in the copy of a Rails app. (it puts it in ./test/dummy).   But your tests are still in my_gem/test , the tests dont' live in the dummy app. And my_gem/test/test_helper.rb is there, written such that tests will be run in the context of the dummy app, booted over at ../dummy/config/environment. \nI describe this because I think a lot of people don't know about this new generator, which sets things up so nicely. \nBut my question is, has anyone figured out how to do this with rspec instead? I have tried to follow the same principles DIY to set things up like this for rspec in a rails plugin gem, but am running into various confusing roadblocks, and am hoping maybe someone else has already figured it out (or would be interested in figuring it out for the rest of us, heh). \n",
        "all_answers": [
            "\nCreate the plugin without test-unit and specify the path for the dummy application:\nrails plugin new foobar --skip-test-unit --dummy-path=spec/dummy\n\nAdd rspec-rails as a development dependency to the gemspec file (foobar.gemspec):\nGem::Specification.new do |s|\n  .\n  .\n  .\n  s.add_development_dependency \"rspec-rails\"\nend\n\nRun bundle install\nCreate a symlink from the dummy app to the plugin spec directory and run the Rspec install generator:\ncd spec/dummy\nln -s ../../spec\nrails generate rspec:install\ncd -\n\nNow edit spec/spec_helper.rb (or spec/rails_helper.rb in rails 4+, not sure about older versions) changing this line (line 3):\nrequire File.expand_path(\"../../config/environment\", __FILE__)\n\nTo this:\nrequire File.expand_path(\"../dummy/config/environment\", __FILE__)\n\nNow you can run Rspec from the root of your plugin and it will pick up specs from the dummy application as well.\nbundle exec rspec spec\n\nI wrote about this in more detail, showing how to also set up capybara, spork and guard in a rails plugin with a dummy application:\nhttps://web.archive.org/web/20130125091106/http://namick.tumblr.com/post/17663752365/how-to-create-a-gemified-plugin-with-rails-3-2-rspec\n",
            "\nJust run rails plugin new <gemname> and then add rspec as development_dependency to gemspec file, and install it rspec --init.\nNow move dummy sub folder from test to spec and add these to spec_helper:\nENV[\"RAILS_ENV\"] = \"test\"\n\nrequire File.expand_path(\"../dummy/config/environment.rb\",  __FILE__)\nrequire \"rails/test_help\"\nrequire '<gemname>'\n\nRails.backtrace_cleaner.remove_silencers!\n\nas they are in test_helper!\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "rspec",
            "rubygems",
            "ruby-on-rails-plugins",
            "rspec-rails"
        ]
    },
    {
        "question_id": "6275299",
        "question": "\nIn my application, there is a registration screen, where i do not want the user to be able to copy/paste text into the EditText field. I have set an onLongClickListener on each EditText so that the context menu showing copy/paste/inputmethod  and other options does not show up. So the user won't be able to copy/ paste into the Edit fields.\n OnLongClickListener mOnLongClickListener = new OnLongClickListener() {\n\n        @Override\n        public boolean onLongClick(View v) {\n            // prevent context menu from being popped up, so that user\n            // cannot copy/paste from/into any EditText fields.\n            return true;\n        }\n    };\n\nBut the problem arises if the user has enabled a third-party keyboard other than the Android default, which may have a button to copy/paste or which may show the same context menu. So how do i disable copy/paste in that scenario ?\nPlease let me know if there are other ways to copy/paste as well. (and possibly how to disable them)\nAny help would be appreciated.\n",
        "all_answers": [
            "\nI found that when you create an input filter to avoid entry of unwanted characters, pasting such characters into the edit text is having no effect. So this sort of solves my problem as well. \n",
            "\nSimilar to GnrlKnowledge, you can clear the Clipboard \nhttp://developer.android.com/reference/android/text/ClipboardManager.html\nIf you want, preserve the text in the Clipboard, and on onDestroy, you can set it again.\n",
            "\nRead the Clipboard, check against the input and the time the input is \"typed\". If the Clipboard has the same text and it is too fast, delete the pasted input.\n",
            "\nIf you are using API level 11 or above then you can stop copy,paste,cut and custom context menus from appearing by.\nedittext.setCustomSelectionActionModeCallback(new ActionMode.Callback() {\n\n            public boolean onPrepareActionMode(ActionMode mode, Menu menu) {\n                return false;\n            }\n\n            public void onDestroyActionMode(ActionMode mode) {                  \n            }\n\n            public boolean onCreateActionMode(ActionMode mode, Menu menu) {\n                return false;\n            }\n\n            public boolean onActionItemClicked(ActionMode mode, MenuItem item) {\n                return false;\n            }\n        });\n\nReturning false from onCreateActionMode(ActionMode, Menu) will prevent the action mode from being started(Select All, Cut, Copy and Paste actions).\n",
            "\nI am able to disable copy-and-paste functionality with the following:\ntextField.setCustomSelectionActionModeCallback(new ActionMode.Callback() {\n\n    public boolean onCreateActionMode(ActionMode actionMode, Menu menu) {\n        return false;\n    }\n\n    public boolean onPrepareActionMode(ActionMode actionMode, Menu menu) {\n        return false;\n    }\n\n    public boolean onActionItemClicked(ActionMode actionMode, MenuItem item) {\n        return false;\n    }\n\n    public void onDestroyActionMode(ActionMode actionMode) {\n    }\n});\n\ntextField.setLongClickable(false);\ntextField.setTextIsSelectable(false);\n\nHope it works for you ;-)\n"
        ],
        "answer": "A4",
        "tags": [
            "android-widget",
            "android-edittext",
            "android",
            "android-keypad"
        ]
    },
    {
        "question_id": "6147102",
        "question": "\nI would like to be able to do something like this:\nclass ThingIDs\n{\n    const Something = 1;\n    const AnotherThing = 2;\n}\n\n$thing = 'Something';\n$id = ThingIDs::$thing;\n\nThis doesn't work. Is there a straightforward way of doing something equivalent? Note that I'm stuck with the class; it's in a library I can't rewrite. I'm writing code that takes arguments on the command line, and I would really like it to take symbolic names instead of id numbers.\n",
        "all_answers": [
            "\nUse Reflection\n$r = new ReflectionClass('ThingIDs');\n$id = $r->getConstant($thing);\n\n",
            "\nUse the constant() function:\n$id = constant(\"ThingIDs::$thing\");\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "class-constants"
        ]
    },
    {
        "question_id": "3446538",
        "question": "\n\n\n\nNot a major problem but I was wondering if there is a cleaner way to do this. It would be good to avoid nesting my code with an unnecessary if statement. If $items is empty php throws an error.\n$items = array('a','b','c');\n\nif(!empty($items)) { // <-Remove this if statement\n  foreach($items as $item) {\n    print $item;\n  }\n}\n\nI could probably just use the '@' error suppressor, but that would be a bit hacky.\n",
        "all_answers": [
            "\nThere are a million ways to do this.\nThe first one would be to go ahead and run the array through foreach anyway, assuming you do have an array.\nIn other cases this is what you might need:\nforeach ((array) $items as $item) {\n    print $item;\n}\n\nNote: to all the people complaining about typecast, please note that the OP asked cleanest way to skip a foreach if array is empty (emphasis is mine). A value of true, false, numbers or strings is not considered empty.\nIn addition, this would work with objects implementing \\Traversable, whereas is_array wouldn't work.\n",
            "\nforeach((array)$items as $item) {}\n\n",
            "\nI wouldn't recommend suppressing the warning output. I would, however, recommend using is_array instead of !empty. If $items happens to be a nonzero scalar, then the foreach will still error out if you use !empty.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "coding-style"
        ]
    },
    {
        "question_id": "19088153",
        "question": "\n#include<stdio.h>\n#include<string.h>\n\nint main()\n{\n    char * p = \"abc\";\n    char * p1 = \"abc\";\n    printf(\"%d %d\", p, p1);\n}\n\nWhen I print the values of the two pointers, it is printing the same address. Why?\n",
        "all_answers": [
            "\nYour compiler has done something called \"string pooling\". You specified that you wanted two pointers, both pointing to the same string literal - so it only made one copy of the literal.\nTechnically: It should have complained at you for not making the pointers \"const\"\nconst char* p = \"abc\";\n\nThis is probably because you are using Visual Studio or you are using GCC without -Wall.\nIf you expressly want them to be stored twice in memory, try:\nchar s1[] = \"abc\";\nchar s2[] = \"abc\";\n\nHere you explicitly state that you want two c-string character arrays rather than two pointers to characters.\nCaveat: String pooling is a compiler/optimizer feature and not a facet of the language. As such different compilers under different environments will produce different behavior depending on things like optimization level, compiler flags and whether the strings are in different compilation units.\n",
            "\nbecause string \"abc\" itself a address in memory. when u write \"abc\" again it store same address \n",
            "\nString literals in the code are stored in a read-only data segment of the code. When you write down a string literal like \"abc\" it actually returns a 'const char*' and if you had all the compiler warnings on it would tell you that you are casting at that point. You are not allowed to alter those strings for the very reason you have pointed out in this question.\n",
            "\nWhen you create a string literal (\"abc\"), it is saved into a memory, which contains string literals, and then it's being reused if you refer to the same string literal, thus both pointers pointing to the same location, where the \"abc\" string literal is stored.\nI've learned this some time ago so I might not have explained it really clearly, sorry.\n",
            "\nWhether two different string literals with same content is placed in the same memory location or different memory locations is implementation-dependent. \nYou should always treat p and p1 as two different pointers (even though they have the same content) as they may or may not point to the same address. You shouldn't rely on compiler optimizations.\nC11 Standard, 6.4.5, String literals, semantics\n\nIt is unspecified whether these arrays are distinct provided their\n  elements have the appropriate values. If the program attempts to\n  modify such an array, the behavior is undefined.\n\n\nThe format for printing must be %p:\n  printf(\"%p %p\", (void*)p, (void*)p1);\n\nSee this answer for why.\n",
            "\nYour compiler seems to be quite clever, detecting that both the literals are the same. And as literals are constant the compiler decided to not store them twice.\nIt seems worth mentioning that this does not necessarily needs to be the case. Please see Blue Moon's answer on this.\n\nBtw: The printf() statement should look like this\nprintf(\"%p %p\", (void *) p, (void *) p1);\n\nas \"%p\" shall be used to print pointer values, and it is defined for pointer of type void * only.*1\n\nAlso I'd say the code misses a return statement, but the C standard seems to be in the process of being changed. Others might kindly clarify this.\n\n*1: Casting to void * here is not necessary for char * pointers, but for pointers to all other types.\n"
        ],
        "answer": "A5",
        "tags": [
            "c",
            "pointers",
            "literals"
        ]
    },
    {
        "question_id": "804045",
        "question": "\nI need to store a multi-dimensional associative array of data in a flat file for caching purposes. I might occasionally come across the need to convert it to JSON for use in my web app but the vast majority of the time I will be using the array directly in PHP.\nWould it be more efficient to store the array as JSON or as a PHP serialized array in this text file? I've looked around and it seems that in the newest versions of PHP (5.3), json_decode is actually faster than unserialize.\nI'm currently leaning towards storing the array as JSON as I feel its easier to read by a human if necessary, it can be used in both PHP and JavaScript with very little effort, and from what I've read, it might even be faster to decode (not sure about encoding, though).\nDoes anyone know of any pitfalls? Anyone have good benchmarks to show the performance benefits of either method?\n",
        "all_answers": [
            "\nJSON is simpler and faster than PHP's serialization format and should be used unless:\n\nYou're storing deeply nested arrays:\njson_decode(): \"This function will return false if the JSON encoded data is deeper than 127 elements.\"\nYou're storing objects that need to be unserialized as the correct class\nYou're interacting with old PHP versions that don't support json_decode\n\n",
            "\nDepends on your priorities.\nIf performance is your absolute driving characteristic, then by all means use the fastest one.  Just make sure you have a full understanding of the differences before you make a choice\n\nUnlike serialize() you need to add extra parameter to keep UTF-8 characters untouched: json_encode($array, JSON_UNESCAPED_UNICODE)  (otherwise it converts UTF-8 characters to Unicode escape sequences).\nJSON will have no memory of what the object's original class was (they are always restored as instances of stdClass).\nYou can't leverage __sleep() and __wakeup() with JSON\nBy default, only public properties are serialized with JSON. (in PHP>=5.4 you can implement JsonSerializable to change this behavior).\nJSON is more portable\n\nAnd there's probably a few other differences I can't think of at the moment.\nA simple speed test to compare the two\n<?php\n\nini_set('display_errors', 1);\nerror_reporting(E_ALL);\n\n// Make a big, honkin test array\n// You may need to adjust this depth to avoid memory limit errors\n$testArray = fillArray(0, 5);\n\n// Time json encoding\n$start = microtime(true);\njson_encode($testArray);\n$jsonTime = microtime(true) - $start;\necho \"JSON encoded in $jsonTime seconds\\n\";\n\n// Time serialization\n$start = microtime(true);\nserialize($testArray);\n$serializeTime = microtime(true) - $start;\necho \"PHP serialized in $serializeTime seconds\\n\";\n\n// Compare them\nif ($jsonTime < $serializeTime) {\n    printf(\"json_encode() was roughly %01.2f%% faster than serialize()\\n\", ($serializeTime / $jsonTime - 1) * 100);\n}\nelse if ($serializeTime < $jsonTime ) {\n    printf(\"serialize() was roughly %01.2f%% faster than json_encode()\\n\", ($jsonTime / $serializeTime - 1) * 100);\n} else {\n    echo \"Impossible!\\n\";\n}\n\nfunction fillArray( $depth, $max ) {\n    static $seed;\n    if (is_null($seed)) {\n        $seed = array('a', 2, 'c', 4, 'e', 6, 'g', 8, 'i', 10);\n    }\n    if ($depth < $max) {\n        $node = array();\n        foreach ($seed as $key) {\n            $node[$key] = fillArray($depth + 1, $max);\n        }\n        return $node;\n    }\n    return 'empty';\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "performance",
            "arrays",
            "json",
            "serialization"
        ]
    },
    {
        "question_id": "1090176",
        "question": "\nI have this little rake task: \nnamespace :db do \n  namespace :test do \n    task :reset do \n      ENV['RAILS_ENV'] = \"test\" \n      Rake::Task['db:drop'].invoke\n      Rake::Task['db:create'].invoke\n      Rake::Task['db:migrate'].invoke\n    end\n  end\nend\n\nNow, when I execute, it will ignore the RAILS_ENV I tried to hard-code. How do I make this task work as expected  \n",
        "all_answers": [
            "\nThe best way of course is to specify the environment from the command line when you run the rake task, but if for some reason that's not what you want to do, you can do this:\nENV[\"RAILS_ENV\"] = 'test'\nRAILS_ENV.replace('test') if defined?(RAILS_ENV)\n\nload \"#{RAILS_ROOT}/config/environment.rb\"\n\nAnd that should do the trick.\n",
            "\nFor this particular task, you only need to change the DB connection, so as Adam pointed out, you can do this:\nnamespace :db do \n  namespace :test do \n    task :reset do \n      ActiveRecord::Base.establish_connection('test')\n      Rake::Task['db:drop'].invoke\n      Rake::Task['db:create'].invoke\n      Rake::Task['db:migrate'].invoke\n      ActiveRecord::Base.establish_connection(ENV['RAILS_ENV'])  #Make sure you don't have side-effects!\n    end\n  end\nend\n\nIf your task is more complicated, and you need other aspects of ENV, you are safest spawning a new rake process:\nnamespace :db do \n  namespace :test do \n    task :reset do \n      system(\"rake db:drop RAILS_ENV=test\")\n      system(\"rake db:create RAILS_ENV=test\")\n      system(\"rake db:migrate RAILS_ENV=test\")\n    end\n  end\nend\n\nor\nnamespace :db do \n  namespace :test do \n    task :reset do \n      if (ENV['RAILS_ENV'] == \"test\")\n        Rake::Task['db:drop'].invoke\n        Rake::Task['db:create'].invoke\n        Rake::Task['db:migrate'].invoke\n      else\n        system(\"rake db:test:reset RAILS_ENV=test\")\n      end\n    end\n  end\nend\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "rake"
        ]
    },
    {
        "question_id": "18002227",
        "question": "\nAn extended Application class can declare global variables. Are there other reasons?\n",
        "all_answers": [
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nApplication class is the object that has the full lifecycle of your application. It is your highest layer as an application. example possible usages:\n\nYou can add what you need when the application is started by overriding onCreate in the Application class.\n\nstore global variables that jump from Activity to Activity. Like Asynctask.\netc\n\n\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nThe Application class is a singleton that you can access from any activity or anywhere else you have a Context object.\nYou also get a little bit of lifecycle.  \nYou could use the Application's onCreate method to instantiate expensive, but frequently used objects like an analytics helper.  Then you can access and use those objects everywhere.\n",
            "\nOffhand, I can't think of a real scenario in which extending Application is either preferable to another approach or necessary to accomplish something. If you have an expensive, frequently used object you can initialize it in an IntentService when you detect that the object isn't currently present. Application itself runs on the UI thread, while IntentService runs on its own thread.\nI prefer to pass data from Activity to Activity with explicit Intents, or use SharedPreferences. There are also ways to pass data from a Fragment to its parent Activity using interfaces.\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n"
        ],
        "answer": "A7",
        "tags": [
            "android",
            "android-application-class"
        ]
    },
    {
        "question_id": "1520234",
        "question": "\nHow can I check which version of NumPy I'm using?\n",
        "all_answers": [
            "\nYou may use numpy.append()... \nimport numpy\n\nB = numpy.array([3])\nA = numpy.array([1, 2, 2])\nB = numpy.append( B , A )\n\nprint B\n\n> [3 1 2 2]\n\nThis will not create two separate arrays but will append two arrays into a single dimensional array.\n",
            "\nimport numpy\nnumpy.version.version\n\n",
            "\n>> import numpy\n>> print numpy.__version__\n\n",
            "\nIn [1]: import numpy as np\n\nIn [2]: a = np.array([[1, 2, 3], [4, 5, 6]])\n\nIn [3]: b = np.array([[9, 8, 7], [6, 5, 4]])\n\nIn [4]: np.concatenate((a, b))\nOut[4]: \narray([[1, 2, 3],\n       [4, 5, 6],\n       [9, 8, 7],\n       [6, 5, 4]])\n\nor this:\nIn [1]: a = np.array([1, 2, 3])\n\nIn [2]: b = np.array([4, 5, 6])\n\nIn [3]: np.vstack((a, b))\nOut[3]: \narray([[1, 2, 3],\n       [4, 5, 6]])\n\n",
            "\nWell, the error message says it all:  NumPy arrays do not have an append() method.  There's a free function numpy.append() however:\nnumpy.append(M, a)\n\nThis will create a new array instead of mutating M in place.  Note that using numpy.append() involves copying both arrays.  You will get better performing code if you use fixed-sized NumPy arrays.\n",
            "\nSven said it all, just be very cautious because of automatic type adjustments when append is called.\nIn [2]: import numpy as np\n\nIn [3]: a = np.array([1,2,3])\n\nIn [4]: b = np.array([1.,2.,3.])\n\nIn [5]: c = np.array(['a','b','c'])\n\nIn [6]: np.append(a,b)\nOut[6]: array([ 1.,  2.,  3.,  1.,  2.,  3.])\n\nIn [7]: a.dtype\nOut[7]: dtype('int64')\n\nIn [8]: np.append(a,c)\nOut[8]: \narray(['1', '2', '3', 'a', 'b', 'c'], \n      dtype='|S1')\n\nAs you see based on the contents the dtype went from int64 to float32, and then to S1\n",
            "\nI found this link while looking for something slightly different, how to start appending array objects to an empty numpy array, but tried all the solutions on this page to no avail.\nThen I found this question and answer: How to add a new row to an empty numpy array\nThe gist here:\n\nThe way to \"start\" the array that you want is:\narr = np.empty((0,3), int)\n\nThen you can use concatenate to add rows like so:\narr = np.concatenate( ( arr, [[x, y, z]] ) , axis=0)\nSee also https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "numpy",
            "version"
        ]
    },
    {
        "question_id": "14678948",
        "question": "\nI'd like to do something like printf(\"?\", count, char) to repeat a character count times.\nWhat is the right format-string to accomplish this?\nEDIT: Yes, it is obvious that I could call printf() in a loop, but that is just what I wanted to avoid.\n",
        "all_answers": [
            "\nprintf doesn't do that -- and printf is overkill for printing a single character.\nchar c = '*';\nint count = 42;\nfor (i = 0; i < count; i ++) {\n    putchar(c);\n}\n\nDon't worry about this being inefficient; putchar() buffers its output, so it won't perform a physical output operation for each character unless it needs to.\n",
            "\nYou can use GCC's nested functions to simulate lambda expressions, in fact, I have a macro to do it for me:\n#define lambda(return_type, function_body) \\\n  ({ \\\n    return_type anon_func_name_ function_body \\\n    anon_func_name_; \\\n  })\n\nUse like this:\nint (*max)(int, int) = lambda (int, (int x, int y) { return x > y ? x : y; });\n\n",
            "\nFFCALL lets you build closures in C -- callback = alloc_callback(&function, data) returns a function pointer such that callback(arg1, ...) is equivalent to calling function(data, arg1, ...).  You will have to handle garbage collection manually, though.\nRelatedly, blocks have been added to Apple's fork of GCC; they're not function pointers, but they let you pass around lambdas while avoiding the need to build and free storage for captured variables by hand (effectively, some copying and reference counting happens, hidden behind some syntactic sugar and runtime libraries).\n",
            "\nFunctional programming is not about lambdas, it is all about pure functions.  So the following broadly promote functional style:\n\nOnly use function arguments, do not use global state.\nMinimise side effects i.e. printf, or any IO.  Return data describing IO which can be executed instead of causing the side effects directly in all functions.  \n\nThis can be achieved in plain c, no need for magic.\n",
            "\nThere is no such thing. You'll have to either write a loop using printf or puts, or write a function that copies the string count times into a new string. \n",
            "\nYou can use the following technique:\nprintf(\"%.*s\", 5, \"=================\");\n\nThis will print \"=====\"\n\nIt works for me on Visual Studio, no reason it shouldn't work on all C compilers.\n",
            "\nHartel & Muller's book, Functional C, can nowadays (2012-01-02) be found at: http://eprints.eemcs.utwente.nl/1077/ (there is a link to PDF version).\n"
        ],
        "answer": "A6",
        "tags": [
            "c",
            "printf"
        ]
    },
    {
        "question_id": "1094984",
        "question": "\nAssuming that I have a typedef declared in my .h file as such:\ntypedef enum {\n  JSON,\n  XML,\n  Atom,\n  RSS\n} FormatType;\n\nI would like to build a function that converts the numeric value of the typedef to a string.  For example, if the message [self toString:JSON] was sent; it would return 'JSON'.\nThe function would look something like this:\n-(NSString *) toString:(FormatType)formatType {\n  //need help here\n  return [];\n}\n\nIncidentally, if I try this syntax \n[self toString:FormatType.JSON];\n\nto pass the typedef value to the method, I get an error.  What am I missing?\n",
        "all_answers": [
            "\nYou can't do it easily.  In C and Objective-C, enums are really just glorified integer constants.  You'll have to generate a table of names yourself (or with some preprocessor abuse).  For example:\n// In a header file\ntypedef enum FormatType {\n    JSON,\n    XML,\n    Atom,\n    RSS\n} FormatType;\n\nextern NSString * const FormatType_toString[];\n\n// In a source file\n// initialize arrays with explicit indices to make sure \n// the string match the enums properly\nNSString * const FormatType_toString[] = {\n    [JSON] = @\"JSON\",\n    [XML] = @\"XML\",\n    [Atom] = @\"Atom\",\n    [RSS] = @\"RSS\"\n};\n...\n// To convert enum to string:\nNSString *str = FormatType_toString[theEnumValue];\n\nThe danger of this approach is that if you ever change the enum, you have to remember to change the array of names.  You can solve this problem with some preprocessor abuse, but it's tricky and ugly.\nAlso note that this assumes you have a valid enum constant.  If you have an integer value from an untrusted source, you additionally need to do a check that your constant is valid, e.g. by including a \"past max\" value in your enum, or by checking if it's less than the array length, sizeof(FormatType_toString) / sizeof(FormatType_toString[0]).\n",
            "\nThis is really a C question, not specific to Objective-C (which is a superset of the C language). Enums in C are represented as integers. So you need to write a function that returns a string given an enum value. There are many ways to do this. An array of strings such that the enum value can be used as an index into the array or a map structure (e.g. an NSDictionary) that maps an enum value to a string work, but I find that these approaches are not as clear as a function that makes the conversion explicit (and the array approach, although the classic C way is dangerous if your enum values are not continguous from 0). Something like this would work:\n- (NSString*)formatTypeToString:(FormatType)formatType {\n    NSString *result = nil;\n\n    switch(formatType) {\n        case JSON:\n            result = @\"JSON\";\n            break;\n        case XML:\n            result = @\"XML\";\n            break;\n        case Atom:\n            result = @\"Atom\";\n            break;\n        case RSS:\n            result = @\"RSS\";\n            break;\n        default:\n            [NSException raise:NSGenericException format:@\"Unexpected FormatType.\"];\n    }\n\n    return result;\n}\n\nYour related question about the correct syntax for an enum value is that you use just the value (e.g. JSON), not the FormatType.JSON sytax. FormatType is a type and the enum values (e.g. JSON, XML, etc.) are values that you can assign to that type.\n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "objective-c",
            "enums",
            "typedef"
        ]
    },
    {
        "question_id": "7859336",
        "question": "\nIn the styles.css, I am using media queries, both of which use a variation of:\n/*--[ Normal CSS styles ]----------------------------------*/\n\n@media only screen and (max-width: 767px) {\n\n    /*--[ Mobile styles go here]---------------------------*/\n}\n\nThe sites resize to the layout I want in a regular browser (Safari, Firefox) when I shrink the window, however, the mobile layout isn't shown at all on a phone. Instead, I just see the default CSS.\nCan anyone point me in the right direction?\n",
        "all_answers": [
            "\nI use a few methods depending.\nIn the same stylesheet i use: @media (max-width: 450px), or for separate make sure you have the link in the header correctly. I had a look at your fixmeup and you have a confusing array of links to css. It acts as you say also on HTC desire S.\n",
            "\nAll three of these were helpful tips, but it looks like I needed to add a meta tag:\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\" />\n\nNow it seems to work in both Android (2.2) and iPhone all right...\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nI suspect the keyword only may be the issue here. I have no issues using media queries like this:\n@media screen and (max-width: 480px) { }\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n"
        ],
        "answer": "A2",
        "tags": [
            "html",
            "css",
            "media-queries",
            "mobile-website"
        ]
    },
    {
        "question_id": "8906527",
        "question": "\nIn Rails MVC, can you call a controller's method from a view (as a method could be called call from a helper)? If yes, how?\n",
        "all_answers": [
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nYou possibly want to declare your method as a \"helper_method\", or alternatively move it to a helper.\nWhat do helper and helper_method do?\n",
            "\nHaven't ever tried this, but calling public methods is similar to:\n@controller.public_method\n\nand private methods:\n@controller.send(\"private_method\", args)\n\nSee more details here\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nHere is the answer:\nclass MyController < ApplicationController\n  def my_method\n    # Lots of stuff\n  end\n  helper_method :my_method\nend\n\nThen, in your view, you can reference it in ERB exactly how you expect with <% or <%=:\n<% my_method %>\n\n"
        ],
        "answer": "A6",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "ruby-on-rails-3",
            "ruby-on-rails-3.1"
        ]
    },
    {
        "question_id": "3176609",
        "question": "\nWhat is the best way to calculate the total number of seconds between two dates?  So far, I've tried something along the lines of: \n$delta   = $date->diff(new DateTime('now'));\n$seconds = $delta->days * 60 * 60 * 24;\n\nHowever, the days property of the DateInterval object seems to be broken in the current PHP5.3 build (at least on Windows, it always returns the same 6015 value).  I also attempted to do it in a way which would fail to preserve number of days in each month (rounds to 30), leap years, etc:\n$seconds = ($delta->s)\n         + ($delta->i * 60)\n         + ($delta->h * 60 * 60)\n         + ($delta->d * 60 * 60 * 24)\n         + ($delta->m * 60 * 60 * 24 * 30)\n         + ($delta->y * 60 * 60 * 24 * 365);\n\nBut I'm really not happy with using this half-assed solution.  \n",
        "all_answers": [
            "\nYou could do it like this:\n$currentTime = time();\n$timeInPast = strtotime(\"2009-01-01 00:00:00\");\n\n$differenceInSeconds = $currentTime - $timeInPast;\n\ntime() returns the current time in seconds since the epoch time (1970-01-01T00:00:00), and strtotime does the same, but based on a specific date/time you give.\n",
            "\nCould you not compare the time stamps instead? \n$now = new DateTime('now');\n$diff = $date->getTimestamp() - $now->getTimestamp()\n\n",
            "\n\nThis method works on both Windows and Unix and is time-zone aware, which is probably what you want if you work with dates.\nIf you don't care about timezone, or want to use the time zone your server uses:\n$d = DateTime::createFromFormat('d-m-Y H:i:s', '22-09-2008 00:00:00');\nif ($d === false) {\n    die(\"Incorrect date string\");\n} else {\n    echo $d->getTimestamp();\n}\n\n1222093324 (This will differ depending on your server time zone...)\n\nIf you want to specify in which time zone, here EST. (Same as New York.)\n$d = DateTime::createFromFormat(\n    'd-m-Y H:i:s',\n    '22-09-2008 00:00:00',\n    new DateTimeZone('EST')\n);\n\nif ($d === false) {\n    die(\"Incorrect date string\");\n} else {\n    echo $d->getTimestamp();\n}\n\n1222093305\n\nOr if you want to use UTC. (Same as \"GMT\".)\n$d = DateTime::createFromFormat(\n    'd-m-Y H:i:s',\n    '22-09-2008 00:00:00',\n    new DateTimeZone('UTC')\n);\n\nif ($d === false) {\n    die(\"Incorrect date string\");\n} else {\n    echo $d->getTimestamp();\n}\n\n1222093289\n\nRegardless, it's always a good starting point to be strict when parsing strings into structured data. It can save awkward debugging in the future. Therefore I recommend to always specify date format.\n",
            "\nThere is also strptime() which expects exactly one format:\n$a = strptime('22-09-2008', '%d-%m-%Y');\n$timestamp = mktime(0, 0, 0, $a['tm_mon']+1, $a['tm_mday'], $a['tm_year']+1900);\n\nWarnings:\n\nThis function is not implemented on Windows\nThis function has been DEPRECATED as of PHP 8.1.0. Relying on this function is highly discouraged.\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "datetime",
            "date"
        ]
    },
    {
        "question_id": "12497940",
        "question": "\nJust curious, as it doesn't immediately seem possible, but is there a sneaky way to leverage the new iOS 6 UIRefreshControl class without using a UITableViewController subclass?\nI often use a UIViewController with a UITableView subview and conform to UITableViewDataSource and UITableViewDelegate rather than using a UITableViewController outright.\n",
        "all_answers": [
            "\nOn a hunch, and based on DrummerB's inspiration, I tried simply adding a UIRefreshControl instance as a subview to my UITableView. And it magically just works!\nUIRefreshControl *refreshControl = [[UIRefreshControl alloc] init];\n[refreshControl addTarget:self action:@selector(handleRefresh:) forControlEvents:UIControlEventValueChanged];\n[self.myTableView addSubview:refreshControl];\n\nThis adds a UIRefreshControl above your table view and works as expected without having to use a UITableViewController :)\n\nEDIT: This above still works but as a few have pointed out, there is a slight \"stutter\" when adding the UIRefreshControl in this manner. A solution to that is to instantiate a UITableViewController, and then setting your UIRefreshControl and UITableView to that, i.e.:\nUITableViewController *tableViewController = [[UITableViewController alloc] init];\ntableViewController.tableView = self.myTableView;\n\nself.refreshControl = [[UIRefreshControl alloc] init];\n[self.refreshControl addTarget:self action:@selector(getConnections) forControlEvents:UIControlEventValueChanged];\ntableViewController.refreshControl = self.refreshControl;\n\n",
            "\nHere are two one-line macros that I use:\n#define TICK   NSDate *startTime = [NSDate date]\n#define TOCK   NSLog(@\"Time: %f\", -[startTime timeIntervalSinceNow])\n\nUse it like this:\nTICK;\n\n/* ... Do Some Work Here ... */\n\nTOCK;\n\n",
            "\nWell UIRefreshControl is a UIView subclass, so you can use it on it's own. I'm not sure though how it renders itself. The rendering could simply depend on the frame, but it also could rely on a UIScrollView or the UITableViewController.\nEither way, it's going to be more of a hack than an elegant solution. I recommend you look into one of the available 3rd party clones or write your own.\nODRefreshControl\n\nSlimeRefresh\n\n",
            "\nNSDate *methodStart = [NSDate date];\n\n/* ... Do whatever you need to do ... */\n\nNSDate *methodFinish = [NSDate date];\nNSTimeInterval executionTime = [methodFinish timeIntervalSinceDate:methodStart];\nNSLog(@\"executionTime = %f\", executionTime);\n\nSwift:\nlet methodStart = NSDate()\n\n/* ... Do whatever you need to do ... */\n\nlet methodFinish = NSDate()\nlet executionTime = methodFinish.timeIntervalSinceDate(methodStart)\nprint(\"Execution time: \\(executionTime)\")\n\nSwift3:\nlet methodStart = Date()\n\n/* ... Do whatever you need to do ... */\n\nlet methodFinish = Date()\nlet executionTime = methodFinish.timeIntervalSince(methodStart)\nprint(\"Execution time: \\(executionTime)\")\n\nEasy to use and has sub-millisecond precision.\n"
        ],
        "answer": "A1",
        "tags": [
            "objective-c",
            "ios",
            "uitableview",
            "ios6",
            "uirefreshcontrol"
        ]
    },
    {
        "question_id": "39575398",
        "question": "\nCan someone briefly explain to me the difference in use between the methods uniq and distinct?\nI've seen both used in similar context, but the difference isnt quite clear to me.\n",
        "all_answers": [
            "\nRails queries acts like arrays, thus .uniq produces the same result as .distinct, but\n\n.distinct is sql query method\n.uniq is array method\n\nNote: In Rails 5+ Relation#uniq is deprecated and recommended to use Relation#distinct instead.\nSee http://edgeguides.rubyonrails.org/5_0_release_notes.html#active-record-deprecations\nHint:\nUsing .includes before calling .uniq/.distinct can slow or speed up your app, because\n\nuniq won't spawn additional sql query\ndistinct will do\n\nBut both results will be the same\nExample:\nusers = User.includes(:posts)\nputs users\n# First sql query for includes\n\nusers.uniq\n# No sql query! (here you speed up you app)\nusers.distinct\n# Second distinct sql query! (here you slow down your app)\n\nThis can be useful to make performant application\nHint:\nSame works for\n\n.size vs .count;\npresent? vs .exists?\nmap vs pluck\n\n",
            "\nFrom the documentation:\n\nuniq(value = true)\nAlias for ActiveRecord::QueryMethods#distinct\n\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nIts not exactly answer your question, but what I know is:\nIf we consider ActiveRecord context then uniq is just an alias for distinct. And both work as removing duplicates on query result set(which you can say up to one level).\nAnd at array context uniq is so powerful that it removes duplicates even if the elements are nested. for example\narr = [[\"first\"], [\"second\"], [\"first\"]]\n\nand if we do\narr.uniq\n\nanswer will be : [[\"first\"], [\"second\"]]\nSo even if elements are blocks it will go in deep and removes duplicates.\nHope it helps you in some ways.\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "activerecord"
        ]
    },
    {
        "question_id": "686353",
        "question": "\nHow do I generate random floats in C++?\nI thought I could take the integer rand and divide it by something, would that be adequate enough?\n",
        "all_answers": [
            "\nTake a look at Boost.Random. You could do something like this:\nfloat gen_random_float(float min, float max)\n{\n    boost::mt19937 rng;\n    boost::uniform_real<float> u(min, max);\n    boost::variate_generator<boost::mt19937&, boost::uniform_real<float> > gen(rng, u);\n    return gen();\n}\n\nPlay around, you might do better passing the same mt19937 object around instead of constructing a new one every time, but hopefully you get the idea.\n",
            "\nrand() can be used to generate pseudo-random numbers in C++.  In combination with RAND_MAX and a little math, you can generate random numbers in any arbitrary interval you choose.  This is sufficient for learning purposes and toy programs.  If you need truly random numbers with normal distribution, you'll need to employ a more advanced method.\n\nThis will generate a number from 0.0 to 1.0, inclusive.\nfloat r = static_cast <float> (rand()) / static_cast <float> (RAND_MAX);\n\nThis will generate a number from 0.0 to some arbitrary float, X:\nfloat r2 = static_cast <float> (rand()) / (static_cast <float> (RAND_MAX/X));\n\nThis will generate a number from some arbitrary LO to some arbitrary HI:\nfloat r3 = LO + static_cast <float> (rand()) /( static_cast <float> (RAND_MAX/(HI-LO)));\n\n\nNote that the rand() function will often not be sufficient if you need truly random numbers.\n\nBefore calling rand(), you must first \"seed\" the random number generator by calling srand().  This should be done once during your program's run -- not once every time you call rand().  This is often done like this:\nsrand (static_cast <unsigned> (time(0)));\n\nIn order to call rand or srand you must #include <cstdlib>.\nIn order to call time, you must #include <ctime>.\n"
        ],
        "answer": "A2",
        "tags": [
            "c++",
            "random",
            "floating-point"
        ]
    },
    {
        "question_id": "3838288",
        "question": "\nWhat is a good way to assert that two arrays of objects are equal, when the order of the elements in the array is unimportant, or even subject to change?\n",
        "all_answers": [
            "\nFor those of you working with symfony (>= 2.8): Symfony's PHPUnit Bridge includes a ClockMock feature that overrides the built-in methods time, microtime, sleep and usleep.\nSee: http://symfony.com/doc/2.8/components/phpunit_bridge.html#clock-mocking\n",
            "\nIf the array is sortable, I would sort them both before checking equality.  If not, I would convert them to sets of some sort and compare those.\n",
            "\nCarbon::setTestNow(Carbon $time = null) makes any call to Carbon::now() or new Carbon('now') return the same time.\nhttps://medium.com/@stefanledin/mock-date-and-time-with-carbon-8a9f72cb843d\nExample:\n    public function testSomething()\n    {\n        $now = Carbon::now();\n        // Mock Carbon::now() / new Carbon('now') to always return the same time\n        Carbon::setTestNow($now);\n\n        // Do the time sensitive test:\n        $this->retroEncabulator('prefabulate')\n            ->assertJsonFragment(['whenDidThisHappen' => $now->timestamp])\n\n        // Release the Carbon::now() mock\n        Carbon::setTestNow();\n    }\n\nThe $this->retroEncabulator() function needs to use Carbon::now() or new Carbon('now') internally of course.\n",
            "\nI recently came up with another solution that is great if you are using PHP 5.3 namespaces. You can implement a new time() function inside your current namespace and create a shared resource where you set the return value in your tests. Then any unqualified call to time() will use your new function.\nFor further reading I described it in detail in my blog\n",
            "\nYou can mock time for test using Clock from ouzo-goodies. (Disclaimer: I wrote this library.)\nIn code use simply:\n$time = Clock::now();\n\nThen in tests:\nClock::freeze('2014-01-07 12:34');\n$result = Class::getCurrDate();\n$this->assertEquals('2014-01-07', $result);\n\n",
            "\nThe cleanest way to do this would be to extend phpunit with a new assertion method. But here's an idea for a simpler way for now. Untested code, please verify:\nSomewhere in your app:\n /**\n * Determine if two associative arrays are similar\n *\n * Both arrays must have the same indexes with identical values\n * without respect to key ordering \n * \n * @param array $a\n * @param array $b\n * @return bool\n */\nfunction arrays_are_similar($a, $b) {\n  // if the indexes don't match, return immediately\n  if (count(array_diff_assoc($a, $b))) {\n    return false;\n  }\n  // we know that the indexes, but maybe not values, match.\n  // compare the values between the two arrays\n  foreach($a as $k => $v) {\n    if ($v !== $b[$k]) {\n      return false;\n    }\n  }\n  // we have identical indexes, and no unequal values\n  return true;\n}\n\nIn your test:\n$this->assertTrue(arrays_are_similar($foo, $bar));\n\n"
        ],
        "answer": "A6",
        "tags": [
            "php",
            "unit-testing",
            "phpunit",
            "assert"
        ]
    },
    {
        "question_id": "403671",
        "question": "\nSo I've been seeing people using .build, .create, and .create! within their controllers more and more lately. What's the difference from just using .new and passing the param'd object and then .save? Are there pros and cons? Does using these other methods offer benefits?\n",
        "all_answers": [
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nThere are a couple differences, but they're not big:\n\n.create is equivalent to .new followed by .save. It's just more succinct.\n.create! is equivalent to .new followed by .save! (throws an error if saving fails). It's also just a wee bit shorter\nI think .build is mostly an alias for .new.  It works one way in Rails 3 and another way in Rails < 3.x\n\nThe most important part, however, is that these methods can be called through an association (has_many, etc.) to automatically link the two models.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\n#create is shorter version of new and save.\n#create! is throwing exception if validation was not positive.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails"
        ]
    },
    {
        "question_id": "1710476",
        "question": "\nIs it possible in Hibernate to print generated SQL queries with real values instead of question marks?\nHow would you suggest to print queries with real values if it is not possible with Hibernate API?\n",
        "all_answers": [
            "\n\nI am deploying my web application in Jboss AS. Should I use JPA to access the stored procedure or CallableStatement. Any advantage of using JPA in this case.\n\nIt is not really supported by JPA but it's doable. Still I wouldn't go this way:\n\nusing JPA just to map the result of a stored procedure call in some beans is really overkill,\nespecially given that JPA is not really appropriate to call stored procedure (the syntax will be pretty verbose).\n\nI would thus rather consider using Spring support for JDBC data access, or a data mapper like MyBatis or, given the simplicity of your application, raw JDBC and CallableStatement. Actually, JDBC would probably be my choice. Here is a basic kickoff example:\nCallableStatement cstmt = con.prepareCall(\"{call getEmployeeDetails(?, ?)}\");\ncstmt.setInt(\"employeeId\", 123);\ncstmt.setInt(\"companyId\", 456);\nResultSet rs = cstmt.executeQuery();\n\nReference\n\nJDBC documentation: Java SE 6\n\n",
            "\nYou need to enable logging for the the following categories:\n\norg.hibernate.SQL   - set to debug to log all SQL DML statements as they are executed\norg.hibernate.type - set to trace to log all JDBC parameters\n\nSo a log4j configuration could look like:\n# logs the SQL statements\nlog4j.logger.org.hibernate.SQL=debug \n\n# Logs the JDBC parameters passed to a query\nlog4j.logger.org.hibernate.type=trace \n\nThe first is equivalent to hibernate.show_sql=true legacy property, the second prints the bound parameters among other things.\nAnother solution (non hibernate based) would be to use a JDBC proxy driver like P6Spy.\n",
            "\nJPA 2.1 now support Stored Procedure, read the Java doc here.\nExample:\nStoredProcedureQuery storedProcedure = em.createStoredProcedureQuery(\"sales_tax\");\n// set parameters\nstoredProcedure.registerStoredProcedureParameter(\"subtotal\", Double.class, ParameterMode.IN);\nstoredProcedure.registerStoredProcedureParameter(\"tax\", Double.class, ParameterMode.OUT);\nstoredProcedure.setParameter(\"subtotal\", 1f);\n// execute SP\nstoredProcedure.execute();\n// get result\nDouble tax = (Double)storedProcedure.getOutputParameterValue(\"tax\");\n\nSee detailed example here.\n",
            "\nTurn on the org.hibernate.type logger to see how the actual parameters are bind to the question marks.\n"
        ],
        "answer": "A2",
        "tags": [
            "java",
            "sql",
            "hibernate",
            "orm"
        ]
    },
    {
        "question_id": "112055",
        "question": "\nI'm looking at a batch file which defines the following variables:\nset _SCRIPT_DRIVE=%~d0\nset _SCRIPT_PATH=%~p0\n\n\nWhat do %~d0 or %~p0 actually mean?\nIs there a set of well-known values for things like current directory, drive, parameters to a script?\nAre there any other similar shortcuts I could use?\n\n",
        "all_answers": [
            "\nThey are enhanced variable substitutions. They modify the %N variables used in batch files. Quite useful if you're into batch programming in Windows.\n%~I         - expands %I removing any surrounding quotes (\"\")\n%~fI        - expands %I to a fully qualified path name\n%~dI        - expands %I to a drive letter only\n%~pI        - expands %I to a path only\n%~nI        - expands %I to a file name only\n%~xI        - expands %I to a file extension only\n%~sI        - expanded path contains short names only\n%~aI        - expands %I to file attributes of file\n%~tI        - expands %I to date/time of file\n%~zI        - expands %I to size of file\n%~$PATH:I   - searches the directories listed in the PATH\n               environment variable and expands %I to the\n               fully qualified name of the first one found.\n               If the environment variable name is not\n               defined or the file is not found by the\n               search, then this modifier expands to the\n               empty string\n\nYou can find the above by running FOR /?.\n",
            "\n%~d0 gives you the drive letter of argument 0 (the script name), %~p0 the path.\n",
            "\nThe magic variables %n contains the arguments used to invoke the file: %0 is the path to the bat-file itself, %1 is the first argument after, %2 is the second and so on.\nSince the arguments are often file paths, there is some additional syntax to extract parts of the path. ~d is drive, ~p is the path (without drive), ~n is the file name. They can be combined so ~dp is drive+path.\n%~dp0 is therefore pretty useful in a bat: it is the folder in which the executing bat file resides.\nYou can also get other kinds of meta info about the file: ~t is the timestamp, ~z is the size. \nLook here for a reference for all command line commands. The tilde-magic codes are described under for.\n",
            "\nFrom Filename parsing in batch file and more idioms - Real's How-to:\nThe path (without drive) where the script is : ~p0\nThe drive where the script is : ~d0 \n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "batch-file"
        ]
    },
    {
        "question_id": "224602",
        "question": "\nGiven this HTML:\n<div>foo</div><div>bar</div><div>baz</div>\n\nHow do you make them display inline like this:\n\nfoo bar baz\n\nnot like this:\n\nfoo\n  bar\n  baz  \n\n",
        "all_answers": [
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nThat's something else then:\n\n\ndiv.inline { float:left; }\r\n.clearBoth { clear:both; }\n<div class=\"inline\">1<br />2<br />3</div>\r\n<div class=\"inline\">1<br />2<br />3</div>\r\n<div class=\"inline\">1<br />2<br />3</div>\r\n<br class=\"clearBoth\" /><!-- you may or may not need this -->\n\n\n\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\n<style type=\"text/css\">\ndiv.inline { display:inline; }\n</style>\n<div class=\"inline\">a</div>\n<div class=\"inline\">b</div>\n<div class=\"inline\">c</div>\n\n",
            "\nTry writing it like this:\n\n\ndiv { border: 1px solid #CCC; }\n    <div style=\"display: inline\">a</div>\r\n    <div style=\"display: inline\">b</div>\r\n    <div style=\"display: inline\">c</div>\n\n\n\n"
        ],
        "answer": "A3",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "19521146",
        "question": "\nI have a table of users in sql and they each have birth dates. I want to convert their date of birth to their age (years only), e.g. date: 15.03.1999 age: 14 and 15.03.2014 will change to age: 15\nHere I want to show the date of the user:\nif(isset($_GET['id']))\n{\n    $id = intval($_GET['id']);\n    $dnn = mysql_fetch_array($dn);\n    $dn = mysql_query('select username, email, skype, avatar, ' .\n        'date, signup_date, gender from users where id=\"'.$id.'\"');\n    $dnn = mysql_fetch_array($dn);\n    echo \"{$dnn['date']}\";\n}\n\n",
        "all_answers": [
            "\nFor a birthday date with format Date/Month/Year\nfunction age($birthday){\n list($day, $month, $year) = explode(\"/\", $birthday);\n $year_diff  = date(\"Y\") - $year;\n $month_diff = date(\"m\") - $month;\n $day_diff   = date(\"d\") - $day;\n if ($day_diff < 0 && $month_diff==0) $year_diff--;\n if ($day_diff < 0 && $month_diff < 0) $year_diff--;\n return $year_diff;\n}\n\nor the same function that accepts day, month, year as parameters :\nfunction age($day, $month, $year){\n $year_diff  = date(\"Y\") - $year;\n $month_diff = date(\"m\") - $month;\n $day_diff   = date(\"d\") - $day;\n if ($day_diff < 0 && $month_diff==0) $year_diff--;\n if ($day_diff < 0 && $month_diff < 0) $year_diff--;\n return $year_diff;\n}\n\nYou can use it like this :\necho age(\"20/01/2000\");\n\nwhich will output the correct age (On 4 June, it's 14).\n",
            "\nPHP >= 5.3.0\n# object oriented\n$from = new DateTime('1970-02-01');\n$to   = new DateTime('today');\necho $from->diff($to)->y;\n\n# procedural\necho date_diff(date_create('1970-02-01'), date_create('today'))->y;\n\ndemo\nfunctions: date_create(), date_diff()\n\nMySQL >= 5.0.0\nSELECT TIMESTAMPDIFF(YEAR, '1970-02-01', CURDATE()) AS age\n\ndemo\nfunctions: TIMESTAMPDIFF(), CURDATE()\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "mysql",
            "date"
        ]
    },
    {
        "question_id": "564443",
        "question": "\nWe want to use Microsoft.Office.Interop.Excel in our web application. Everything works fine on our local machines, but on our test machine we're running into problems. It has neither Visual Studio nor Office installed on it.\nWe're using .NET framework 2.0 and the server is running on Windows Server 2003 with IIS6.  \nIs there a dll that needs to be installed on the machine or added to the bin of the web application?\n",
        "all_answers": [
            "\nPlease go through the following URLs for redistribution:\nHow to make changes in references\nWhere to get distribution\nThis may help your suituation. And also according to the distribution page, you also need to install office also.\n",
            "\nLooking at the documentation here http://msdn.microsoft.com/en-us/library/microsoft.office.tools.excel.worksheet.move(v=vs.80).aspx, it indicates that the 'after' object isn't a numerical position; it's the object representing the sheet you want to position your sheet after. The code should probably be something like (untested):\nworkbook.Sheets.Add(After: workbook.Sheets[workbook.Sheets.Count]); \n\n",
            "\nI'm pretty sure that you will need to have Office installed on the machine it's runnnig on. At least that's my experience from building desktop apps that uses Office.Interop\n",
            "\nit works for me\nWorkBook.Worksheets.Add(\n    System.Reflection.Missing.Value,\n    WorkBook.Worksheets[WorkBook.Worksheets.Count], \n    1, \n    System.Reflection.Missing.Value);\n\n",
            "\nIf you want to merge cells dynamically, you can also use:\n\nworksheet.Cells[FromRow, FromColumn, ToRow, ToColumn].Merge = true;\n\nAll these variables are integers.\n",
            "\nYou have to use it like this:\nws.Cells[\"A1:C1\"].Merge = true;\n\ninstead of:\nusing (ExcelRange rng = ws.Cells[\"A1:C1\"])\n{\n    bool merge = rng.Merge;\n}\n\n",
            "\nThis is the only way that works for me:\nxlWorkSheet = (Microsoft.Office.Interop.Excel.Worksheet)xlWorkBook.Worksheets.Add\n    (System.Reflection.Missing.Value,\n     xlWorkBook.Worksheets[xlWorkBook.Worksheets.Count], \n     System.Reflection.Missing.Value, \n     System.Reflection.Missing.Value);\n\n",
            "\nThis should do the job: \nwSheet.Move(Missing.Value, workbook.Sheets[workbook.Sheets.Count]);\n\n",
            "\nYou will need to have MS Office and the Office Interop assemblies installed on your server in order for that to work.\n",
            "\nYou can create a extension method:\npublic static void Merge(this ExcelRangeBase range)\n{\n    ExcelCellAddress start = range.Start;\n    ExcelCellAddress end = range.End;\n    range.Worksheet.Cells[start.Row, start.Column, end.Row, end.Column].Merge = true;\n}\n\nYou can use this as you would via interop:\nrange.Merge();\n\n"
        ],
        "answer": "A9",
        "tags": [
            "asp.net",
            "excel",
            "interop",
            "asp.net-2.0"
        ]
    },
    {
        "question_id": "106862",
        "question": "\n\n\n\nIntel's Threading Building Blocks (TBB) open source library looks really interesting.  Even though there's even an O'Reilly Book about the subject I don't hear about a lot of people using it.  I'm interested in using it for some multi-level parallel applications (MPI + threads) in Unix (Mac, Linux, etc.) environments.  For what it's worth, I'm interested in high performance computing / numerical methods kinds of applications.\nDoes anyone have experiences with TBB?  Does it work well?  Is it fairly portable (including GCC and other compilers)?  Does the paradigm work well for programs you've written?  Are there other libraries I should look into?\n",
        "all_answers": [
            "\nZThread is LGPL, you are limited to use the library in dynamic linkage if not working in a open source project.  \nThe Threading Building Blocks (TBB) in the open source version, (there is a  new commercial version, $299 , don't know the differences yet) is GNU General Public License version 2 with a so-called “Runtime Exception” (that is specific to the use only on creating free software.)\nI've seen other Runtime Exceptions that attempt to approach LGPL but enabling commercial use and static linking this is not is now the case.\nI'm only writing this because I took the chance to examine the libraries licenses and those should be also a consideration for selection based on the use one intends to give them.\n\nTxs, Jihn for pointing out this update...\n",
            "\nI have used TBB briefly, and will probably use it more in the future. I liked using it, most importantly because you dont have to deal with macros/extensions of C++, but remain within the language. Also its pretty portable. I have used it on both windows and linux. One thing though: it is difficult to work with threads using TBB, you would have to think in terms of tasks (which is actually a good thing). Intel TBB would not support your use of bare locks (it will make this tedious). But overall, this is my preliminary experience. \nI'd also recommend having a look at openMP 3 too.  \n",
            "\nI've introduced it into our code base because we needed a bettor malloc to use when we moved to a 16 core machine. With 8 and under it wasn't a significant issue. It has worked well for us. We plan on using the fine grained concurrent containers next. Ideally we can make use of the real meat of the product, but that requires rethinking how we build our code. I really like the ideas in TBB, but it's not easy to retrofit onto a code base.\nYou can't think of TBB as another threading library. They have a whole new model that really sits on top of threads and abstracts the threads away. You learn to think in task, parallel_for type operations and pipelines. If I were to build a new project I would probably try to model it in this fashion. \nWe work in Visual Studio and it works just fine. It was originally written for linux/pthreads so it runs just fine over there also.\n",
            "\nI've looked into TBB but never used it in a project. I saw no advantages (for my purposes) over ZThread. A brief and somewhat dated overview can be found here.\nIt's fairly complete with several thread dispatch options, all the usual synchronization classes and a very handy exception based  thread \"interrupt\" mechanism . It's easily extendable, well written and documented. I've used it on 20+ projects.\nIt also plays nice with any *NIX that supports POSIX threads as well as Windows.\nWorth a look.\n",
            "\nHave you looked at boost library with its thread API? \n",
            "\nGCC Atomic Built-ins\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "multithreading",
            "intel",
            "tbb"
        ]
    },
    {
        "question_id": "3964681",
        "question": "\n\n\n\nHow can I find all the files in a directory having the extension .txt in python?\n",
        "all_answers": [
            "\nSomething like that should do the job\nfor root, dirs, files in os.walk(directory):\n    for file in files:\n        if file.endswith('.txt'):\n            print(file)\n\n",
            "\nUse glob.\n>>> import glob\n>>> glob.glob('./*.txt')\n['./outline.txt', './pip-log.txt', './test.txt', './testingvim.txt']\n\n",
            "\nYou can use glob:\nimport glob, os\nos.chdir(\"/mydir\")\nfor file in glob.glob(\"*.txt\"):\n    print(file)\n\nor simply os.listdir:\nimport os\nfor file in os.listdir(\"/mydir\"):\n    if file.endswith(\".txt\"):\n        print(os.path.join(\"/mydir\", file))\n\nor if you want to traverse directory, use os.walk:\nimport os\nfor root, dirs, files in os.walk(\"/mydir\"):\n    for file in files:\n        if file.endswith(\".txt\"):\n             print(os.path.join(root, file))\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "file-io"
        ]
    },
    {
        "question_id": "3561648",
        "question": "\nWhy is friendship not at least optionally inheritable in C++?  I understand transitivity and reflexivity being forbidden for obvious reasons (I say this only to head off simple FAQ quote answers), but the lack of something along the lines of virtual friend class Foo; puzzles me.  Does anyone know the historical background behind this decision?  Was friendship really just a limited hack that has since found its way into a few obscure respectable uses?\nEdit for clarification: I'm talking about the following scenario, not where children of A are exposed to either B or to both B and its children.  I can also imagine optionally granting access to overrides of friend functions, etc.\nclass A {\n  int x;\n  friend class B;\n};\n\nclass B {\n  // OK as per friend declaration above.\n  void foo(A& a, int n) { a.x = n; }\n};\n\nclass D : public B { /* can't get in A w/o 'friend class D' declaration. */ };\n\nAccepted answer: as Loki states, the effect can be simulated more or less by making protected proxy functions in friended base classes, so there is no strict need for granting friendship to a class or virtual method heirarchy.  I dislike the need for boilerplate proxies (which the friended base effectively becomes), but I suppose that this was deemed preferable over a language mechanism that would more likely be misused most of the time.  I think it's probably time I bought and read Stroupstrup's The Design and Evolution of C++, which I've seen enough people here recommend, to get better insight to these types of questions ...\n",
        "all_answers": [
            "\nBecause I may write Foo and its friend Bar (thus there is a trust relationship). \nBut do I trust the people who write classes that are derived from Bar?\nNot really. So they should not inherit friendship.\nAny change in the internal representation of a class will require a modification to anything that is dependent on that representation. Thus all members of a class and also all friends of the class will require modification. \nTherefore if the internal representation of Foo is modified then Bar must also be modified (because friendship tightly binds Bar to Foo). If friendship was inherited then all class derived from Bar would also be tightly bound to Foo and thus require modification if Foo's internal representation is changed. But I have no knowledge of derived types (nor should I. They may even be developed by different companies etc). Thus I would be unable to change Foo as doing so would introduce breaking changes into the code base (as I could not modify all class derived from Bar).\nThus if friendship was inherited you are inadvertently introducing a restriction on the ability to modify a class. This is undesirable as you basically render useless the concept of a public API.\nNote: A child of Bar can access Foo by using Bar, just make the method in Bar protected. Then the child of Bar can access a Foo by calling through its parent class.\nIs this what you want?\nclass A\n{\n    int x;\n    friend class B;\n};\n\nclass B\n{\n    protected:\n       // Now children of B can access foo\n       void foo(A& a, int n) { a.x = n; }\n};\n\nclass D : public B\n{\n    public:\n        foo(A& a, int n)\n        {\n            B::foo(a, n + 5);\n        }\n};\n\n",
            "\nNo, there's no difference - you just tell that class B is a friend of class A and now can access its private and protected members, that's all.\n",
            "\nA guess: If a class declares some other class/function as a friend, it's because that second entity needs privileged access to the first.  What use is there in granting the second entity privileged access to an arbitrary number of classes derived from the first?\n"
        ],
        "answer": "A1",
        "tags": [
            "c++",
            "inheritance",
            "language-design",
            "friend"
        ]
    },
    {
        "question_id": "4196971",
        "question": "\nUsing $('html').html() I can get the HTML within the <html> tag (<head>, <body>, etc.). But how can I get the actual HTML of the <html> tag (with attributes)?\nAlternatively, is it possible to get the entire HTML of the page (including doctype, <html>, etc.) with jQuery (or plain old JavaScript)?\n",
        "all_answers": [
            "\nif you want to get an attribute of an HTML element with jQuery you can use .attr();\nso $('html').attr('someAttribute'); will give you the value of someAttribute of the element html\nhttp://api.jquery.com/attr/\nAdditionally:\nthere is a jQuery plugin here: http://plugins.jquery.com/project/getAttributes\nthat allows you to get all attributes from an HTML element\n",
            "\nThis is how to get the html DOM element purely with JS:\nvar htmlElement = document.getElementsByTagName(\"html\")[0];\n\nor\nvar htmlElement = document.querySelector(\"html\");\n\nAnd if you want to use jQuery to get attributes from it...\n$(htmlElement).attr(INSERT-ATTRIBUTE-NAME);\n\n",
            "\nIn jQuery:\nvar html_string = $('html').outerHTML()\n\nIn plain Javascript:\nvar html_string = document.documentElement.outerHTML\n\n",
            "\nIn addition to some of the other answers, you could also access the HTML element via:\nvar htmlEl = document.body.parentNode;\n\nThen you could get the inner HTML content:\nvar inner = htmlEl.innerHTML;\n\nDoing so this way seems to be marginally faster.  If you are just obtaining the HTML element, however, document.body.parentNode seems to be quite a bit faster.\nAfter you have the HTML element, you can mess with the attributes with the getAttribute and setAttribute methods.\nFor the DOCTYPE, you could use document.doctype, which was elaborated upon in this question.\n",
            "\nThe simplest way to get the html element natively is:\ndocument.documentElement\n\nHere's the reference: https://developer.mozilla.org/en-US/docs/Web/API/Document.documentElement.\nUPDATE: To then grab the html element as a string you would do:\ndocument.documentElement.outerHTML\n\n"
        ],
        "answer": "A5",
        "tags": [
            "javascript",
            "jquery"
        ]
    },
    {
        "question_id": "6259775",
        "question": "\nWhat is the inbuilt template tag to display the present year dynamically. Like \"2011\" what would be the template tag to display that?\n",
        "all_answers": [
            "\n{% now %}\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nAnother way to avoid the SerializerMethodField solution and therefore still allow writing to the serializer as well would be to subclass the RelatedField and do the filtering there.\nTo only allow active users as values for the field, the example would look like:\nclass ActiveUsersPrimaryKeyField(serializers.PrimaryKeyRelatedField):\n    def get_queryset(self):\n        return super().get_queryset().filter(active=True)\n\nclass MySerializer(serializers.ModelSerializer):\n    users = ActiveUsersPrimaryKeyField(many=True)\n    class Meta:\n        model = MyModel\n        fields = ('users',)\n\nAlso see this response.\nNote that this only restricts the set of input values to active users, though, i.e. only when creating or updating model instances, inactive users will be disallowed.\n\nIf you also use your serializer for reading and MyModel already has a relation to a user that has become inactive in the meantime, it will still be serialized. To prevent this, one way is to filter the relation using django's Prefetch objects. Basically, you'll filter out inactive users before they even get into the serializer:\nfrom django.db.models import Prefetch\n\n# Fetch a model instance, eagerly prefetching only those users that are active\nmodel_with_active_users = MyModel.objects.prefetch_related(\n    Prefetch(\"users\", queryset=User.objects.filter(active=True))\n).first()\n\n# serialize the data with the serializer defined above and see that only active users are returned\ndata = MyModelSerializer(model_with_active_users).data\n\n\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nThe full tag to print just the current year is {% now \"Y\" %}. Note that the Y must be in quotes.\n"
        ],
        "answer": "A6",
        "tags": [
            "python",
            "django"
        ]
    },
    {
        "question_id": "9187209",
        "question": "\nIs there a way to configure rails to use haml by default, i.e. when a scaffold is generated the according scaffold_name/index.html.haml is generated instead of scaffold_name/index.html.erb.  \nSimilar to how you are able to add config.sass.preferred_syntax = :sass to config/application.rb and have scaffold_name.sass generated by default.\nTried adding the following to config/application.rb\nconfig.generators do |g| \n  g.template_engine :haml\nend\n\nbut ened up with the following\n$ rails generate scaffold foo name:string\n  invoke  active_record\n  create    db/migrate/20120208152550_create_foos.rb\n  create    app/models/foo.rb\n  invoke    test_unit\n  create      test/unit/foo_test.rb\n  create      test/fixtures/foos.yml\n   route  resources :foos\n  invoke  scaffold_controller\n  create    app/controllers/foos_controller.rb\n   error    haml [not found]\n  invoke    test_unit\n  create      test/functional/foos_controller_test.rb\n  invoke    helper\n  create      app/helpers/foos_helper.rb\n  invoke      test_unit\n  create        test/unit/helpers/foos_helper_test.rb\n  invoke  assets\n  invoke    coffee\n  create      app/assets/javascripts/foos.js.coffee\n  invoke    sass\n  create      app/assets/stylesheets/foos.css.sass\n  invoke  sass\n  identical    app/assets/stylesheets/scaffolds.css.sass\n$ rails destroy scaffold foo                                                                                                                        \n  invoke  active_record\n  remove    db/migrate/20120208152550_create_foos.rb\n  remove    app/models/foo.rb\n  invoke    test_unit\n  remove      test/unit/foo_test.rb\n  remove      test/fixtures/foos.yml\n   route  resources :foos\n  invoke  scaffold_controller\n  remove    app/controllers/foos_controller.rb\n   error    haml [not found]\n  invoke    test_unit\n  remove      test/functional/foos_controller_test.rb\n  invoke    helper\n  remove      app/helpers/foos_helper.rb\n  invoke      test_unit\n  remove        test/unit/helpers/foos_helper_test.rb\n  invoke  assets\n  invoke    coffee\n  remove      app/assets/javascripts/foos.js.coffee\n  invoke    sass\n  remove      app/assets/stylesheets/foos.css.sass\n  invoke  sass\n\nI created a nice little bundle command to replace all erb with haml files following this screencast but I'm still interested in making it default when the scaffold is created!  How do I make it so haml files (not erb!) are generated by default?\n",
        "all_answers": [
            "\nTry\n  def bye\n    @counter  = 4\n    flash.now[:error] = \"Your book was not found\"\n    render :index\n  end\n\n",
            "\nThe haml [not found] error is usually because the bundle is incomplete. Have you tried running bundle update and then rerunning the generator?\n",
            "\nI use gem 'haml-rails', '= 0.3.4' in my gemfile. it automatically generates *.html.haml without any configuration.\n",
            "\nI'm confused as to why that Rails Guide mentions using flash values in render, since they only appear to work in redirect_to at the moment. I think you'll find your approach works if you put a flash.now[:alert] = 'Alert message!' before your render method call.\nEdit: this is a flaw in the guides that will be fixed, you should use the separate method call to set the flash prior to calling render. \n",
            "\nIn your application config, try setting the following:\nconfig.generators do |g|\n  g.template_engine :haml\nend\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "haml",
            "ruby-on-rails-3.2"
        ]
    },
    {
        "question_id": "6169666",
        "question": "\nThis seems trivial but after all the research and coding I can't get it to work. Conditions are:\n\nThe browser window size is unknown. So please don't propose a solution involving absolute pixel sizes.\nThe image's original dimensions are unknown, and may or may not already fit the browser window.\nThe image is vertically and horizontally centered.\nThe image proportions must be conserved.\nThe image must be displayed in its entirety in the window (no cropping.)\nI do not wish scrollbars to appear (and they shouldn't if the image fits.)\nThe image automatically resizes when the window dimensions change, to occupy all the available space without being larger than its original size.\n\nBasically what I want is this:\n.fit {\n  max-width: 99%;\n  max-height: 99%;\n}\n<img class=\"fit\" src=\"pic.png\">\n\nThe problem with the code above is that it doesn't work: the pic takes all the vertical space it needs by adding a vertical scroll bar. \nAt my disposal is PHP, Javascript, JQuery but I'd kill for a CSS-only solution. I don't care if it doesn't work in IE.\n",
        "all_answers": [
            "\nUpdate 2018-04-11\nHere's a Javascript-less, CSS-only solution. The image will dynamically be centered and resized to fit the window.\n<html>\n<head>\n    <style>\n        * {\n            margin: 0;\n            padding: 0;\n        }\n        .imgbox {\n            display: grid;\n            height: 100%;\n        }\n        .center-fit {\n            max-width: 100%;\n            max-height: 100vh;\n            margin: auto;\n        }\n    </style>\n</head>\n<body>\n<div class=\"imgbox\">\n    <img class=\"center-fit\" src='pic.png'>\n</div>\n</body>\n</html>\n\n\nThe [other, old] solution, using JQuery, sets the height of the image container (body in the example below) so that the max-height property on the image works as expected. The image will also automatically resize when the client window is resized.\n<!DOCTYPE html>\n<html>\n<head>\n    <style>\n        * {\n            padding: 0;\n            margin: 0;\n        }\n        .fit { /* set relative picture size */\n            max-width: 100%;\n            max-height: 100%;\n        }\n        .center {\n            display: block;\n            margin: auto;\n        }\n    </style>\n</head>\n<body>\n\n<img class=\"center fit\" src=\"pic.jpg\" >\n\n<script src=\"http://code.jquery.com/jquery-latest.js\"></script>\n<script type=\"text/javascript\" language=\"JavaScript\">\n    function set_body_height() { // set body height = window height\n        $('body').height($(window).height());\n    }\n    $(document).ready(function() {\n        $(window).bind('resize', set_body_height);\n        set_body_height();\n    });\n</script>\n\n</body>\n</html>\n\nNote: User gutierrezalex packaged a very similar solution as a JQuery plugin on this page.\n",
            "\nwidth: 100%;\noverflow: hidden;\n\nI believe that should do the trick.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nhtml, body{width: 99%; height: 99%; overflow: hidden}\nimg.fit{width: 100%; height: 100%;}\n\nOr maybe check this out:\nhttp://css-tricks.com/how-to-resizeable-background-image/\n"
        ],
        "answer": "A1",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "830423",
        "question": "\nI know you can view all possible rake tasks by typing\nrake -T\n\nBut I need to know what exactly a task does.  From the output, how can I find a source file that actually has the task?  For example, I'm trying to find the source for the db:schema:dump task.\n",
        "all_answers": [
            "\nFor most rake tasks in Rails, look in the Rails gem directory, in lib/tasks.\nIf you've vendored Rails into your app directory structure then look in vendor/rails/railties/lib/tasks instead\nEither way, db:schema:dump is in databases.rake.\n",
            "\nDespite what others have said, you can programmatically get the source location of rake tasks in a rails application.  To do this, just run something like the following in your code or from a console:\n# load all the tasks associated with the rails app\nRails.application.load_tasks\n\n# get the source locations of actions called by a task\ntask_name = 'db:schema:load' # fully scoped task name\nRake.application[task_name].actions.map(&:source_location)\n\nThis will return the source locations of any code that gets executed for this task.  You can also use #prerequisites instead of #source_location to get a list of prerequisite task names (e.g. 'environment', etc).\nYou can also list all tasks loaded using:\nRake.application.tasks\n\nUPDATE: See Magne's good answer below. For versions of rake >= 0.9.0 you can use rake -W to show the source location of your rake tasks.\n",
            "\nThere is no programmatic way to do this unfortunately.  Rake tasks can be loaded either from rails itself, lib/tasks, or from any plugin with a tasks directory.\nThis should nab most everything not within Rails itself:\nfind . -name \"*.rake\" | xargs grep \"whatever\"\n\nAs for db:schema:dump, here's the source:\ndesc \"Create a db/schema.rb file that can be portably used against any DB supported by AR\"\ntask :dump => :environment do\n  require 'active_record/schema_dumper'\n  File.open(ENV['SCHEMA'] || \"#{RAILS_ROOT}/db/schema.rb\", \"w\") do |file|\n    ActiveRecord::SchemaDumper.dump(ActiveRecord::Base.connection, file)\n  end\nend\n\nIt can be found on line 242 of lib/tasks/database.rake in the rails 2.2.2 gem.  If you've got a different version of Rails, just search for \"namespace :schema\".\nYou probably actually want the source of the ActiveRecord::SchemaDumper, but I think you should have no trouble figuring out where that is.  :-)\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "rake"
        ]
    },
    {
        "question_id": "2793098",
        "question": "\nWhen do you use attr_reader/attr_writer/attr_accessor in Rails models?\n",
        "all_answers": [
            "\nNever, unless you have specific need for it. Automatic database-backed accessors are created for you, so you don't need to worry.\nAny attr_accessors you do create will change the relevant @attr on the rails object, but this will be lost when the object is destroyed, unless you stick it back in the database. Sometimes you do want this behavior, but it's unusual in a rails app.\nNow in ruby, it's a different story, and you end up using these very frequently. But I'd be surprised if you need them in rails---especially initially.\n",
            "\nattr_accessor can be used for values you don't want to store in the database directly and that will only exist for the life of the object (e.g. passwords).\nattr_reader can be used as one of several alternatives to doing something like this:\ndef instance_value\n  \"my value\"\nend\n\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby"
        ]
    },
    {
        "question_id": "4584373",
        "question": "\nWhat is the difference between $(window).load(function() {}) and $(document).ready(function() {}) in jQuery?\n",
        "all_answers": [
            "\nYou've mixed different approaches how to include legacy vendor modules. This is how I'd tackle it:\n1. Prefer unminified CommonJS/AMD over dist\nMost modules link the dist version in the main field of their package.json. While this is useful for most developers, for webpack it is better to alias the src version because this way webpack is able to optimize dependencies better (e.g. when using the DedupePlugin).\n// webpack.config.js\n\nmodule.exports = {\n    ...\n    resolve: {\n        alias: {\n            jquery: \"jquery/src/jquery\"\n        }\n    }\n};\n\nHowever, in most cases the dist version works just fine as well.\n\n2. Use the ProvidePlugin to inject implicit globals\nMost legacy modules rely on the presence of specific globals, like jQuery plugins do on $ or jQuery. In this scenario you can configure webpack, to prepend var $ = require(\"jquery\") everytime it encounters the global $ identifier.\nvar webpack = require(\"webpack\");\n\n    ...\n    \n    plugins: [\n        new webpack.ProvidePlugin({\n            $: \"jquery\",\n            jQuery: \"jquery\"\n        })\n    ]\n\n\n3. Use the imports-loader to configure this\nSome legacy modules rely on this being the window object. This becomes a problem when the module is executed in a CommonJS context where this equals module.exports. In this case you can override this with the imports-loader.\nRun npm i imports-loader --save-dev and then\nmodule: {\n    loaders: [\n        {\n            test: /[\\/\\\\]node_modules[\\/\\\\]some-module[\\/\\\\]index\\.js$/,\n            loader: \"imports-loader?this=>window\"\n        }\n    ]\n}\n\nThe imports-loader can also be used to manually inject variables of all kinds. But most of the time the ProvidePlugin is more useful when it comes to implicit globals.\n\n4. Use the imports-loader to disable AMD\nThere are modules that support different module styles, like AMD, CommonJS and legacy. However, most of the time they first check for define and then use some quirky code to export properties. In these cases, it could help to force the CommonJS path by setting define = false.\nmodule: {\n    loaders: [\n        {\n            test: /[\\/\\\\]node_modules[\\/\\\\]some-module[\\/\\\\]index\\.js$/,\n            loader: \"imports-loader?define=>false\"\n        }\n    ]\n}\n\n\n5. Use the script-loader (no longer mantained) to globally import scripts\nIf you don't care about global variables and just want legacy scripts to work, you can also use the script-loader. It executes the module in a global context, just as if you had included them via the <script> tag.\n\n6. Use noParse to include large dists\nWhen there is no AMD/CommonJS version of the module and you want to include the dist, you can flag this module as noParse. Then webpack will just include the module without parsing it, which can be used to improve the build time. This means that any feature requiring the AST, like the ProvidePlugin, will not work.\nmodule: {\n    noParse: [\n        /[\\/\\\\]node_modules[\\/\\\\]angular[\\/\\\\]angular\\.js$/\n    ]\n}\n\n",
            "\nFrom jquery prospective - it's just adding load/onload event to window and document.\nCheck this out: \nwindow.onload vs document.onload\n",
            "\n\ndocument.ready is a jQuery event, it runs when the DOM is ready, e.g. all elements are there to be found/used, but not necessarily all content.\nwindow.onload fires later (or at the same time in the worst/failing cases) when images and such are loaded, so if you're using image dimensions for example, you often want to use this instead.\n\n"
        ],
        "answer": "A3",
        "tags": [
            "jquery"
        ]
    },
    {
        "question_id": "4721449",
        "question": "\nI know that the question about turning on/off GPS programatically on android has been discussed many times, and the answer is always the same: \n\n\"You can't for security/privacy reasons, you have to forward to location preferences screen and let the user enable/disable it.\"\n\nI understand that, however I recently bought Tasker from the market and, among many other things that you can accomplish with it, you can set rules to auto-enable GPS on entering pre-determined applications and disable it on exit (see here for the tutorial on how to do it, and it just works!) and this app can't be signed with the firmware signing key as it works on many android versions and different devices and you don't even need to be rooted.\nI would like to do this in my app. Of course, I don't want to blow up the users privacy, so I would first ask the user if he wants to turn it on automatically with the typical \"remember my decision\" checkbox and if he answers yes, enable it.\nDoes anybody have any idea or clue on how Tasker achieves this?\n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nthe GPS can be toggled by exploiting a bug in the power manager widget. see this xda thread for discussion.\nhere's some example code i use\nprivate void turnGPSOn(){\n    String provider = Settings.Secure.getString(getContentResolver(), Settings.Secure.LOCATION_PROVIDERS_ALLOWED);\n\n    if(!provider.contains(\"gps\")){ //if gps is disabled\n        final Intent poke = new Intent();\n        poke.setClassName(\"com.android.settings\", \"com.android.settings.widget.SettingsAppWidgetProvider\"); \n        poke.addCategory(Intent.CATEGORY_ALTERNATIVE);\n        poke.setData(Uri.parse(\"3\")); \n        sendBroadcast(poke);\n    }\n}\n\nprivate void turnGPSOff(){\n    String provider = Settings.Secure.getString(getContentResolver(), Settings.Secure.LOCATION_PROVIDERS_ALLOWED);\n\n    if(provider.contains(\"gps\")){ //if gps is enabled\n        final Intent poke = new Intent();\n        poke.setClassName(\"com.android.settings\", \"com.android.settings.widget.SettingsAppWidgetProvider\");\n        poke.addCategory(Intent.CATEGORY_ALTERNATIVE);\n        poke.setData(Uri.parse(\"3\")); \n        sendBroadcast(poke);\n    }\n}\n\nuse the following to test if the existing version of the power control widget is one which will allow you to toggle the gps.\nprivate boolean canToggleGPS() {\n    PackageManager pacman = getPackageManager();\n    PackageInfo pacInfo = null;\n\n    try {\n        pacInfo = pacman.getPackageInfo(\"com.android.settings\", PackageManager.GET_RECEIVERS);\n    } catch (NameNotFoundException e) {\n        return false; //package not found\n    }\n\n    if(pacInfo != null){\n        for(ActivityInfo actInfo : pacInfo.receivers){\n            //test if recevier is exported. if so, we can toggle GPS.\n            if(actInfo.name.equals(\"com.android.settings.widget.SettingsAppWidgetProvider\") && actInfo.exported){\n                return true;\n            }\n        }\n    }\n\n    return false; //default\n}\n\n",
            "\nMaybe with reflection tricks around the class android.server.LocationManagerService.\nAlso, there is a method (since API 8) android.provider.Settings.Secure.setLocationProviderEnabled\n"
        ],
        "answer": "A2",
        "tags": [
            "android",
            "gps"
        ]
    },
    {
        "question_id": "5525071",
        "question": "\nI'm working on an Extension in Chrome, and I'm wondering: what's the best way to find out when an element comes into existence? Using plain javascript, with an interval that checks until an element exists, or does jQuery have some easy way to do this?\n",
        "all_answers": [
            "\nI was having this same problem, so I went ahead and wrote a plugin for it.\n$(selector).waitUntilExists(function);\nCode:\n;(function ($, window) {\n\nvar intervals = {};\nvar removeListener = function(selector) {\n\n    if (intervals[selector]) {\n\n        window.clearInterval(intervals[selector]);\n        intervals[selector] = null;\n    }\n};\nvar found = 'waitUntilExists.found';\n\n/**\n * @function\n * @property {object} jQuery plugin which runs handler function once specified\n *           element is inserted into the DOM\n * @param {function|string} handler \n *            A function to execute at the time when the element is inserted or \n *            string \"remove\" to remove the listener from the given selector\n * @param {bool} shouldRunHandlerOnce \n *            Optional: if true, handler is unbound after its first invocation\n * @example jQuery(selector).waitUntilExists(function);\n */\n\n$.fn.waitUntilExists = function(handler, shouldRunHandlerOnce, isChild) {\n\n    var selector = this.selector;\n    var $this = $(selector);\n    var $elements = $this.not(function() { return $(this).data(found); });\n\n    if (handler === 'remove') {\n\n        // Hijack and remove interval immediately if the code requests\n        removeListener(selector);\n    }\n    else {\n\n        // Run the handler on all found elements and mark as found\n        $elements.each(handler).data(found, true);\n\n        if (shouldRunHandlerOnce && $this.length) {\n\n            // Element was found, implying the handler already ran for all \n            // matched elements\n            removeListener(selector);\n        }\n        else if (!isChild) {\n\n            // If this is a recurring search or if the target has not yet been \n            // found, create an interval to continue searching for the target\n            intervals[selector] = window.setInterval(function () {\n\n                $this.waitUntilExists(handler, shouldRunHandlerOnce, true);\n            }, 500);\n        }\n    }\n\n    return $this;\n};\n\n}(jQuery, window));\n\n",
            "\nDOMNodeInserted is being deprecated, along with the other DOM mutation events, because of performance issues - the recommended approach is to use a MutationObserver to watch the DOM. It's only supported in newer browsers though, so you should fall back onto DOMNodeInserted when MutationObserver isn't available.\nlet observer = new MutationObserver((mutations) => {\n  mutations.forEach((mutation) => {\n    if (!mutation.addedNodes) return\n\n    for (let i = 0; i < mutation.addedNodes.length; i++) {\n      // do things to your newly added nodes here\n      let node = mutation.addedNodes[i]\n    }\n  })\n})\n\nobserver.observe(document.body, {\n    childList: true\n  , subtree: true\n  , attributes: false\n  , characterData: false\n})\n\n// stop watching using:\nobserver.disconnect()\n\n",
            "\nYou can do\n$('#yourelement').ready(function() {\n\n});\n\nPlease note that this will only work if the element is present in the DOM when being requested from the server. If the element is being dynamically added via JavaScript, it will not work and you may need to look at the other answers.\n",
            "\nYou can listen to DOMNodeInserted or DOMSubtreeModified events which fire whenever a new element is added to the DOM. \nThere is also LiveQuery jQuery plugin which would detect when a new element is created:\n$(\"#future_element\").livequery(function(){\n    //element created\n});\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "jquery",
            "google-chrome",
            "google-chrome-extension"
        ]
    },
    {
        "question_id": "10775367",
        "question": "\n\n\n\nI want to send temperature value from a microcontroller using UART to C# interface and Display temperature on Label.Content. Here is my microcontroller code:\nwhile(1) {\n   key_scan(); // get value of temp\n   if (Usart_Data_Ready())\n   {\n      while(temperature[i]!=0)\n      {\n         if(temperature[i]!=' ')\n         {\n            Usart_Write(temperature[i]);\n            Delay_ms(1000);\n         }\n         i = i + 1;\n      }\n      i =0;\n      Delay_ms(2000);\n   }\n}\n\nand my C# code is:\nprivate void serialPort1_DataReceived(object sender, System.IO.Ports.SerialDataReceivedEventArgs e)\n{\n   txt += serialPort1.ReadExisting().ToString();\n   textBox1.Text = txt.ToString();\n}\n\nbut exception arises there \"Cross-thread operation not valid: Control 'textBox1' accessed from a thread other than the thread it was created on\"\nPlease tell me how to get temperature string from my microcontroller and remove this Error!\n",
        "all_answers": [
            "\nUse a shared container to transfer data between threads.\n",
            "\nA lock is specific to the AppDomain, while Mutex to the Operating System allowing you to perform inter-process locking and synchronization (IPC).\n",
            "\nThe data received in your serialPort1_DataReceived method is coming from another thread context than the UI thread, and that's the reason you see this error.\nTo remedy this, you will have to use a dispatcher as descibed in the MSDN article:\nHow to: Make Thread-Safe Calls to Windows Forms Controls\nSo instead of setting the text property directly in the serialport1_DataReceived method, use this pattern:\ndelegate void SetTextCallback(string text);\n\nprivate void SetText(string text)\n{\n  // InvokeRequired required compares the thread ID of the\n  // calling thread to the thread ID of the creating thread.\n  // If these threads are different, it returns true.\n  if (this.textBox1.InvokeRequired)\n  { \n    SetTextCallback d = new SetTextCallback(SetText);\n    this.Invoke(d, new object[] { text });\n  }\n  else\n  {\n    this.textBox1.Text = text;\n  }\n}\n\nSo in your case:\nprivate void serialPort1_DataReceived(object sender, System.IO.Ports.SerialDataReceivedEventArgs e)\n{\n  txt += serialPort1.ReadExisting().ToString();\n  SetText(txt.ToString());\n}\n\n",
            "\nlock is a compiler keyword, not an actual class or object.  It's a wrapper around the functionality of the Monitor class and is designed to make the Monitor easier to work with for the common case.\nThe Monitor (and the lock keyword) are, as Darin said, restricted to the AppDomain.  Primarily because a reference to a memory address (in the form of an instantiated object) is required to manage the \"lock\" and maintain the identity of the Monitor\nThe Mutex, on the other hand, is a .Net wrapper around an operating system construct, and can be used for system-wide synchronization, using string data (instead of a pointer to data) as its identifier.  Two mutexes that reference two strings in two completely different memory addresses, but having the same data, will actually utilize the same operating-system mutex.\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "multithreading",
            "invoke",
            "uart"
        ]
    },
    {
        "question_id": "5818362",
        "question": "\nI have a function in C# that can be called multiple times from multiple threads and I want it to be done only once so I thought about this:\nclass MyClass\n{\n    bool done = false;\n    public void DoSomething()\n    {\n        lock(this)\n            if(!done)\n            {\n                done = true;\n                _DoSomething();\n            }\n    }\n}\n\nThe problem is _DoSomething takes a long time and I don't want many threads to wait on it when they can just see that done is true.\nSomething like this can be a workaround:\nclass MyClass\n{\n    bool done = false;\n    public void DoSomething()\n    {\n        bool doIt = false;\n        lock(this)\n            if(!done)\n                doIt = done = true;\n        if(doIt)\n             _DoSomething();\n    }\n}\n\nBut just doing the locking and unlocking manually will be much better.\nHow can I manually lock and unlock just like the lock(object) does? I need it to use same interface as lock so that this manual way and lock will block each other (for more complex cases).\n",
        "all_answers": [
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nHere is a good write up about .NET events and race conditions with threads.  It covers some common scenarios and has some good references in it.\nHope this helps.\n",
            "\nThe lock keyword is just syntactic sugar for Monitor.Enter and Monitor.Exit:\nMonitor.Enter(o);\ntry\n{\n    //put your code here\n}\nfinally\n{\n    Monitor.Exit(o);\n}\n\nis the same as\nlock(o)\n{\n    //put your code here\n}\n\n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nYou can check the value of done before and after the lock:\n    if (!done)\n    {\n        lock(this)\n        {\n            if(!done)\n            {\n                done = true;\n                _DoSomething();\n            }\n        }\n    }\n\nThis way you won't enter the lock if done is true. The second check inside the lock is to cope with race conditions if two threads enter the first if at the same time.\nBTW, you shouldn't lock on this, because it can cause deadlocks. Lock on a private field instead (like private readonly object _syncLock = new object())\n"
        ],
        "answer": "A4",
        "tags": [
            "c#",
            "multithreading",
            "locking"
        ]
    },
    {
        "question_id": "40938752",
        "question": "\nJoe Albahari has a great series on multithreading that's a must read and should be known by heart for anyone doing C# multithreading.\nIn part 4 however he mentions the problems with volatile:\n\nNotice that applying volatile doesn’t prevent a write followed by a\n  read from being swapped, and this can create brainteasers. Joe Duffy\n  illustrates the problem well with the following example: if Test1 and\n  Test2 run simultaneously on different threads, it’s possible for a and\n  b to both end up with a value of 0 (despite the use of volatile on\n  both x and y)\n\nFollowed by a note that the MSDN documentation is incorrect:\n\nThe MSDN documentation states that use of the volatile keyword ensures\n  that the most up-to-date value is present in the field at all times.\n  This is incorrect, since as we’ve seen, a write followed by a read can\n  be reordered.\n\nI've checked the MSDN documentation, which was last changed in 2015 but still lists:\n\nThe volatile keyword indicates that a field might be modified by\n  multiple threads that are executing at the same time. Fields that are\n  declared volatile are not subject to compiler optimizations that\n  assume access by a single thread. This ensures that the most\n  up-to-date value is present in the field at all times.\n\nRight now I still avoid volatile in favor of the more verbose to prevent threads using stale data:\nprivate int foo;\nprivate object fooLock = new object();\npublic int Foo {\n    get { lock(fooLock) return foo; }\n    set { lock(fooLock) foo = value; }\n}\n\nAs the parts about multithreading were written in 2011, is the argument still valid today? Should volatile still be avoided at all costs in favor of locks or full memory fences to prevent introducing very hard to produce bugs that as mentioned are even dependent on the CPU vendor it's running on?\n",
        "all_answers": [
            "\nVolatile in its current implementation is not broken despite popular blog posts claiming such a thing. It is however badly specified and the idea of using a modifier on a field to specify memory ordering is not that great (compare volatile in Java/C# to C++'s atomic specification that had enough time to learn from the earlier mistakes). The MSDN article on the other hand was clearly written by someone who has no business talking about concurrency and is completely bogus.. the only sane option is to completely ignore it.\nVolatile guarantees acquire/release semantics when accessing the field and can only be applied to types that allow atomic reads and writes. Not more, not less. This is enough to be useful to implement many lock-free algorithms efficiently such as non-blocking hashmaps. \nOne very simple sample is using a volatile variable to publish data. Thanks to the volatile on x, the assertion in the following snippet cannot fire:\nprivate int a;\nprivate volatile bool x;\n\npublic void Publish()\n{\n    a = 1;\n    x = true;\n}\n\npublic void Read()\n{\n    if (x)\n    {\n        // if we observe x == true, we will always see the preceding write to a\n        Debug.Assert(a == 1); \n    }\n}\n\nVolatile is not easy to use and in most situations you are much better off to go with some higher level concept, but when performance is important or you're implementing some low level data structures, volatile can be exceedingly useful.\n",
            "\nAs I read the MSDN documentation, I believe it is saying that if you see volatile on a variable, you do not have to worry about compiler optimizations screwing up the value because they reorder the operations. It doesn't say that you are protected from errors caused by your own code executing operations on separate threads in the wrong order. (although admittedly, the comment is not clear as to this.)\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "multithreading",
            "volatile"
        ]
    },
    {
        "question_id": "742205",
        "question": "\ncreate table check2(f1 varchar(20),f2 varchar(20));\n\ncreates a table with the default collation latin1_general_ci;\nalter table check2 collate latin1_general_cs;\nshow full columns from check2;\n\nshows the individual collation of the columns as 'latin1_general_ci'.\nThen what is the effect of the alter table command?\n",
        "all_answers": [
            "\nIt sets the default collation for the table; if you create a new column, that should be collated with latin_general_ci -- I think.  Try specifying the collation for the individual column and see if that works.  MySQL has some really bizarre behavior in regards to the way it handles this.\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nMySQL has 4 levels of collation: server, database, table, column.\nIf you change the collation of the server, database or table, you don't change the setting for each column, but you change the default collations.\nE.g if you change the default collation of a database, each new table you create in that database will use that collation, and if you change the default collation of a table, each column you create in that table will get that collation.\n",
            "\nTo change the default character set and collation of a table including those of existing columns (note the convert to clause):\nalter table <some_table> convert to character set utf8mb4 collate utf8mb4_unicode_ci;\n\nEdited the answer, thanks to the prompting of some comments:\n\nShould avoid recommending utf8. It's almost never what you want, and often leads to unexpected messes. The utf8 character set is not fully compatible with UTF-8. The utf8mb4 character set is what you want if you want UTF-8. – Rich Remer Mar 28 '18 at 23:41 \n\nand\n\nThat seems quite important, glad I read the comments and thanks @RichRemer . Nikki , I think you should edit that in your answer considering how many views this gets. See here https://dev.mysql.com/doc/refman/8.0/en/charset-unicode-utf8.html and here What is the difference between utf8mb4 and utf8 charsets in MySQL? – Paulpro Mar 12 at 17:46\n\n"
        ],
        "answer": "A5",
        "tags": [
            "mysql",
            "sql",
            "collation"
        ]
    },
    {
        "question_id": "9512549",
        "question": "\nI switched to master after developing on a branch for a long time. The log shows:\n\nYour branch is behind 'origin/master' by 167 commits, and can be fast-forwarded.\n\nI tried:\ngit checkout HEAD\n\nIt doesn't have any effect. This is because I have checked out an intermediate commit on master.\nHow can I make master stay on head?\n",
        "all_answers": [
            "\nTry git merge origin/master.  If you want to be sure that it only does a fast-forward, you can say git merge --ff-only origin/master.\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\ngit checkout master\ngit pull\n\nshould do the job.\nYou will get the \"Your branch is behind\" message every time when you work on a branch different than master, someone does changes to master and you git pull.\n(branch) $ //hack hack hack, while someone push the changes to origin/master\n(branch) $ git pull   \n\nnow the origin/master reference is pulled, but your master is not merged with it\n(branch) $ git checkout master\n(master) $ \n\nnow master is behind origin/master and can be fast forwarded\nthis will pull and merge (so merge also newer commits to origin/master)\n(master) $ git pull \n\nthis will just merge what you have already pulled\n(master) $ git merge origin/master\n\nnow your master and origin/master are in sync\n",
            "\nDoing:\ngit checkout master\ngit pull origin\n\nwill fetch and merge the origin/master branch (you may just say git pull as origin is the default).\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n"
        ],
        "answer": "A5",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "294138",
        "question": "\nWhat's the best way to merge 2 or more dictionaries (Dictionary<TKey, TValue>) in C#?\n(3.0 features like LINQ are fine).\nI'm thinking of a method signature along the lines of:\npublic static Dictionary<TKey,TValue>\n                 Merge<TKey,TValue>(Dictionary<TKey,TValue>[] dictionaries);\n\nor\npublic static Dictionary<TKey,TValue>\n                 Merge<TKey,TValue>(IEnumerable<Dictionary<TKey,TValue>> dictionaries);\n\nRegarding the handling of duplicate keys: In case of collision, it doesn't matter which value is saved to the dictionary as long as it's consistent.\n",
        "all_answers": [
            "\nTryGetValue will be faster.\nContainsKey uses the same check as TryGetValue, which internally refers to the actual entry location.  The Item property actually has nearly identical code functionality as TryGetValue, except that it will throw an exception instead of returning false.\nUsing ContainsKey followed by the Item basically duplicates the lookup functionality, which is the bulk of the computation in this case. \n",
            "\nThe trivial solution would be:\nusing System.Collections.Generic;\n...\npublic static Dictionary<TKey, TValue>\n    Merge<TKey,TValue>(IEnumerable<Dictionary<TKey, TValue>> dictionaries)\n{\n    var result = new Dictionary<TKey, TValue>();\n    foreach (var dict in dictionaries)\n        foreach (var x in dict)\n            result[x.Key] = x.Value;\n    return result;\n}\n\n",
            "\nThis partly depends on what you want to happen if you run into duplicates. For instance, you could do:\nvar result = dictionaries.SelectMany(dict => dict)\n                         .ToDictionary(pair => pair.Key, pair => pair.Value);\n\nThat will throw an exception if you get any duplicate keys.\nEDIT: If you use ToLookup then you'll get a lookup which can have multiple values per key. You could then convert that to a dictionary:\nvar result = dictionaries.SelectMany(dict => dict)\n                         .ToLookup(pair => pair.Key, pair => pair.Value)\n                         .ToDictionary(group => group.Key, group => group.First());\n\nIt's a bit ugly - and inefficient - but it's the quickest way to do it in terms of code. (I haven't tested it, admittedly.)\nYou could write your own ToDictionary2 extension method of course (with a better name, but I don't have time to think of one now) - it's not terribly hard to do, just overwriting (or ignoring) duplicate keys. The important bit (to my mind) is using SelectMany, and realising that a dictionary supports iteration over its key/value pairs.\n",
            "\nIf you're using .NET 3.5 or .NET 4, it's easy to create the dictionary using LINQ:\nDictionary<string, ArrayList> result = target.GetComponents()\n                                      .ToDictionary(x => x.Key, x => x.Value);\n\nThere's no such thing as an IEnumerable<T1, T2> but a KeyValuePair<TKey, TValue> is fine.\n",
            "\nTry the following\nstatic Dictionary<TKey, TValue>\n    Merge<TKey, TValue>(this IEnumerable<Dictionary<TKey, TValue>> enumerable)\n{\n    return enumerable.SelectMany(x => x).ToDictionary(x => x.Key, y => y.Value);\n}\n\n",
            "\nAs of .NET Core 2.0, the constructor Dictionary<TKey,TValue>(IEnumerable<KeyValuePair<TKey,TValue>>) now exists.\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "dictionary",
            "merge"
        ]
    },
    {
        "question_id": "234365",
        "question": "\nI'm new to Windows programming and after reading the Petzold book I wonder: is it still good practice to use the TCHAR type and the _T() function to declare strings or should I just use the wchar_t and L\"\" strings in new code?\nI will target only modern Windows (as of this writing versions 10 and 11) and my code will be i18n from the start up.\n",
        "all_answers": [
            "\nIf you're wondering if it's still in practice, then yes - it is still used quite a bit. No one will look at your code funny if it uses TCHAR and _T(\"\"). The project I'm working on now is converting from ANSI to unicode - and we're going the portable (TCHAR) route.\nHowever...\nMy vote would be to forget all the ANSI/UNICODE portable macros (TCHAR, _T(\"\"), and all the _tXXXXXX calls, etc...) and just assume unicode everywhere. I really don't see the point of being portable if you'll never need an ANSI version. I would use all the wide character functions and types directly. Preprend all string literals with a L.\n",
            "\nAfter I tried algirdas' solution, my Windows crashed (Win 7 Pro 64bit) so I decided to try a different solution:\n\nStart Run (Win+R)\nType cmd /K chcp 65001\n\nYou will get mostly what you want. To start it from the taskbar or anywhere else, make a shortcut (you can name it cmd.unicode.exe or whatever you like) and change its Target to C:\\Windows\\System32\\cmd.exe /K chcp 65001.\n",
            "\nI would still use the TCHAR syntax if I was doing a new project today. There's not much practical difference between using it and the WCHAR syntax, and I prefer code which is explicit in what the character type is. Since most API functions and helper objects take/use TCHAR types (e.g.: CString), it just makes sense to use it. Plus it gives you flexibility if you decide to use the code in an ASCII app at some point, or if Windows ever evolves to Unicode32, etc.\nIf you decide to go the WCHAR route, I would be explicit about it. That is, use CStringW instead of CString, and casting macros when converting to TCHAR (eg: CW2CT).\nThat's my opinion, anyway.\n",
            "\nYes, absolutely; at least for the _T macro.  I'm not so sure about the wide-character stuff, though.\nThe reason being is to better support WinCE or other non-standard Windows platforms.  If you're 100% certain that your code will remain on NT, then you can probably just use regular C-string declarations.  However, it's best to tend towards the more flexible approach, as it's much easier to #define that macro away on a non-windows platform in comparison to going through thousands of lines of code and adding it everywhere in case you need to port some library to windows mobile.\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "c",
            "windows",
            "unicode",
            "wchar-t"
        ]
    },
    {
        "question_id": "13635429",
        "question": "\nUsing the GitHub Windows client I did a sync to pull remote changes to my local machine, but before finishing the sync, I ran out of disk space and the sync failed.  Now I seem to have a bunch of local changes that are actually changes that were being pulled from origin.  I tried to run git pull but got:\nC:\\Users\\Tom\\SourceLog [master +4 ~26 -0 !]> git pull\nUpdating b3a86e1..5afd74f\nerror: Your local changes to the following files would be overwritten by merge:\n        SourceLog.Interface/IChangedFile.cs\n        SourceLog.Interface/ILogEntry.cs\n        ...\nPlease, commit your changes or stash them before you can merge.\nerror: The following untracked working tree files would be overwritten by merge:\n        Lib/MSBuildExtensionPack/4.0.6.0/Ionic.Zip.dll\n        Lib/MSBuildExtensionPack/4.0.6.0/MSBuild.ExtensionPack.dll\n        ...\nAborting\n\nSo now I'm trying to discard the local changes but I'm getting:\nC:\\Users\\Tom\\SourceLog [master +4 ~26 -0 !]> git checkout -- .\nRename from '.git/index.lock' to '.git/index' failed. Should I try again? (y/n) y\nRename from '.git/index.lock' to '.git/index' failed. Should I try again? (y/n) n\nfatal: unable to write new index file\n\nHow can I clean this up?  (I didn't have any local changes before starting the sync.)\nUpdate\nCan't seem to reset head..\nC:\\Users\\Tom\\SourceLog [master +4 ~0 -0 !]> git reset head\nRename from '.git/index.lock' to '.git/index' failed. Should I try again? (y/n) y\nRename from '.git/index.lock' to '.git/index' failed. Should I try again? (y/n) n\nerror: Could not write new index file.\nfatal: Could not reset index file to revision 'head'.\n\n",
        "all_answers": [
            "\nIn the vein of teaching how to fish: take a look at https://git.wiki.kernel.org/index.php/InterfacesFrontendsAndTools page on Git Wiki, which has section about GUIs.\nGit Homepage also has section about GUIs: http://git-scm.com/downloads/guis\n",
            "\nSource Tree (for MAC)\nScreenshot:\n\n",
            "\nLooks like the following process had a lock on the .git\\index file:\nssh-agent.exe\nC:\\Users\\Tom\\AppData\\Local\\GitHub\\PortableGit_8810fd5c2c79c73adcc73fd0825f3b32fdb816e7\\bin\\ssh-agent.exe\n\nI killed the process and ran git reset HEAD and looks like I'm back to normal now.\n",
            "\nWindows has TortoiseGit. It is not as mature as TortoiseSVN, but I've been using it and it works well enough for my purposes.\nScreenshot:\n\nEDIT [Dec 2014]: I'd also recommend looking at Dan's answer. Github's UI is probably the most mature/supported tool out there now (even if you don't use Github!)\n",
            "\nHere's one for Mac: GitX\nScreenshot:\n\n",
            "\nGitGui comes with git. It has always worked great for me. Is there some problem you have with it?\nScreenshot:\n\n",
            "\nTo discard local changes, go \ngit reset HEAD\n\nThen checkout your old commit, delete the new one, and pull again.\ngit checkout \"hashOld\"\ngit branch -d \"hashNew\"\ngit pull\n\n",
            "\nTry Git Extensions.\nScreenshot:\n\n",
            "\nI'm surprised nobody has mentioned Tower for Mac OSX.\nHere is a screenshot:\n\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "git",
            "windows-7",
            "github"
        ]
    },
    {
        "question_id": "1924939",
        "question": "\nWhich of these code will be faster?\n$temp = $_REQUEST['s'];\n\nor\nif (isset($_GET['s'])) {\n  $temp = $_GET['s'];\n}\nelse {\n  $temp = $_POST['s'];\n}\n\n",
        "all_answers": [
            "\nI would use the second method as it is more explicit. Otherwise you don't know where the variables are coming from.\nWhy do you need to check both GET and POST anyway? Surely using one or the other only makes more sense.\n",
            "\nUse REQUEST.  Nobody cares about the speed of such a simple operation, and it's much cleaner code.\n",
            "\n$_REQUEST, by default, contains the contents of $_GET, $_POST and $_COOKIE. \nBut it's only a default, which depends on variables_order ; and not sure you want to work with cookies.\nIf I had to choose, I would probably not use $_REQUEST, and I would choose $_GET or $_POST -- depending on what my application should do (i.e. one or the other, but not both) : generally speaking :\n\nYou should use $_GET when someone is requesting data from your application.\nAnd you should use $_POST when someone is pushing (inserting or updating ; or deleting) data to your application.\n\nEither way, there will not be much of a difference about performances : the difference will be negligible, compared to what the rest of your script will do.\n"
        ],
        "answer": "A3",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "743858",
        "question": "\nWhen you create an index on a column or number of columns in MS SQL Server (I'm using version 2005), you can specify that the index on each column be either ascending or descending. I'm having a hard time understanding why this choice is even here. Using binary sort techniques, wouldn't a lookup be just as fast either way? What difference does it make which order I choose?\n",
        "all_answers": [
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nThe sort order matters when you want to retrieve lots of sorted data, not individual records.\nNote that (as you are suggesting with your question) the sort order is typically far less significant than what columns you are indexing (the system can read the index in reverse if the order is opposite what it wants). I rarely give index sort order any thought, whereas I agonize over the columns covered by the index.\n@Quassnoi provides a great example of when it does matter.\n",
            "\nThis primarily matters when used with composite indexes:\nCREATE INDEX ix_index ON mytable (col1, col2 DESC);\n\ncan be used for either:\nSELECT  *\nFROM    mytable\nORDER BY\n        col1, col2 DESC\n\nor:\nSELECT  *\nFROM    mytable\nORDER BY\n        col1 DESC, col2\n\n, but not for:\nSELECT  *\nFROM    mytable\nORDER BY\n        col1, col2\n\nAn index on a single column can be efficiently used for sorting in both ways.\nSee the article in my blog for details:\n\nDescending indexes\n\nUpdate:\nIn fact, this can matter even for a single column index, though it's not so obvious.\nImagine an index on a column of a clustered table:\nCREATE TABLE mytable (\n       pk INT NOT NULL PRIMARY KEY,\n       col1 INT NOT NULL\n)\nCREATE INDEX ix_mytable_col1 ON mytable (col1)\n\nThe index on col1 keeps ordered values of col1 along with the references to rows.\nSince the table is clustered, the references to rows are actually the values of the pk. They are also ordered within each value of col1.\nThis means that that leaves of the index are actually ordered on (col1, pk), and this query:\nSELECT  col1, pk\nFROM    mytable\nORDER BY\n        col1, pk\n\nneeds no sorting.\nIf we create the index as following:\nCREATE INDEX ix_mytable_col1_desc ON mytable (col1 DESC)\n\n, then the values of col1 will be sorted descending, but the values of pk within each value of col1 will be sorted ascending.\nThis means that the following query:\nSELECT  col1, pk\nFROM    mytable\nORDER BY\n        col1, pk DESC\n\ncan be served by ix_mytable_col1_desc but not by ix_mytable_col1.\nIn other words, the columns that constitute a CLUSTERED INDEX on any table are always the trailing columns of any other index on that table.\n"
        ],
        "answer": "A3",
        "tags": [
            "sql",
            "sql-server",
            "optimization",
            "indexing"
        ]
    },
    {
        "question_id": "2004491",
        "question": "\nSymbols are usually represented as such\n:book_author_title\n\nbut if I have a string:\n\"Book Author Title\"\n\nis there a built in way in rails/ruby to convert it into a symbol where I can use the :  notation without just doing a raw string regex replace?\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nRails got ActiveSupport::CoreExtensions::String::Inflections module that provides such methods. They're all worth looking at. For your example:\n'Book Author Title'.parameterize.underscore.to_sym # :book_author_title\n\n",
            "\nfrom: http://ruby-doc.org/core/classes/String.html#M000809\nstr.intern => symbol\nstr.to_sym => symbol\n\nReturns the Symbol corresponding to str, creating the symbol if it did not previously exist. See Symbol#id2name.\n\"Koala\".intern         #=> :Koala\ns = 'cat'.to_sym       #=> :cat\ns == :cat              #=> true\ns = '@cat'.to_sym      #=> :@cat\ns == :@cat             #=> true\n\nThis can also be used to create symbols that cannot be represented using the :xxx notation.\n'cat and dog'.to_sym   #=> :\"cat and dog\"\n\nBut for your example ...\n\"Book Author Title\".gsub(/\\s+/, \"_\").downcase.to_sym\n\nshould go ;)\n",
            "\nIn Rails you can do this using underscore method:\n\"Book Author Title\".delete(' ').underscore.to_sym\n=> :book_author_title\n\nThe simpler code is using regex (works with Ruby):\n\"Book Author Title\".downcase.gsub(/\\s+/, \"_\").to_sym\n=> :book_author_title\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby"
        ]
    },
    {
        "question_id": "2473392",
        "question": "\nI have a form like:\n#forms.py\nfrom django import forms\n\nclass MyForm(forms.Form):\n    title = forms.CharField()\n    file = forms.FileField()\n\n\n#tests.py\nfrom django.test import TestCase\nfrom forms import MyForm\n\nclass FormTestCase(TestCase)\n    def test_form(self):\n        upload_file = open('path/to/file', 'r')\n        post_dict = {'title': 'Test Title'}\n        file_dict = {} #??????\n        form = MyForm(post_dict, file_dict)\n        self.assertTrue(form.is_valid())\n\nHow do I construct the file_dict to pass upload_file to the form?\n",
        "all_answers": [
            "\n\nHow do you mock users?\n\nInitialise a django.contrib.auth.models.User object. User.objects.create_user makes this easy.\n\nHow do you mock requests?\n\nInitialise a django.http.HttpRequest object.\nOf course, there are shortcuts depending on what you want to do. If you just need an object with a user attribute that points to a user, simply create something (anything) and give it that attribute.\n",
            "\nRead about mock objects here\nhttp://en.wikipedia.org/wiki/Mock_object\nhttp://www.mockobjects.com/\nAnd use this python lib to mock a user\nhttp://python-mock.sourceforge.net/\nelse you can write a simple User class yourself, use this as a starting point\nclass MockUser(object):\n    def __call__(self, *args, **kwargs):\n        return self\n\n    def __getattr__(Self, name):\n        return self\n\nadd specfic cases etc etc\n",
            "\nFor request, I would use RequestFactory included with Django.\nfrom django.test.client import RequestFactory\nrf = RequestFactory()\nget_request = rf.get('/hello/')\npost_request = rf.post('/submit/', {'foo': 'bar'})\n\nfor users, I would use django.contrib.auth.models.User as @ozan suggested and maybe with factory boy for speed (with factory boy you can choose to not to save to DB)\n",
            "\nThe place you want your data to be stored is your new model instance:\ndef save(self, commit=True):\n    instance = super(MyForm, self).save(commit=False)\n    instance.flag1 = 'flag1' in self.cleaned_data['multi_choice'] # etc\n    if commit:\n        instance.save()\n    return instance\n\n",
            "\nYou don't need to mock Users, as you can just create one within your test - the database is destroyed after the test is finished.\nTo mock requests, use this snippet from Simon Willison.\n",
            "\nYou can either roll your own mocks, as Anurag Uniyal has suggested, or you can use a mocking framework.\nIn response to those saying you can just create an ordinary user as you would anyway in Django... I would suggest this defeats the point of the unit test. A unit test shouldn't touch the database, but by creating a user, you've changed the database, hence why we would want to mock one.\n",
            "\nSo far I have found this way that works\nfrom django.core.files.uploadedfile import SimpleUploadedFile\n ...\ndef test_form(self):\n        upload_file = open('path/to/file', 'rb')\n        post_dict = {'title': 'Test Title'}\n        file_dict = {'file': SimpleUploadedFile(upload_file.name, upload_file.read())}\n        form = MyForm(post_dict, file_dict)\n        self.assertTrue(form.is_valid())\n\n",
            "\nMay be this is not quite correct, but I'm creating image file in unit test using StringIO:\nimgfile = StringIO('GIF87a\\x01\\x00\\x01\\x00\\x80\\x01\\x00\\x00\\x00\\x00ccc,\\x00'\n                     '\\x00\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\x02\\x02D\\x01\\x00;')\nimgfile.name = 'test_img_file.gif'\n\nresponse = self.client.post(url, {'file': imgfile})\n\n"
        ],
        "answer": "A7",
        "tags": [
            "django",
            "unit-testing",
            "django-forms"
        ]
    },
    {
        "question_id": "26181221",
        "question": "\nHow can I convert Int to UInt8 in Swift?\nExample. I want to convert number 22 to 0b00010110\nvar decimal = 22\nvar binary:UInt8 = ??? //What should I write here?\n\n",
        "all_answers": [
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nIf you want binary to have the value of 22, just assign it that: binary = 22 or you could write it as binary = 0b00010110; the two statements are equivalent.\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nYou can convert the decimal value to a human-readable binary representation using the String initializer that takes a radix parameter:\nlet num = 22\nlet str = String(num, radix: 2)\nprint(str) // prints \"10110\"\n\nIf you wanted to, you could also pad it with any number of zeroes pretty easily as well:\nSwift 5\nfunc pad(string : String, toSize: Int) -> String {\n  var padded = string\n  for _ in 0..<(toSize - string.count) {\n    padded = \"0\" + padded\n  }\n    return padded\n}\n\nlet num = 22\nlet str = String(num, radix: 2)\nprint(str) // 10110\npad(string: str, toSize: 8)  // 00010110\n\n"
        ],
        "answer": "A5",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "8919682",
        "question": "\nI'm creating a navigation menu with words with different colors (href links). I would like the color NOT to change on any state (hover, visited etc).\nI know how to set the the colors for the different states, but I would like to know the code to just leave the text color (and any other styling/formatting) as it is.\nAny Suggestions?\n",
        "all_answers": [
            "\nYou can just use an a selector in your stylesheet to define all states of an anchor/hyperlink. For example:\na {\n    color: blue;\n}\n\nWould override all link styles and make all the states the colour blue.\n",
            "\nYou can simply define a style for links, which would override a:hover, a:visited etc.:\na {\n  color: blue;\n  text-decoration: none; /* no underline */\n}\n\nYou can also use the inherit value if you want to use attributes from parent styles instead:\nbody {\n  color: blue;\n}\na {\n  color: inherit; /* blue colors for links too */\n  text-decoration: inherit; /* no underline */\n}\n\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nif you state a.redLink{color:red;} then to keep this on hover and such add a.redLink:hover{color:red;}  This will make sure no other hover states will change the color of your links\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n"
        ],
        "answer": "A2",
        "tags": [
            "html",
            "css",
            "href"
        ]
    },
    {
        "question_id": "6132721",
        "question": "\nIs there a way to use http_build_query() without having it URL encode according to some RFC standard?\nWhy I don't want to URL encode everything: I'm querying the Ebay API.. They honestly insist on parameter names not being URL encoded, as far as commas in parentheses.  E.g. DomainName(0) is a parameter, and the query fails if those parens are encoded.\n",
        "all_answers": [
            "\nNope, it appears to always want to encode (which it should, it is meant to URL encode when building a list of params for a URL).\nYou could make your own...\n$params = array('a' => 'A', 'b' => 'B');\n\n$paramsJoined = array();\n\nforeach($params as $param => $value) {\n   $paramsJoined[] = \"$param=$value\";\n}\n\n$query = implode('&', $paramsJoined);\n\nCodePad.\n",
            "\nYou might want to try their JSON API instead. I tried to get a working sample, but I don't have an app name so I can't verify the result. Here's the code:\n<?php\n$appName = \"Your App Name Here\";\n\n$post_data = array(\n  'jsonns.xsi' => 'http://www.w3.org/2001/XMLSchema-instance',\n  'jsonns.xs' => 'http://www.w3.org/2001/XMLSchema',\n  'jsonns.tns' => 'http://www.ebay.com/marketplace/search/v1/services',\n  'tns.findItemsByKeywordsRequest' => array(\n    'keywords' => 'harry potter pheonix'\n  )\n);\n\n$headers = array(\n  \"X-EBAY-SOA-REQUEST-DATA-FORMAT: JSON\", \n  \"X-EBAY-SOA-RESPONSE-DATA-FORMAT: JSON\",\n  \"X-EBAY-SOA-OPERATION-NAME: findItemsByKeywords\",\n  \"X-EBAY-SOA-SECURITY-APPNAME: $appName\"\n);\n\n$ch = curl_init();\n\ncurl_setopt($ch, CURLOPT_URL, 'http://svcs.ebay.com/services/search/FindingService/v1');\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\ncurl_setopt($ch, CURLOPT_POST, 1);\ncurl_setopt($ch, CURLOPT_POSTFIELDS, json_encode($post_data));\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);\n\n$result = curl_exec($ch);\nif($result) {\n  $response = json_decode($result);\n}\n\ncurl_close($ch);\n?>\n\nYou'll need to to fill $appName with whatever the name of the app is. Also the X-EBAY-SOA-OPERATION-NAME will need to be set to the actual call, and the JSON modified if the call is different.\n",
            "\nYou can use urldecode() function on a result string which you get from http_build_query()\n",
            "\nmy take on alex's answer but is faster\n$params = array('a' => 'A', 'b' => 'B');\n$query = '';\n\nforeach ($params as $param => $value) {\n   $query .= $param.'='.$value .'&';\n}\n\necho substr($query, 0, -1);\n\n"
        ],
        "answer": "A3",
        "tags": [
            "php",
            "urlencode"
        ]
    },
    {
        "question_id": "38198668",
        "question": "\nI've upgraded one of my apps from Rails 4.2.6 to Rails 5.0.0. The Upgrade Guide says, that the Autoload feature is now disabled in production by default.\nNow I always get an error on my production server since I load all lib files with autoload in the application.rb file.\nmodule MyApp\n    class Application < Rails::Application\n        config.autoload_paths += %W( lib/ )\n    end\nend\n\nFor now, I've set the config.enable_dependency_loading to true but I wonder if there is a better solution to this. There must be a reason that Autoloading is disabled in production by default.\n",
        "all_answers": [
            "\nAs of Rails 2.3.9, there is a setting in config/application.rb in which you can specify directories that contain files you want autoloaded.\nFrom application.rb:\n# Custom directories with classes and modules you want to be autoloadable.\n# config.autoload_paths += %W(#{config.root}/extras)\n\n",
            "\nAutoloading is disabled in the production environment because of thread safety. Thank you to @Зелёный for the link.\nI solved this problem by storing the lib files in a lib folder in my app directory as recommended on Github. Every folder in the app folder gets loaded by Rails automatically.\n",
            "\n# Autoload lib/ folder including all subdirectories\nconfig.autoload_paths += Dir[\"#{config.root}/lib/**/\"]\n\nSource: Rails 3 Quicktip: Autoload lib directory including all subdirectories, avoid lazy loading\nPlease mind that files contained in the lib folder are only loaded when the server is started. If you want the comfort to autoreload those files, read: Rails 3 Quicktip: Auto reload lib folders in development mode. Be aware that this is not meant for a production environment since the permanent reload slows down the machine.\n",
            "\n\nThere must be a reason that Autoloading is disabled in production by\n  default.\n\nHere is a long discussion about this issue. https://github.com/rails/rails/issues/13142\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "autoload",
            "ruby-on-rails-5"
        ]
    },
    {
        "question_id": "13671328",
        "question": "\nI am working on a small project with gist and since it is growing I would like to put it on github. \nLet's suppose that:\n\nmy gist repo is at: https://gist.github.com/1234\nmy new (empty) repo is at: https://github.com/ChrisJamesC/myNewProject\n\nThe ideal solution would be one that pushes my changes on both the gist and the github repository.\n",
        "all_answers": [
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nYou can add the github repository as a remote to your checked out gist repository.\ngit clone git@gist.github.com:1234.git\ngit remote add github git@github.com:ChrisJamesC/myNewProject.git\n\nPush it to initialize the git on github\ngit push -u github master\n\n\nIf your github repo wasn't quite empty (you created it with a README, license, etc. which you don't mind losing) you will have to do a force overwrite on your push\ngit push -f -u github master\n\nIf you don't want to lose the exiting commits and files, see https://stackoverflow.com/a/40408059/117471\n\nThis will also change the upstream of the branch, so github will be default.\nYou now can rename the remote of gist:\ngit remote rename origin gist\n\nEach time you make changes (or pull changes from github/gist), you can do:\ngit push                 # To github\ngit push gist master     # To gist\n\nThis will also push back your changes to the gist and not only the github repo.\n",
            "\nYou can clone the gist locally.\nAdd the github repository as new remote.\nPush your local repository to the new github remote.\nDelete all files in your gist but the README.md file . in this file you can write a hint that the gist has moved to a new repository\n",
            "\nGithub now has a new feature - import from another repository. So the steps are much simplified:\n\nUse the import feature and specify the URL of the repository.\nProfit!\n\nUpdate:\nYou don't have to create a repo. The + button in the top right corner now has 'Import Repository' as an option.\n\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nSorry for shaking an old question, and that I can't comment, but in the second step as given by gzm0 you may have to use --force, i.e.\ngit push -f -u github master\n\nIt may have been because there was a README in the Github repo, but I guess others may run into this too.\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nClone the gist (e.g. git clone git://gist.github.com/123.git) to your local harddrive, then set the new URL for origin (e.g. git remote set-url origin https://github.com/ChrisJamesC/myNewProject). Push to the new repository (git push origin master). Happy gitting!\n"
        ],
        "answer": "A5",
        "tags": [
            "git",
            "github",
            "gist"
        ]
    },
    {
        "question_id": "64349920",
        "question": "\nI getting this error when ever I do git clone\nError :-\nfatal: invalid branch name: init.defaultBranch =\nTried to reinstall git (latest)\nStill same error\nOS :- Windows\n\n",
        "all_answers": [
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nGot it\nEnter this in terminal\ngit config --global init.defaultBranch master\n",
            "\nIt would appear that you have experimented with the new (2.28) init.defaultBranch configuration value.\nAssign it a proper value:\ngit config --global init.defaultBranch main\n\n"
        ],
        "answer": "A3",
        "tags": [
            "git",
            "github"
        ]
    },
    {
        "question_id": "32795227",
        "question": "\nI just went over the alpha release notes for Django 1.9 and saw that the startapp management command now adds an apps.py file.\nWhat's the purpose of this file? The startapp documentation didn't provide more information.\n",
        "all_answers": [
            "\nPurpose of apps.py file:\nThis file is created to help the user include any application configuration for the app. Using this, you can configure some of the attributes of the application.\nFrom Application Configuration documentation:  \n\nApplication configuration objects store metadata for an application.\n  Some attributes can be configured in AppConfig subclasses. Others are\n  set by Django and read-only.\n\nExample from the docs:\nLets say you’re creating a pluggable app called \"Rock ’n’ roll\", then to provide a proper name for the admin we can do the following:\nIn rock_n_roll app, we create a RockNRollConfig AppConfig class. \n#rock_n_roll/apps.py\nfrom django.apps import AppConfig\n\nclass RockNRollConfig(AppConfig): # Our app config class\n    name = 'rock_n_roll'\n    verbose_name = \"Rock ’n’ roll\"\n\nWe can make your application load this AppConfig subclass by default by specifying the default_app_config in the rock_n_roll/__init__.py file.\n# rock_n_roll/__init__.py    \ndefault_app_config = 'rock_n_roll.apps.RockNRollConfig'\n\nDoing this will cause RockNRollConfig to be used when INSTALLED_APPS just contains 'rock_n_roll'. This allows us to make use of AppConfig features without requiring our users to update their INSTALLED_APPS setting.\n",
            "\nIt is the recommended place to put your application configuration. This feature has been here since 1.7, but to promote its use and enable easier configuration, the apps.py file has been added to the default app template. \n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A1",
        "tags": [
            "django"
        ]
    },
    {
        "question_id": "5847642",
        "question": "\nI've been reading the \"Real World Haskell\" book, the chapter on concurrency and parallelism. My question is as follows:\n\nSince Haskell threads are really just multiple \"virtual\" threads inside one \"real\" OS-thread, does this mean that creating a lot of them (like 1000) will not have a drastic impact on performance? I.e., can we say that the overhead incurred from creating a Haskell thread with forkIO is (almost) negligible? Please bring pactical examples if possible.\nDoesn't the concept of lightweight threads prevent us from using the benefints of multicore architectures? As I understand, it is not possible for two Haskell threads to execute concurrently on two separate cores, because they are really one single thread from the operating system's point of view. Or does the Haskell runtime do some clever tricks to ensure that multiple CPU's can be made use of? \n\n",
        "all_answers": [
            "\n\nThe Warp webserver uses these lightweight threads extensively to get really good performance. Note that the other Haskell web servers also smoke the competition: this is more of a \"Haskell is good\" than \"Warp is good.\"\nHaskell provides a multithreaded runtime which can distribute lightweight threads across multiple system threads. It works very well for up to 4 cores. Past that, there are some performance issues, though those are being actively worked on.\n\n",
            "\nI have also been looking for such a book, they are very hard to come by. This one will be released in May, if that's any help:\nhttp://www.manning.com/williams/\nI purchased this book:\nhttp://www.amazon.co.uk/gp/product/0123705916/ref=oss_product\nIt's very good, it's in java, but most of the principles apply to c/c++ anyway.\n",
            "\nCreating 1000 processes is relatively light weight; don't worry about doing it. As for performance, you should just benchmark it.\nAs has been pointed out before, multiple cores work just fine.  Several Haskell threads can run at the same time by being scheduled on different OS threads. \n",
            "\nGHC's runtime provides an execution environment supporting billions of sparks, thousands of lightweight threads, which may be distributed over multiple hardware cores. Compile with -threaded and use the +RTS -N4 flags to set your desired number of cores. \n\nSpecifically:\n\ndoes this mean that creating a lot of them (like 1000) will not have a drastic impact on performance?\n\nWell, creating 1,000,000 of them is certainly possible. 1000 is so cheap it won't even show up. You can see in thread creation benchmarks, such as \"thread ring\" that GHC is very, very good.\n\nDoesn't the concept of lightweight threads prevent us from using the benefints of multicore architectures?\n\nNot at all. GHC has been running on multicores since 2004. The current status of the multicore runtime is tracked here.\nHow does it do it? The best place to read up on this architecture is in the paper, \"Runtime Support for Multicore Haskell\":\n\nThe GHC runtime system supports millions of lightweight threads\n  by multiplexing them onto a handful of operating system threads,\n  roughly one for each physical CPU. ...\nHaskell threads are executed by a set of operating system\n  threads, which we call worker threads. We maintain roughly one\n  worker thread per physical CPU, but exactly which worker thread\n  may vary from moment to moment ...\nSince the worker thread may change, we maintain exactly one\n  Haskell Execution Context (HEC) for each CPU. The HEC is a\n  data structure that contains all the data that an OS worker thread\n  requires in order to execute Haskell threads\n\nYou can monitor your threads being created, and where they're executing, via threadscope.. Here, e.g. running the binary-trees benchmark:\n\n"
        ],
        "answer": "A4",
        "tags": [
            "multithreading",
            "haskell",
            "concurrency",
            "multicore",
            "lightweight-processes"
        ]
    },
    {
        "question_id": "31096130",
        "question": "\nI have a date object that's created by the user, with the timezone filled in by the browser, like so:\nvar date = new Date(2011, 05, 07, 04, 0, 0);\n> Tue Jun 07 2011 04:00:00 GMT+1000 (E. Australia Standard Time)\n\nWhen I stringify it, though, the timezone goes bye-bye\nJSON.stringify(date);\n> \"2011-06-06T18:00:00.000Z\"\n\nThe best way I can get a ISO8601 string while preserving the browser's timezone is by using moment.js and using moment.format(), but of course that won't work if I'm serializing a whole command via something that uses JSON.stringify internally (in this case, AngularJS)\nvar command = { time: date, contents: 'foo' };\n$http.post('/Notes/Add', command);\n\nFor completeness, my domain does need both the local time and the offset.\n",
        "all_answers": [
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n",
            "\nAssuming you have some kind of object that contains a Date:\nvar o = { d : new Date() };\n\nYou can override the toJSON function of the Date prototype.  Here I use moment.js to create a moment object from the date, then use moment's format function without parameters, which emits the ISO8601 extended format including the offset.\nDate.prototype.toJSON = function(){ return moment(this).format(); }\n\nNow when you serialize the object, it will use the date format you asked for:\nvar json = JSON.stringify(o);  //  '{\"d\":\"2015-06-28T13:51:13-07:00\"}'\n\nOf course, that will affect all Date objects.  If you want to change the behavior of only the specific date object, you can override just that particular object's toJSON function, like this:\no.d.toJSON = function(){ return moment(this).format(); }\n\n",
            "\n\nWhen I stringify it, though, the timezone goes bye-bye\n\nThat’s because Tue Jun 07 2011 04:00:00 GMT+1000 (E. Australia Standard Time) is actually the result of the toString method of the Date object, whereas stringify seems to call the toISOString method instead.\nSo if the toString format is what you want, then simply stringify that:\nJSON.stringify(date.toString());\n\nOr, since you want to stringify your “command” later on, put that value in there in the first place:\nvar command = { time: date.toString(), contents: 'foo' };\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "json",
            "date",
            "datetime",
            "momentjs"
        ]
    },
    {
        "question_id": "662773",
        "question": "\nSomething like:\nusing (IDisposable disposable = GetSomeDisposable())\n{\n    //.....\n    //......\n    return Stg();\n}\n\nI believe it is not a proper place for a return statement, is it?\n",
        "all_answers": [
            "\nSince a lot of people still do:\nusing (System.IO.StreamReader r = new System.IO.StreamReader(\"\"))\nusing (System.IO.StreamReader r2 = new System.IO.StreamReader(\"\")) {\n   //code\n}\n\nI guess a lot of people still don't know that you can do:\nusing (System.IO.StreamReader r = new System.IO.StreamReader(\"\"), r2 = new System.IO.StreamReader(\"\")) {\n   //code\n}\n\n",
            "\nThe reason for the using statement is to ensure that the object is disposed as soon as it goes out of scope, and it doesn't require explicit code to ensure that this happens.\nAs in Understanding the 'using' statement in C# (codeproject) and Using objects that implement IDisposable (microsoft), the C# compiler converts\nusing (MyResource myRes = new MyResource())\n{\n    myRes.DoSomething();\n}\n\nto\n{ // Limits scope of myRes\n    MyResource myRes= new MyResource();\n    try\n    {\n        myRes.DoSomething();\n    }\n    finally\n    {\n        // Check for a null resource.\n        if (myRes != null)\n            // Call the object's Dispose method.\n            ((IDisposable)myRes).Dispose();\n    }\n}\n\nC# 8 introduces a new syntax, named \"using declarations\":\n\nA using declaration is a variable declaration preceded by the using keyword. It tells the compiler that the variable being declared should be disposed at the end of the enclosing scope.\n\nSo the equivalent code of above would be:\nusing var myRes = new MyResource();\nmyRes.DoSomething();\n\nAnd when control leaves the containing scope (usually a method, but it can also be a code block), myRes will be disposed.\n",
            "\nThis will work perfectly fine, just as returning in the middle of try{}finally{}\n",
            "\nIt's perfectly fine.\nYou are apparently thinking that \nusing (IDisposable disposable = GetSomeDisposable())\n{\n    //.....\n    //......\n    return Stg();\n}\n\nis blindly translated into:\nIDisposable disposable = GetSomeDisposable()\n//.....\n//......\nreturn Stg();\ndisposable.Dispose();\n\nWhich, admittedly, would be a problem, and would make the using statement rather pointless --- which is why that's not what it does.  \nThe compiler makes sure that the object is disposed before control leaves the block -- regardless of how it leaves the block.\n",
            "\nIt's absolutely fine - no problem at all. Why do you believe it's wrong?\nA using statement is just syntactic sugar for a try/finally block, and as Grzenio says it's fine to return from a try block too.\nThe return expression will be evaluated, then the finally block will be executed, then the method will return.\n",
            "\nAs several others have pointed out in general this is not a problem.\nThe only case it will cause you issues is if you return in the middle of a using statement and additionally return the in using variable.  But then again, this would also cause you issues even if you didn't return and simply kept a reference to a variable.  \nusing ( var x = new Something() ) { \n  // not a good idea\n  return x;\n}\n\nJust as bad\nSomething y;\nusing ( var x = new Something() ) {\n  y = x;\n}\n\n",
            "\nThat is totally acceptable. A using statement ensures the IDisposable object will be disposed no matter what.\nFrom MSDN:\n\nThe using statement ensures that Dispose is called even if an exception occurs while you are calling methods on the object. You can achieve the same result by putting the object inside a try block and then calling Dispose in a finally block; in fact, this is how the using statement is translated by the compiler.\n\n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            "dispose",
            "idisposable",
            "using-statement"
        ]
    },
    {
        "question_id": "1882692",
        "question": "\nIn C#, when you do\nClass(Type param1, Type param2) : base(param1) \n\nis the constructor of the class executed first, and then the superclass constructor is called or does it call the base constructor first?\n",
        "all_answers": [
            "\nThe constructor of the baseclass is called first.\n",
            "\nNo, not exactly. But it can inherit from a class and implement one or more interfaces.\nClear terminology is important when discussing concepts like this. One of the things that you'll see mark out Jon Skeet's writing, for example, both here and in print, is that he is always precise in the way he decribes things.\n",
            "\nIt will call the base constructor first. Also keep in mind that if you don't put the :base(param1) after your constructor, the base's empty constructor will be called.\n",
            "\nThe order is:\n\nMember variables are initialized to default values for all classes in the hierarchy\n\nThen starting with the most derived class:\n\nVariable initializers are executed for the most-derived type\nConstructor chaining works out which base class constructor is going to be called\nThe base class is initialized (recurse all of this :)\nThe constructor bodies in the chain in this class are executed (note that there can be more than one if they're chained with Foo() : this(...) etc\n\nNote that in Java, the base class is initialized before variable initializers are run. If you ever port any code, this is an important difference to know about :)\nI have a page with more details if you're interested.\n",
            "\nYes. Try:\nclass USBDevice : GenericDevice, IOurDevice\n\nNote: The base class should come before the list of interface names.\nOf course, you'll still need to implement all the members that the interfaces define. However, if the base class contains a member that matches an interface member, the base class member can work as the implementation of the interface member and you are not required to manually implement it again.\n",
            "\n[Edit: in the time it took me to answer, the question had totally changed].\nThe answer is that it calls the base first.\n[Original answer to the old question below]\nAre you asking when you would do the \"base\" bit of the constructor call?\nIf so, you would \"chain\" a call to the constructor base if the class is derived from another class which has this constructor:\n  public class CollisionBase\n    {\n        public CollisionBase(Body body, GameObject entity)\n        {\n\n        }\n    }\n\n    public class TerrainCollision : CollisionBase\n    {\n        public TerrainCollision(Body body, GameObject entity)\n            : base(body, entity)\n        {\n\n        }\n    }\n\nIn this example, TerrainCollision derives from CollisionBase. By chaining the constructors in this way, it ensures the specified constructor is called on the base class with the supplied parameters, rather than the default constructor (if there is one on the base)\n",
            "\nYour question is a bit unclear but I'm assuming you meant to ask the following\n\nWhen to I call the base constructor for my XNA object vs. using the impilict default constructor \n\nThe answer to this is highly dependent on both your scenario and the underlying object.  Could you clarify a bit wit the following\n\nWhat is the scenario\nWhat is the type of the base object of TerrainCollision?\n\nMy best answer though is that in the case where you have parameters that line up with the parameters of the base class`s constructor, you should almost certainly be calling it.  \n"
        ],
        "answer": "A4",
        "tags": [
            "c#",
            "inheritance",
            "constructor",
            "constructor-chaining"
        ]
    },
    {
        "question_id": "768969",
        "question": "\nWhat's the correct way to pass a bundle to the activity that is being launched from the current one? Shared properties?\n",
        "all_answers": [
            "\nYou have a few options:\n1) Use the Bundle from the Intent:\nIntent mIntent = new Intent(this, Example.class);\nBundle extras = mIntent.getExtras();\nextras.putString(key, value);  \n\n2) Create a new Bundle\nIntent mIntent = new Intent(this, Example.class);\nBundle mBundle = new Bundle();\nmBundle.putString(key, value);\nmIntent.putExtras(mBundle);\n\n3) Use the putExtra() shortcut method of the Intent\nIntent mIntent = new Intent(this, Example.class);\nmIntent.putExtra(key, value);\n\n\nThen, in the launched Activity, you would read them via:\nString value = getIntent().getExtras().getString(key)\n\nNOTE: Bundles have \"get\" and \"put\" methods for all the primitive types, Parcelables, and Serializables. I just used Strings for demonstrational purposes.\n",
            "\nThis answer is specific to situations where the objects to be passed has nested class structure. With nested class structure, making it Parcelable or Serializeable is a bit tedious. And, the process of serialising an object is not efficient on Android. Consider the example below,\nclass Myclass    {\n  int a;\n  class SubClass    {\n       int b;\n  }\n}\n\nWith Google's GSON library, you can directly parse an object into a JSON formatted String and convert it back to the object format after usage. For example,\nMyClass src = new MyClass();\nGson gS = new Gson();\nString target = gS.toJson(src); // Converts the object to a JSON String\n\nNow you can pass this String across activities as a StringExtra with the activity intent.\nIntent i = new Intent(FromActivity.this, ToActivity.class);\ni.putExtra(\"MyObjectAsString\", target);\n\nThen in the receiving activity, create the original object from the string representation.\nString target = getIntent().getStringExtra(\"MyObjectAsString\");\nMyClass src = gS.fromJson(target, MyClass.class); // Converts the JSON String to an Object\n\nIt keeps the original classes clean and reusable. Above of all, if these class objects are created from the web as JSON objects, then this solution is very efficient and time saving.\nUPDATE\n\nWhile the above explained method works for most situations, for obvious performance reasons, do not rely on Android's bundled-extra system to pass objects around. There are a number of solutions makes this process flexible and efficient, here are a few. Each has its own pros and cons.\n\nEventbus\nOtto\n\n",
            "\nWhen you are creating an object of intent, you can take advantage of following two methods\nfor passing objects between two activities.\nputParcelable\nputSerializable\nYou can have your class implement either Parcelable or Serializable. Then you can pass around your custom classes across activities. I have found this very useful.\nHere is a small snippet of code I am using\nCustomListing currentListing = new CustomListing();\nIntent i = new Intent();\nBundle b = new Bundle();\nb.putParcelable(Constants.CUSTOM_LISTING, currentListing);\ni.putExtras(b);\ni.setClass(this, SearchDetailsActivity.class);\nstartActivity(i);\n\nAnd in newly started activity code will be something like this...\nBundle b = this.getIntent().getExtras();\nif (b != null)\n    mCurrentListing = b.getParcelable(Constants.CUSTOM_LISTING);\n\n",
            "\nYou can use the Bundle from the Intent:\nBundle extras = myIntent.getExtras();\nextras.put*(info);\n\nOr an entire bundle:\nmyIntent.putExtras(myBundle);\n\nIs this what you're looking for?\n",
            "\nYou can create a subclass of Application and store your shared object there.  The Application object should exist for the lifetime of your app as long as there is some active component.\nFrom your activities, you can access the application object via getApplication().\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "android-activity",
            "bundle"
        ]
    },
    {
        "question_id": "106206",
        "question": "\nI'm writing an import utility that is using phone numbers as a unique key within the import.\nI need to check that the phone number does not already exist in my DB. The problem is that   phone numbers in the DB could have things like dashes and parenthesis and possibly other things. I wrote a function to remove these things, the problem is that it is slow and with thousands of records in my DB and thousands of records to import at once, this process can be unacceptably slow. I've already made the phone number column an index.\nI tried using the script from this post:\nT-SQL trim &nbsp (and other non-alphanumeric characters)\nBut that didn't speed it up any.\nIs there a faster way to remove non-numeric characters? Something that can perform well when 10,000 to 100,000 records have to be compared.\nWhatever is done needs to perform fast.\nUpdate\nGiven what people responded with, I think I'm going to have to clean the fields before I run the import utility. \nTo answer the question of what I'm writing the import utility in, it is a C# app. I'm comparing BIGINT to BIGINT now, with no need to alter DB data and I'm still taking a performance hit with a very small set of data (about 2000 records). \nCould comparing BIGINT to BIGINT be slowing things down?\nI've optimized the code side of my app as much as I can (removed regexes, removed unneccessary DB calls). Although I can't isolate SQL as the source of the problem anymore, I still feel like it is.\n",
        "all_answers": [
            "\ncan you remove them in a nightly process, storing them in a separate field, then do an update on changed records right before you run the process?\nOr on the insert/update, store the \"numeric\" format, to reference later.  A trigger would be an easy way to do it.\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nI may misunderstand, but you've got two sets of data to remove the strings from one for current data in the database and then a new set whenever you import.\nFor updating the existing records, I would just use SQL, that only has to happen once.\nHowever, SQL isn't optimized for this sort of operation, since you said you are writing an import utility, I would do those updates in the context of the import utility itself, not in SQL.  This would be much better performance wise.  What are you writing the utility in?\nAlso, I may be completely misunderstanding the process, so I apologize if off-base.\nEdit: \nFor the initial update, if you are using SQL Server 2005, you could try a CLR function.  Here's a quick one using regex.  Not sure how the performance would compare, I've never used this myself except for a quick test right now.\nusing System;  \nusing System.Data;  \nusing System.Text.RegularExpressions;  \nusing System.Data.SqlClient;  \nusing System.Data.SqlTypes;  \nusing Microsoft.SqlServer.Server;  \n\npublic partial class UserDefinedFunctions  \n{  \n    [Microsoft.SqlServer.Server.SqlFunction]  \n    public static SqlString StripNonNumeric(SqlString input)  \n    {  \n        Regex regEx = new Regex(@\"\\D\");  \n        return regEx.Replace(input.Value, \"\");  \n    }  \n};  \n\nAfter this is deployed, to update you could just use:\nUPDATE table SET phoneNumber = dbo.StripNonNumeric(phoneNumber)\n\n"
        ],
        "answer": "A3",
        "tags": [
            "sql",
            "sql-server",
            "performance",
            "optimization"
        ]
    },
    {
        "question_id": "18434364",
        "question": "\nIn Django, we can get the time user last logged in by using Auth.User.last_login.  That is only updated when the user logs in using his username/password.  Suppose the user is already logged in and the authentication information is saved in a cookie, therefore is able to access the site without logging in.  How can we get the date the user previously visited the site?  This would be useful for queries such as getting the number of new records since the last visit.\n",
        "all_answers": [
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nExample model:\nclass User(models.Model):\n    last_visit = models.DateTimeField(...)\n    ...\n\nExample middleware which will be executed for all logged-in users:\nfrom django.utils.timezone import now\n\nclass SetLastVisitMiddleware(object):\n    def process_response(self, request, response):\n        if request.user.is_authenticated():\n            # Update last visit time after request finished processing.\n            User.objects.filter(pk=request.user.pk).update(last_visit=now())\n        return response\n\nAdd the new middleware to Your settings.py:\nMIDDLEWARE_CLASSES = (\n    ...\n    'path.to.your.SetLastVisitMiddleware',\n    ...\n)\n\nWarning: not tested, but doesn't require external packages to be installed and it's only 5 lines of code.\nSee more in the docs about Middleware and custom user models (since Django 1.5)\n",
            "\nI would go for django-last-seen\nUsage:\nfrom last_seen.model import LastSeen\n\nseen = LastSeen.object.when(user=user)\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A2",
        "tags": [
            "django"
        ]
    },
    {
        "question_id": "137359",
        "question": "\nI produce a report as an CSV file.\nWhen I try to open the file in Excel, it makes an assumption about the data type based on the contents of the cell, and reformats it accordingly.\nFor example, if the CSV file contains\n...,005,...\n\nThen Excel shows it as 5.\nIs there a way to override this and display 005?\nI would prefer to do something to the file itself, so that the user could just double-click on the CSV file to open it.\nI use Excel 2003.\n",
        "all_answers": [
            "\nIf you want to group by Years as well - hold down the Ctrl Key whilst you select the Month (both categories will then show up)\n",
            "\nYou can simply format your range as Text.\nAlso here is a nice article on the number formats and how you can program them.\n",
            "\nThere isn’t an easy way to control the formatting Excel applies when opening a .csv file.  However listed below are three approaches that might help.\nMy preference is the first option.\nOption 1 – Change the data in the file\nYou could change the data in the .csv file as follows ...,=”005”,...\nThis will be displayed in Excel as ...,005,...\nExcel will have kept the data as a formula, but copying the column and using paste special values will get rid of the formula but retain the formatting\nOption 2 – Format the data\nIf it is simply a format issue and all your data in that column has a three digits length.  Then open the data in Excel and then format the column containing the data with this custom format 000\nOption 3 – Change the file extension to .dif (Data interchange format)\nChange the file extension and use the file import wizard to control the formats.\nFiles with a .dif extension are automatically opened by Excel when double clicked on.\nStep by step:\n\nChange the file extension from .csv to .dif\nDouble click on the file to open it in Excel.\nThe 'File Import Wizard' will be launched.\nSet the 'File type' to 'Delimited' and click on the 'Next' button.\nUnder Delimiters, tick 'Comma' and click on the 'Next' button.\nClick on each column of your data that is displayed and select a 'Column data format'.  The column with the value '005' should be formatted as 'Text'.\nClick on the finish button, the file will be opened by Excel with the formats that you have specified.\n\n",
            "\nActually I discovered that, at least starting with Office 2003, you can save an Excel spreadsheet as an XML file.\nThus, I can produce an XML file and when I double-click on it, it'll be opened in Excel.\nIt provides the same level of control as SYLK, but XML syntax is more intuitive.\n",
            "\nI believe when you import the file you can select the Column Type.  Make it Text instead of Number.  I don't have a copy in front of me at the moment to check though.\n",
            "\nDon't use CSV, use SYLK.\nhttp://en.wikipedia.org/wiki/SYmbolic_LinK_(SYLK)\nIt gives much more control over formatting, and Excel won't try to guess the type of a field by examining the contents.  It looks a bit complicated, but you can get away with using a very small subset.\n",
            "\nWhen opening a CSV, you get the text import wizard.  At the last step of the wizard, you should be able to import the specific column as text, thereby retaining the '00' prefix.  After that you can then format the cell any way that you want.\nI tried with with Excel 2007 and it appeared to work.\n",
            "\nTry creating a pivot chart, then grouping the dates by month (right-click a date in the pivot table, and click \"Group by... Month\".\n"
        ],
        "answer": "A3",
        "tags": [
            "excel",
            "csv",
            "formatting",
            "number-formatting"
        ]
    },
    {
        "question_id": "33725862",
        "question": "\nI am trying to connect to SQL through python to run some queries on some SQL databases on Microsoft SQL server. From my research online and on this forum the most promising library seems to be pyodbc. So I have made the following code \nimport pyodbc\nconn = pyodbc.connect(init_string=\"driver={SQLOLEDB}; server=+ServerName+; \ndatabase=+MSQLDatabase+; trusted_connection=true\")\ncursor = conn.cursor()\n\nand get the following error\nTraceback (most recent call last):\n  File \"C:\\Users...\\scrap.py\", line 3, in <module>\n    conn = pyodbc.connect(init_string=\"driver={SQLOLEDB}; server=+ServerName+; database=+MSQLDatabase+; trusted_connection=true\")\npyodbc.Error: ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')\n\nI have looked at the folowing posts and tried changing my driver to {sql server} and have connected using ODBC links before in SAS, which is partially what my above code is based on, so don't think I need to install anything else.\npyodbc.Error: ('IM002', '[IM002] [unixODBC][Driver Manager]Data source name not found, and no default driver specified (0) (SQLDriverConnect)')\nPyodbc - \"Data source name not found, and no default driver specified\"\nThanks\n",
        "all_answers": [
            "\nIn data source connections between a client and server there are two general types: ODBC which uses a DRIVER and OLEDB which uses a PROVIDER. And in the programming world, it is a regular debate as to which route to go in connecting to data sources. \nYou are using a provider, SQLOLEDB, but specifying it as a driver. As far as I know, neither the pyodbc nor pypyodbc modules support Window OLEDB connections. However, the adodbapi does which uses the Microsoft ADO as an underlying component.\nBelow are both approaches for your connection parameters. Also, I string format your variables as your concatenation did not properly break quotes within string. You'll notice I double the curly braces since it is needed in connection string and string.format() also uses it.\n# PROVIDER\nimport adodbapi\nconn = adodbapi.connect(\"PROVIDER=SQLOLEDB;Data Source={0};Database={1}; \\\n       trusted_connection=yes;UID={2};PWD={3};\".format(ServerName,MSQLDatabase,username,password))\ncursor = conn.cursor()\n\n# DRIVER\nimport pyodbc\nconn = pyodbc.connect(\"DRIVER={{SQL Server}};SERVER={0}; database={1}; \\\n       trusted_connection=yes;UID={2};PWD={3}\".format(ServerName,MSQLDatabase,username,password))\ncursor = conn.cursor()\n\n",
            "\nThis is how I do it...\nimport pyodbc \ncnxn = pyodbc.connect(\"Driver={SQL Server Native Client 11.0};\"\n                      \"Server=server_name;\"\n                      \"Database=db_name;\"\n                      \"Trusted_Connection=yes;\")\n\n\ncursor = cnxn.cursor()\ncursor.execute('SELECT * FROM Table')\n\nfor row in cursor:\n    print('row = %r' % (row,))\n\nRelevant resources:\n\nhttps://github.com/mkleehammer/pyodbc/wiki/Connecting-to-SQL-Server-from-Windows\nhttp://blogs.msdn.com/b/cdndevs/archive/2015/03/11/python-and-data-sql-server-as-a-data-source-for-python-applications.aspx\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "sql",
            "windows"
        ]
    },
    {
        "question_id": "10069993",
        "question": "\nSo I perform a query to the db and I have a complete array of objects:\n@attachments = Job.find(1).attachments\n\nNow that I have an array of objects I don't want to perform another db query, but I would like to filter the array based on the Attachment object's file_type so that I can have a list of attachments where the file type is 'logo' and then another list of attachments where the file type is 'image'\nSomething like this:\n@logos  = @attachments.where(\"file_type = ?\", 'logo')\n@images = @attachments.where(\"file_type = ?\", 'image')\n\nBut in memory instead of a db query.\n",
        "all_answers": [
            "\nhave you tried eager loading? \n@attachments = Job.includes(:attachments).find(1).attachments\n\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nTry :\nThis is fine :\n@logos = @attachments.select { |attachment| attachment.file_type == 'logo' }\n@images = @attachments.select { |attachment| attachment.file_type == 'image' }\n\nbut for performance wise you don't need to iterate @attachments twice :\n@logos , @images = [], []\n@attachments.each do |attachment|\n  @logos << attachment if attachment.file_type == 'logo'\n  @images << attachment if attachment.file_type == 'image'\nend\n\n",
            "\nIf your attachments are \n@attachments = Job.find(1).attachments\n\nThis will be array of attachment objects\nUse select method to filter based on file_type.\n@logos = @attachments.select { |attachment| attachment.file_type == 'logo' }\n@images = @attachments.select { |attachment| attachment.file_type == 'image' }\n\nThis will not trigger any db query.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "activerecord"
        ]
    },
    {
        "question_id": "57035746",
        "question": "\nI'd like to create a text view inside a circle view. The font size should be automatically set to fit the size of the circle. How can this be done in SwiftUI? I tried scaledToFill and scaledToFit modifiers, but they have no effect on the Text view:\nstruct ContentView : View {\n    var body: some View {\n        ZStack {\n            Circle().strokeBorder(Color.red, lineWidth: 30)\n            Text(\"Text\").scaledToFill()\n        }\n    }\n}\n\n",
        "all_answers": [
            "\nOne possible \"hack\" is to use a big font size and a small scale factor so it will shrink itself:\nZStack {\n    Circle().strokeBorder(Color.red, lineWidth: 30)\n\n    Text(\"Text\")\n        .padding(40)\n        .font(.system(size: 500))\n        .minimumScaleFactor(0.01)\n     }\n}\n\n",
            "\nOne can use GeometryReader in order to make it also work in landscape mode.\nIt first checks if the width or the height is smaller and then adjusts the font size according to the smaller of these.\nGeometryReader{g in\n    ZStack {\n        Circle().strokeBorder(Color.red, lineWidth: 30)\n        Text(\"Text\")\n            .font(.system(size: g.size.height > g.size.width ? g.size.width * 0.4: g.size.height * 0.4))\n    }\n}\n\n\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nTo achieve this you don't need the ZStack. You can add a background to the Text:\nText(\"Text text text?\")\n    .padding()\n    .background(\n       Circle()\n          .strokeBorder(Color.red, lineWidth: 10)\n          .scaledToFill()\n          .foregroundColor(Color.white)\n    )\n\nThe result is this:\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n"
        ],
        "answer": "A2",
        "tags": [
            "swift",
            "swiftui"
        ]
    },
    {
        "question_id": "3794420",
        "question": "\nI know that if I am modifying a control from a different thread, I should take care because WinForms and WPF don't allow modifying control's state from other threads.\nWhy is this restriction in place?\nIf I can write thread-safe code, I should be able to modify control state safely. Then why is this restriction present?\n",
        "all_answers": [
            "\n.NET reserves the right to access your control in the thread where you created it at any time.  Therefore accesses that come from another thread can never be thread safe.\n",
            "\nSeveral GUI frameworks have this limitation. According to the book Java Concurrency in Practice the reason for this is to avoid complex locking. The problem is that GUI controls may have to react to both events from the UI, data binding and so forth, which leads to locking from several different sources and thus a risk of deadlocks. To avoid this .NET WinForms (and other UIs) restricts access to components to a single thread and thus avoids locking. \n",
            "\nYou can use join() to wait for all threads to finish. Like below:\nfor (int i = 0; i < 10; i++) \n{\n    Thread T1 = new Thread(new ThreadTest(i));                \n    T1.start();   \n    try {             \n       T1.join(); \n    } catch (InterruptedException e) {\n       e.printStackTrace();\n    }\n}\n\n",
            "\nBetter alternatives to join() method have been evolved over a period of time.\nExecutorService.html#invokeAll is one alternative.\n\nExecutes the given tasks, returning a list of Futures holding their status and results when all complete. Future.isDone() is true for each element of the returned list. \n\nNote that a completed task could have terminated either normally or by throwing an exception. The results of this method are undefined if the given collection is modified while this operation is in progress.\nForkJoinPool or Executors.html#newWorkStealingPool provides other alternatives to achieve the same purpose. \nExample code snippet:\n\nimport java.util.concurrent.*;\n\nimport java.util.*;\n\npublic class InvokeAllDemo{\n    public InvokeAllDemo(){\n        System.out.println(\"creating service\");\n        ExecutorService service = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\n\n        List<MyCallable> futureList = new ArrayList<MyCallable>();\n        for ( int i=0; i<10; i++){\n            MyCallable myCallable = new MyCallable((long)i);\n            futureList.add(myCallable);\n        }\n        System.out.println(\"Start\");\n        try{\n            List<Future<Long>> futures = service.invokeAll(futureList);  \n        }catch(Exception err){\n            err.printStackTrace();\n        }\n        System.out.println(\"Completed\");\n        service.shutdown();\n    }\n    public static void main(String args[]){\n        InvokeAllDemo demo = new InvokeAllDemo();\n    }\n    class MyCallable implements Callable<Long>{\n        Long id = 0L;\n        public MyCallable(Long val){\n            this.id = val;\n        }\n        public Long call(){\n            // Add your business logic\n            return id;\n        }\n    }\n}\n\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "multithreading"
        ]
    },
    {
        "question_id": "4717352",
        "question": "\nI'm terribly new to scripting on windows. Using windows 7 64.\nI'm trying to make a .bat file that I can double click, and have it open a command prompt and automatically cd me to a certain directory.\nI tried making a .bat file with\n@ECHO OFF\ncmd \"cd C:\\my\\destination\"\n\nWhich opens what looks like a command prompt, but doesn't seem to let me type any commands.\nI then tried:\n@ECHO OFF\nstart cmd \"cd C:\\my\\destination\"\n\nBut this just sent me into a loop opening tons and tons of prompts until my computer crashed :) The .bat file was located in the destination directory if that matters.\n",
        "all_answers": [
            "\nUse the /K switch:\n@ECHO OFF\nstart cmd.exe /K \"cd C:\\my\\destination\"\n\nBut IMHO, the most useful switch is /?. \nStarts a new instance of the Windows XP command interpreter\n\nCMD [/A | /U] [/Q] [/D] [/E:ON | /E:OFF] [/F:ON | /F:OFF] [/V:ON | /V:OFF]\n    [[/S] [/C | /K] string]\n\n/C      Carries out the command specified by string and then terminates\n/K      Carries out the command specified by string but remains\n/S      Modifies the treatment of string after /C or /K (see below)\n/Q      Turns echo off\n...\n\nAnd only if it does not work, then Google it, as @Neeraj suggested :D\n",
            "\nThis works for me:\n@ECHO OFF\ncmd.exe /K \"cd C:\\my\\destination && C:\"\n\nThe quoted string is actually two commands (separated by a double ampersand): The first command is to change to the specified directory, the second command is to change to the specified drive letter.\nPut this in a batch (.BAT) file and when you execute it you should see a Command Prompt window at the specified directory.\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "command-line",
            "batch-file"
        ]
    },
    {
        "question_id": "35074209",
        "question": "\nI've been using iPython (aka Jupyter) quite a bit lately for data analysis and some machine learning. But one big headache is copying results from the notebook app (browser) into either Excel or Google Sheets so I can manipulate results or share them with people who don't use iPython.\nI know how to convert results to csv and save. But then I have to dig through my computer, open the results and paste them into Excel or Google Sheets. That takes too much time.\nAnd just highlighting a resulting dataframe and copy/pasting usually completely messes up the formatting, with columns overflowing. (Not to mention the issue of long resulting dataframes being truncated when printed in iPython.)\nHow can I easily copy/paste an iPython result into a spreadsheet? \n",
        "all_answers": [
            "\nTry using the to_clipboard() method. E.g., for a dataframe, df: df.to_clipboard() will copy said dataframe to your clipboard. You can then paste it into Excel or Google Docs.\n",
            "\nThere is a way to make it more pythonic (works with three or more letters and uses less magic numbers):\ndef col2num(col):\n    num = 0\n    for c in col:\n        if c in string.ascii_letters:\n            num = num * 26 + (ord(c.upper()) - ord('A')) + 1\n    return num\n\nAnd as a one-liner using reduce (does not check input and is less readable so I don't recommend it):\ncol2num = lambda col: reduce(lambda x, y: x*26 + y, [ord(c.upper()) - ord('A') + 1 for c in col])\n\n",
            "\nIf you are able to make the csv or html available and reachable by a url - you can use this in google sheets.\n=IMPORTDATA(\"url to the csv/html file\")\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "excel",
            "google-sheets",
            "ipython",
            "jupyter-notebook"
        ]
    },
    {
        "question_id": "13896666",
        "question": "\nI am currently testing In-App Billing for a future app, and after I successfully \"bought\" the test item \"android.test.purchased\" the first time, I now receive the response code 7 every time I try to buy it again, which means that I already own this item.\n\n12-15 23:02:14.149: E/IabHelper(19829): In-app billing error: Unable\n  to buy item, Error response: 7:Item Already Owned\n\nFrom what I understand, this purchase is supposed to always be possible, right? So that the developer can test his/her app?\nIf not, how can I \"reset\" its state to not owned? I am using the util package from the Google In-App Billing Sample.\n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nIt turns out that the android.test.purchased item behaves like a regular ID. It means that if you want be able to buy it again, you have to consume it somewhere in your code. I think that the Google documentation is misleading on this matter, and that they should add another static ID that you can buy endlessly for test purposes.\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nThis is the difference between consumable and non-consumable items; non-consumable items (what you seem to be dealing with here) have their state tracked persistently, while consumable items can be purchased multiple times. You'll have to go into your Play management console and cancel/refund the sale to test it again.\n"
        ],
        "answer": "A4",
        "tags": [
            "android",
            "in-app-billing"
        ]
    },
    {
        "question_id": "4264127",
        "question": "\nWhat is the correct format specifier for double in printf? Is it %f or is it %lf? I believe it's %f, but I am not sure.\nCode sample\n#include <stdio.h>\n\nint main()\n{\n   double d = 1.4;\n   printf(\"%lf\", d); // Is this wrong?\n}\n\n",
        "all_answers": [
            "\nWhy C++ doesn't have support for unsigned floats is because there is no equivalent machine code operations for the CPU to execute.  So it would be very inefficient to support it.  \nIf C++ did support it, then you would be sometimes using an unsigned float and not realizing that your performance has just been killed.  If C++ supported it then every floating point operation would need to be checked to see if it is signed or not.  And for programs that do millions of floating point operations, this is not acceptable. \nSo the question would be why don't hardware implementers support it.  And I think the answer to that is that there was no unsigned float standard defined originally.  Since languages like to be backwards compatible, even if it were added languages couldn't make use of it.  To see the floating point spec you should look at the IEEE standard 754 Floating-Point.\nYou can get around not having an unsigned floating point type though by creating a unsigned float class that encapsulates a float or double and throws warnings if you try to pass in a negative number.   This is less efficient, but probably if you aren't using them intensely you won't care about that slight performance loss.\nI definitely see the usefulness of having an unsigned float.  But C/C++ tends to chose efficiency that works best for everyone over safety. \n",
            "\n%Lf (note the capital L) is the format specifier for long doubles.\nFor plain doubles, either %e, %E, %f, %g or %G will do.\n",
            "\nIt can be %f, %g or %e depending on how you want the number to be formatted. See here for more details. The l modifier is required in scanf with double, but not in printf.\n",
            "\n\"%f\" is the (or at least one) correct format for a double. There is no format for a float, because if you attempt to pass a float to printf, it'll be promoted to double before printf receives it1. \"%lf\" is also acceptable under the current standard -- the l is specified as having no effect if followed by the f conversion specifier (among others).\nNote that this is one place that printf format strings differ substantially from scanf (and fscanf, etc.) format strings. For output, you're passing a value, which will be promoted from float to double when passed as a variadic parameter. For input you're passing a pointer, which is not promoted, so you have to tell scanf whether you want to read a float or a double, so for scanf, %f means you want to read a float and %lf means you want to read a double (and, for what it's worth, for a long double, you use %Lf for either printf or scanf).\n\n\n1. C99, §6.5.2.2/6: \"If the expression that denotes the called function has a type that does not include a prototype, the integer promotions are performed on each argument, and arguments that have type float are promoted to double. These are called the default argument promotions.\" In C++ the wording is somewhat different (e.g., it doesn't use the word \"prototype\") but the effect is the same: all the variadic parameters undergo default promotions before they're received by the function.\n\n"
        ],
        "answer": "A4",
        "tags": [
            "c",
            "floating-point",
            "printf",
            "double",
            "format-specifiers"
        ]
    },
    {
        "question_id": "63312642",
        "question": "\nI recently downloaded the Nodejs file from the official site and I don't know how to install the Nodejs from a archived file.\nPlease help me how can I install this file so that I can run the \"npm\" command from the CLI for installation of several packages for my own project.\n",
        "all_answers": [
            "\nIt seems to be a problem with @angular-devkit/build-angular.\nTry updating it by running \nnpm i @angular-devkit/build-angular\n\nOr downgrading it by specifying a previous version, such as\nnpm i @angular-devkit/[email protected]\n\n",
            "\ni am new using linux, i use elementary for my old pc, so, i use\nsudo apt install nodejs\n\nand then\nsudo apt install npm\n\nbut was a old version of node and npm so...npm cache clean -f and then npm install -g n\nso the last thing i use sudo n stable and is all node v14 installed :)\n",
            "\nSteps to download and install node in ubuntu\nStep 1: Download latest or recommended node .tar.xz file from https://nodejs.org/en/\nor you can download node version 14.15.5 (.tar.xz file) directly from here ->\nhttps://nodejs.org/dist/v14.15.5/node-v14.15.5-linux-x64.tar.xz\nStep 2: Go to the directory in which (.tar.xz file) is downloaded.\nIn my case --> /Download directory\nStep 3: Update System Repositories\nsudo apt update\nStep 4: Install the package xz-utils\nsudo apt install xz-utils\nStep 5: To Extract the .tar.xz file\nsudo tar -xvf name_of_file\nIn my case -->  sudo tar -xvf node-v14.15.5-linux-x64.tar.xz\nStep 6: sudo cp -r directory_name/{bin,include,lib,share} /usr/\nIn my case --> sudo cp -r node-v14.15.5-linux-x64/{bin,include,lib,share} /usr/\nStep 7: Update the Path export PATH=/usr/node_directory_name/bin:$PATH\nIn my case --> export PATH=/usr/node-v14.15.5-linux-x64/bin:$PATH\nStep 8: Check the node version\nnode --version\nResult In my case -> v14.15.5\n",
            "\nI had this error after npm audit found vulnerabilities in the version of @angular-devkit/build-angular that I was using. I ran npm audit fix which updated it to 0.900.2, but when I ran ng serve it gave the error quoted in the question.\nI resolved it by downgrading to version 0.803.25. This was the highest version I could find which did not cause any errors when running ng serve. The vulnerabilities found by npm audit are resolved in this version.\nThis is the command I ran:\nnpm i @angular-devkit/[email protected]\n\n",
            "\nI found the answer finally!\nif anyone is struggling with .tar.xz files then follow the below steps for installation:\n\nEXTRACT THE FILE (Use either terminal or right-click on the file and click \"Extract here\", file archive will extract the xxxxxx.tar.xz file and you will get a folder with the same your file name xxxxxx)\n\nCopy the entire folder(xxxxxx folder) to /usr/\n\n\n\nyou may need to sudo prefix to copy that folder into /usr/\ncommand to copy is\n#sudo cp -r /path-to-the-folder/xxxxxx(sub_folder_name-1,sub_folder_name-2,....) /usr/\n\nThere you go.now the program/software is installed and you can use it using your teminal.\n"
        ],
        "answer": "A3",
        "tags": [
            "node.js",
            "node-modules",
            "npm-install"
        ]
    },
    {
        "question_id": "1276763",
        "question": "\nI only want the Keys and not the Values of a Dictionary.\nI haven't been able to get any code to do this yet. Using another array proved to be too much work as I use remove also.\nHow do I get a List of the Keys in a Dictionary?\n",
        "all_answers": [
            "\nYou should be able to just look at .Keys:\n    Dictionary<string, int> data = new Dictionary<string, int>();\n    data.Add(\"abc\", 123);\n    data.Add(\"def\", 456);\n    foreach (string key in data.Keys)\n    {\n        Console.WriteLine(key);\n    }\n\n",
            "\nusing System.Linq;\n\n...\ndouble total = myList.Sum(item => item.Amount);\n\n",
            "\nAnd if you need to do it on items that match a specific condition...\ndouble total = myList.Where(item => item.Name == \"Eggs\").Sum(item => item.Amount);\n\n",
            "\nUse the Dictionary<TKey,TValue>.Keys property:\nList<string> keyList = new List<string>(this.yourDictionary.Keys);\n\n",
            "\nYour status-codes are also a collection, so use Contains:\nvar allowedStatus = new[]{ \"A\", \"B\", \"C\" };\nvar filteredOrders = orders.Order.Where(o => allowedStatus.Contains(o.StatusCode));\n\nor in query syntax:\nvar filteredOrders = from order in orders.Order\n                     where allowedStatus.Contains(order.StatusCode)\n                     select order;\n\n",
            "\nNB: this is LINQ to objects, I am not 100% sure if it works in LINQ to entities, and have no time to check it right now. In fact it isn't too difficult to translate it to x in [A, B, C] but you have to check for yourself.\nSo, instead of Contains as a replacement of the ???? in your code you can use Any which is more LINQ-uish:\n// Filter the orders based on the order status\nvar filteredOrders = from order in orders.Order\n                     where new[] { \"A\", \"B\", \"C\" }.Any(s => s == order.StatusCode)\n                     select order;\n\nIt's the opposite to what you know from SQL this is why it is not so obvious.\nOf course, if you prefer fluent syntax here it is:\nvar filteredOrders = orders.Order.Where(order => new[] {\"A\", \"B\", \"C\"}.Any(s => s == order.StatusCode));\n\nHere we again see one of the LINQ surprises (like Joda-speech which puts select at the end). However it is quite logical in this sense that it checks if at least one of the items (that is any) in a list (set, collection) matches a single value.\n",
            "\nAs of .NET Core 2.0, the constructor Dictionary<TKey,TValue>(IEnumerable<KeyValuePair<TKey,TValue>>) now exists.\n",
            "\nAnother alternative:\nmyPlanetsList.Select(i => i.Moons).Sum();\n\n",
            "\nTry with Contains function;\n\nDetermines whether a sequence contains a specified element.\n\nvar allowedStatus = new[]{ \"A\", \"B\", \"C\" };\nvar filteredOrders = orders.Order.Where(o => allowedStatus.Contains(o.StatusCode));\n\n",
            "\nIf you're using .NET 3.5 or .NET 4, it's easy to create the dictionary using LINQ:\nDictionary<string, ArrayList> result = target.GetComponents()\n                                      .ToDictionary(x => x.Key, x => x.Value);\n\nThere's no such thing as an IEnumerable<T1, T2> but a KeyValuePair<TKey, TValue> is fine.\n",
            "\nvar statuses = new[] { \"A\", \"B\", \"C\" };\n\nvar filteredOrders = from order in orders.Order\n                             where statuses.Contains(order.StatusCode)\n                             select order;\n\n"
        ],
        "answer": "A4",
        "tags": [
            "c#",
            "list",
            "dictionary"
        ]
    },
    {
        "question_id": "14830669",
        "question": "\nI'm using this to login the user in:\ndef login_backend(request):\n    if request.method == 'POST':\n        username = request.POST['username']\n        password = request.POST['password']\n        user = authenticate(username=username, password=password)\n        if user is not None:\n            login(request, user)\n            request.session.set_expiry(300)\n            return HttpResponseRedirect('/overview/')\n        else:\n            return HttpResponseRedirect('/login_backend/')\n    else:\n        return render_to_response('login_backend.html', context_instance=RequestContext(request))\n\nI want session to expire after 5mins thus I added request.session.set_expiry(300) in the view above. But the session is never expiring. What am I doing wrong?\n",
        "all_answers": [
            "\nThere are two parameters to expire sessions, SESSION_EXPIRE_AT_BROWSER_CLOSE and SESSION_COOKIE_AGE.\nIf you want to expire in 5 minutes yours settings should like as:\nSESSION_EXPIRE_AT_BROWSER_CLOSE = False\nSESSION_COOKIE_AGE = 5 * 60\n\nTo combine both learn how do it writing your custom middleware \"Is there a way to combine behavior of SESSION_EXPIRE_AT_BROWSER_CLOSE and SESSION_COOKIE_AGE\"\n",
            "\nDepending on your project, this might not be sufficient.\nFor example, what if the user spends 6 minutes filling a form and clicks \"Save\" ? Browser will be redirected to the login page and form data will be lost.\nAlso, there is a potential security issue if the user leaves his workstation with confidential data in an opened page of the browser.\nAlso, what if the user reads a page during 6 minutes ? It is then not really cool to log him out without warning or any way to extend his session ...\nConsidering these matters, you might find django-session-security useful.\n",
            "\nUpdate for Django 1.6\nThe middleware code below is not working in Django 1.6 and above version because of json serializable. To make it work in all versions of Django, put the session serializer.\nsettings.py\n#Handle session is not Json Serializable\nSESSION_SERIALIZER = 'django.contrib.sessions.serializers.PickleSerializer'\n\nThe above sample of serializer is for Django 1.6. Kindly search for other version. Thanks...\nCreate middleware.py\nfrom datetime import datetime, timedelta\nfrom django.conf import settings\nfrom django.contrib import auth\n\n\nclass AutoLogout:\n  def process_request(self, request):\n    if not request.user.is_authenticated() :\n      #Can't log out if not logged in\n      return\n\n    try:\n      if datetime.now() - request.session['last_touch'] > timedelta( 0, settings.AUTO_LOGOUT_DELAY * 60, 0):\n        auth.logout(request)\n        del request.session['last_touch']\n        return\n    except KeyError:\n      pass\n\n    request.session['last_touch'] = datetime.now()\n\nUpdate your settings.py:\nMIDDLEWARE_CLASSES = [\n    .........................\n\n    'app_name.middleware.AutoLogout', \n]\n\n# Auto logout delay in minutes\nAUTO_LOGOUT_DELAY = 5 #equivalent to 5 minutes\n\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "python-3.x",
            "django",
            "django-views",
            "django-sessions"
        ]
    },
    {
        "question_id": "541430",
        "question": "\nHow should I read any header in PHP?\nFor example the custom header: X-Requested-With.\n",
        "all_answers": [
            "\nIF: you only need a single header, instead of all headers, the quickest method is:\n<?php\n// Replace XXXXXX_XXXX with the name of the header you need in UPPERCASE (and with '-' replaced by '_')\n$headerStringValue = $_SERVER['HTTP_XXXXXX_XXXX'];\n\n\nELSE IF: you run PHP as an Apache module or, as of PHP 5.4, using FastCGI (simple method):\napache_request_headers()\n<?php\n$headers = apache_request_headers();\n\nforeach ($headers as $header => $value) {\n    echo \"$header: $value <br />\\n\";\n}\n\n\nELSE: In any other case, you can use (userland implementation):\n<?php\nfunction getRequestHeaders() {\n    $headers = array();\n    foreach($_SERVER as $key => $value) {\n        if (substr($key, 0, 5) <> 'HTTP_') {\n            continue;\n        }\n        $header = str_replace(' ', '-', ucwords(str_replace('_', ' ', strtolower(substr($key, 5)))));\n        $headers[$header] = $value;\n    }\n    return $headers;\n}\n\n$headers = getRequestHeaders();\n\nforeach ($headers as $header => $value) {\n    echo \"$header: $value <br />\\n\";\n}\n\n\nSee Also:\ngetallheaders() - (PHP >= 5.4) cross platform edition Alias of apache_request_headers()\napache_response_headers() - Fetch all HTTP response headers.\nheaders_list() - Fetch a list of headers to be sent.\n",
            "\n$_SERVER['HTTP_X_REQUESTED_WITH']\n\nRFC3875, 4.1.18:\n\nMeta-variables with names beginning with HTTP_ contain values read from the client request header fields, if the protocol used is HTTP. The HTTP header field name is converted to upper case, has all occurrences of - replaced with _ and has HTTP_ prepended to give the meta-variable name.\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "http-headers"
        ]
    },
    {
        "question_id": "31569051",
        "question": "\nI am fairly new to swift and Xcode and I am trying to make a tic tac toe game. I have everything figured out except how to draw a line through the three x's or o's. I have no idea on how to draw lines. I have looked on the web for the answer and can't figure it out.\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nIn general, you have to draw a path in Core Graphics. You can follow this example:\nlet context = UIGraphicsGetCurrentContext()\nCGContextSetLineWidth(context, 2.0)\nCGContextSetStrokeColorWithColor(context, color)\nCGContextMoveToPoint(context, startPoint)\nCGContextAddLineToPoint(context, endPoint)\nCGContextStrokePath(context)\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nTry looking into UIBezierPath, it will help you a lot for drawing lines. Here is documentation. Here is an example:\noverride func drawRect(rect: CGRect) {\n    let aPath = UIBezierPath()\n\n    aPath.move(to: CGPoint(x:<#start x#>, y:<#start y#>))\n    aPath.addLine(to: CGPoint(x: <#end x#>, y: <#end y#>))\n\n    // Keep using the method addLine until you get to the one where about to close the path\n    aPath.close()\n\n    // If you want to stroke it with a red color\n    UIColor.red.set()\n    aPath.lineWidth = <#line width#>\n    aPath.stroke()\n}\n\nMake sure you put this code in the drawRect, like in the example above.\nIf you need to update the drawing just call setNeedsDisplay() to update.\n"
        ],
        "answer": "A5",
        "tags": [
            "ios",
            "swift"
        ]
    },
    {
        "question_id": "24012511",
        "question": "\nHow do I use mathematical functions like sqrt(), floor(), round(), sin(), etc?\n\nWhen doing:\n_ = floor(2.0)\n_ = sqrt(2.0)\n\nI get:\n\nerror: use of unresolved identifier 'floor'\n  error: use of unresolved identifier 'sqrt'  \n\n\n",
        "all_answers": [
            "\nAs other noted you have several options. If you want only mathematical functions. You can import only Darwin.\nimport Darwin\n\nIf you want mathematical functions and other standard classes and functions. You can import Foundation.\nimport Foundation\n\nIf you want everything and also classes for user interface, it depends if your playground is for OS X or iOS.\nFor OS X, you need import Cocoa.\nimport Cocoa\n\nFor iOS, you need import UIKit.\nimport UIKit\n\nYou can easily discover your playground platform by opening File Inspector (⌥⌘1).\n\n",
            "\nYou can use them right inline:\nvar square = 9.4\nvar floored = floor(square)\nvar root = sqrt(floored)\n\nprintln(\"Starting with \\(square), we rounded down to \\(floored), then took the square root to end up with \\(root)\")\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n"
        ],
        "answer": "A1",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "16113570",
        "question": "\nI am trying to add a new column to my MYSQL table using PHP. I am unsure how to alter my table so that the new column is created. In my assessment table I have:\nassessmentid | q1 | q2 | q3 | q4 | q5 \n\nSay I have a page with a textbox and I type q6 in to the textbox and press a button then the table is updated to:\nassessmentid | q1 | q2 | q3 | q4 | q5 | q6\n\nMy code:\n<?php \n  mysql_query(\"ALTER TABLE `assessment` ADD newq INT(1) NOT NULL AFTER `q10`\");\n?>\n  <form method=\"post\" action=\"\">\n    <input type=\"text\" name=\"newq\" size=\"20\">\n    <input type=\"submit\" name=\"submit\" value=\"Submit\">\n\n",
        "all_answers": [
            "\nSomething like:\n$db = mysqli_connect(\"localhost\", \"user\", \"password\", \"database\");\n$name = $db->mysqli_real_escape_string($name);\n$query = 'ALTER TABLE assesment ADD ' . $name . ' TINYINT NOT NULL DEFAULT \\'0\\'';\nif($db->query($query)) {\n    echo \"It worked\";\n}\n\nHaven't tested it but should work.\n",
            "\nyour table:\nq1 | q2 | q3 | q4 | q5\n\nyou can also do \nALTER TABLE yourtable ADD q6 VARCHAR( 255 ) after q5\n\n",
            "\n $table  = 'your table name';\n $column = 'q6'\n $add = mysql_query(\"ALTER TABLE $table ADD $column VARCHAR( 255 ) NOT NULL\");\n\nyou can change VARCHAR( 255 ) NOT NULL into what ever datatype you want.\n",
            "\nBased on your comment it looks like your'e only adding the new column if: mysql_query(\"SELECT * FROM assessment\"); returns false. That's probably not what you wanted. Try removing the '!' on front of $sql in the first 'if' statement. So your code will look like:\n$sql=mysql_query(\"SELECT * FROM assessment\");\nif ($sql) {\n mysql_query(\"ALTER TABLE assessment ADD q6 INT(1) NOT NULL AFTER q5\");\n echo 'Q6 created'; \n}else...\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "mysql",
            "addition",
            "alter"
        ]
    },
    {
        "question_id": "425132",
        "question": "\nThe following code\nusing System.Threading;\n\nclass Test\n{\n    volatile int counter = 0;\n    public void Increment()\n    {\n        Interlocked.Increment(ref counter);\n    }\n}\n\nRaises the following compiler warning:\n\"A reference to a volatile field will not be treated as volatile\"\n\nAm I doing something wrong here to raise this warning? Why does the compiler me warn about this?\n",
        "all_answers": [
            "\nHere is a good write up about .NET events and race conditions with threads.  It covers some common scenarios and has some good references in it.\nHope this helps.\n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nYou're getting the error because you're passing the field by reference. I think what this means is that the target method has no idea the field is marked as volatile, and therefore will not treat it as such.\n",
            "\nBasically the warning is that when you pass a volatile field by reference, the calling code doesn't know to treat it in a volatile manner. For Interlocked.Increment that probably doesn't matter, due to the nature of the method - but then you don't need the variable to be volatile anyway if you're using Interlocked.\nIn general, I think I'd avoid mixing the two - if you're using Interlocked, do it everywhere (using Interlocked.CompareExchange(ref counter, 0, 0) to read it). I can't say I use volatile very often, personally. For simple counters I might use Interlocked, but I'm more likely to use a lock for most tasks.\n",
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nYou are not doing anything wrong. According to the documentation:\n\nA volatile field should not normally\n  be passed using a ref or out\n  parameter, since it will not be\n  treated as volatile within the scope\n  of the function. There are exceptions\n  to this, such as when calling an\n  interlocked API.\n\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            ".net",
            "multithreading",
            "volatile"
        ]
    },
    {
        "question_id": "133357",
        "question": "\nHow do I find the name of the namespace or module 'Foo' in the filter below?\nclass ApplicationController < ActionController::Base\n  def get_module_name\n    @module_name = ???\n  end\nend\n\n\nclass Foo::BarController < ApplicationController\n  before_filter :get_module_name\nend\n\n",
        "all_answers": [
            "\nThis would work if the controller did have a module name, but would return the controller name if it did not.\nclass ApplicationController < ActionController::Base\n  def get_module_name\n    @module_name = self.class.name.split(\"::\").first\n  end\nend\n\nHowever, if we change this up a bit to:\nclass ApplicatioNController < ActionController::Base\n  def get_module_name\n    my_class_name = self.class.name\n    if my_class_name.index(\"::\").nil? then\n      @module_name = nil\n    else\n      @module_name = my_class_name.split(\"::\").first\n    end\n  end\nend\n\nYou can determine if the class has a module name or not and return something else other than the class name that you can test for.\n",
            "\nNone of these solutions consider a constant with multiple parent modules.  For instance:\nA::B::C\n\nAs of Rails 3.2.x you can simply:\n\"A::B::C\".deconstantize #=> \"A::B\"\n\nAs of Rails 3.1.x you can:\nconstant_name = \"A::B::C\"\nconstant_name.gsub( \"::#{constant_name.demodulize}\", '' )\n\nThis is because #demodulize is the opposite of #deconstantize:\n\"A::B::C\".demodulize #=> \"C\"\n\nIf you really need to do this manually, try this:\nconstant_name = \"A::B::C\"\nconstant_name.split( '::' )[0,constant_name.split( '::' ).length-1]\n\n",
            "\nI know this is an old thread, but I just came across the need to have separate navigation depending on the namespace of the controller. The solution I came up with was this in my application layout:\n<%= render \"#{controller.class.name[/^(\\w*)::\\w*$/, 1].try(:downcase)}/nav\" %>\n\nWhich looks a bit complicated but basically does the following - it takes the controller class name, which would be for example \"People\" for a non-namespaced controller, and \"Admin::Users\" for a namespaced one. Using the [] string method with a regular expression that returns anything before two colons, or nil if there's nothing. It then changes that to lower case (the \"try\" is there in case there is no namespace and nil is returned). This then leaves us with either the namespace or nil. Then it simply renders the partial with or without the namespace, for example no namespace:\napp/views/_nav.html.erb\n\nor in the admin namespace:\napp/views/admin/_nav.html.erb\n\nOf course these partials have to exist for each namespace otherwise an error occurs. Now the navigation for each namespace will appear for every controller without having to change any controller or view.\n",
            "\nThis should do it:\n  def get_module_name\n    @module_name = self.class.to_s.split(\"::\").first\n  end\n\n",
            "\nI don't think there is a cleaner way, and I've seen this somewhere else\nclass ApplicationController < ActionController::Base\n  def get_module_name\n    @module_name = self.class.name.split(\"::\").first\n  end\nend\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "namespaces"
        ]
    },
    {
        "question_id": "987072",
        "question": "\nIn an Android app, is there anything wrong with the following approach:\npublic class MyApp extends android.app.Application {\n\n    private static MyApp instance;\n\n    public MyApp() {\n        instance = this;\n    }\n\n    public static Context getContext() {\n        return instance;\n    }\n\n}\n\nand pass it everywhere (e.g. SQLiteOpenHelper) where context is required (and not leaking of course)?\n",
        "all_answers": [
            "\nIn my experience this approach shouldn't be necessary.  If you need the context for anything you can usually get it via a call to View.getContext() and using the Context obtained there you can call Context.getApplicationContext() to get the Application context.  If you are trying to get the Application context this from an Activity you can always call Activity.getApplication() which should be able to be passed as the Context needed for a call to SQLiteOpenHelper().\nOverall there doesn't seem to be a problem with your approach for this situation, but when dealing with Context just make sure you are not leaking memory anywhere as described on the official Google Android Developers blog.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nThere are a couple of potential problems with this approach, though in a lot of circumstances (such as your example) it will work well.\nIn particular you should be careful when dealing with anything that deals with the GUI that requires a Context. For example, if you pass the application Context into the LayoutInflater you will get an Exception. Generally speaking, your approach is excellent: it's good practice to use an Activity's Context within that Activity, and the Application Context when passing a context beyond the scope of an Activity to avoid memory leaks.\nAlso, as an alternative to your pattern you can use the shortcut of calling getApplicationContext() on a Context object (such as an Activity) to get the Application Context.\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "android-context"
        ]
    },
    {
        "question_id": "1137966",
        "question": "\nProblem: I have a large Visual C++ project that I'm trying to migrate to Visual Studio 2010.  It's a huge mix of stuff from various sources and of various ages.  I'm getting problems because something is including both winsock.h and winsock2.h.\nQuestion: What tools and techniques are there for displaying the #include hierarchy for a Visual Studio C++ source file?\nI know about cl /P for getting the preprocessor output, but that doesn't clearly show which file includes which other files (and in this case the /P output is 376,932 lines long 8-)\nIn a perfect world I'd like a hierarchical display of which files include which other files, along with line numbers so I can jump into the sources:\nsource.cpp(1)\n  windows.h(100)\n    winsock.h\n  some_other_thing.h(1234)\n    winsock2.h\n\n",
        "all_answers": [
            "\nSettings for compiler\nIn the project where you want to #include the header file from another project, you will need to add the path of the header file into the Additional Include Directories section in the project configuration.\nTo access the project configuration:\n\nRight-click on the project, and select Properties.\nSelect Configuration Properties->C/C++->General.\nSet the path under Additional Include Directories.\n\nHow to include\nTo include the header file, simply write the following in your code:\n#include \"filename.h\"\n\nNote that you don't need to specify the path here, because you include the directory in the Additional Include Directories already, so Visual Studio will know where to look for it.\nIf you don't want to add every header file location in the project settings, you could just include a directory up to a point, and then #include relative to that point:\n// In project settings\nAdditional Include Directories    ..\\..\\libroot\n\n// In code\n#include \"lib1/lib1.h\"    // path is relative to libroot\n#include \"lib2/lib2.h\"    // path is relative to libroot\n\nSetting for linker\nIf using static libraries (i.e. .lib file), you will also need to add the library to the linker input, so that at linkage time the symbols can be linked against (otherwise you'll get an unresolved symbol):\n\nRight-click on the project, and select Properties.\nSelect Configuration Properties->Linker->Input\nEnter the library under Additional Dependencies.\n\n",
            "\nThere is a setting:\nProject Settings -> Configuration Properties -> C/C++ -> Advanced -> Show Includes\nthat will generate the tree.  It maps to the compiler switch /showIncludes\n",
            "\ncl /P should show you the line numbers, such that you can tell the context of where a header file is being included from.\nIf you grep out the lines with ...\ngrep \"^#line\" file.i \n... then you should have a pretty clean indication of what files were encountered in order by the preprocessor.\nIf it's a one off incident this should be a pretty quick diagnostic.\n",
            "\nIncludeFinder is a good 3rd-party, FOSS tool.  You can export results to XML, which will include data on number of occurrences and line numbers.\n",
            "\nSince both projects are under the same solution, there's a simpler way for the include files and linker as described in https://learn.microsoft.com/en-us/cpp/build/adding-references-in-visual-cpp-projects?view=vs-2019 :\n\nThe include can be written in a relative path (E.g. #include \"../libProject/libHeader.h\").\nFor the linker, right click on \"References\", Click on Add Reference, and choose the other project.\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c++",
            "visual-studio",
            "include"
        ]
    },
    {
        "question_id": "3448831",
        "question": "\nI was wondering if it's possible to store the return json in a hidden input field. For example this is what my json return:\n[{\"id\":\"15aea3fa\",\"firstname\":\"John\",\"lastname\":\"Doe\"}]\n\nI would like to just store the id in a hidden field so I can reference it later to do something with it.\nExample: I have something like this:\n<input id=\"HiddenForId\" type=\"hidden\" value=\"\" />\n\nand would like jquery to return the value later to me like so:\nvar scheduletimeid = $('#HiddenForId').val();\n\n",
        "all_answers": [
            "\nvar array = new Array(); // or the shortcut: = []\narray.push ( {\"cool\":\"34.33\",\"also cool\":\"45454\"} );\narray.push (  {\"cool\":\"34.39\",\"also cool\":\"45459\"} );\n\nYour variable is a javascript object {} not an array [].\nYou could do:\nvar o = {}; // or the longer form: = new Object()\no.SomeNewProperty = \"something\";\no[\"SomeNewProperty\"] = \"something\";\n\nand\nvar o = { SomeNewProperty: \"something\" };\nvar o2 = { \"SomeNewProperty\": \"something\" };\n\nLater, you add those objects to your array: array.push (o, o2);\nAlso JSON is simply a string representation of a javascript object, thus:\nvar json = '{\"cool\":\"34.33\",\"alsocool\":\"45454\"}'; // is JSON\nvar o = JSON.parse(json); // is a javascript object\njson = JSON.stringify(o); // is JSON again\n\n",
            "\njust set the hidden field with javascript :\ndocument.getElementById('elementId').value = 'whatever';\n\nor do I miss something?\n",
            "\nYou can store it in a hidden field, OR store it in a javascript object (my preference) as the likely access will be via javascript.\nNOTE: since you have an array, this would then be accessed as myvariable[0] for the first element (as you have it).\nEDIT show example:\nclip...\n            success: function(msg)\n            {\n                LoadProviders(msg);\n            },\n...\n\nvar myvariable =\"\";\n\nfunction LoadProviders(jdata)\n{\n  myvariable = jdata;\n};\nalert(myvariable[0].id);// shows \"15aea3fa\" in the alert\n\nEDIT: Created this page:http://jsfiddle.net/GNyQn/ to demonstrate the above.  This example makes the assumption that you have already properly returned your named string values in the array and simply need to store it per OP question.  In the example, I also put the values of the first array returned (per OP example) into a div as text.\nI am not sure why this has been viewed as \"complex\" as I see no simpler way to handle these strings in this array.\n",
            "\nThat is an object, not an array. So you would do:\nvar json = { cool: 34.33, alsocool: 45454 };\njson.supercool = 3.14159;\nconsole.dir(json);\n\n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "jquery",
            "json"
        ]
    },
    {
        "question_id": "3995215",
        "question": "\nHow do I add and remove views such as TextViews from Android app like on the original stock Android contacts screen where you press a small icon on the right side of a field and it adds or deletes a field which consists of a TextView and an editTextView (from what I can see).\nAny examples on how to achieve this?\n",
        "all_answers": [
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nHi You can try this way by adding relative layout and than add textview in that. \nLinearLayout.LayoutParams lp = new LinearLayout.LayoutParams(\n            (LayoutParams.WRAP_CONTENT), (LayoutParams.WRAP_CONTENT));\n\nRelativeLayout relative = new RelativeLayout(getApplicationContext());\nrelative.setLayoutParams(lp);\n\nTextView tv = new TextView(getApplicationContext());\ntv.setLayoutParams(lp);\n\nEditText edittv = new EditText(getApplicationContext());\nedittv.setLayoutParams(lp);\n\nrelative.addView(tv);\nrelative.addView(edittv);\n\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nViewParents in general can't remove views, but ViewGroups can. You need to cast your parent to a ViewGroup (if it is a ViewGroup) to accomplish what you want. \nFor example:\nView namebar = View.findViewById(R.id.namebar);\n((ViewGroup) namebar.getParent()).removeView(namebar);\n\nNote that all Layouts are ViewGroups.\n",
            "\nViewGroup class provides API for child views management in run-time, allowing  to add/remove views as well.\nSome other links on the subject:\nAndroid, add new view without XML Layout\nAndroid Runtime Layout Tutorial\nhttp://developer.android.com/reference/android/view/View.html\nhttp://developer.android.com/reference/android/widget/LinearLayout.html\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n"
        ],
        "answer": "A6",
        "tags": [
            "android",
            "android-view"
        ]
    },
    {
        "question_id": "13600790",
        "question": "\nIn one of my project source files, I found this C function definition:\nint (foo) (int *bar)\n{\n    return foo (bar);\n}\n\nNote: there is no asterisk next to foo, so it's not a function pointer. Or is it?\nWhat is going on here with the recursive call?\n",
        "all_answers": [
            "\nstatic functions are functions that are only visible to other functions in the same file (more precisely the same translation unit).\nEDIT: For those who thought, that the author of the questions meant a 'class method': As the question is tagged C he means a plain old C function. For (C++/Java/...) class methods, static means that this method can be called on the class itself, no instance of that class necessary.\n",
            "\nIn the absence of any preprocessor stuff going on, foo's signature is equivalent to\nint foo (int *bar)\n\nThe only context in which I've seen people putting seemingly unnecessary parentheses around function names is when there are both a function and a function-like macro with the same name, and the programmer wants to prevent macro expansion.\nThis practice may seem a little odd at first, but the C library sets a precedent by providing some macros and functions with identical names.\nOne such function/macro pair is isdigit(). The library might define it as follows:\n/* the macro */\n#define isdigit(c) ...\n\n/* the function */\nint (isdigit)(int c) /* avoid the macro through the use of parentheses */\n{\n  return isdigit(c); /* use the macro */\n}\n\nYour function looks almost identical to the above, so I suspect this is what's going on in your code too.\n",
            "\nThe parentheses are meaningless.\nThe code you show is nothing but an infinite recursion.\nWhen defining a function pointer, you sometimes see strange parentheses that do mean something. But this isn't the case here.\n",
            "\nThere is a big difference between static functions in C and static member functions in C++.  In C, a static function is not visible outside of its translation unit, which is the object file it is compiled into.  In other words, making a function static limits its scope.  You can think of a static function as being \"private\" to its *.c file (although that is not strictly correct).\nIn C++, \"static\" can also apply to member functions and data members of classes.  A static data member is also called a \"class variable\", while a non-static data member is an \"instance variable\". This is Smalltalk terminology.  This means that there is only one copy of a static data member shared by all objects of a class, while each object has its own copy of a non-static data member.  So a static data member is essentially a global variable, that is a member of a class.\nNon-static member functions can access all data members of the class: static and non-static.  Static member functions can only operate on the static data members.\nOne way to think about this is that in C++ static data members and static member functions do not belong to any object, but to the entire class.\n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "function",
            "parentheses"
        ]
    },
    {
        "question_id": "8878676",
        "question": "\nWhen I compile C/C++ program with popen in php... I got this error:\ng++: error trying to exec 'cc1plus': execvp: No such file or directory\n\nbut if I run php code in shell.. it works fine..\nin Arch Linux..\nPHP Code:\n<?php\n    function rfile($fp) {\n    $out=\"\";\n       while (!feof($fp)) {\n           $out.= fgets($fp, 1024000);\n       }\n       return $out;\n    }\n    $p = popen('g++ -Wall -g aplusb.cc -o aplusb 2>&1', 'r');\n    $result = rfile($p);\n    pclose($p);\n    echo $result;\n?>\n\nthanks\n",
        "all_answers": [
            "\nI had the same issue with gcc \"gnat1\" and it was due to the path being wrong. Gnat1 was on version 4.6 but I was executing version 4.8.1, which I had installed. As a temporary solution, I copied gnat1 from 4.6 and pasted under the 4.8.1 folder. \nThe path to gcc on my computer is /usr/lib/gcc/i686-linux-gnu/\nYou can find the path by using the find command:\nfind /usr -name \"gnat1\"\n\nIn your case you would look for cc1plus:\nfind /usr -name \"cc1plus\"\n\nOf course, this is a quick solution and a more solid answer would be fixing the broken path.\n",
            "\nYou need to install gcc-c++ package.\nyum install gcc-c++\n\n",
            "\nEach compiler has its own libexec/ directory.  Normally libexec directory contains small helper programs called by other programs.  In this case, gcc is looking for its own 'cc1' compiler.  Your machine may contains different versions of gcc, and each version should have its own 'cc1'.  Normally these compilers are located on:\n\n/usr/local/libexec/gcc/<architecture>/<compiler>/<compiler_version>/cc1\n\nSimilar path for g++.  Above error means, that the current gcc version used is not able to find its own 'cc1' compiler.  This normally points to a PATH issue.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "c++",
            "c",
            "linux",
            "gcc"
        ]
    },
    {
        "question_id": "2173936",
        "question": "\nI'm trying to set the background color of a View (in this case a Button).\nI use this code:\n// set the background to green\nv.setBackgroundColor(0x0000FF00 );\nv.invalidate();\n\nIt causes the Button to disappear from the screen.   What am I doing wrong, and what is the correct way to change the background color on any View?\nThanks.\n",
        "all_answers": [
            "\nThis question talks about changing the background color of a view. In one of the answers, the person explains how to change the background color during runtime. Obviously you are going to look into how to modify other objects on the screen, but this should give you a good start by at least allowing you to modify the background color of the view on button click.\n",
            "\n\nand what is the correct way to change\n  the background color on any View?\n\nOn any View? What you have is correct, though you should drop the invalidate() call.\nHowever, some Views already have backgrounds. A Button, for example, already has a background: the face of the button itself. This background is a StateListDrawable, which you can find in android-2.1/data/res/drawable/btn_default.xml in your Android SDK installation. That, in turn, refers to a bunch of nine-patch bitmap images, available in multiple densities. You would need to clone and modify all of that to accomplish your green goals.\nIn short, you will be better served finding another UI pattern rather than attempting to change the background of a Button.\n",
            "\nYou made your button transparent. The first byte is the alpha.\nTry v.setBackgroundColor(0xFF00FF00);\n",
            "\n// set the background to green\nv.setBackgroundColor(0x0000FF00 );\nv.invalidate();\n\nThe code does not set the button to green. Instead, it makes the button totally invisible.\nExplanation: the hex value of the color is wrong. With an Alpha value of zero, the color will be invisible.\nThe correct hex value is 0xFF00FF00 for full opacity green. Any Alpha value between 00 and FF would cause transparency.\n",
            "\nWhen you call setBackgoundColor it overwrites/removes any existing background resource, including any borders, corners, padding, etc.\nWhat you want to do is change the color of the existing background resource...\nView v;\nv.getBackground().setColorFilter(Color.parseColor(\"#00ff00\"), PorterDuff.Mode.DARKEN);\n\nExperiment with PorterDuff.Mode.* for different effects.\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "view",
            "colors",
            "background",
            "set"
        ]
    },
    {
        "question_id": "4604239",
        "question": "\nIs possible to programmatically install a dynamically downloaded apk from a custom Android application.\n",
        "all_answers": [
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nYes it's possible. But for that you need the phone to install unverified sources. For example, slideMe does that. I think the best thing you can do is to check if the application is present and send an intent for the Android Market. you should use something the url scheme for android Market.\nmarket://details?id=package.name\n\nI don't know exactly how to start the activity but if you start an activity with that kind of url. It should open the android market and give you the choice to install the apps.\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nYou can easily launch a market link or an install prompt:\nIntent promptInstall = new Intent(Intent.ACTION_VIEW)\n    .setDataAndType(Uri.parse(\"file:///path/to/your.apk\"), \n                    \"application/vnd.android.package-archive\");\nstartActivity(promptInstall); \n\nsource\nIntent goToMarket = new Intent(Intent.ACTION_VIEW)\n    .setData(Uri.parse(\"market://details?id=com.package.name\"));\nstartActivity(goToMarket);\n\nsource\nHowever, you cannot install .apks without user's explicit permission; not unless the device and your program is rooted.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n"
        ],
        "answer": "A6",
        "tags": [
            "android",
            "apk"
        ]
    },
    {
        "question_id": "39576174",
        "question": "\nI have following input\n\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA7YAAAISCAIAAAB3YsSDAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAA5JxJREFUeNrsnQl4FEX6xqcJJEAS7ivhBkMAQTSJ4h0QEQ+I90rAc1cOL3QBXXV1AV1dVwmrsCqQ9VwJ6HoC7oon0T8iEkABwRC5IeE+kkAIkPT/nfmSmprunskk5CDw/p55hu7qOr76api8........\"\n\nI want to save this file in file field. What can I do?\nmodels.py\nclass SomeModel(models.Model):\n    file = models.FileField(upload_to=get_upload_report)\n    created = models.DateTimeField(auto_now_add=True)\n    modified = models.DateTimeField(auto_now=True)\n\nI'm trying to do this\ndef get_file(data):\n    from django.core.files import File\n    return File(data)\n\nand save return file to model instance\nsomemodel.file = get_file(image_base64_data)\n\nbut it's gives a following error\nAttributeError at /someurl/\n\n'File' object has no attribute 'decode'\n\n",
        "all_answers": [
            "\nimport base64\n\nfrom django.core.files.base import ContentFile\nformat, imgstr = data.split(';base64,') \next = format.split('/')[-1] \n\ndata = ContentFile(base64.b64decode(imgstr), name='temp.' + ext) # You can save this as file instance.\n\nUse this code snippet to decode the base64 string.\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nThis question looks like it should help: Django - how to create a file and save it to a model's FileField? \nYou should be able to decode the base64 string and supply that as the content argument to FieldFile.save: \n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django",
            "image",
            "filefield"
        ]
    },
    {
        "question_id": "43762338",
        "question": "\nSome time ago I added info(files) that must be private. Removing from the project is not problem, but I also need to remove it from git history.\nI use Git and Github (private account).\nNote: On this thread  something similar is shown, but here is an old file that was added to a feature branch, that branch merged to a development branch and finally merged to master, since this, a lot of changes was done. So it's not the same and what is needed is to change the history, and hide that files for privacy.\n",
        "all_answers": [
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nIf you have recently committed that file, or if that file has changed in one or two commits, then I'd suggest you use rebase and cherrypick to remove that particular commit.\nOtherwise, you'd have to rewrite the entire history.\ngit filter-branch --tree-filter 'rm -f <path_to_file>' HEAD\n\nWhen you are satisfied with the changes and have duly ensured that everything seems fine, you need to update all remote branches -\ngit push origin --force --all\n\nNote:- It's a complex operation, and you must be aware of what you are doing. First try doing it on a demo repository to see how it works. You also need to let other developers know about it, such that they don't make any change in the mean time.\n",
            "\nI have found this answer and it helped:\ngit filter-branch --index-filter 'git rm -rf --cached --ignore-unmatch path_to_file' HEAD\n\nFound it here https://myopswork.com/how-remove-files-completely-from-git-repository-history-47ed3e0c4c35\n"
        ],
        "answer": "A3",
        "tags": [
            "git",
            "github"
        ]
    },
    {
        "question_id": "2661062",
        "question": "\nI just installed the plugin for Paperclip and I am getting the following error message but I am not sure why:\nNoMethodError (undefined method `has_attached_file' for #<Class:0x10338acd0>):\n  /Users/bgadoci/.gem/ruby/1.8/gems/will_paginate-2.3.12/lib/will_paginate/finder.rb:170:in `method_missing'\n  app/models/post.rb:2\n  app/controllers/posts_controller.rb:50:in `show'\n\nIt is referencing the will_paginate gem. From what I can find, it seems that either there is something wrong with my PostsController#index or perhaps a previously attempt at installing the gem instead of the plugin, in which case I have read I should be able to remedy through the /config/environments.rb file somehow. \nI didn't think that previous gem installation would matter as I did it in an old version of the site that I trashed before installing the plugin. In the current version of the site I show that the table has been updated with the Paperclip columns after migration. Here is my code:\nPostsConroller#show:\n  def show\n    @post = Post.find(params[:id])\n\n    respond_to do |format|\n      format.html # show.html.erb\n      format.xml  { render :xml => @post }\n    end\n  end\n\nPost model:\nclass Post < ActiveRecord::Base\n\n  has_attached_file :photo\n  validates_presence_of :body, :title\n  has_many :comments, :dependent => :destroy\n  has_many :tags, :dependent => :destroy\n  has_many :votes, :dependent => :destroy\n  belongs_to :user\n  after_create :self_vote\n      def self_vote\n       # I am assuming you have a user_id field in `posts` and `votes` table.\n       self.votes.create(:user => self.user)\n      end\n\n  cattr_reader :per_page \n    @@per_page = 10\n\nend\n\n/views/posts/new.html.erb:\n<h1>New post</h1>\n<%= link_to 'Back', posts_path %>\n<% form_for(@post, :html => { :multipart => true}) do |f| %>\n  <%= f.error_messages %>\n\n  <p>\n    <%= f.label :title %><br />\n    <%= f.text_field :title %>\n  </p>\n  <p>\n    <%= f.label :body %><br />\n    <%= f.text_area :body %>\n  </p>\n  <p>\n    <%= f.file_field :photo %>\n  </p>\n\n  <p>\n    <%= f.submit 'Create' %>\n  </p>\n<% end %>\n\n",
        "all_answers": [
            "\nIt is very important that you restart your server after installing new gems/plugins. This should solve your problem\n",
            "\nI'd suggest installing paperclip gem. Then you'd just need to add config.gem 'paperclip' to your environment.rb and run sudo rake gems:install.\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "paperclip"
        ]
    },
    {
        "question_id": "25006235",
        "question": "\nIs there a way/software to give precise time needed to execute a block of code written in Swift, other than the following?\nlet date_start = NSDate()\n\n// Code to be executed \n\nprintln(\"\\(-date_start.timeIntervalSinceNow)\")\n\n",
        "all_answers": [
            "\nIf you just want a standalone timing function for a block of code, I use the following Swift helper functions:\nfunc printTimeElapsedWhenRunningCode(title:String, operation:()->()) {\n    let startTime = CFAbsoluteTimeGetCurrent()\n    operation()\n    let timeElapsed = CFAbsoluteTimeGetCurrent() - startTime\n    print(\"Time elapsed for \\(title): \\(timeElapsed) s.\")\n}\n\nfunc timeElapsedInSecondsWhenRunningCode(operation: ()->()) -> Double {\n    let startTime = CFAbsoluteTimeGetCurrent()\n    operation()\n    let timeElapsed = CFAbsoluteTimeGetCurrent() - startTime\n    return Double(timeElapsed)\n}\n\nThe former will log out the time required for a given section of code, with the latter returning that as a float. As an example of the first variant:\nprintTimeElapsedWhenRunningCode(title:\"map()\") {\n    let resultArray1 = randoms.map { pow(sin(CGFloat($0)), 10.0) }\n}\n\nwill log out something like:\n\nTime elapsed for map(): 0.0617449879646301 s\n\nBe aware that Swift benchmarks will vary heavily based on the level of optimization you select, so this may only be useful for relative comparisons of Swift execution time. Even that may change on a per-beta-version basis. \n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nIf you want to get insight into performance of a certain block of code and make sure performance doesn't hurt when you make edits, best thing would be using XCTest's measuring performance functions, like measure(_ block: () -> Void). \nWrite a unit test that executes method you want to benchmark, and that unit test will run it multiple times giving you time needed and deviation of results \nfunc testExample() {\n\n    self.measure {\n        //do something you want to measure\n    }\n}\n\nYou can find more info in apple docs under Testing with Xcode -> Performance Testing\n"
        ],
        "answer": "A1",
        "tags": [
            "swift",
            "performance"
        ]
    },
    {
        "question_id": "3954438",
        "question": "\n\n\n\nIs there a method to remove an item from a JavaScript array?\nGiven an array:\nvar ary = ['three', 'seven', 'eleven'];\n\nI would like to do something like:\nremoveItem('seven', ary);\n\nI've looked into splice() but that only removes by the position number, whereas I need something to remove an item by its value.\n",
        "all_answers": [
            "\nThis can be a global function  or a method of a custom object, if you aren't allowed to add to native prototypes. It removes all of the items from the array that match any of the arguments.\nArray.prototype.remove = function() {\n    var what, a = arguments, L = a.length, ax;\n    while (L && this.length) {\n        what = a[--L];\n        while ((ax = this.indexOf(what)) !== -1) {\n            this.splice(ax, 1);\n        }\n    }\n    return this;\n};\n\nvar ary = ['three', 'seven', 'eleven'];\n\nary.remove('seven');\n\n/*  returned value: (Array)\nthree,eleven\n*/\n\nTo make it a global-\nfunction removeA(arr) {\n    var what, a = arguments, L = a.length, ax;\n    while (L > 1 && arr.length) {\n        what = a[--L];\n        while ((ax= arr.indexOf(what)) !== -1) {\n            arr.splice(ax, 1);\n        }\n    }\n    return arr;\n}\nvar ary = ['three', 'seven', 'eleven'];\nremoveA(ary, 'seven');\n\n\n/*  returned value: (Array)\nthree,eleven\n*/\n\nAnd to take care of IE8 and below-\nif(!Array.prototype.indexOf) {\n    Array.prototype.indexOf = function(what, i) {\n        i = i || 0;\n        var L = this.length;\n        while (i < L) {\n            if(this[i] === what) return i;\n            ++i;\n        }\n        return -1;\n    };\n}\n\n",
            "\nYou can use the indexOf method like this:\nvar index = array.indexOf(item);\nif (index !== -1) {\n  array.splice(index, 1);\n}\n\n\nNote: You'll need to shim it for IE8 and below\n\n\n\nvar array = [1,2,3,4]\nvar item = 3\n\nvar index = array.indexOf(item);\narray.splice(index, 1);\n\nconsole.log(array)\n\n\n\n",
            "\nindexOf is an option, but it's implementation is basically searching the entire array for the value, so execution time grows with array size. (so it is in every browser I guess, I only checked Firefox).\nI haven't got an IE6 around to check, but I'd call it a safe bet that you can check at least a million array items per second this way on almost any client machine. If [array size]*[searches per second] may grow bigger than a million you should consider a different implementation.\nBasically you can use an object to make an index for your array, like so:\nvar index={'three':0, 'seven':1, 'eleven':2};\n\nAny sane JavaScript environment will create a searchable index for such objects so that you can quickly translate a key into a value, no matter how many properties the object has.\nThis is just the basic method, depending on your need you may combine several objects and/or arrays to make the same data quickly searchable for different properties. If you specify your exact needs I can suggest a more specific data structure.\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "arrays"
        ]
    },
    {
        "question_id": "2145147",
        "question": "\nI've heard and read many times that it is better to catch an exception as reference-to-const rather than as reference. Why is:\ntry {\n    // stuff\n} catch (const std::exception& e) {\n    // stuff\n}\n\nbetter than:\ntry {\n    // stuff\n} catch (std::exception& e) {\n    // stuff\n}\n\n",
        "all_answers": [
            "\nThrowing an exception is the best way of dealing with constructor failure. You should particularly avoid half-constructing an object and then relying on users of your class to detect construction failure by testing flag variables of some sort.\nOn a related point, the fact that you have several different exception types for dealing with mutex errors worries me slightly. Inheritance is a great tool, but it can be over-used. In this case I would probably prefer a single MutexError exception, possibly containing an informative error message.\n",
            "\nYou need:\n\na reference so you can access the exception polymorphically\na const to increase performance, and tell the compiler you're not going to modify the object\n\nThe latter is not as much important as the former, but the only real reason to drop const would be to signal that you want to do changes to the exception (usually useful only if you want to rethrow it with added context into a higher level).\n",
            "\nare you going to modify the exception? if not, it may as well be const.  same reason you SHOULD use const anywhere else (I say SHOULD because it doesn't really make that much difference on the surface, might help compilers, and also help coders use your code properly and not do stuff they shouldn't)\nexception handlers, may be platform specific, and may put exceptions in funny places because they aren't expecting them to change?\n",
            "\nIt tells the compiler that you won't be calling any function which modify the exception, which may help to optimize the code.  Probably doesn't make much of a difference, but the cost of doing it is very small too.\n",
            "\nYes, throwing an exception from the failed constructor is the standard way of doing this. Read this FAQ about Handling a constructor that fails for more information. Having a init() method will also work, but everybody who creates the object of mutex has to remember that init() has to be called. I feel it goes against the RAII principle.\n",
            "\nIf you do throw an exception from a constructor, keep in mind that you need to use the function try/catch syntax if you need to catch that exception in a constructor initializer list.\ne.g.\nfunc::func() : foo()\n{\n    try {...}\n    catch (...) // will NOT catch exceptions thrown from foo constructor\n    { ... }\n}\n\nvs.\nfunc::func()\n    try : foo() {...}\n    catch (...) // will catch exceptions thrown from foo constructor\n    { ... }\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c++",
            "exception",
            "constants"
        ]
    },
    {
        "question_id": "1270024",
        "question": "\nI have the following function to get validation errors for a card.  My question relates to dealing with GetErrors.  Both methods have the same return type IEnumerable<ErrorInfo>.\nprivate static IEnumerable<ErrorInfo> GetErrors(Card card)\n{\n    var errors = GetMoreErrors(card);\n    foreach (var e in errors)\n        yield return e;\n    \n    // further yield returns for more validation errors\n}\n\nIs it possible to return all the errors in GetMoreErrors without having to enumerate through them?\n",
        "all_answers": [
            "\nAs of .NET Core 2.0, the constructor Dictionary<TKey,TValue>(IEnumerable<KeyValuePair<TKey,TValue>>) now exists.\n",
            "\nIf you're using .NET 3.5 or .NET 4, it's easy to create the dictionary using LINQ:\nDictionary<string, ArrayList> result = target.GetComponents()\n                                      .ToDictionary(x => x.Key, x => x.Value);\n\nThere's no such thing as an IEnumerable<T1, T2> but a KeyValuePair<TKey, TValue> is fine.\n",
            "\nI don't see anything wrong with your function, I'd say that it is doing what you want.\nThink of the Yield as returning an element in the final Enumeration each time that it is invoked, so when you have it in the foreach loop like that, each time it is invoked it returns 1 element. You have the ability to put conditional statements in your foreach to filter the resultset. (simply by not yielding on your exclusion criteria)\nIf you add subsequent yields later in the method, it will continue to add 1 element to the enumeration, making it possible to do things like...\npublic IEnumerable<string> ConcatLists(params IEnumerable<string>[] lists)\n{\n  foreach (IEnumerable<string> list in lists)\n  {\n    foreach (string s in list)\n    {\n      yield return s;\n    }\n  }\n}\n\n",
            "\nIt is something that F# supports with yield! for a whole collection vs yield for a single item. (That can be very useful in terms of tail recursion...)\nUnfortunately it's not supported in C#.\nHowever, if you have several methods each returning an IEnumerable<ErrorInfo>, you can use Enumerable.Concat to make your code simpler:\nprivate static IEnumerable<ErrorInfo> GetErrors(Card card)\n{\n    return GetMoreErrors(card).Concat(GetOtherErrors())\n                              .Concat(GetValidationErrors())\n                              .Concat(AnyMoreErrors())\n                              .Concat(ICantBelieveHowManyErrorsYouHave());\n}\n\nThere's one very important difference between the two implementations though: this one will call all of the methods immediately, even though it will only use the returned iterators one at a time. Your existing code will wait until it's looped through everything in GetMoreErrors() before it even asks about the next errors.\nUsually this isn't important, but it's worth understanding what's going to happen when.\n"
        ],
        "answer": "A4",
        "tags": [
            "c#",
            "ienumerable",
            "yield",
            "yield-return"
        ]
    },
    {
        "question_id": "38460327",
        "question": "\nHello i have working no error codes for UITextfield border color change but when using it in Swift 3 dont change textfield border color and dont gives error. I need your help my codes under below. \n@IBOutlet weak var email: UITextField!\n@IBOutlet weak var pass: UITextField!\n\n\noverride func viewDidLoad() {\n    super.viewDidLoad()\n\n    let myColor : UIColor = UIColor.white()\n    email.layer.borderColor = myColor.cgColor\n    pass.layer.borderColor = myColor.cgColor\n\n\n}\n\nThank you !\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nTry to use this,\nIt might be helpful to you\nlet myColor : UIColor = UIColor( red: 0.5, green: 0.5, blue:0, alpha: 1.0 )\nmyTextField.layer.masksToBounds = true\nmyTextField.layer.borderColor = myColor.CGColor\nmyTextField.layer.borderWidth = 2.0\n\n",
            "\nYou also need to set border width, because your border color is set already but your default border width is 0.0 so you can't see it.\nSo, set border width something like,\n  email.layer.borderWidth = 1.0\n\nUpdate :\nYour code should be like,\n @IBOutlet weak var email: UITextField!\n @IBOutlet weak var pass: UITextField!\n\n override func viewDidLoad() {\n   super.viewDidLoad()\n\n   let myColor = UIColor.white\n   email.layer.borderColor = myColor.cgColor\n   pass.layer.borderColor = myColor.cgColor\n\n   email.layer.borderWidth = 1.0\n   pass.layer.borderWidth = 1.0\n\n}\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n"
        ],
        "answer": "A4",
        "tags": [
            "ios",
            "swift",
            "swift3",
            "uitextfield"
        ]
    },
    {
        "question_id": "2043615",
        "question": "\nIf I initialize a generic dictionary once, and no further adds/updates/removes are allowed, is it safe to have multiple threads reading from it with no locking (assuming that the dictionary is initialized before the readers are started)?\nThere is a note in the help for the non-generic HashTable that says that it is safe for multiple readers, but I did not see something similar for the Generic Dictionary.\n",
        "all_answers": [
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nThis Java Tutorial can probably help you understand what using synchronized on an object does.\nWhen object.wait() is called it will release the lock held on that object (which happens when you say synchronized(object)), and freeze the thread. The thread then waits until object.notify() or object.notifyAll() is called by a separate thread. Once one of these calls occurs, it will allow any threads that were stopped due to object.wait() to continue. This does not mean that the thread that called object.notify() or object.notifyAll() will freeze and pass control to a waiting thread, it just means these waiting threads are now able to continue, whereas before they were not.\n",
            "\nYes, it's safe if you don't modify the dictionary any more. Thread safety is only an issue in read/write scenarios\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nFor your future reference, the documentation is here:\nhttp://msdn.microsoft.com/en-us/library/xfhwa508.aspx\nIt says:\n\nA Dictionary\n  can support multiple readers\n  concurrently, as long as the\n  collection is not modified. Even so,\n  enumerating through a collection is\n  intrinsically not a thread-safe\n  procedure. In the rare case where an\n  enumeration contends with write\n  accesses, the collection must be\n  locked during the entire enumeration.\n  To allow the collection to be accessed\n  by multiple threads for reading and\n  writing, you must implement your own\n  synchronization.\n\n",
            "\nHere is a good write up about .NET events and race conditions with threads.  It covers some common scenarios and has some good references in it.\nHope this helps.\n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            "multithreading",
            "thread-safety"
        ]
    },
    {
        "question_id": "46653833",
        "question": "\nI deleted it by accident and have made many changes to package.json since. An npm install or npm update do not generate package-lock.json anymore. I tried clearing my npm cache and my nvm cache, but nothing seems to be working. I tried it on several versions of Node.js (6.10.3 Node.js - 3.10.10 npm is what I would like it to work on), and it doesn't work on any.\nIs there a way to force npm to generate the package-lock.json file?\n",
        "all_answers": [
            "\nThis is answered in the comments; package-lock.json is a feature in npm v5 and higher. npm shrinkwrap is how you create a lockfile in all versions of npm.\n",
            "\nBy default, package-lock.json is updated whenever you run npm install. However, this can be disabled globally by setting package-lock=false in ~/.npmrc.\nWhen the global package-lock=false setting is active, you can still force a project’s package-lock.json file to be updated by running:\nnpm install --package-lock\n\nThis command is the only surefire way of forcing a package-lock.json update.\n",
            "\nIn npm 6.x and 7.x you can use\nnpm i --package-lock-only\n\nAccording to the docs of npm v6, npm v7 or latest version:\n\nThe --package-lock-only argument will only update the package-lock.json, instead of checking node_modules and downloading dependencies.\n\n"
        ],
        "answer": "A3",
        "tags": [
            "node.js",
            "npm",
            "package-lock.json"
        ]
    },
    {
        "question_id": "13050695",
        "question": "\nI'm using such configuration:\n\n.NET framework 4.5\nWindows Server 2008 R2\nHP DL360p Gen8 (2 * Xeon E5-2640, x64)\n\nI have such field somewhere in my program:\nprotected int HedgeVolume;\n\nI access this field from several threads. I assume that as I have multi-processor system it's possible that this threads are executing on different processors.\nWhat should I do to guarantee that any time I use this field the most recent value is \"read\"? And to make sure that when I \"write\" value it become available to all other threads immediately?\nWhat should I do?\n\njust leave field as is.\ndeclare it volatile\nuse Interlocked class to access the field\nuse .NET 4.5 Volatile.Read, Volatile.Write methods to access the field\nuse lock\n\nI only need simplest way to make my program work on this configuration I don't need my program to work on another computers or servers or operation systems. Also I want minimal latency so I'm looking for fastest solution that will always work on this standard configuration (multiprocessor intel x64, .net 4.5).\n",
        "all_answers": [
            "\nDepends what you DO. For reading only, volatile is easiest, interlocked allows a little more control. Lock is unnecessary as it is more ganular than the problem you describe. Not sure about Volatile.Read/Write, never used them.\n",
            "\nYour question is missing one key element... How important is the integrity of the data in that field?\nvolatile gives you performance, but if a thread is currently writing changes to the field, you won't get that data until it's done, so you might access out of date information, and potentially overwrite changes another thread is currently doing. If the data is sensitive, you might get bugs that would get very hard to track. However, if you are doing very quick update, overwrite the value without reading it and don't care that once in a while you get outdated (by a few ms) data, go for it.\nlock guaranty that only one thread can access the field at a time. You can put it only on the methods that write the field and leave the reading method alone. The down side is, it is slow, and may block a thread while another is performing its task. However, you are sure your data stay valid.\nInterlock exist to shield yourself from the scheduler context switch. My opinion? Don't use it unless you know exactly why you would be using it and exactly how to use it. It gives options, but with great options comes great problematic. It prevents a context switch while a variable is being update. It might not do what you think it does and won't prevent parallel threads from performing their tasks simultaneously.\n",
            "\nvolatile - bad, there are some issues (see Joe Duffy's blog)\nif all you do is read the value or unconditionally write a value - use Volatile.Read and Volatile.Write\nif you need to read and subsequently write an updated value - use the lock syntax. You can however achieve the same effect without lock using the Interlocked classes functionality, but this is more complex (involves CompareExchange s to ensure that you are updating the read value i.e. has not been modified since the read operation + logic to retry if the value was modified since the read).\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            ".net",
            "multithreading"
        ]
    },
    {
        "question_id": "5225700",
        "question": "\n(I've already seen the H2 database In memory - Init schema via Spring/Hibernate question; it is not applicable here.)\nI'd like to know if there's a setting in H2 that will allow me to auto-create a schema upon connecting to it.  If it helps, I'm only interested in the in-memory case.\nH2 supports various semicolon-separated modifiers at the end of the URL, but I didn't find one for automatically creating a schema.  Is there such a feature?\n",
        "all_answers": [
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nYes, H2 supports executing SQL statements when connecting. You could run a script, or just a statement or two:\nString url = \"jdbc:h2:mem:test;\" + \n             \"INIT=CREATE SCHEMA IF NOT EXISTS TEST\"\nString url = \"jdbc:h2:mem:test;\" + \n             \"INIT=CREATE SCHEMA IF NOT EXISTS TEST\\\\;\" + \n                  \"SET SCHEMA TEST\";\nString url = \"jdbc:h2:mem;\" + \n             \"INIT=RUNSCRIPT FROM '~/create.sql'\\\\;\" + \n                  \"RUNSCRIPT FROM '~/populate.sql'\";\n\nPlease note the double backslash (\\\\) is only required within Java. The backslash(es) before ; within the INIT is required.\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\n\"By default, when an application calls DriverManager.getConnection(url, ...) and the database specified in the URL does not yet exist, a new (empty) database is created.\"—H2 Database.\nAddendum: @Thomas Mueller shows how to Execute SQL on Connection, but I sometimes just create and populate in the code, as suggested below.\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.Statement;\n\n/** @see http://stackoverflow.com/questions/5225700 */\npublic class H2MemTest {\n\n    public static void main(String[] args) throws Exception {\n        Connection conn = DriverManager.getConnection(\"jdbc:h2:mem:\", \"sa\", \"\");\n        Statement st = conn.createStatement();\n        st.execute(\"create table customer(id integer, name varchar(10))\");\n        st.execute(\"insert into customer values (1, 'Thomas')\");\n        Statement stmt = conn.createStatement();\n        ResultSet rset = stmt.executeQuery(\"select name from customer\");\n        while (rset.next()) {\n            String name = rset.getString(1);\n            System.out.println(name);\n        }\n    }\n}\n\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n"
        ],
        "answer": "A2",
        "tags": [
            "java",
            "sql",
            "database",
            "h2"
        ]
    },
    {
        "question_id": "11360401",
        "question": "\nI have a pre-populated array list. And I have multiple threads which will remove elements from the array list. Each thread calls the remove method below and removes one item from the list. Does the following code give me consistent behavior ?\nArrayList<String> list = Collections.synchronizedList(new ArrayList<String>());\n\nvoid remove(String item)\n{\n     do something; (doesn't work on the list)\n     list.remove(item);\n}\n\nThanks!\n",
        "all_answers": [
            "\nYes, Just be careful if you are also iterating over the list, because in this case you will need to synchronize on it.  From the Javadoc:\n\nIt is imperative that the user manually synchronize on the returned list when iterating over it:\n\nList list = Collections.synchronizedList(new ArrayList());\n    ...\nsynchronized (list) {\n    Iterator i = list.iterator(); // Must be in synchronized block\n    while (i.hasNext())\n        foo(i.next());\n}\n\nOr, you can use CopyOnWriteArrayList which is slower for writes but doesn't have this issue.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nBetter alternatives to join() method have been evolved over a period of time.\nExecutorService.html#invokeAll is one alternative.\n\nExecutes the given tasks, returning a list of Futures holding their status and results when all complete. Future.isDone() is true for each element of the returned list. \n\nNote that a completed task could have terminated either normally or by throwing an exception. The results of this method are undefined if the given collection is modified while this operation is in progress.\nForkJoinPool or Executors.html#newWorkStealingPool provides other alternatives to achieve the same purpose. \nExample code snippet:\n\nimport java.util.concurrent.*;\n\nimport java.util.*;\n\npublic class InvokeAllDemo{\n    public InvokeAllDemo(){\n        System.out.println(\"creating service\");\n        ExecutorService service = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\n\n        List<MyCallable> futureList = new ArrayList<MyCallable>();\n        for ( int i=0; i<10; i++){\n            MyCallable myCallable = new MyCallable((long)i);\n            futureList.add(myCallable);\n        }\n        System.out.println(\"Start\");\n        try{\n            List<Future<Long>> futures = service.invokeAll(futureList);  \n        }catch(Exception err){\n            err.printStackTrace();\n        }\n        System.out.println(\"Completed\");\n        service.shutdown();\n    }\n    public static void main(String args[]){\n        InvokeAllDemo demo = new InvokeAllDemo();\n    }\n    class MyCallable implements Callable<Long>{\n        Long id = 0L;\n        public MyCallable(Long val){\n            this.id = val;\n        }\n        public Long call(){\n            // Add your business logic\n            return id;\n        }\n    }\n}\n\n",
            "\nThat should be fine as long as you don't require the \"remove\" method to be atomic.\nIn other words, if the \"do something\" checks that the item appears more than once in the list for example, it is possible that the result of that check will be wrong by the time you reach the next line.\nAlso, make sure you synchronize on the list when iterating:\nsynchronized(list) {\n    for (Object o : list) {}\n}\n\nAs mentioned by Peter Lawrey, CopyOnWriteArrayList can make your life easier and can provide better performance in a highly concurrent environment.\n"
        ],
        "answer": "A1",
        "tags": [
            "java",
            "multithreading"
        ]
    },
    {
        "question_id": "3841295",
        "question": "\nJust curious about SQL syntax. So if I have\nSELECT \n itemName as ItemName,\n substring(itemName, 1,1) as FirstLetter,\n Count(itemName)\nFROM table1\nGROUP BY itemName, FirstLetter\n\nThis would be incorrect because \nGROUP BY itemName, FirstLetter \n\nreally should be \nGROUP BY itemName, substring(itemName, 1,1)\n\nBut why can't we simply use the former for convenience?\n",
        "all_answers": [
            "\nBack in the day I found that Rdb, the former DEC product now supported by Oracle allowed the column alias to be used in the GROUP BY.  Mainstream Oracle through version 11 does not allow the column alias to be used in the GROUP BY.  Not sure what Postgresql, SQL Server, MySQL, etc will or won't allow.  YMMV.\n",
            "\nYou could always use a subquery so you can use the alias; Of course, check the performance (Possible the db server will run both the same, but never hurts to verify):\nSELECT ItemName, FirstLetter, COUNT(ItemName)\nFROM (\n    SELECT ItemName, SUBSTRING(ItemName, 1, 1) AS FirstLetter\n    FROM table1\n    ) ItemNames\nGROUP BY ItemName, FirstLetter\n\n",
            "\nSQL Server doesn't allow you to reference the alias in the GROUP BY clause because of the logical order of processing.  The GROUP BY clause is processed before the SELECT clause, so the alias is not known when the GROUP BY clause is evaluated.  This also explains why you can use the alias in the ORDER BY clause.\nHere is one source for information on the SQL Server logical processing phases.\n",
            "\nSQL is implemented as if a query was executed in the following order:\n\nFROM clause\nWHERE clause\nGROUP BY clause\nHAVING clause\nSELECT clause\nORDER BY clause\n\nFor most relational database systems, this order explains which names (columns or aliases) are valid because they must have been introduced in a previous step.\nSo in Oracle and SQL Server, you cannot use a term in the GROUP BY clause that you define in the SELECT clause because the GROUP BY is executed before the SELECT clause.\nThere are exceptions though: MySQL and Postgres seem to have additional smartness that allows it.\n",
            "\nAt least in PostgreSQL you can use the column number in the resultset in your GROUP BY clause: \nSELECT \n itemName as ItemName,\n substring(itemName, 1,1) as FirstLetter,\n Count(itemName)\nFROM table1\nGROUP BY 1, 2\n\nOf course this starts to be a pain if you are doing this interactively and you edit the query to change the number or order of columns in the result. But still. \n",
            "\nSee the document referenced by CodeByMoonlight in an answer to your recent question.\nThe HAVING clause is evaluated before the SELECT - so the server doesn't yet know about that alias.\n\n\nFirst the product of all tables in the from clause is formed.\nThe where clause is then evaluated to eliminate rows that do not satisfy\n  the search_condition.\nNext, the rows are grouped using the columns in the group by clause.\nThen, Groups that do not satisfy the search_condition in the having\n  clause are eliminated.\nNext, the expressions in the select clause target list are\n  evaluated.\nIf the distinct keyword in present in the select clause, duplicate rows\n  are now eliminated.\nThe union is taken after each sub-select is evaluated.\nFinally, the resulting rows are sorted according to the columns\n  specified in the order by clause.\n\n\n",
            "\nSome DBMSs will let you use an alias instead of having to repeat the entire expression.\nTeradata is one such example.\nI avoid ordinal position notation as recommended by Bill for reasons documented in this SO question.\nThe easy and robust alternative is to always repeat the expression in the GROUP BY clause.\nDRY does NOT apply to SQL.\n"
        ],
        "answer": "A4",
        "tags": [
            "sql",
            "group-by",
            "alias"
        ]
    },
    {
        "question_id": "22752777",
        "question": "\nI'm trying to manually execute SQL commands so I can access procedures in NuoDB.\nI'm using Ruby on Rails and I'm using the following command:\nActiveRecord::Base.connection.execute(\"SQL query\")\n\nThe \"SQL query\" could be any SQL command.\nFor example, I have a table called \"Feedback\" and when I execute the command:\nActiveRecord::Base.connection.execute(\"SELECT `feedbacks`.* FROM `feedbacks`\")\n\nThis would only return a \"true\" response instead of sending me all the data requested.\nThis is the output on the Rails Console is:\nSQL (0.4ms)  SELECT `feedbacks`.* FROM `feedbacks`\n => true\n\nI would like to use this to call stored procedures in NuoDB but upon calling the procedures, this would also return a \"true\" response.\nIs there any way I can execute SQL commands and get the data requested instead of getting a \"true\" response?\n",
        "all_answers": [
            "\nYou can try this\nUser.find(:all, limit: 10,\n            joins:  \"LEFT JOIN `user_points` ON user_points.user_id = users.id\" ,\n            select: \"users.*, count(user_points.id)\", \n            group:  \"user_points.user_id\")\n\n",
            "\nRails 5 has a left_outer_joins method. So you can do\nUser.left_outer_joins(:user_points)\n\nor use the alias\nUser.left_joins(:user_points)\n\n",
            "\nres = ActiveRecord::Base.connection_pool.with_connection { |con| con.exec_query( \"SELECT 1;\" ) }\n\nThe above code is an example for\n\nexecuting arbitrary SQL on your database-connection\nreturning the connection back to the connection pool afterwards\n\n",
            "\nThe working command I'm using to execute custom SQL statements is:\nresults = ActiveRecord::Base.connection.execute(\"foo\")\n\nwith \"foo\" being the sql statement( i.e. \"SELECT * FROM table\").\nThis command will return a set of values as a hash and put them into the results variable.\nSo on my rails application_controller.rb I added this:\ndef execute_statement(sql)\n  results = ActiveRecord::Base.connection.execute(sql)\n\n  if results.present?\n    return results\n  else\n    return nil\n  end\nend\n\nUsing execute_statement will return the records found and if there is none, it will return nil.\nThis way I can just call it anywhere on the rails application like for example:\nrecords = execute_statement(\"select * from table\")\n\n\"execute_statement\" can also call NuoDB procedures, functions, and also Database Views.\n",
            "\nJust for future reference, adding :all gives a deprecated message. In later versions of rails you can simply chain the methods like this:\nUser.joins(\"LEFT JOIN `user_points` ON user_points.user_id = users.id\").select(\"users.*, count(user_points.id)\").group(\"user_points.user_id\")\n\nOR use a scope like this:\nscope :my_scope_name_here, -> { \n        joins(\"LEFT JOIN `user_points` ON user_points.user_id = users.id\")\n        .select(\"users.*, count(user_points.id)\")\n        .group(\"user_points.user_id\")\n}\n\nYou can also chain .where between the .join and the .select.\nHope this helps someone in the future.\n",
            "\nReposting the answer from our forum to help others with a similar issue:\n@connection = ActiveRecord::Base.connection\nresult = @connection.exec_query('select tablename from system.tables')\nresult.each do |row|\nputs row\nend\n\n"
        ],
        "answer": "A4",
        "tags": [
            "sql",
            "ruby-on-rails",
            "activerecord",
            "nuodb"
        ]
    },
    {
        "question_id": "5341202",
        "question": "\nint main ()\n{\n   int a = 5,b = 2;\n   printf(\"%d\",a+++++b);\n   return 0;\n}\n\nThis code gives the following error:\n\nerror: lvalue required as increment operand\n\nBut if I put spaces throughout a++ + and ++b, then it works fine.\nint main ()\n{\n   int a = 5,b = 2;\n   printf(\"%d\",a++ + ++b);\n   return 0;\n}\n\nWhat does the error mean in the first example?\n",
        "all_answers": [
            "\nYou can use GCC's nested functions to simulate lambda expressions, in fact, I have a macro to do it for me:\n#define lambda(return_type, function_body) \\\n  ({ \\\n    return_type anon_func_name_ function_body \\\n    anon_func_name_; \\\n  })\n\nUse like this:\nint (*max)(int, int) = lambda (int, (int x, int y) { return x > y ? x : y; });\n\n",
            "\nYour compiler desperately tries to parse a+++++b, and interprets it as (a++)++ +b. Now, the result of the post-increment (a++) is not an lvalue, i.e. it can't be post-incremented again.\nPlease don't ever write such code in production quality programs. Think about the poor fellow coming after you who needs to interpret your code.\n",
            "\nFunctional programming is not about lambdas, it is all about pure functions.  So the following broadly promote functional style:\n\nOnly use function arguments, do not use global state.\nMinimise side effects i.e. printf, or any IO.  Return data describing IO which can be executed instead of causing the side effects directly in all functions.  \n\nThis can be achieved in plain c, no need for magic.\n",
            "\n(a++)++ +b\n\na++ returns the previous value, a rvalue. You can't increment this.\n",
            "\nHartel & Muller's book, Functional C, can nowadays (2012-01-02) be found at: http://eprints.eemcs.utwente.nl/1077/ (there is a link to PDF version).\n",
            "\nprintf(\"%d\",a+++++b); is interpreted as (a++)++ + b according to the Maximal Munch Rule!.\n++ (postfix) doesn't evaluate to an lvalue but it requires its operand to be an lvalue.\n!\n6.4/4 says\nthe next preprocessing token is the longest sequence of characters that could constitute a preprocessing token\"\n\n",
            "\nFFCALL lets you build closures in C -- callback = alloc_callback(&function, data) returns a function pointer such that callback(arg1, ...) is equivalent to calling function(data, arg1, ...).  You will have to handle garbage collection manually, though.\nRelatedly, blocks have been added to Apple's fork of GCC; they're not function pointers, but they let you pass around lambdas while avoiding the need to build and free storage for captured variables by hand (effectively, some copying and reference counting happens, hidden behind some syntactic sugar and runtime libraries).\n"
        ],
        "answer": "A6",
        "tags": [
            "c",
            "lvalue"
        ]
    },
    {
        "question_id": "2065993",
        "question": "\nI need to take screenshots of an android application running on an emulator in Eclipse Galileo.\nIs there a built-in feature for this or do I have to download a plugin of some sorts?\n",
        "all_answers": [
            "\nI found this code snippet from @gypsicoder code  here\n\n    private CharSequence[] items = {\"Set as Ringtone\", \"Set as Alarm\"};\n    AlertDialog.Builder builder = new AlertDialog.Builder(this);\n    builder.setItems(items, new DialogInterface.OnClickListener() {\n        public void onClick(DialogInterface dialog, int item) {\n\n            if(item == 0) {\n\n            } else if(item == 1) {\n\n            } else if(item == 2) {\n\n            }\n        }\n    });\n    \n    AlertDialog dialog = builder.create();\n    dialog.requestWindowFeature(Window.FEATURE_NO_TITLE);\n    WindowManager.LayoutParams wmlp = dialog.getWindow().getAttributes();\n    \n    wmlp.gravity = Gravity.TOP | Gravity.LEFT;\n    wmlp.x = 100;   //x position\n    wmlp.y = 100;   //y position\n    \n    dialog.show();\n\nHere x position's value is pixels from left to right. For y position\nvalue is from bottom to top.\n\n",
            "\nNew BottomSheetDialog:\nBottomSheetDialog dialog = new BottomSheetDialog(YourActivity.this);    \ndialog.setContentView(YourView);\n\ndialog.show();\n\n",
            "\nI used this code to show the dialog at the bottom of the screen:\nDialog dlg = <code to create custom dialog>;\n\nWindow window = dlg.getWindow();\nWindowManager.LayoutParams wlp = window.getAttributes();\n\nwlp.gravity = Gravity.BOTTOM;\nwlp.flags &= ~WindowManager.LayoutParams.FLAG_DIM_BEHIND;\nwindow.setAttributes(wlp);\n\nThis code also prevents android from dimming the background of the dialog, if you need it. You should be able to change the gravity parameter to move the dialog about\n",
            "\nYou can take a screenshot if you open the Android view \"devices\" (under Window --> Show View --> Other... --> Android --> Devices).  Click on the device or emulator you want to take a screen shot of, then click the \"Screen Capture\" button (it looks like a little picture, and it should be next to a stop sign button).  Occasionally the device won't immediately load the picture; sometimes you have to close/reopen the screen capture window.\nThis is equivalent to taking a picture via DDMS, but you can do it in Eclipse instead of opening another application.\n",
            "\nYou load the emulator with your app normally, through Eclipse, but you take the actual screenshot from DDMS, a tool that's included in your SDK, under the \"tools\" folder.\nIn DDMS, press Ctrl+S to take a screenshot.\n",
            "\nuse bottomSHeet :\nBottomSheetDialog dialog = new BottomSheetDialog(YourActivity.this);\ndialog.setContentView(YourView);\ndialog.show();\n\n",
            "\njust add this to your code:\ndialog.getWindow().setGravity(Gravity.BOTTOM);\n\n",
            "\nprivate void showPictureialog() {\n    final Dialog dialog = new Dialog(this,\n            android.R.style.Theme_Translucent_NoTitleBar);\n\n    // Setting dialogview\n    Window window = dialog.getWindow();\n    window.setGravity(Gravity.CENTER);\n\n    window.setLayout(LayoutParams.FILL_PARENT, LayoutParams.FILL_PARENT);\n    dialog.setTitle(null);\n    dialog.setContentView(R.layout.selectpic_dialog);\n    dialog.setCancelable(true);\n\n    dialog.show();\n}\n\nyou can customize you dialog based on gravity and layout parameters\nchange gravity and layout parameter on the basis of your requirenment\n",
            "\nFor me, this worked out pretty well where I was trying to position my dialog somewhere exactly at the bottom of the textview where it gets selected.\npublic void setPosition(int yValue) {\n    Window window = getWindow();\n    WindowManager.LayoutParams param = window.getAttributes();\n    param.gravity = Gravity.TOP | Gravity.CENTER_HORIZONTAL;\n    param.y = yValue;\n    window.setAttributes(param);\n    window.clearFlags(WindowManager.LayoutParams.FLAG_DIM_BEHIND);\n}\n\n"
        ],
        "answer": "A4",
        "tags": [
            "android",
            "eclipse",
            "android-emulator",
            "screenshot",
            "eclipse-3.5"
        ]
    },
    {
        "question_id": "1485983",
        "question": "\nHow do I obtain a function pointer for a class member function, and later call that member function with a specific object?  I’d like to write:\nclass Dog : Animal\n{\n    Dog ();\n    void bark ();\n}\n\n…\nDog* pDog = new Dog ();\nBarkFunction pBark = &Dog::bark;\n(*pBark) (pDog);\n…\n\nAlso, if possible, I’d like to invoke the constructor via a pointer as well:\nNewAnimalFunction pNew = &Dog::Dog;\nAnimal* pAnimal = (*pNew)();    \n\nIs this possible, and if so, what is the preferred way to do this?\n",
        "all_answers": [
            "\nRead this for detail :\n// 1 define a function pointer and initialize to NULL\n\nint (TMyClass::*pt2ConstMember)(float, char, char) const = NULL;\n\n// C++\n\nclass TMyClass\n{\npublic:\n   int DoIt(float a, char b, char c){ cout << \"TMyClass::DoIt\"<< endl; return a+b+c;};\n   int DoMore(float a, char b, char c) const\n         { cout << \"TMyClass::DoMore\" << endl; return a-b+c; };\n\n   /* more of TMyClass */\n};\npt2ConstMember = &TMyClass::DoIt; // note: <pt2Member> may also legally point to &DoMore\n\n// Calling Function using Function Pointer\n\n(*this.*pt2ConstMember)(12, 'a', 'b');\n\n",
            "\nTo create a new object you can either use placement new, as mentioned above, or have your class implement a clone() method that creates a copy of the object.  You can then call this clone method using a member function pointer as explained above to create new instances of the object.  The advantage of clone is that sometimes you may be working with a pointer to a base class where you don't know the type of the object.  In this case a clone() method can be easier to use.  Also, clone() will let you copy the state of the object if that is what you want.\n",
            "\ntypedef void (Dog::*memfun)();\nmemfun doSomething = &Dog::bark;\n....\n(pDog->*doSomething)(); // if pDog is a pointer\n// (pDog.*doSomething)(); // if pDog is a reference\n\n",
            "\nReason why you cannot use function pointers to call member functions is that\nordinary function pointers are usually just the memory address of the function.\nTo call a member function, you need to know two things:\n\nWhich member function to call \nWhich instance should be used (whose member function)\n\nOrdinary function pointers cannot store both. C++ member function pointers are used\nto store a), which is why you need to specify the instance explicitly when calling a member function pointer.\n",
            "\nA non-static member function must be called with an object. That is, it always implicitly passes \"this\" pointer as its argument.\nBecause your std::function signature specifies that your function doesn't take any arguments (<void(void)>), you must bind the first (and the only) argument.\nstd::function<void(void)> f = std::bind(&Foo::doSomething, this);\n\nIf you want to bind a function with parameters, you need to specify placeholders:\nusing namespace std::placeholders;\nstd::function<void(int,int)> f = std::bind(&Foo::doSomethingArgs, this, std::placeholders::_1, std::placeholders::_2);\n\nOr, if your compiler supports C++11 lambdas:\nstd::function<void(int,int)> f = [=](int a, int b) {\n    this->doSomethingArgs(a, b);\n}\n\n(I don't have a C++11 capable compiler at hand right now, so I can't check this one.)\n"
        ],
        "answer": "A1",
        "tags": [
            "c++",
            "function-pointers",
            "class-method"
        ]
    },
    {
        "question_id": "8790381",
        "question": "\nIn this post, slice function is used to get only necessary elements of params. What would be the function I should use to exclude an element of params (such as user_id)?\nArticle.new(params[:article].slice(:title, :body))\n\nThank you.\n",
        "all_answers": [
            "\nUse except:\na = {\"foo\" => 0, \"bar\" => 42, \"baz\" => 1024 }\na.except(\"foo\")\n# returns => {\"bar\" => 42, \"baz\" => 1024}\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nTry this\nparams = { :title => \"title\", :other => \"other\", :body => \"body\"  }\n\nparams.select {|k,v| [:title, :body].include? k  } #=> {:title => \"title\", :body => \"body\"}  \n\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "mass-assignment"
        ]
    },
    {
        "question_id": "12611345",
        "question": "\nAs the title asks, why did the Django guys decide to implement the request.POST object with a querydict (which, of course, in turn, makes the whole thing immutable?)\nI know you can mutify it by making a copy of the post data \npost = request.POST.copy()\n\nbut why do this? Surely it would be simpler just to allow the thing to be mutable anyway? Or is it being used for some other reason too which might cause issue?\n",
        "all_answers": [
            "\nUpdate:\nGareth Rees was right that point 1 & 3 were not valid in this case. Though I think point 2 and 4 are still valid, therefore I will leave theses here. \n(I noticed that the request.POST object of both Pyramid(Pylon) and Django is some form of MultiDict. So perhaps it is a more common practice than making request.POST immutable.) \n\nI can't speak for the Django guys, though it seems to me that it could because of some of these reasons:\n\n Performence. immutable objects are \"faster\" over mutable ones in that they allow substantial optimizations. An object is immutable means that we can allocate space for it at creation time, and the space requirements are not changing. It also has things like copy efficiency and comparison efficiency because of it. \nEdit: this is not the case for QueryDict as Gareth Rees pointed out. \nIn the case of request.POST, it seems no activity in the server side should need to alter the request's data. And hence immutable objects are more suited, not to mention they have substantial performence advantage.\n Immutable objects can be used as dict keys, which I suppose could be very useful somewhere in Django.. \nEdit: my mistake, immutable does not directly imply hashable; hashable objects however, are typically immutable as well. \nWhen you pass around request.POST (especially to third-party plugins and out), you can expect that this request object from the user will remain unchanged.\n\nIn some way these reasons are also generic answers to \"immutable vs mutable?\" question. I am certain there are much more design considerations than above in the Django case.\n",
            "\nIt's a bit of a mystery, isn't it? Several superficially plausible theories turn out to be wrong on investigation:\n\nSo that the POST object doesn't have to implement mutation methods? No: the POST object belongs to the django.http.QueryDict class, which implements a full set of mutation methods including __setitem__, __delitem__, pop and clear. It implements immutability by checking a flag when you call one of the mutation methods. And when you call the copy method you get another QueryDict instance with the mutable flag turned on.\nFor performance improvement? No: the QueryDict class gains no performance benefit when the mutable flag is turned off.\nSo that the POST object can be used as a dictionary key? No: QueryDict objects are not hashable.\nSo that the POST data can be built lazily (without committing to read the whole response), as claimed here? I see no evidence of this in the code: as far as I can tell, the whole of the response is always read, either directly, or via MultiPartParser for multipart responses.\nTo protect you against programming errors? I've seen this claimed, but I've never seen a good explanation of what these errors are, and how immutability protects you against them.\n\nIn any case, POST is not always immutable: when the response is multipart, then POST is mutable. This seems to put the kibosh on most theories you might think of. (Unless this behaviour is an oversight.)\nIn summary, I can see no clear rationale in Django for the POST object to be immutable for non-multipart requests.\n"
        ],
        "answer": "A2",
        "tags": [
            "django",
            "post"
        ]
    },
    {
        "question_id": "15051869",
        "question": "\nCan a TABLE have a primary key without a clustered index?\nAnd can a TABLE have a clustered index without having a primary key?\nCan anybody briefly tell me the relationship between primary key and clustered index?\n",
        "all_answers": [
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nA primary key is a logical concept - it's the unique identifier for a row in a table. As such, it has a bunch of attributes - it may not be null, and it must be unique. Of course, as you're likely to be searching for records by their unique identifier a lot, it would be good to have an index on the primary key. \nA clustered index is a physical concept - it's an index that affects the order in which records are stored on disk. This makes it a very fast index when accessing data, though it may slow down writes if your primary key is not a sequential number. \nYes, you can have a primary key without a clustered index - and sometimes, you may want to (for instance when your primary key is a combination of foreign keys on a joining table, and you don't want to incur the disk shuffle overhead when writing). \nYes, you can create a clustered index on columns that aren't a primary key. \n",
            "\nA table can have a primary key that is not clustered, and a clustered table does not require a primary key.  So the answer to both questions is yes.\nA clustered index stores all columns at the leaf level.  That means a clustered index contains all data in the table.  A table without a clustered index is called a heap.\nA primary key is a unique index that is clustered by default.  By default means that when you create a primary key, if the table is not clustered yet, the primary key will be created as a clustered unique index.  Unless you explicitly specify the nonclustered option.\nAn example, where t1 has a nonclustered primary key, and t2 is not clustered but has a primary key:\ncreate table t1 (id int not null, col1 int);\nalter table t1 add constraint PK_T1 primary key nonclustered (id);\ncreate clustered index IX_T1_COL1 on t1 (col1);\n\ncreate table t2 (id int not null, col1 int);\nalter table t2 add constraint PK_T2 primary key nonclustered (id);\n\nExample at SQL Fiddle. \n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "sql-server",
            "database",
            "database-design"
        ]
    },
    {
        "question_id": "844746",
        "question": "\nPython's getattr() method is useful when you don't know the name of a certain attribute in advance.\nThis functionality would also come in handy in templates, but I've never figured out a way to do it. Is there a built-in tag or non-built-in tag that can perform dynamic attribute lookups?\n",
        "all_answers": [
            "\nI ended up adding a method to the model in question, and that method can be accessed like an attribute in the template.\nStill, i think it would be great if a built in tag allowed you to dynamically lookup an attribute, since this is a problem a lot of us constantly have in our templates. \n",
            "\nThere isn't a built-in tag, but it shouldn't be too difficult to write your own.\n",
            "\nI also had to write this code as a custom template tag recently. To handle all look-up scenarios, it first does a standard attribute look-up, then tries to do a dictionary look-up, then tries a getitem lookup (for lists to work), then follows standard Django template behavior when an object is not found.\n(updated 2009-08-26 to now handle list index lookups as well)\n# app/templatetags/getattribute.py\n\nimport re\nfrom django import template\nfrom django.conf import settings\n\nnumeric_test = re.compile(\"^\\d+$\")\nregister = template.Library()\n\ndef getattribute(value, arg):\n    \"\"\"Gets an attribute of an object dynamically from a string name\"\"\"\n\n    if hasattr(value, str(arg)):\n        return getattr(value, arg)\n    elif hasattr(value, 'has_key') and value.has_key(arg):\n        return value[arg]\n    elif numeric_test.match(str(arg)) and len(value) > int(arg):\n        return value[int(arg)]\n    else:\n        return settings.TEMPLATE_STRING_IF_INVALID\n\nregister.filter('getattribute', getattribute)\n\nTemplate usage:\n{% load getattribute %}\n{{ object|getattribute:dynamic_string_var }}\n\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nI don't think so.  But it wouldn't be too hard to write a custom template tag to return an attribute in the context dict.  If you're simply trying to return a string, try something like this:\nclass GetAttrNode(template.Node):\n    def __init__(self, attr_name):\n        self.attr_name = attr_name\n\n    def render(self, context):\n        try:\n            return context[self.attr_name]\n        except:\n            # (better yet, return an exception here)\n            return ''\n\n@register.tag\ndef get_attr(parser, token):\n    return GetAttrNode(token)\n\nNote that it's probably just as easy to do this in your view instead of in the template, unless this is a condition that is repeated often in your data.\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "django",
            "django-templates"
        ]
    },
    {
        "question_id": "7387937",
        "question": "\nGiven:\na1 = [5, 1, 6, 14, 2, 8]\n\nI would like to determine if it contains all elements of:\na2 = [2, 6, 15]\n\nIn this case the result is false.\nAre there any built-in Ruby/Rails methods to identify such array inclusion?\nOne way to implement this is:\na2.index{ |x| !a1.include?(x) }.nil?\n\nIs there a better, more readable, way?\n",
        "all_answers": [
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nPerhaps this is easier to read:\na2.all? { |e| a1.include?(e) }\n\nYou can also use array intersection:\n(a1 & a2).size == a1.size\n\nNote that size is used here just for speed, you can also do (slower):\n(a1 & a2) == a1\n\nBut I guess the first is more readable. These 3 are plain ruby (not rails).\n",
            "\na = [5, 1, 6, 14, 2, 8]\nb = [2, 6, 15]\n\na - b\n# => [5, 1, 14, 8]\n\nb - a\n# => [15]\n\n(b - a).empty?\n# => false\n\n",
            "\nThis can be achieved by doing\n(a2 & a1) == a2\n\nThis creates the intersection of both arrays, returning all elements from a2 which are also in a1. If the result is the same as a2, you can be sure you have all elements included in a1.\nThis approach only works if all elements in a2 are different from each other in the first place. If there are doubles, this approach fails. The one from Tempos still works then, so I wholeheartedly recommend his approach (also it's probably faster).\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "arrays",
            "ruby"
        ]
    },
    {
        "question_id": "2876616",
        "question": "\nWhat is the difference between returning IQueryable<T> vs. IEnumerable<T>, when should one be preferred over the other?\nIQueryable<Customer> custs = from c in db.Customers\nwhere c.City == \"<City>\"\nselect c;\n\nIEnumerable<Customer> custs = from c in db.Customers\nwhere c.City == \"<City>\"\nselect c;\n\nWill both be deferred execution and when should one be preferred over the other?\n",
        "all_answers": [
            "\nYes, both will give you deferred execution.\nThe difference is that IQueryable<T> is the interface that allows LINQ-to-SQL (LINQ.-to-anything really) to work. So if you further refine your query on an IQueryable<T>, that query will be executed in the database, if possible. \nFor the IEnumerable<T> case, it will be LINQ-to-object, meaning that all objects matching the original query will have to be loaded into memory from the database.\nIn code:\nIQueryable<Customer> custs = ...;\n// Later on...\nvar goldCustomers = custs.Where(c => c.IsGold);\n\nThat code will execute SQL to only select gold customers. The following code, on the other hand, will execute the original query in the database, then filtering out the non-gold customers in the memory:\nIEnumerable<Customer> custs = ...;\n// Later on...\nvar goldCustomers = custs.Where(c => c.IsGold);\n\nThis is quite an important difference, and working on IQueryable<T> can in many cases save you from returning too many rows from the database. Another prime example is doing paging: If you use Take and Skip on IQueryable, you will only get the number of rows requested; doing that on an IEnumerable<T> will cause all of your rows to be loaded in memory.\n",
            "\nThe following query works. It uses each group to do the select instead of SelectMany. SelectMany works on each element from each collection. For example, in your query you have a result of 2 collections. SelectMany gets all the results, a total of 3, instead of each collection. The following code works on each IGrouping in the select portion to get your aggregate operations working correctly.\nvar results = from line in Lines\n              group line by line.ProductCode into g\n              select new ResultLine {\n                ProductName = g.First().Name,\n                Price = g.Sum(pc => pc.Price).ToString(),\n                Quantity = g.Count().ToString(),\n              };\n\n",
            "\nBoth will give you deferred execution, yes.\nAs for which is preferred over the other, it depends on what your underlying datasource is.\nReturning an IEnumerable will automatically force the runtime to use LINQ to Objects to query your collection.\nReturning an IQueryable (which implements IEnumerable, by the way) provides the extra functionality to translate your query into something that might perform better on the underlying source (LINQ to SQL, LINQ to XML, etc.).\n",
            "\nI don't understand where the first \"result with sample data\" is coming from, but the problem in the console app is that you're using SelectMany to look at each item in each group.\nI think you just want:\nList<ResultLine> result = Lines\n    .GroupBy(l => l.ProductCode)\n    .Select(cl => new ResultLine\n            {\n                ProductName = cl.First().Name,\n                Quantity = cl.Count().ToString(),\n                Price = cl.Sum(c => c.Price).ToString(),\n            }).ToList();\n\nThe use of First() here to get the product name assumes that every product with the same product code has the same product name. As noted in comments, you could group by product name as well as product code, which will give the same results if the name is always the same for any given code, but apparently generates better SQL in EF.\nI'd also suggest that you should change the Quantity and Price properties to be int and decimal types respectively - why use a string property for data which is clearly not textual?\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "linq",
            "linq-to-sql",
            "ienumerable",
            "iqueryable"
        ]
    },
    {
        "question_id": "48804039",
        "question": "\nWhen a CSV file is generated using C# and opened in Microsoft Excel it displays Â characters before special symbols e.g. £\nIn Notepad++ the hex value for Â is:  C2\nSo before writing the £ symbol to file, I have tried the following...\n    var test = \"£200.00\";\n    var replaced = test.Replace(\"\\xC2\", \" \");\n\n    StreamWriter outputFile = File.CreateText(\"testoutput.csv\"); // default UTF-8\n    outputFile.WriteLine(replaced);\n    outputFile.Close(); \n\nWhen opening the CSV file in Excel, I still see the \"Â\" character before the £ symbol (hex equivalent \\xC2 \\xA3); It made no difference.\nDo I need to use a different encoding? or am I missing something?\n",
        "all_answers": [
            "\nI tried your code and Excel does show AŁ in the cell.\nThen I tried to open the csv with LibreOffice Clac. At first there too was AŁ, but\non import the program will ask you about encoding. \nOnce I chose UTF-8 the £ symbol was displayed correctly. \nMy guess is that in fact there is an issue with your encoding. \nThis might help with Excel https://superuser.com/questions/280603/how-to-set-character-encoding-when-opening-excel\n",
            "\nThank you @Evk and @Mortalier, your suggestions lead me to the right direction...\nI needed to update my StreamWriter so it would explicitly include UTF-8 BOM at the beginning http://thinkinginsoftware.blogspot.co.uk/2017/12/correctly-generate-csv-that-excel-can.html\nSo my code has changed from: \nStreamWriter outputFile = File.CreateText(\"testoutput.csv\"); // default UTF-8\n\nTo:\nStreamWriter outputFile = new StreamWriter(\"testoutput.csv\", false, new UTF8Encoding(true))\n\nOr: Another solution I found here was to use a different encoding if you're only expecting latin characters...\nhttp://theoldsewingfactory.com/2010/12/05/saving-csv-files-in-utf8-creates-a-characters-in-excel/\nStreamWriter outputFile = new StreamWriter(\"testoutput.csv\", false, Encoding.GetEncoding(\"Windows-1252\"))\n\nMy system will most likely use latin & non-latin characters so I'm using the UTF-8 BOM solution.\nFinal code\n    var test = \"£200.00\";\n    StreamWriter outputFile = new StreamWriter(\"testoutput.csv\", false, new UTF8Encoding(true))\n    outputFile.WriteLine(test);\n    outputFile.Close();\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            ".net",
            "excel",
            "csv",
            "utf-8"
        ]
    },
    {
        "question_id": "24009598",
        "question": "\nI tried to create a UILabel in playground but failed. Does playground only support OS X development for now?\n",
        "all_answers": [
            "\nI found I could add a new playground file in IOS project, and in that file I can import UIKit.\n",
            "\nYes. \nI started by just adding a class file in the Sources directory.\nI made everything public:\n\nclass \ninit \nmembers\n\nAfter much trying, nothing worked. The XCode crashed and after reopening it all worked like a charm.\n\n",
            "\nThere's two ways to use your project's code in a Playground\nPlayground's Sources Folder\nYes, in Xcode 6.3 Beta 3 (and hopefully, into the future):\n\nPlaygrounds are now represented within Xcode as a bundle with a disclosure triangle that reveals Resources and Sources folders when clicked. These folders contain additional content that is easily accessible from your playground’s main Swift code. To see these folders, choose View > Navigators > Show Project Navigator (or just hit Command-1).\n\nOpen up a new playground and hit cmd + 1 to see the left pane, then drag files into the source folder to use within the playground.\nNote:\nThe files in the source folder are compiled to a framework which means if you want classes, functions, etc. to be accessible in the playground, they must be explicitly marked as public.\npublic class VisibleClass {\n}\n\nclass InvisibleClass {\n}\n\nSource: release blog\nCompile Project Into Framework\n\nMove project to workspace if it isn't already.  (File -> Save as Workspace) will do the trick\nAdd framework target to your project\nBuild framework\nMake sure files you want to access are added to your framework target\nAdd Playground to workspace (NOT the project)\nUse @testable import YourFrameworkName\nAccess code in playground\n\nI made a write up here that goes into a bit more detail if you want to check it out.\n",
            "\nEdited@2014-11-13: It seems the new xcode 6 had fixed this.\nNO, It doesn't. But it's worth noting that you can import UIKit.\nIf you want to import UIKit you cound follow this:\n\nView -> Utilities -> Show File Inspector (opt + cmd + 1)\nOn the right side of Xcode Change “Playground Settings -> Platform” from OS X to iOS\n\nthen you could import UIKit or some module for iOS\nps. I try to create a UIImageView but it doesn't show the correct image on the right side. It seem worthless to import UIKit \n",
            "\nYES, it does!\nFile: New > File... > iOS > Source > Playground\nimport UIKit\nlet lbl = UILabel(frame: CGRect(x: 0, y: 0, width: 300, height: 100))\nlbl.text = \"Hello StackOverflow!\"\n\nThen, save the file. (Or manually run it.) This will trigger the Playground to interpret UI related things. At this point, the word \"UILabel\" should appear on the right-hand side.\n\nNow, to actually view what you've done, you've got to click on the \"Quick View\" eye on the right, or the white circle to open it in Assistant Editor:\nHere's a screenshot of some basic things with UIImage working, etc.\n\n(EDIT: minor text update to current CGRect syntax -- But, screenshots still show old syntax.)\n",
            "\nPress Option+Cmd+1 and choose iOS in the Platform setting. Then you can import UIKit and play~\n",
            "\nThey cannot. Playgrounds are self-contained. This will hopefully change in the future.\nEdit: As of Xcode 6.3, Playgrounds can now contain supporting code. They still cannot see other code in the same project, but code can be added to the support folder of a Playground that can be used from within the playground. See the Swift blog for more info.\n"
        ],
        "answer": "A5",
        "tags": [
            "uikit",
            "swift",
            "swift-playground"
        ]
    },
    {
        "question_id": "5129423",
        "question": "\nIn a Rails 3 application using Steak, Capybara and RSpec how do I test the page's title?\n",
        "all_answers": [
            "\nYou should be able to search for the title element to make sure it contains the text you want:\npage.should have_xpath(\"//title\", :text => \"My Title\")\n\n",
            "\nSome answers suggest to set request.env which is unsafe, because request can be nil and you will end up with private method env' called for nil:NilClass, especially when run single tests with rspec -e\nCorrect approach will be:\ndef http_login\n  user = 'user'\n  password = 'passw'\n  {\n    HTTP_AUTHORIZATION: ActionController::HttpAuthentication::Basic.encode_credentials(user,password)\n  }\nend\n\nget 'index', nil, http_login\n\npost 'index', {data: 'post-data'}, http_login\n\n",
            "\nSince the version 2.1.0 of capybara there are methods on the session to deal with the title.\nYou have\npage.title\npage.has_title? \"my title\"\npage.has_no_title? \"my not found title\"\n\nSo you can test the title like:\nexpect(page).to have_title \"my_title\"\n\nAccording to github.com/jnicklas/capybara/issues/863 the following is also working with capybara 2.0:\nexpect(first('title').native.text).to eq \"my title\"\n\n",
            "\nUpdate (2013): Matt Connolly has provided a GIST which also works for request and controller specs: http://gist.github.com/4158961\n\nAnother way of doing this if you have many tests to run and don't want to include it everytime (DRYer code):\nCreate a /spec/support/auth_helper.rb file:\nmodule AuthHelper\n  def http_login\n    user = 'username'\n    pw = 'password'\n    request.env['HTTP_AUTHORIZATION'] = ActionController::HttpAuthentication::Basic.encode_credentials(user,pw)\n  end  \nend\n\nIn your test spec file:\ndescribe HomeController do\n  render_views\n\n  # login to http basic auth\n  include AuthHelper\n  before(:each) do\n    http_login\n  end\n\n  describe \"GET 'index'\" do\n    it \"should be successful\" do\n      get 'index'\n      response.should be_success\n    end\n  end\n\nend\n\nCredit here - Archived site\n",
            "\nTesting the Title of each page can be done in a much easier way with RSpec.\nrequire 'spec_helper'\n\ndescribe PagesController do\n  render_views\n\n  describe \"GET 'home'\" do\n    before(:each) do\n      get 'home'\n      @base_title = \"Ruby on Rails\"\n    end\n\n    it \"should have the correct title \" do\n      response.should have_selector(\"title\",\n                                :content => @base_title + \" | Home\")\n    end\n  end\nend\n\n",
            "\nSorry I didn't search enough, the solution seems to be the following:\ndescribe \"GET 'index'\" do\n  it \"should be successful\" do\n    @request.env[\"HTTP_AUTHORIZATION\"] = \"Basic \" + Base64::encode64(\"username:password\")\n    get 'index'\n    response.should be_success\n  end\nend\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "rspec",
            "capybara"
        ]
    },
    {
        "question_id": "37552876",
        "question": "\nI need to customise the look of a back button in a Swift project.\nHere's what I have:\n\nHere's what I want:\n\nI've tried creating my own UIBarButtonItem but I can't figure out how to get the image to be beside the text, rather than as a background or a replacement for the text.\nlet backButton = UIBarButtonItem(title: \"Custom\", style: .Plain, target: self, action: nil    )\n//backButton.image = UIImage(named: \"imageName\") //Replaces title\nbackButton.setBackgroundImage(UIImage(named: \"imageName\"), forState: .Normal, barMetrics: .Default) // Stretches image\nnavigationItem.setLeftBarButtonItem(backButton, animated: false)\n\n",
        "all_answers": [
            "\nFor the back button image: \n\nBy this tutorial: (but didn't work for me)\nUINavigationBar.appearance().backIndicatorImage = UIImage(named: \"imageName\")\n\nBut this stack answer: (worked for me)\nvar backButtonImage = UIImage(named: \"back-button-image\")\nbackButtonImage = backButtonImage?.stretchableImage(withLeftCapWidth: 15, topCapHeight: 30)\nUIBarButtonItem.appearance().setBackButtonBackgroundImage(backButtonImage, for: .normal, barMetrics: .default)\n\n\nAnd for the font, assuming you want the font to match for the whole navigation bar:(currently in use)\nif let font = UIFont(name: \"Avenir-Book\", size: 22) {\n  UINavigationBar.appearance().titleTextAttributes = [NSFontAttributeName: font]\n}\n\n",
            "\nYou can do something like that:\nlet yourBackImage = UIImage(named: \"back_button_image\")\nself.navigationController?.navigationBar.backIndicatorImage = yourBackImage\nself.navigationController?.navigationBar.backIndicatorTransitionMaskImage = yourBackImage\nself.navigationController?.navigationBar.backItem?.title = \"Custom\"\n\nYour image will only have one color though\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "swift",
            "uinavigationcontroller",
            "uikit",
            "uibarbuttonitem"
        ]
    },
    {
        "question_id": "24007129",
        "question": "\nI realize the Swift book provided an implementation of a random number generator.  Is the best practice to copy and paste this implementation? Or is there a library that does this that we can use now?\n",
        "all_answers": [
            "\nYou can do it the same way that you would in C:\nlet randomNumber = arc4random()\n\nrandomNumber is inferred to be of type UInt32 (a 32-bit unsigned integer)\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nI've been able to just use rand() to get a random CInt. You can make it an Int by using something like this: \nlet myVar: Int = Int(rand())\n\nYou can use your favourite C random function, and just convert to value to Int if needed.\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nSwift 4.2+\nSwift 4.2 shipped with Xcode 10 introduces new easy-to-use random functions for many data types.\nYou simply call the random() method on numeric types.\nlet randomInt = Int.random(in: 0..<6)\nlet randomDouble = Double.random(in: 2.71828...3.14159)\nlet randomBool = Bool.random()\n\n"
        ],
        "answer": "A6",
        "tags": [
            "swift",
            "random"
        ]
    },
    {
        "question_id": "12633",
        "question": "\n\n\n\nI'm trying to parse an INI file using C++. Any tips on what is the best way to achieve this? Should I use the Windows API tools for INI file processing (with which I am totally unfamiliar), an open-source solution or attempt to parse it manually?\n",
        "all_answers": [
            "\nYou can use the Windows API functions, such as GetPrivateProfileString() and GetPrivateProfileInt().\n",
            "\nFor myself, I would assume unsigned int is platform specific. Integers could be 16 bits, 32 bits or even 64 bits.\nOn the other hand, DWORD specifies its own size, which is Double Word. Words are 16 bits, so DWORD will be known as 32 bits across all platforms.\n",
            "\nSDK developers prefer to define their own types using typedef. This allows changing underlying types only in one place, without changing all client code. It is important to follow this convention. DWORD is unlikely to be changed, but types like DWORD_PTR are different on different platforms, like Win32 and x64. So, if some function has DWORD parameter, use DWORD and not unsigned int, and your code will be compiled in all future windows headers versions.\n",
            "\nWhen MS-DOS and Windows 3.1 operated in 16-bit mode, an Intel 8086 word was 16 bits, a Microsoft WORD was 16 bits, a Microsoft DWORD was 32 bits, and a typical compiler's unsigned int was 16 bits.\nWhen Windows NT operated in 32-bit mode, an Intel 80386 word was 32 bits, a Microsoft WORD was 16 bits, a Microsoft DWORD was 32 bits, and a typical compiler's unsigned int was 32 bits.  The names WORD and DWORD were no longer self-descriptive but they preserved the functionality of Microsoft programs.\nWhen Windows operates in 64-bit mode, an Intel word is 64 bits, a Microsoft WORD is 16 bits, a Microsoft DWORD is 32 bits, and a typical compiler's unsigned int is 32 bits.  The names WORD and DWORD are no longer self-descriptive, AND an unsigned int no longer conforms to the principle of least surprises, but they preserve the functionality of lots of programs.\nI don't think WORD or DWORD will ever change.\n",
            "\nI have never parsed ini files, so I can't be too specific on this issue.\nBut i have one advice:\nDon't reinvent the wheel as long as an existing one meets your requirements\nhttp://en.wikipedia.org/wiki/INI_file#Accessing_INI_files\nhttp://sdl-cfg.sourceforge.net/\nhttp://sourceforge.net/projects/libini/\nhttp://www.codeproject.com/KB/files/config-file-parser.aspx\nGood luck :)\n",
            "\nDWORD is not a C++ type, it's defined in <windows.h>.\nThe reason is that DWORD has a specific range and format Windows functions rely on, so if you require that specific range use that type. (Or as they say \"When in Rome, do as the Romans do.\") For you, that happens to correspond to unsigned int, but that might not always be the case. To be safe, use DWORD when a DWORD is expected, regardless of what it may actually be.\nFor example, if they ever changed the range or format of unsigned int they could use a different type to underly DWORD to keep the same requirements, and all code using DWORD would be none-the-wiser. (Likewise, they could decide DWORD needs to be unsigned long long, change it, and all code using DWORD would be none-the-wiser.)\n\nAlso note unsigned int does not necessary have the range 0 to 4,294,967,295. See here.\n"
        ],
        "answer": "A1",
        "tags": [
            "c++",
            "winapi",
            "ini",
            "fileparse"
        ]
    },
    {
        "question_id": "7079804",
        "question": "\nSo I want to do something like follows:\n{% if age > 18 %}\n    {% with patient as p %}\n{% else %}\n    {% with patient.parent as p %}\n    ...\n{% endwith %}\n{% endif %}\n\nBut Django is telling me that I need another {% endwith %} tag.  Is there any way to rearrange the withs to make this work, or is the syntactic analyzer purposefully carefree in regards to this sort of thing?\nMaybe I'm going about this the wrong way.  Is there some sort of best practice when it comes to something like this?\n",
        "all_answers": [
            "\nSorry for comment in an old post but if you want to use an else if statement this will help you\n{% if title == source %}\n    Do This\n{% elif title == value %}\n    Do This\n{% else %}\n    Do This\n{% endif %}\n\nFor more info see https://docs.djangoproject.com/en/3.2/ref/templates/builtins/#if\n",
            "\nif you want to stay DRY, use an include.  \n{% if foo %}\n  {% with a as b %}\n    {% include \"snipet.html\" %}\n  {% endwith %} \n{% else %}\n  {% with bar as b %}\n    {% include \"snipet.html\" %}\n  {% endwith %} \n{% endif %}\n\nor, even better would be to write a method on the model that encapsulates the core logic:\ndef Patient(models.Model):\n    ....\n    def get_legally_responsible_party(self):\n       if self.age > 18:\n          return self\n       else:\n          return self.parent\n\nThen in the template:\n{% with patient.get_legally_responsible_party as p %}\n  Do html stuff\n{% endwith %} \n\nThen in the future, if the logic for who is legally responsible changes you have a single place to change the logic -- far more DRY than having to change if statements in a dozen templates.\n",
            "\nYou shouldn't use the double-bracket {{ }} syntax within if or ifequal statements, you can simply access the variable there like you would in normal python:\n{% if title == source %}\n   ...\n{% endif %}\n\n",
            "\nLike this:\n{% if age > 18 %}\n    {% with patient as p %}\n    <my html here>\n    {% endwith %}\n{% else %}\n    {% with patient.parent as p %}\n    <my html here>\n    {% endwith %}\n{% endif %}\n\nIf the html is too big and you don't want to repeat it, then the logic would better be placed in the view. You set this variable and pass it to the template's context:\np = (age > 18 && patient) or patient.parent\n\nand then just use {{ p }} in the template.\n",
            "\n{% for source in sources %}\n  <tr>\n    <td>{{ source }}</td>\n    <td>\n      {% ifequal title source %}\n        Just now!\n      {% endifequal %}\n    </td>\n  </tr>\n{% endfor %}\n\n                or\n\n\n{% for source in sources %}\n      <tr>\n        <td>{{ source }}</td>\n        <td>\n          {% if title == source %}\n            Just now!\n          {% endif %}\n        </td>\n      </tr>\n    {% endfor %}\n\nSee Django Doc\n"
        ],
        "answer": "A2",
        "tags": [
            "django",
            "templates",
            "with-statement",
            "if-statement"
        ]
    },
    {
        "question_id": "6836740",
        "question": "\nHow can I change the display text in a <select> field while selecting a field which is a ForeignKey?\nI need to display not only the name of ForeignKey, but also the name of its parent.\n",
        "all_answers": [
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n",
            "\nSee https://docs.djangoproject.com/en/1.3/ref/models/instances/#unicode\nclass Person(models.Model):\n    first_name = models.CharField(max_length=50)\n    last_name = models.CharField(max_length=50)\n\n    def __unicode__(self):\n        return u'%s %s' % (self.first_name, self.last_name)\n\nyou have to define what you want to display in the unicode method of your model (where is the ForeignKey).\nRegards,\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nsettings.py\nALLOWED_HOSTS = ['*'] // if you are in dev or docker\n\nEdited\nOk guys, dont do this in production if you are not using docker, just put the IP addr.\nGrettings\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nIf you want it to take effect only in admin, and not globally, then you could create a custom ModelChoiceField subclass, use that in a custom ModelForm and then set the relevant admin class to use your customized form.\nUsing an example which has a ForeignKey to the Person model used by @Enrique:\nclass Invoice(models.Model):\n      person = models.ForeignKey(Person)\n      ....\n\nclass InvoiceAdmin(admin.ModelAdmin):\n      form = MyInvoiceAdminForm\n\n\nclass MyInvoiceAdminForm(forms.ModelForm):\n    person = CustomModelChoiceField(queryset=Person.objects.all()) \n    class Meta:\n          model = Invoice\n      \nclass CustomModelChoiceField(forms.ModelChoiceField):\n     def label_from_instance(self, obj):\n         return \"%s %s\" % (obj.first_name, obj.last_name)\n\n",
            "\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['62.63.141.41', 'namjoosadr.com']\n\nand then restart your apache. in ubuntu:\n/etc/init.d/apache2 restart\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n"
        ],
        "answer": "A6",
        "tags": [
            "python",
            "python-3.x",
            "django",
            "foreign-keys",
            "django-admin"
        ]
    },
    {
        "question_id": "4249695",
        "question": "\nI'm installing the Android SDK on a fresh installation of Fedora 14 (Linux). I installed eclipse, and ran the tools/android sdk tool to install all the Eclipse components for the SDK. I was able to get DDMS to install when selecting it by itself.\nAnd for the last component - the Android developer tools, I'm getting the ugly error message pasted below. \nNow I'm Stuck in Eclipse dependency hell. \nI've searched through the available packages in Fedora and I can't find the one that has the files necessary to satisfy this Eclipse dependency. Can anybody please translate what it is that Eclipse is asking for and what Fedora package it lives in?\nThe ugly error:\nCannot complete the install because one or more required items could not be found.\n  Software being installed: Android Development Tools 0.9.9.v201009221407-60953 (com.android.ide.eclipse.adt.feature.group 0.9.9.v201009221407-60953)\n  Missing requirement: Android Development Tools 0.9.9.v201009221407-60953 (com.android.ide.eclipse.adt.feature.group 0.9.9.v201009221407-60953) requires 'org.eclipse.wst.sse.core 0.0.0' but it could not be found\n\n",
        "all_answers": [
            "\nGoogle is your friend. Make sure you use the right version of Eclipse, and you may have to run Eclipse as root when installing.\nThe issue is that the versions of Eclipse that ship with Linux distributions are usually very generic in their configuration. It is unlikely that you will find the right package through your package manager, you want to use Eclipse's mechanism.\n",
            "\nI found that removing ~/.eclipse solved this issue for me on the stock Ubuntu eclipse\n",
            "\nI've just encountered exactly the same problem in Eclipse 3.6 (Helios). After plenty of Googling I came across this link:\nhttp://code.google.com/intl/es/eclipse/docs/faq.html#wstinstallerror\n\nDuring installation, there's an error\n  about requiring\n  org.eclipse.wst.sse.ui. How do I fix\n  that?\nThe Google Plugin for Eclipse depends\n  on other specific Eclipse components,\n  such as WST. Your installation of\n  Eclipse may not yet include all of\n  them, but they can be easily installed\n  by following these instructions.\n  Eclipse 3.6 (Helios)\n\nSelect Help > Install New Software...\nClick the link for Available Software Sites.\nEnsure there is an update site named Helios. If this is not present,\n  click Add... and enter\n  http://download.eclipse.org/releases/helios\n  for the Location.\nNow go through the installation steps; Eclipse should download and\n  install the plugin's dependencies.\n\n\n(There are examples in that page for 3.5 (Galileo), 3.4 (Ganymede) & 3.3 (Europa) for anyone with different versions)\nThe exact same steps work for 3.7 (Indigo) as well.\nJust use http://download.eclipse.org/releases/indigo for the location.\nJuno: http://download.eclipse.org/releases/juno\nKepler: http://download.eclipse.org/releases/kepler\nNote: Step four is not necessary. Only steps one to three are necessary.\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "eclipse",
            "eclipse-plugin",
            "android-2.2-froyo"
        ]
    },
    {
        "question_id": "740287",
        "question": "\nI'm trying to find a short way to see if any of the following items is in a list, but my first attempt does not work. Besides writing a function to accomplish this, is the any short way to check if one of multiple items is in a list.\n>>> a = [2,3,4]\n>>> print (1 or 2) in a\nFalse\n>>> print (2 or 1) in a\nTrue\n\n",
        "all_answers": [
            "\nThink about what the code actually says!\n>>> (1 or 2)\n1\n>>> (2 or 1)\n2\n\nThat should probably explain it. :)  Python apparently implements \"lazy or\", which should come as no surprise.  It performs it something like this:\ndef or(x, y):\n    if x: return x\n    if y: return y\n    return False\n\nIn the first example, x == 1 and y == 2.  In the second example, it's vice versa.  That's why it returns different values depending on the order of them.\n",
            "\n>>> L1 = [2,3,4]\n>>> L2 = [1,2]\n>>> [i for i in L1 if i in L2]\n[2]\n\n\n>>> S1 = set(L1)\n>>> S2 = set(L2)\n>>> S1.intersection(S2)\nset([2])\n\nBoth empty lists and empty sets are False, so you can use the value directly as a truth value.\n"
        ],
        "answer": "A2",
        "tags": [
            "python"
        ]
    },
    {
        "question_id": "8969122",
        "question": "\nI have a TextView in my application. I want to align the text in it to the right. I tried adding:\nandroid:gravity=\"right\"\n\nBut this doesn't work for me.\nWhat might I be doing wrong?\n",
        "all_answers": [
            "\nI think that you are doing this: android:layout_width = \"wrap_content\"\nIf this is the case, do this: android:layout_width = \"match_parent\"\n",
            "\nMake sure that you are not using android:layout_width=\"wrap_content\" if so then it won't be able to set the gravity because you are not having enough space for the text to align. Instead use android:layout_width=\"fill_parent\"\n",
            "\nJust in case anybody finds this, there's a nicer alternative that's not documented (I tripped over it after searching for hours, and finally found it in the bug list for the Android SDK itself). You CAN include raw HTML in strings.xml, as long as you wrap it in\n<![CDATA[ ...raw html... ]]>\n\nEdge Cases:\n\nCharacters like apostrophe ('), double-quote (\"), and ampersand (&) only need to be escaped if you want them to appear in the rendered text AS themselves, but they COULD be plausibly interpreted as HTML.\n\n' and \" can be represented as\\' and \\\", or &apos; and &quot;.\n< and > always need to be escaped as &lt; and &gt; if you literally want them to render as '<' and '>' in the text.\nAmpersand (&) is a little more complicated.\n\nAmpersand followed by whitespace renders as ampersand.\nAmpersand followed by one or more characters that don't form a valid HTML entity code render as Ampersand followed by those characters. So... &qqq; renders as &qqq;, but &lt;1 renders as <1.\n\n\n\n\n\nExample:\n<string name=\"nice_html\">\n<![CDATA[\n<p>This is a html-formatted \\\"string\\\" with <b>bold</b> and <i>italic</i> text</p>\n<p>This is another paragraph from the same \\'string\\'.</p>\n<p>To be clear, 0 &lt; 1, & 10 &gt; 1<p>\n]]>\n</string>\n\nThen, in your code:\nTextView foo = (TextView)findViewById(R.id.foo);\nfoo.setText(Html.fromHtml(getString(R.string.nice_html), FROM_HTML_MODE_LEGACY));\n\nIMHO, this is several orders of magnitude nicer to work with :-)\n\nAugust 2021 update: My original answer used Html.fromHtml(String), which was deprecated in API 24. The alternative fromHtml(String,int) form is suggested as its replacement.\nFROM_HTML_MODE_LEGACY is likely to work... but one of the other flags might be a better choice for what you want to do.\nOn a final note, if you'd prefer to render Android Spanned text suitable for use in a TextView using Markdown syntax instead of HTML, there are now multiple thirdparty libraries to make it easy including https://noties.io/Markwon.\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "alignment",
            "textview"
        ]
    },
    {
        "question_id": "9477753",
        "question": "\nI read in a paper that the underlying system call to create processes and threads is actually the same, and thus the cost of creating processes over threads is not that great.  \n\nFirst, I wanna know what is the system call that creates\nprocesses/threads (possibly a sample code or a link?)\nSecond, is\nthe author correct to assume that creating processes instead of\nthreads is inexpensive?\n\nEDIT:\nQuoting article:  \n\nReplacing pthreads with processes is surprisingly inexpensive,\n  especially on Linux where both pthreads and processes are invoked\n  using the same underlying system call.\n\n",
        "all_answers": [
            "\nTry using Process explorer. It's much more powerful than task manager and should suit your needs.\n",
            "\nYou can also try processHacker which is free, Open source and mature.It has more option than ProcessExplorer.\n",
            "\nThe underlying system call to create threads is clone(2) (it is Linux specific). BTW, the list of Linux system calls is on syscalls(2), and you could use the strace(1) command to understand the syscalls done by some process or command. Processes are usually created with fork(2) (or vfork(2), which is not much useful these days). However, you could (and some C standard libraries might do that) create them with some particular form of clone. I guess that the kernel is sharing some code to implement clone, fork etc... (since some functionalities, e.g. management of the virtual address space, are common).\nIndeed, process creation (and also thread creation) is generally quite fast on most Unix systems (because they use copy-on-write machinery for the virtual memory), typically a small fraction of a millisecond. But you could have pathological cases (e.g. thrashing) which makes that much longer.\nSince most C standard library implementations are free software on Linux, you could study the source code of the one on your system (often GNU glibc, but sometimes musl-libc or something else).\n",
            "\nProcesses are usually created with fork, threads (lightweight processes) are usually created with clone nowadays. However, anecdotically, there exist 1:N thread models, too, which don't do either.\nBoth fork and clone map to the same kernel function do_fork internally. This function can create a lightweight process that shares the address space with the old one, or a separate process (and many other options), depending on what flags you feed to it. The clone syscall is more or less a direct forwarding of that kernel function (and used by the higher level threading libraries) whereas fork wraps do_fork into the functionality of the 50 year old traditional Unix function.\nThe important difference is that fork guarantees that a complete, separate copy of the address space is made. This, as Basil points out correctly, is done with copy-on-write nowadays and therefore is not nearly as expensive as one would think.\nWhen you create a thread, it just reuses the original address space and the same memory.\nHowever, one should not assume that creating processes is generally \"lightweight\" on unix-like systems because of copy-on-write. It is somewhat less heavy than for example under Windows, but it's nowhere near free.\nOne reason is that although the actual pages are not copied, the new process still needs a copy of the page table. This can be several kilobytes to megabytes of memory for processes that use larger amounts of memory.\nAnother reason is that although copy-on-write is invisible and a clever optimization, it is not free, and it cannot do magic. When data is modified by either process, which inevitably happens, the affected pages fault.\nRedis is a good example where you can see that fork is everything but lightweight (it uses fork to do background saves).\n"
        ],
        "answer": "A4",
        "tags": [
            "linux",
            "multithreading",
            "process",
            "system-calls"
        ]
    },
    {
        "question_id": "2231474",
        "question": "\nI'm trying to import and existing Android project into my current Eclipse workspace.  I select File->New->Android Project, which brings up the Android project dialog, I then select, \"Create project from existing source\", Location, Build Target and Finish.  \nI get the following error: Invalid project description.  \nDoes anybody know how to get past this error?\n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nSolved: If you want to \"Create project from existing source\", you need to create a new directory and then put the project directory tree into that new directory.  Then point to the new directory when importing.\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nIm not sure this will solve your problem since I dont know where it originats from, but when I import a project i go File -> Import -> Existing projects into workspace. Maybe it will circumvent your problem.\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "eclipse"
        ]
    },
    {
        "question_id": "6146963",
        "question": "\nI can't really think of any reason why Python needs the del keyword (and most languages seem to not have a similar keyword). For instance, rather than deleting a variable, one could just assign None to it. And when deleting from a dictionary, a del method could be added.\nIs there a reason to keep del in Python, or is it a vestige of Python's pre-garbage collection days?\n",
        "all_answers": [
            "\nThere's this part of what del does (from the Python Language Reference):\n\nDeletion of a name removes the binding of that name from the local or global namespace\n\nAssigning None to a name does not remove the binding of the name from the namespace.\n(I suppose there could be some debate about whether removing a name binding is actually useful, but that's another question.)\n",
            "\n\nWhen is del useful in python?\n\nYou can use it to remove a single element of an array instead of the slice syntax x[i:i+1]=[]. This may be useful if for example you are in os.walk and wish to delete an element in the directory. I would not consider a keyword useful for this though, since one could just make a [].remove(index) method (the .remove method is actually search-and-remove-first-instance-of-value).\n",
            "\nFirstly, you can del other things besides local variables\ndel list_item[4]\ndel dictionary[\"alpha\"]\n\nBoth of which should be clearly useful. Secondly, using del on a local variable makes the intent clearer.  Compare:\ndel foo\n\nto\nfoo = None\n\nI know in the case of del foo that the intent is to remove the variable from scope. It's not clear that foo = None is doing that. If somebody just assigned foo = None I might think it was dead code. But I instantly know what somebody who codes del foo was trying to do.\n",
            "\nThere is a specific example of when you should use del (there may be others, but I know about this one off hand) when you are using sys.exc_info() to inspect an exception.  This function returns a tuple, the type of exception that was raised, the message, and a traceback.  \nThe first two values are usually sufficient to diagnose an error and act on it, but the third contains the entire call stack between where the exception was raised and where the the exception is caught.  In particular, if you do something like\ntry:\n    do_evil()\nexcept:\n    exc_type, exc_value, tb = sys.exc_info()\n    if something(exc_value):\n        raise\n\nthe traceback, tb ends up in the locals of the call stack, creating a circular reference that cannot be garbage collected.  Thus, it is important to do:\ntry:\n    do_evil()\nexcept:\n    exc_type, exc_value, tb = sys.exc_info()\n    del tb\n    if something(exc_value):\n        raise\n\nto break the circular reference.  In many cases where you would want to call sys.exc_info(), like with metaclass magic, the traceback is useful, so you have to make sure that you clean it up before you can possibly leave the exception handler.  If you don't need the traceback, you should delete it immediately, or just do:\nexc_type, exc_value = sys.exc_info()[:2]\n\nTo avoid it all together.  \n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "dictionary",
            "python-internals",
            "del"
        ]
    },
    {
        "question_id": "40850089",
        "question": "\nI'm using Python and Keras (currently using Theano backend, but I have no qualms with switching). I have a neural network that I load and process multiple sources of information with in parallel. Currently, I've been running each one in a separate process and it loads its own copy of the network from the file. This seems like a waste of RAM, so I was thinking it would be more efficient to have a single multi-threaded process with one instance of the network that is used by all threads. However, I'm wondering if Keras is thread safe with either backend. If I run .predict(x) on two different inputs at the same time in different threads, will I run into race conditions or other issues?\nThanks\n",
        "all_answers": [
            "\nYes, Keras is thread safe, if you pay a little attention to it. \nIn fact, in reinforcement learning there is an algorithm called Asynchronous Advantage Actor Critics (A3C) where each agent relies on the same neural network to tell them what they should do in a given state. In other words, each thread calls model.predict concurrently as in your problem. An example implementation with Keras of it is here.\nYou should, however, pay extra attention to this line if you looked into the code:\nmodel._make_predict_function() # have to initialize before threading\nThis is never mentioned in the Keras docs, but its necessary to make it work concurrently. In short, _make_predict_function is a function that compiles the predict function. In multi thread setting, you have to manually call this function to compile predict in advance, otherwise the predict function will not be compiled until you run it the first time, which will be problematic when many threading calling it at once. You can see a detailed explanation here.\nI have not met any other issues with multi threading in Keras till now.\n",
            "\nto quote the kind fcholet: \n\n_make_predict_function is a private API. We should not recommend calling it.\nHere, the user should simply call predict first.\nNote that Keras models can't be guaranteed to be thread-safe. \n  Consider having independent copies of the model in each thread \n  for CPU inference.\n\n",
            "\nIt's pretty simple to delegate a method to a thread or sub-process using BaseEventLoop.run_in_executor:\nimport asyncio\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef cpu_bound_operation(x):\n    time.sleep(x) # This is some operation that is CPU-bound\n\n@asyncio.coroutine\ndef main():\n    # Run cpu_bound_operation in the ProcessPoolExecutor\n    # This will make your coroutine block, but won't block\n    # the event loop; other coroutines can run in meantime.\n    yield from loop.run_in_executor(p, cpu_bound_operation, 5)\n\n\nloop = asyncio.get_event_loop()\np = ProcessPoolExecutor(2) # Create a ProcessPool with 2 processes\nloop.run_until_complete(main())\n\nAs for whether to use a ProcessPoolExecutor or ThreadPoolExecutor, that's kind of hard to say; pickling a large object will definitely eat some CPU cycles, which initially would make you think ProcessPoolExecutor is the way to go. However, passing your 100MB object to a Process in the pool would require pickling the instance in your main process, sending the bytes to the child process via IPC, unpickling it in the child, and then pickling it again so you can write it to disk. Given that, my guess is the pickling/unpickling overhead will be large enough that you're better off using a ThreadPoolExecutor, even though you're going to take a performance hit because of the GIL.\nThat said, it's very simple to test both ways and find out for sure, so you might as well do that.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "multithreading",
            "keras"
        ]
    },
    {
        "question_id": "6398172",
        "question": "\nI have this code: \n<table class=\"topics\" >\n    <tr>\n        <td style=\"white-space: nowrap; padding: 0 5px 0 0; color:#3A5572; font-weight: bold;\">Test</td>\n        <td style=\"padding: 0 4px 0 0;\">1.0</td>\n        <td>abc</td>\n    </tr>\n    <tr>\n\n        <td style=\"white-space: nowrap; padding: 0 5px 0 0; color:#3A5572; font-weight: bold;\">test2</td>\n        <td style=\"padding: 0 4px 0 0;\">1.3</td>\n        <td>def</td>\n    </tr>\n</table>\n\nThe rows are spaced too far apart. I want the lines closer together.\nWhat I did was to add the following CSS but it doesn't seem to change anything. \n.topics tr { height: 14px; }\n\nWhat am I doing wrong?\n",
        "all_answers": [
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\ntry setting the attribute for td\nso:\n.topic td{ height: 14px };\n\n",
            "\ntry this:\n.topics tr { line-height: 14px; }\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n"
        ],
        "answer": "A3",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "17121846",
        "question": "\nI have code like the following:\nvar req = require('request');\n\nreq.post('someUrl',\n   { form: { username: 'user', password: '', opaque: 'someValue', logintype: '1'}, },\n   function (e, r, body) {\n      console.log(body);\n});\n\nHow can I set headers for this?\nI need user-agent, content-type and probably something else to be in the headers:\nheaders = { \n   'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.110 Safari/537.36',\n   'Content-Type' : 'application/x-www-form-urlencoded' \n};\n\nI've tried in multiple ways but I can either send header or form-data, failed to send both.\n",
        "all_answers": [
            "\nThis should work. \nvar url = 'http://<your_url_here>';\nvar headers = { \n    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:24.0) Gecko/20100101 Firefox/24.0',\n    'Content-Type' : 'application/x-www-form-urlencoded' \n};\nvar form = { username: 'user', password: '', opaque: 'someValue', logintype: '1'};\n\nrequest.post({ url: url, form: form, headers: headers }, function (e, r, body) {\n    // your callback body\n});\n\n",
            "\nI've finally managed to do it.\nAnswer in code snippet below:\nvar querystring = require('querystring');\nvar request = require('request');\n\nvar form = {\n    username: 'usr',\n    password: 'pwd',\n    opaque: 'opaque',\n    logintype: '1'\n};\n\nvar formData = querystring.stringify(form);\nvar contentLength = formData.length;\n\nrequest({\n    headers: {\n      'Content-Length': contentLength,\n      'Content-Type': 'application/x-www-form-urlencoded'\n    },\n    uri: 'http://myUrl',\n    body: formData,\n    method: 'POST'\n  }, function (err, res, body) {\n    //it works!\n  });\n\n",
            "\nYou need to use the request-promise module, not the request module or http.request().\nawait works on functions that return a promise, not on functions that return the request object and expect you to use callbacks or event listeners to know when things are done.\nThe request-promise module supports the same features as the request module, but asynchronous functions in it return promises so you can use either .then() or await with them rather than the callbacks that the request module expects.\nSo, install the request-promise module and then change this:\nvar request = require(\"request\");\n\nto this:\nconst request = require(\"request-promise\");\n\nThen, you can do:\nvar result = await request(options);\n\n\nEDIT Jan, 2020 - request() module in maintenance mode\nFYI, the request module and its derivatives like request-promise are now in maintenance mode and will not be actively developed to add new features.  You can read more about the reasoning here.  There is a list of alternatives in this table with some discussion of each one.\nI have been using got() myself and it's built from the beginning to use promises, supports many of the same options as the request() module and is simple to program.\nNewer versions of nodejs also have the fetch() interface built-in directly for making http requests and getting responses back (same API as fetch in the browser, but built into nodejs).\n"
        ],
        "answer": "A2",
        "tags": [
            "node.js",
            "header",
            "request",
            "form-data"
        ]
    },
    {
        "question_id": "27828404",
        "question": "\nChanges exist upstream in a tracked branch, but when I type git status it indicates that my local branch is up-to-date.  Is this new behavior, did I change a config setting, or is something wrong?\nubuntu@host:/my/repo# git status\nOn branch master\nYour branch is up-to-date with 'origin/master'.\n\nnothing to commit, working directory clean\n\n\nubuntu@host:/my/repo# git pull\nremote: Counting objects: 11, done.\nremote: Compressing objects: 100% (11/11), done.\nremote: Total 11 (delta 6), reused 0 (delta 0)\nUnpacking objects: 100% (11/11), done.\nFrom bitbucket.org:my/repo\n   1234567..abcdefg  master     -> origin/master\nUpdating 1234567..abcdefg\nFast-forward\n file1        |  1 -\n file2        | 43 +++++++++++++++++++++++++++++++++++++++++++\n file3        | 21 ++++++++++++---------\n file4        | 21 ++++++++++++---------\n 4 files changed, 67 insertions(+), 19 deletions(-)\n create mode 100644 file5\n\n",
        "all_answers": [
            "\nThis is because your local repo hasn't checked in with the upstream remotes. To have this work as you're expecting it to, use git fetch then run a git status again.\n",
            "\nWhat the status is telling you is that you're behind the ref called origin/master which is a local ref in your local repo. In this case that ref happens to track a branch in some remote, called origin, but the status is not telling you anything about the branch on the remote. It's telling you about the ref, which is just a commit ID stored on your local filesystem (in this case, it's typically in a file called .git/refs/remotes/origin/master in your local repo).\ngit pull does two operations; first it does a git fetch to get up to date with the commits in the remote repo (which updates the origin/master ref in your local repo), then it does a git merge to merge those commits into the current branch.\nUntil you do the fetch step (either on its own or via git pull) your local repo has no way to know that there are additional commits upstream, and git status only looks at your local origin/master ref.\nWhen git status says up-to-date, it means \"up-to-date with the branch that the current branch tracks\", which in this case means \"up-to-date with the local ref called origin/master\". That only equates to \"up-to-date with the upstream status that was retrieved last time we did a fetch\" which is not the same as \"up-to-date with the latest live status of the upstream\".\nWhy does it work this way? Well the fetch step is a potentially slow and expensive network operation. The design of Git (and other distributed version control systems) is to avoid network operations when unnecessary, and is a completely different model to the typical client-server system many people are used to (although as pointed out in the comments below, Git's concept of a \"remote tracking branch\" that causes confusion here is not shared by all DVCSs). It's entirely possible to use Git offline, with no connection to a centralized server, and the output of git status reflects this.\nCreating and switching branches (and checking their status) in Git is supposed to be lightweight, not something that performs a slow network operation to a centralized system. The assumption when designing Git, and the git status output, was that users understand this (too many Git features only make sense if you already know how Git works). With the adoption of Git by lots and lots of users who are not familiar with DVCS this assumption is not always valid.\n"
        ],
        "answer": "A2",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "3685790",
        "question": "\nIs there a clever way to let the user switch between hide and view password in an android EditText?\nA number of PC based apps let the user do this.\n",
        "all_answers": [
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nYou can dynamically change the attributes of a TextView. If you would set the XML Atrribute android:password to true the view would show dots if you set it to false the text is shown. \nWith the method setTransformationMethod you should be able to change this attributes from code. (Disclaimer: I have not tested if the method still works after the view is displayed. If you encounter problems with that leave me a comment for me to know.) \nThe full sample code would be \nyourTextView.setTransformationMethod(new PasswordTransformationMethod());\n\nto hide the password. To show the password you could set one of the existing transformation methods or implement an empty TransformationMethod that does nothing with the input text.\nyourTextView.setTransformationMethod(new DoNothingTransformation());\n\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nDid you try with setTransformationMethod? It's inherited from TextView and want a TransformationMethod as a parameter.\nYou can find more about TransformationMethods here.\nIt also has some cool features, like character replacing.\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "passwords"
        ]
    },
    {
        "question_id": "27315592",
        "question": "\nclass ChromeLoginView(View):\n\n     def get(self, request):\n          return JsonResponse({'status': request.user.is_authenticated()})\n\n     @method_decorator(csrf_exempt)\n     def post(self, request):\n          username = request.POST['username']\n          password = request.POST['password']\n          user = authenticate(username=username, password=password)\n          if user is not None:\n                if user.is_active:\n                     login(request, user)\n                     return JsonResponse({'status': True})\n          return JsonResponse({'status': False})\n\nI am expecting that the post does stopped by csrf, but it return 403 error.\nBut if remove that decorator and do this in the URLConf\nurl(r'^chrome_login/', csrf_exempt(ChromeLoginView.as_view()), name='chrome_login'),\n\nit will work.\nWhat happened here? didn't it supposed to work, because I guess that's what method_decorator do.\nI'm using python3.4 and django1.7.1\nAny advice would be great.\n",
        "all_answers": [
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nAs @knbk said, this is the dispatch() method that must be decorated.\nSince Django 1.9, you can use the method_decorator directly on a class:\nfrom django.utils.decorators import method_decorator\n\n@method_decorator(csrf_exempt, name='dispatch')\nclass ChromeLoginView(View):\n\n    def get(self, request):\n        return JsonResponse({'status': request.user.is_authenticated()})\n\n    def post(self, request):\n        username = request.POST['username']\n        password = request.POST['password']\n        user = authenticate(username=username, password=password)\n        if user is not None:\n            if user.is_active:\n                login(request, user)\n                return JsonResponse({'status': True})\n        return JsonResponse({'status': False})\n\nThis avoids overriding the dispatch() method only to decorate it.\n",
            "\nYou need to decorate the dispatch method for csrf_exempt to work. What it does is set an csrf_exempt attribute on the view function itself to True, and the middleware checks for this on the (outermost) view function. If only a few of the methods need to be decorated, you still need to use csrf_exempt on the dispatch method, but you can use csrf_protect on e.g. put(). If a GET, HEAD, OPTIONS or TRACE HTTP method is used it won't be checked whether you decorate it or not. \nclass ChromeLoginView(View):\n    @method_decorator(csrf_exempt)\n    def dispatch(self, request, *args, **kwargs):\n        return super(ChromeLoginView, self).dispatch(request, *args, **kwargs)\n\n    def get(self, request):\n        return JsonResponse({'status': request.user.is_authenticated()})\n\n    def post(self, request):\n        username = request.POST['username']\n        password = request.POST['password']\n        user = authenticate(username=username, password=password)\n        if user is not None:\n            if user.is_active:\n                login(request, user)\n                return JsonResponse({'status': True})\n        return JsonResponse({'status': False})\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django"
        ]
    },
    {
        "question_id": "37464",
        "question": "\nIf I create an application on my Mac, is there any way I can get it to run on an iPhone without going through the app store?\nIt doesn't matter if the iPhone has to be jailbroken, as long as I can still run an application created using the official SDK. For reasons I won't get into, I can't have this program going through the app store.\n",
        "all_answers": [
            "\nOfficial Developer Program\nFor a standard iPhone you'll need to pay the US$99/yr to be a member of the developer program. You can then use the adhoc system to install your application onto up to 100 devices. The developer program has the details but it involves adding UUIDs for each of the devices to your application package. UUIDs can be easiest retrieved using Ad Hoc Helper available from the App Store. For further details on this method, see Craig Hockenberry's Beta testing on iPhone 2.0 article\nJailbroken iPhone\nFor jailbroken iPhones, you can use the following method which I have personally tested using the AccelerometerGraph sample app on iPhone OS 3.0.\nCreate Self-Signed Certificate\nFirst you'll need to create a self signed certificate and patch your iPhone SDK to allow the use of this certificate:\n\nLaunch Keychain Access.app. With no items selected, from the Keychain menu select Certificate Assistant, then Create a Certificate.\nName: iPhone Developer\nCertificate Type: Code Signing\nLet me override defaults: Yes  \nClick Continue\nValidity: 3650 days\nClick Continue\nBlank out the Email address field.\nClick Continue until complete.\nYou should see \"This root certificate is not trusted\". This is expected.\nSet the iPhone SDK to allow the self-signed certificate to be used:\n\nsudo /usr/bin/sed -i .bak 's/XCiPhoneOSCodeSignContext/XCCodeSignContext/' /Developer/Platforms/iPhoneOS.platform/Info.plist\n\nIf you have Xcode open, restart it for this change to take effect.\n\nManual Deployment over WiFi\nThe following steps require openssh, and uikittools to be installed first. Replace jasoniphone.local with the hostname of the target device.  Be sure to set your own password on both the mobile and root users after installing SSH.\nTo manually compile and install your application on the phone as a system app (bypassing Apple's installation system):\n\nProject, Set Active SDK, Device and Set Active Build Configuration, Release.\nCompile your project normally (using Build, not Build & Go).\nIn the build/Release-iphoneos directory you will have an app bundle. Use your preferred method to transfer this to /Applications on the device.\n\nscp -r AccelerometerGraph.app root@jasoniphone:/Applications/\n\nLet SpringBoard know the new application has been installed:\n\nssh mobile@jasoniphone.local uicache\n\nThis only has to be done when you add or remove applications. Updated applications just need to be relaunched.\n\nTo make life easier for yourself during development, you can setup SSH key authentication and add these extra steps as a custom build step in your project.\nNote that if you wish to remove the application later you cannot do so via the standard SpringBoard interface and you'll need to use SSH and update the SpringBoard:\nssh root@jasoniphone.local rm -r /Applications/AccelerometerGraph.app &&\nssh mobile@jasoniphone.local uicache\n\n",
            "\nYes, once you have joined the iPhone Developer Program, and paid Apple $99, you can provision your applications on up to 100 iOS devices.\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "iphone"
        ]
    },
    {
        "question_id": "24279948",
        "question": "\nHow can I restrict a Rails validation to check only on create OR when the field isn't blank? I'm creating a user settings page for an app I'm working on and the problem is that, when updating using the parameters provided by the form, the settings will only save when both a password and password confirmation are present. I would like these password fields to validate on create no matter what, but only on update when they are provided.\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nPlease try\nvalidates :<attributes>, if: Proc.new{|obj| obj.new_record? || !obj.<attribute>.blank? }\n\nor add custom method names instead of attribute name.    \n",
            "\nIf you want to allow blank values use: allow_blank with validates.\nclass Topic < ActiveRecord::Base\n  validates :title, length: { is: 5 }, allow_blank: true\nend\n\nIf you want to validate only on create, use on with validates.\nclass Topic < ActiveRecord::Base\n  validates :email, uniqueness: true, on: :create\nend\n\nTo cover your case:\nclass Topic\n  validates :email, presence: true, if: :should_validate?\n\n  def should_validate?\n    new_record? || email.present?\n  end\nend\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "rails-activerecord"
        ]
    },
    {
        "question_id": "2503923",
        "question": "\nI know this isn't right, but for the sake of illustration I'd like to do something like this:\n<%= Html.Button(\"Action\", \"Controller\") %>\n\nMy goal is to make an HTML button that will call my MVC controller's action method.\n",
        "all_answers": [
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nThe HTML <button> element can only postback to the form containing it.\nTherefore, you need to make a form that POSTs to the action, then put a <button> or <input type=\"submit\" /> in the form.\n",
            "\nNo need to use a form at all unless you want to post to the action. An input button (not submit) will do the trick.\n  <input type=\"button\"\n         value=\"Go Somewhere Else\"\n         onclick=\"location.href='<%: Url.Action(\"Action\", \"Controller\") %>'\" />\n\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYou can use Url.Action to specify generate the url to a controller action, so you could use either of the following:\n<form method=\"post\" action=\"<%: Url.Action(\"About\", \"Home\") %>\">\n   <input type=\"submit\" value=\"Click me to go to /Home/About\" />\n</form>\n\nor:\n<form action=\"#\">\n  <input type=\"submit\" onclick=\"parent.location='<%: Url.Action(\"About\", \"Home\") %>';return false;\" value=\"Click me to go to /Home/About\" />\n  <input type=\"submit\" onclick=\"parent.location='<%: Url.Action(\"Register\", \"Account\") %>';return false;\" value=\"Click me to go to /Account/Register\" />\n</form>\n\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n"
        ],
        "answer": "A3",
        "tags": [
            "html",
            "asp.net-mvc"
        ]
    },
    {
        "question_id": "17603907",
        "question": "\nThere is a field 'noticeBy' enum('email','mobile','all','auto','nothing') NOT NULL DEFAULT 'auto'. As it known ordering by ENUM field performs relative to its index. However, how it possible make order by its values?\n",
        "all_answers": [
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nAs documented under Sorting:\n\nENUM values are sorted based on their index numbers, which depend on the order in which the enumeration members were listed in the column specification. For example, 'b' sorts before 'a' for ENUM('b', 'a'). The empty string sorts before nonempty strings, and NULL values sort before all other enumeration values.\nTo prevent unexpected results when using the ORDER BY clause on an ENUM column, use one of these techniques:\n\nSpecify the ENUM list in alphabetic order.\nMake sure that the column is sorted lexically rather than by index number by coding ORDER BY CAST(col AS CHAR) or ORDER BY CONCAT(col).\n\n\nPer the second bullet, you can therefore sort on the column after it has been cast to a string:\nORDER BY CAST(noticeBy AS CHAR)\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\nYou can define your order however you wish:\nORDER BY CASE noticeBy\n           WHEN 'email' THEN 1\n           WHEN 'mobile' THEN 2\n           WHEN 'all' THEN 3\n           WHEN 'auto' THEN 4\n           ELSE 5\n         END\n\nThis will return the rows in the following order: email, mobile, all, auto, nothing.\n",
            "\nThis also works:\nORDER BY FIELD(noticeBy, 'all','auto','email','mobile','nothing')\n\n(I don't believe that there is a setting to achieve this, you have to provide the sort-values.)\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "mysql",
            "sql",
            "enums",
            "sql-order-by"
        ]
    },
    {
        "question_id": "879391",
        "question": "\nUsing LINQ on collections, what is the difference between the following lines of code?\nif(!coll.Any(i => i.Value))\n\nand\nif(!coll.Exists(i => i.Value))\n\nUpdate 1\nWhen I disassemble .Exists it looks like there is no code.\nUpdate 2\nAnyone know why there is no code there for this one?\n",
        "all_answers": [
            "\nSee documentation\nList.Exists (Object method - MSDN)\n\nDetermines whether the List(T) contains elements that match the conditions defined by the specified predicate.\n\nThis exists since .NET 2.0, so before LINQ. Meant to be used with the Predicate delegate, but lambda expressions are backward compatible. Also, just List has this (not even IList)\nIEnumerable.Any (Extension method - MSDN)   \n\nDetermines whether any element of a sequence satisfies a condition.\n\nThis is new in .NET 3.5 and uses Func(TSource, bool) as argument, so this was intended to be used with lambda expressions and LINQ.\nIn behaviour, these are identical.\n",
            "\nI don't understand where the first \"result with sample data\" is coming from, but the problem in the console app is that you're using SelectMany to look at each item in each group.\nI think you just want:\nList<ResultLine> result = Lines\n    .GroupBy(l => l.ProductCode)\n    .Select(cl => new ResultLine\n            {\n                ProductName = cl.First().Name,\n                Quantity = cl.Count().ToString(),\n                Price = cl.Sum(c => c.Price).ToString(),\n            }).ToList();\n\nThe use of First() here to get the product name assumes that every product with the same product code has the same product name. As noted in comments, you could group by product name as well as product code, which will give the same results if the name is always the same for any given code, but apparently generates better SQL in EF.\nI'd also suggest that you should change the Quantity and Price properties to be int and decimal types respectively - why use a string property for data which is clearly not textual?\n",
            "\nThe following query works. It uses each group to do the select instead of SelectMany. SelectMany works on each element from each collection. For example, in your query you have a result of 2 collections. SelectMany gets all the results, a total of 3, instead of each collection. The following code works on each IGrouping in the select portion to get your aggregate operations working correctly.\nvar results = from line in Lines\n              group line by line.ProductCode into g\n              select new ResultLine {\n                ProductName = g.First().Name,\n                Price = g.Sum(pc => pc.Price).ToString(),\n                Quantity = g.Count().ToString(),\n              };\n\n",
            "\nThe difference is that Any is an extension method for any IEnumerable<T> defined on System.Linq.Enumerable.  It can be used on any IEnumerable<T> instance.  \nExists does not appear to be an extension method.  My guess is that coll is of type List<T>.  If so Exists is an instance method which functions very similar to Any.  \nIn short, the methods are essentially the same.  One is more general than the other.\n\nAny also has an overload which takes no parameters and simply looks for any item in the enumerable. \nExists has no such overload.\n\n",
            "\nAdditionally, this will only work if Value is of type bool. Normally this is used with predicates. Any predicate would be generally used find whether there is any element satisfying a given condition. Here you're just doing a map from your element i to a bool property. It will search for an \"i\" whose Value property is true. Once done, the method will return true.\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "linq",
            "collections"
        ]
    },
    {
        "question_id": "5450047",
        "question": "\n\n\n\nI want to do Graphics programming in C. I had searched a lot about the compiler that provides a rich set of functions for doing GUI programming in C, but I couldn't find anything.\nBasically I want to draw buttons and then accept the choice from the user and take an appropriate action. It would be helpful if you can suggest a C compiler, or a library that I can add to my compiler. I am working on the Windows operating system.\nPresently, I am using TURBO C compiler that does not support direct methods for creating buttons. Any help would be appreciated.\n",
        "all_answers": [
            "\nA C compiler itself won't provide you with GUI functionality, but there are plenty of libraries for that sort of thing. The most popular is probably GTK+, but it may be a little too complicated if you are just starting out and want to quickly get a GUI up and running.\nFor something a little simpler, I would recommend IUP. With it, you can use a simple GUI definition language called LED to layout controls (but you can do it with pure C, if you want to).\n",
            "\nThe most famous library to create some GUI in C language is certainly GTK.\nWith this library you can easily create some buttons (for your example). When a user clicks on the button, a signal is emitted and you can write a handler to do some actions.\n",
            "\nUse the following: \nUIManager.setLookAndFeel(UIManager.getSystemLookAndFeelClassName());\n\nRead UIManager and How to Set the Look and Feel for more information. \n",
            "\nThis is guaranteed to have nothing to do with the compiler. All compilers do is compile the code that they are given. What you're looking for is a GUI library, which you can write code against using any compiler that you want.\nOf course, that being said, your first order of business should be to ditch Turbo C. That compiler is about 20 years old and continuing to use it isn't doing you any favors. You can't write modern GUI applications, as it will only produce 16-bit code. All modern operating systems are 32-bit, and many are now 64-bit. It's also worth noting that 64-bit editions of Windows will not run 16-bit applications natively. You'll need an emulator for that; it's not really going to engender much feeling of accomplishment if you can only write apps that work in a DOS emulator. :-)\nMicrosoft's Visual Studio Express C++ is available as a free download. It includes the same compiler available in the full version of the suite. The C++ package also compiles pure C code.\nAnd since you're working in Windows, the Windows API is a natural choice. It allows you to write native Windows applications that have access to the full set of GUI controls. You'll find a nice tutorial here on writing WinAPI applications in C. If you choose to go with Visual Studio, it also includes boilerplate code for a blank WinAPI application that will get you up and running quickly.\nIf you really care about learning to do this, Charles Petzold's Programming Windows is the canonical resource of the subject, and definitely worth a read. The entire Windows API was written in C, and it's entirely possible to write full-featured Windows applications in C. You don't need no stinkin' C++.\nThat's the way I'd do it, at least. As the other answers suggest, GTK is also an option. But the applications it generates are just downright horrible-looking on Windows.\n\nEDIT:  It looks like you're not alone in wanting to write \"GUI\" applications using an antiquated compiler. A Google search turns up the following library: TurboGUI: A GUI Framework for Turbo C/C++:\n \nIf you're required use Turbo C, this might be an option.\n"
        ],
        "answer": "A4",
        "tags": [
            "c",
            "windows",
            "user-interface",
            "graphics"
        ]
    },
    {
        "question_id": "1768343",
        "question": "\nWhat does the =& (equals-ampersand) assignment operator do in PHP?\nIs it deprecated?\n",
        "all_answers": [
            "\nIf you use AND and OR, you'll eventually get tripped up by something like this:\n$this_one = true;\n$that = false;\n\n$truthiness = $this_one and $that;\n\nWant to guess what $truthiness equals?\nIf you said false... bzzzt, sorry, wrong!\n$truthiness above has the value true.  Why?  = has a higher precedence than and. The addition of parentheses to show the implicit order makes this clearer:\n($truthiness = $this_one) and $that\n\nIf you used && instead of and in the first code example, it would work as expected and be false.\nAs discussed in the comments below, this also works to get the correct value, as parentheses have higher precedence than =:\n$truthiness = ($this_one and $that)\n\n",
            "\nFor safety, I always parenthesise my comparisons and space them out. That way, I don't have to rely on operator precedence:\nif( \n    ((i==0) && (b==2)) \n    || \n    ((c==3) && !(f==5)) \n  )\n\n",
            "\nIt's two different operators. = is assignment as you probably know. And & means the variable should be accessed by reference rather than by value.\n",
            "\nSince and has lower precedence than = you can use it in condition assignment:\nif ($var = true && false) // Compare true with false and assign to $var\nif ($var = true and false) // Assign true to $var and compare $var to false\n\n",
            "\nIt's not deprecated and is unlikely to be. It's the standard way to, for example, make part of one array or object mirror changes made to another, instead of copying the existing data.\nIt's called assignment by reference, which, to quote the manual, \"means that both variables end up pointing at the same data, and nothing is copied anywhere\".\nThe only thing that is deprecated with =& is \"assigning the result of new by reference\" in PHP 5, which might be the source of any confusion. new is automatically assigned by reference, so & is redundant/deprecated in$o = &new C;, but not in $o = &$c;.\n\nSince it's hard to search, note that =& (equals ampersand) is the same as = & (equals space ampersand) and is often written such that it runs into the other variable like $x = &$y['z']; or $x = &$someVar (ampersand dollar sign variable name). Example simplified from the docs:\n$a = 3;\n$b = &$a;\n$a = 4;\nprint \"$b\"; // prints 4\n\n\nHere's a handy link to a detailed section on Assign By Reference in the PHP manual. That page is part of a series on references - it's worth taking a minute to read the whole series.\n",
            "\nDepending on how it's being used, it might be necessary and even handy.\nhttp://php.net/manual/en/language.operators.logical.php\n// \"||\" has a greater precedence than \"or\"\n\n// The result of the expression (false || true) is assigned to $e\n// Acts like: ($e = (false || true))\n$e = false || true;\n\n// The constant false is assigned to $f and then true is ignored\n// Acts like: (($f = false) or true)\n$f = false or true;\n\nBut in most cases it seems like more of a developer taste thing, like every occurrence of this that I've seen in CodeIgniter framework like @Sarfraz has mentioned.\n"
        ],
        "answer": "A5",
        "tags": [
            "php",
            "operators",
            "assignment-operator"
        ]
    },
    {
        "question_id": "6317033",
        "question": "\nI want to minimize a C# WinForms app to system tray. I've tried this:\nHaving the application minimize to the system tray when button is clicked?. The first time I minimize it, it's nowhere to be found on the screen - taskbar/above taskbar/tray.\nIf i hit alt tab, I can see my app there; if I alt tab into it and minimize it again, it shows up above the taskbar:\n\nWhat am I doing wrong?\n",
        "all_answers": [
            "\nYou need to add a NotifyIcon to your form. You can then use the Click event of the NotifyIcon to have it set the Visible property on your Form to true again.\n",
            "\nWhat about the option of hiding the form when minimized then showing once you click on the tray icon?  \nIn the form resize event, do the check there and hide the form\n   private void Form_Resize(object sender, EventArgs e)\n    {\n        if (WindowState == FormWindowState.Minimized)\n        {\n            this.Hide();\n        }\n    }\n\nThen when clicking on the taskbar icon just restore it.\n    private void notifyIcon_Click(object sender, EventArgs e)\n    {\n        this.Show();\n        this.WindowState = FormWindowState.Normal;\n    }\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            ".net",
            "windows",
            "winforms",
            "notifyicon"
        ]
    },
    {
        "question_id": "4713571",
        "question": "\nUsing Rails 3, is there a way to use link_to helper, or any helper for that matter, inside model?\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThere are some reasons that you may need link_to in a model. Yes, @andy, it's a violation of MVC, but that doesn't mean you should get points for not answering the question. \n@schwabsauce, it's easier than that. The first line isn't even strictly necessary if you do it in an initializer or something. Same thing works for .sanitize and .raw and a whole load of other awesome functions. \nActionView::Base.send(:include, Rails.application.routes.url_helpers)\nActionController::Base.helpers.link_to(whatever)\n\nIf you want to use autopaths you may have to do this inside your link_to:\nRails.application.routes.url_helpers.page_path(@page)\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nI got this to work with the following inclusions:\ninclude ActionView::Helpers::UrlHelper\ninclude ActionController::UrlFor\ninclude Rails.application.routes.url_helpers\n\ncattr_accessor :controller\ndef controller; self.class.controller; end\ndef request; controller.request; end\n\nThen in my controller I populated the attribute (creating a controller from scratch requires a significant amount of data in the arguments hash).\nLead.controller = self\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby-on-rails-3"
        ]
    },
    {
        "question_id": "5999193",
        "question": "\nI am confused a bit about wait and notify/notifyAll.\nI know there is a lock for every java object. I know wait will release the lock for other thread. How about notify/notifyall? Does notify/notifyAll release the lock it is holding for other thread?\n",
        "all_answers": [
            "\nNo -- notify/notifyAll don't release locks like wait does. The awakened thread can't run until the code which called notify releases its lock.\nThis is what the Javadoc says:\n\nThe thread releases ownership of this monitor and waits until another thread notifies threads waiting on this object's monitor to wake up either through a call to the notify method or the notifyAll method. The thread then waits until it can re-obtain ownership of the monitor and resumes execution. \n\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nBetter alternatives to join() method have been evolved over a period of time.\nExecutorService.html#invokeAll is one alternative.\n\nExecutes the given tasks, returning a list of Futures holding their status and results when all complete. Future.isDone() is true for each element of the returned list. \n\nNote that a completed task could have terminated either normally or by throwing an exception. The results of this method are undefined if the given collection is modified while this operation is in progress.\nForkJoinPool or Executors.html#newWorkStealingPool provides other alternatives to achieve the same purpose. \nExample code snippet:\n\nimport java.util.concurrent.*;\n\nimport java.util.*;\n\npublic class InvokeAllDemo{\n    public InvokeAllDemo(){\n        System.out.println(\"creating service\");\n        ExecutorService service = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\n\n        List<MyCallable> futureList = new ArrayList<MyCallable>();\n        for ( int i=0; i<10; i++){\n            MyCallable myCallable = new MyCallable((long)i);\n            futureList.add(myCallable);\n        }\n        System.out.println(\"Start\");\n        try{\n            List<Future<Long>> futures = service.invokeAll(futureList);  \n        }catch(Exception err){\n            err.printStackTrace();\n        }\n        System.out.println(\"Completed\");\n        service.shutdown();\n    }\n    public static void main(String args[]){\n        InvokeAllDemo demo = new InvokeAllDemo();\n    }\n    class MyCallable implements Callable<Long>{\n        Long id = 0L;\n        public MyCallable(Long val){\n            this.id = val;\n        }\n        public Long call(){\n            // Add your business logic\n            return id;\n        }\n    }\n}\n\n",
            "\n\nwait( ) tells the calling thread to give up the monitor and go to sleep until some other\nthread enters the same monitor and calls notify( ).\nnotify( ) wakes up a thread that called wait( ) on the same object.\nnotifyAll( ) wakes up all the threads that called wait( ) on the same object. The\nhighest priority thread will run first.\n\n",
            "\nYou can use join() to wait for all threads to finish. Like below:\nfor (int i = 0; i < 10; i++) \n{\n    Thread T1 = new Thread(new ThreadTest(i));                \n    T1.start();   \n    try {             \n       T1.join(); \n    } catch (InterruptedException e) {\n       e.printStackTrace();\n    }\n}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "java",
            "multithreading",
            "locking"
        ]
    },
    {
        "question_id": "7451716",
        "question": "\nI have a Java app which needs to perform partial least squares regression. It would appear there are no Java implementations of PLSR out there. Weka might have had something like it at some point, but it is no longer in the API. On the other hand, I have found a good R implementation, which has an added bonus to it. It was used by the people whose result I want to replicate, which means there is less chance that things will go wrong because of differences in the way PLSR is implemented.\nThe question is: is there a good enough (and simple to use) package that enable Java to call R, pass in some parameters to a function and read back the results? My other option is to have Java spawn R in a Process and then monitor it. Data would be read and written to disk. Which of the two would you recommend? Am I missing the obvious third option?\n",
        "all_answers": [
            "\nThis error is often resolved by installing a Java version (i.e. 64-bit Java or 32-bit Java) that fits to the type of R version that you are using (i.e. 64-bit R or 32-bit R). This problem can easily effect Windows 7 users, since they might have installed a version of Java that is different than the version of R they are using.\nhttp://www.r-statistics.com/2012/08/how-to-load-the-rjava-package-after-the-error-java_home-cannot-be-determined-from-the-registry/\n",
            "\nI have successfully used two alternatives in the past.\nJRI\n\nPros: probably better performance.\nCons: you have to configure some environment variables and libraries, different in Win/UNIX.\n\nRServe\n\nPros: easy to setup, you don't need to initialize R or link against\nany R library, can run in a different machine.\nCons: based on TCP/IP (a server is running), no callbacks from R.\n\nOther alternatives I have never used : RCaller\n",
            "\nI had similar need a while back and tested a few of the interfaces to R.  The one I found to be the best for my needs (windows, c#) was Rserve which I believe is written in Java.  My only gripe with it is that it wasn't 64-bit.  I used a simple client written in c# and it worked very well.  I'm sure the Java client is a lot better.\n",
            "\nInstall 64 bit Java from https://java.com/en/download/manual.jsp.\nThen in windows cmd run\nsetx PATH \"C:\\Program Files\\Java\\jre1.8.0_211\\bin\\server;%PATH%\"\n(make sure your path is correct). \nThen in RStudio run\nSys.setenv(JAVA_HOME=\"\")\nNow, you should be able to run rJava!!\n",
            "\nThere has been work by Duncan Temple Lang: http://rss.acs.unt.edu/Rdoc/library/SJava/Docs/RFromJava.pdf . \nMy guess as to the most robust solution would be JGR. The developers of JGR have a mailing list, Stats-Rosuda and the mailing list Archive indicates the list remains active as of 2013.\nThere is also code that has been put up at Googlecode, with an example here:\nhttp://stdioe.blogspot.com/2011/07/rcaller-20-calling-r-from-java.html\n",
            "\nI got the same error resolved by installing same version of R and Java i.e. 64 bits and manually updating the path i.e. ,\nSys.setenv(JAVA_HOME='C:/Program Files/Java/jre1.8.0_121') # for 64-bit version\n\n"
        ],
        "answer": "A2",
        "tags": [
            "java",
            "r",
            "machine-learning",
            "regression"
        ]
    },
    {
        "question_id": "489340",
        "question": "\nWhy won't vertical-align: middle work?  And yet, vertical-align: top does work.\n\n\nspan{\n  vertical-align: middle;\n}\n<div>\n  <img src=\"https://via.placeholder.com/30\" alt=\"small img\" />\n  <span>Doesn't work.</span>\n</div>\n\n\n\n",
        "all_answers": [
            "\nBecause you have to set the line-height to the height of the div for this to work\n",
            "\nThere is .center-block class in Twitter Bootstrap 3 (Since v3.0.1), so use:\n<img src=\"...\" alt=\"...\" class=\"img-responsive center-block\" />\n\n",
            "\nSimply put all the images thumbnails inside a row/col divs like this:\n<div class=\"row text-center\">\n <div class=\"col-12\">\n  # your images here...\n </div>\n</div>\n\nand everything will work fine!\n",
            "\nAdd only the class center-block to an image, this works with Bootstrap 4 as well:\n<img src=\"...\" alt=\"...\" class=\"center-block\" />\n\nNote: center-block works even when img-responsive is used\n",
            "\nI would suggest a more \"abstract\" classification. Add a new class \"img-center\" which can be used in combination with .img-responsive class:\n// Center responsive images\n.img-responsive.img-center {\n  margin: 0 auto;\n}\n\n",
            "\nActually, in this case it's quite simple: apply the vertical align to the image. Since it's all in one line, it's really the image you want aligned, not the text.\n\n\n<!-- moved \"vertical-align:middle\" style from span to img -->\n<div>\n  <img style=\"vertical-align:middle\" src=\"https://via.placeholder.com/60x60\" alt=\"A grey image showing text 60 x 60\">\n  <span style=\"\">Works.</span>\n</div>\n\n\n\nTested in FF3.\nNow you can use flexbox for this type of layout.\n\n\n.box {\n   display: flex;\n   align-items:center;\n}\n<div class=\"box\">\n    <img src=\"https://via.placeholder.com/60x60\">\n    <span style=\"\">Works.</span>\n</div>\n\n\n\n",
            "\nThis should center the image and make it responsive.\n<img src=\"...\" class=\"img-responsive\" style=\"margin:0 auto;\"/>\n\n",
            "\nYou can use property of d-block here or you can use a parent div with property 'text-center' in bootstrap or 'text-align: center' in css.\nImage by default is displayed as inline-block, you need to display it as block in order to center it with .mx-auto. This can be done with built-in .d-block:\n<div>\n    <img class=\"mx-auto d-block\" src=\"...\">  \n</div>\n\nOr leave it as inline-block and wrapped it in a div with .text-center:\n<div class=\"text-center\">\n    <img src=\"...\">  \n</div>\n\n",
            "\nJust use .text-center class if you're using Bootstrap 3.\n<div class=\"text-center\">\n    <img src=\"...\" alt=\"...\"/>\n</div>\n\nNote: This doesn't work with img-responsive\n",
            "\nIf you're using Bootstrap v3.0.1 or greater, you should use this solution instead. It doesn't override Bootstrap's styles with custom CSS, but instead uses a Bootstrap feature.\nMy original answer is shown below for posterity\n\nThis is a pleasantly easy fix. Because .img-responsive from Bootstrap already sets display: block, you can use margin: 0 auto to center the image:\n.product .img-responsive {\n    margin: 0 auto;\n}\n\n"
        ],
        "answer": "A6",
        "tags": [
            "html",
            "css",
            "alignment",
            "vertical-alignment"
        ]
    },
    {
        "question_id": "3258634",
        "question": "\nI have a PHP script that needs to make responses with HTTP response codes (status-codes), like HTTP 200 OK, or some 4XX or 5XX code.\nHow can I do this in PHP?\n",
        "all_answers": [
            "\nAdd this line before any output of the body, in the event you aren't using output buffering.\nheader(\"HTTP/1.1 200 OK\");\n\nReplace the message portion ('OK') with the appropriate message, and the status code with your code as appropriate (404, 501, etc)\n",
            "\nWith the header function. There is an example in the section on the first parameter it takes.\n",
            "\nI just found this question and thought it needs a more comprehensive answer:\nAs of PHP 5.4 there are three methods to accomplish this:\nAssembling the response code on your own (PHP >= 4.0)\nThe header() function has a special use-case that detects a HTTP response line and lets you replace that with a custom one\nheader(\"HTTP/1.1 200 OK\");\n\nHowever, this requires special treatment for (Fast)CGI PHP:\n$sapi_type = php_sapi_name();\nif (substr($sapi_type, 0, 3) == 'cgi')\n    header(\"Status: 404 Not Found\");\nelse\n    header(\"HTTP/1.1 404 Not Found\");\n\nNote: According to the HTTP RFC, the reason phrase can be any custom string (that conforms to the standard), but for the sake of client compatibility I do not recommend putting a random string there.\nNote: php_sapi_name() requires PHP 4.0.1\n3rd argument to header function (PHP >= 4.3)\nThere are obviously a few problems when using that first variant. The biggest of which I think is that it is partly parsed by PHP or the web server and poorly documented.\nSince 4.3, the header function has a 3rd argument that lets you set the response code somewhat comfortably, but using it requires the first argument to be a non-empty string. Here are two options:\nheader(':', true, 404);\nheader('X-PHP-Response-Code: 404', true, 404);\n\nI recommend the 2nd one. The first does work on all browsers I have tested, but some minor browsers or web crawlers may have a problem with a header line that only contains a colon. The header field name in the 2nd. variant is of course not standardized in any way and could be modified, I just chose a hopefully descriptive name.\nhttp_response_code function (PHP >= 5.4)\nThe http_response_code() function was introduced in PHP 5.4, and it made things a lot easier.\nhttp_response_code(404);\n\nThat's all.\nCompatibility\nHere is a function that I have cooked up when I needed compatibility below 5.4 but wanted the functionality of the \"new\" http_response_code function. I believe PHP 4.3 is more than enough backwards compatibility, but you never know...\n// For 4.3.0 <= PHP <= 5.4.0\nif (!function_exists('http_response_code'))\n{\n    function http_response_code($newcode = NULL)\n    {\n        static $code = 200;\n        if($newcode !== NULL)\n        {\n            header('X-PHP-Response-Code: '.$newcode, true, $newcode);\n            if(!headers_sent())\n                $code = $newcode;\n        }       \n        return $code;\n    }\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "php",
            "http-response-codes"
        ]
    },
    {
        "question_id": "22279301",
        "question": "\nI implemented a REST api in django with django-rest-framework and used oauth2 for authentication.\nI tested with:\ncurl -X POST -d \"client_id=YOUR_CLIENT_ID&client_secret=YOUR_CLIENT_SECRET&grant_type=password&username=YOUR_USERNAME&password=YOUR_PASSWORD\" http://localhost:8000/oauth2/access_token/\n\nand\ncurl -H \"Authorization: Bearer <your-access-token>\" http://localhost:8000/api/\n\non localhost with successful results consistent with the documentation.\nWhen pushing this up to an existing AWS elastic beanstalk instance, I received:\n{ \"detail\" : \"Authentication credentials were not provided.\" }\n\n",
        "all_answers": [
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nI thought the problem was with my configuration in django or some other error type instead of focusing on the differences between localhost and EB. The issue is with EB's Apache settings.\nWSGIPassAuthorization is natively set to OFF, so it must be turned ON. This can be done in your *.config file in your .ebextensions folder with the following command added:\ncontainer_commands:\n  01_wsgipass:\n    command: 'echo \"WSGIPassAuthorization On\" >> ../wsgi.conf'\n\nPlease let me know if I missed something or if there is a better way I should be looking at the problem. I could not find anything specifically about this anywhere on the web and thought this might save somebody hours of troubleshooting then feeling foolish.\n",
            "\nI use a slightly different approach now. sahutchi's solution worked as long as env variables were not changed as Tom dickin pointed out. I dug a bit deeper inside EB and found out where the wsgi.conf template is located and added the \"WSGIPassAuthorization On\" option there.\ncommands:\n  WSGIPassAuthorization:\n    command: sed -i.bak '/WSGIScriptAlias/ a WSGIPassAuthorization On' config.py\n    cwd: /opt/elasticbeanstalk/hooks\n\nThat will always work, even when changing environment variables. I hope you find it useful.\nEdit: Seems like lots of people are still hitting this response. I haven't used ElasticBeanstalk in a while, but I would look into using Manel Clos' solution below. I haven't tried it personally, but seems a much cleaner solution. This one is literally a hack on EBs scripts and could potentially break in the future if EB updates them, specially if they move them to a different location.\n"
        ],
        "answer": "A3",
        "tags": [
            "django",
            "amazon-web-services",
            "oauth-2.0",
            "amazon-elastic-beanstalk",
            "django-rest-framework"
        ]
    },
    {
        "question_id": "27431187",
        "question": "\nToday I tried to learn more about Google Web Starter Kit so I followed these instructions and after a lot of fight and problem I just tried to start a local server (the first task we’ll look at is: $ gulp serve.) and received this error:\nC:\\gwsk>gulp serve\nError: Cannot find module 'lodash'\n    at Function.Module._resolveFilename (module.js:338:15)\n    at Function.Module._load (module.js:280:25)\n    at Module.require (module.js:364:17)\n    at require (module.js:380:17)\n    at Object.<anonymous> (C:\\gwsk\\node_modules\\browser-sync\\node_modules\\portsc\nanner-plus\\lib\\index.js:3:9)\n    at Module._compile (module.js:456:26)\n    at Object.Module._extensions..js (module.js:474:10)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:312:12)\n    at Module.require (module.js:364:17)\n    at require (module.js:380:17)\n    at Object.<anonymous> (C:\\gwsk\\node_modules\\browser-sync\\lib\\utils.js:6:19)\n\nHonestly I'm completely lost here, so any help is pretty welcome. I'm new to node.js, to gulp, I just wanted it to try GWSK but turn into a headache :(... I'm a web designer not developer.... \n",
        "all_answers": [
            "\nBe sure to install lodash in the required folder. This is probably your C:\\gwsk directory.\nIf that folder has a package.json file, it is also best to add --save behind the install command.\n$ npm install lodash --save\n\nThe package.json file holds information about the project, but to keep it simple, it holds your project dependencies.\nThe save command will add the installed module to the project dependencies.\nIf the package.json file exists, and if it contains the lodash dependency you could try to remove the node_modules folder and run following command:\n$ npm cache clean    \n$ npm install\n\nThe first command will clean the npm cache. (just to be sure)\nThe second command will install all (missing) dependencies of the project.\n",
            "\nIf your node version is 4 and you are using gulp-sass, then try\nnpm uninstall --save-dev gulp-sass\n\nnpm install --save-dev gulp-sass@2\n\n",
            "\nnpm rebuild node-sass was giving me errors (Ubuntu) and npm install gulp-sass didn't make the error go away.\nSaw a solution on GitHub which worked for me:\nnpm uninstall --save-dev gulp-sass\nnpm install --save-dev gulp-sass\n",
            "\nI ran into this error using node 0.12.0 and it was fixed by deleting the existing /node_modules directory and running npm update.\n",
            "\nMaybe loadash needs to be installed. Usually these things are handled by the package manager. On your command line:\nnpm install lodash \n\nor maybe it needs to be globally installed\nnpm install -g lodash\n\n",
            "\nI found this useful command:\nnpm rebuild node-sass\n\nFrom the rebuild documentation:\n\nThis is useful when you install a new version of node (or switch node\n  versions), and must recompile all your C++ addons with the new node.js\n  binary.\n\nhttp://laravel.io/forum/10-29-2014-laravel-elixir-sass-error\n"
        ],
        "answer": "A1",
        "tags": [
            "node.js",
            "gulp",
            "gulp-sass"
        ]
    },
    {
        "question_id": "7250381",
        "question": "\nI'm looking for the html code for the dot. Not the dot that's at the end of sentences but the dot that's used to separate items horizontally.\nItem 1 . Item 2 . Item 3\n\nThe traditional dot is centered on the bottom of the line while the dot I'm looking for is centered on the middle.\n",
        "all_answers": [
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nIt's called a middle dot: ·\nHTML entities:\n\n&middot;\n&#183;\n&#xb7;\n\nIn CSS:\n\n\\00B7\n\n",
            "\nDo you mean bulletpoints? • • •\n&bull;\n\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nAs of Feb. 2016, CSS 3 has the support mentioned below. Here is a snippet from a WooCommerce's single product page with price discount\n/*Price before discount on single product page*/\nbody.single-product .price del .amount {\ncolor:           hsl(0, 90%, 65%);\nfont-size:       15px;\ntext-decoration: line-through;\n/*noinspection CssOverwrittenProperties*/\ntext-decoration: white double line-through; /* Ignored in CSS1/CSS2 UAs */\n}\n\nResulting in:\n\n\nCSS 3 will likely have direct support using the text-decoration-color property. In particular:\n\nThe text-decoration-color CSS property sets the color used when drawing underlines, overlines, or strike-throughs specified by text-decoration-line. This is the preferred way to color these text decorations, rather than using combinations of other HTML elements.\n\nAlso see text-decoration-color in the CSS 3 draft spec.\nIf you want to use this method immediately, you probably have to prefix it, using -moz-text-decoration-color. (Also specify it without -moz-, for forward-compatibility.)\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n"
        ],
        "answer": "A2",
        "tags": [
            "html",
            "html-entities"
        ]
    },
    {
        "question_id": "1602318",
        "question": "\nI want to store a value that represents a percent in SQL server, what data type should be the prefered one?\n",
        "all_answers": [
            "\ndecimal(p, s) and numeric(p, s)\np (precision):\nThe maximum total number of decimal digits that will be stored (both to the left and to the right of the decimal point)\n\ns (scale):\nThe number of decimal digits that will be stored to the right of the decimal point (-> s defines the number of decimal places)\n\n0 <= s <= p.\n\np ... total number of digits\ns ... number of digits to the right of the decimal point\np-s ... number of digits to the left of the decimal point\n\n\nExample:\nCREATE TABLE dbo.MyTable\n( MyDecimalColumn decimal(5,2)\n ,MyNumericColumn numeric(10,5)\n);\n\nINSERT INTO dbo.MyTable VALUES (123, 12345.12);\n\nSELECT MyDecimalColumn, MyNumericColumn FROM dbo.MyTable;\n\nResult:\nMyDecimalColumn: 123.00 (p=5, s=2)\n\nMyNumericColumn: 12345.12000 (p=10, s=5)\n\nlink: msdn.microsoft.com\n",
            "\nI agree, DECIMAL is where you should store this type of number.  But to make the decision easier, store it as a percentage of 1, not as a percentage of 100.  That way you can store exactly the number of decimal places you need regardless of the \"whole\" number.  So if you want 6 decimal places, use DECIMAL(9, 8) and for 23.3436435%, you store 0.23346435.  Changing it to 23.346435% is a display problem, not a storage problem, and most presentation languages / report writers etc. are capable of changing the display for you.\n",
            "\nThe datatype of the column should be decimal.\n",
            "\nI think decimal(p, s) should be used while s represents the percentage capability.\nthe 'p' could of been even 1 since we will never need more than one byte since each digit in left side of the point is one hunderd percent, so the p must be at least s+1, in order you should be able to store up to 1000%.\nbut SQL doesn't allow the 'p' to be smaller than the s.\nExamples:\n28.2656579879% should be decimal(13, 12) and should be stored 00.282656579879\n128.2656579879% should be decimal(13, 12) and should be stored 01.282656579879\n28% should be stored in decimal(3,2) as 0.28\n128% should be stored in decimal(3,2) as 1.28\nNote: if you know that you're not going to reach the 100% (i.e. your value will always be less than 100% than use decimal(s, s), if it will, use decimal(s+1, s).\nAnd so on\n",
            "\nYou should use decimal(p,s) in 99.9% of cases.\nPercent is only a presentation concept: 10% is still 0.1.\nSimply choose precision and scale for the highest expected values/desired decimal places when expressed as real numbers. You can have p = s for values < 100% and simply decide based on decimal places.\nHowever, if you do need to store 100% or 1, then you'll need p = s+1.\nThis then allows up to 9.xxxxxx or 9xx.xxxx%, so I'd add a check constraint to keep it maximum of 1 if this is all I need.\n"
        ],
        "answer": "A1",
        "tags": [
            "sql",
            "sql-server",
            "t-sql",
            "types"
        ]
    },
    {
        "question_id": "14977632",
        "question": "\nI have two vectors:\nstd::vector<int> v1, v2;\n\n// Filling v1\n...\n\nAnd now I need to copy v1 to v2. Is there any reason to prefer \nv2 = v1;\nto \nstd::copy (v1.begin(), v1.end(), v2.begin());\n(or vice versa)?\n",
        "all_answers": [
            "\nYou can always use std::advance to move the iterator a certain amount of positions in constant time:\nstd::vector<int>::iterator it = myvector.begin();\nstd::advance(it, 2);\n\n",
            "\nAssignment, by far.  More generally, any time the size of the vector might change, or change the entire contents of the vector, you should prefer member functions.  The only time std::copy would be appropriate is if you are only replacing a small range totally within the vector.\n",
            "\nGenerally I would strongly prefer v2 = v1:\n\nIt is shorter and makes the intent more clear\nstd::copy won't work if v2 doesn't have the same length as v1 (it won't resize it, so it will retain some of the old elements best case (v2.size() > v1.size() and overwrite some random data used elsewhere in the program worst case\nIf v1 is about to expire (and you use C++11) you can easily modify it to move the contents\nPerformancewise assignment is unlikely to be slower then std::copy, since the implementers would probably use std::copy internally, if it gave a performance benefit.\n\nIn conclusion, std::copy is less expressive, might do the wrong thing and isn't even faster. So there isn't really any reason to use it here.\n",
            "\nTry this:\nvector<Type>::iterator nth = v.begin() + index;\n\n",
            "\nIt's shorter.\nstd::copy is mainly meant for copying sections of containers. If you need to copy an entire container, you might as well use the copy constructor.\n",
            "\nAlso; auto it = std::next(v.begin(), index);\nUpdate: Needs a C++11x compliant compiler\n",
            "\nway mentioned by @dirkgently ( v.begin() + index ) nice and fast for vectors  \nbut std::advance( v.begin(), index ) most generic way and for random access iterators works constant time too.  \nEDIT\ndifferences in usage:  \nstd::vector<>::iterator it = ( v.begin() + index );\n\nor \nstd::vector<>::iterator it = v.begin();\nstd::advance( it, index );\n\nadded after @litb notes.\n",
            "\nThe invocation of std::copy may try to access items beyond the end of the destination vector.\nUse assignment.\nIt's not your job to micro-optimize: that's the library writer's responsibility, and ultimately the compiler's responsibility.\nYou can make your code arbitrarily fast if it doesn't have to be correct.\nIn the case of the copy, however, it's rather doubtful whether it even is faster, and it's certainly not correct for the general case.\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "stl",
            "copy"
        ]
    },
    {
        "question_id": "4424435",
        "question": "\nI have the following:\nanswers = Answer.objects.filter(id__in=[answer.id for answer in answer_set.answers.all()])\n\nthen later:\nfor i in range(len(answers)):\n    # iterate through all existing QuestionAnswer objects\n    for existing_question_answer in existing_question_answers:\n        # if an answer is already associated, remove it from the\n        # list of answers to save\n        if answers[i].id == existing_question_answer.answer.id:\n            answers.remove(answers[i])           # doesn't work\n            existing_question_answers.remove(existing_question_answer)\n\nI get an error:\n'QuerySet' object has no attribute 'remove'\n\nI've tried all sorts to convert the QuerySet to a standard set or list. Nothing works.\nHow can I remove an item from the QuerySet so it doesn't delete it from the database, and doesn't return a new QuerySet (since it's in a loop that won't work)?\n",
        "all_answers": [
            "\nWhy not just call list() on the Queryset?\nanswers_list = list(answers)\n\nThis will also evaluate the QuerySet/run the query. You can then remove/add from that list.\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nYou could do this:\nimport itertools\n\nids = set(existing_answer.answer.id for existing_answer in existing_question_answers)\nanswers = itertools.ifilter(lambda x: x.id not in ids, answers)\n\nRead when QuerySets are evaluated and note that it is not good to load the whole result into memory (e.g. via list()).\nReference: itertools.ifilter\nUpdate with regard to the comment:\nThere are various ways to do this. One (which is probably not the best one in terms of memory and time) is to do exactly the same :\nanswer_ids = set(answer.id for answer in answers)\nexisting_question_answers = filter(lambda x: x.answer.id not in answers_id, existing_question_answers)\n\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n"
        ],
        "answer": "A3",
        "tags": [
            "django"
        ]
    },
    {
        "question_id": "9624284",
        "question": "\nIs there any way to get milliseconds out of a timestamp in MySql or PostgreSql (or others just out of curiosity)?\nSELECT CURRENT_TIMESTAMP\n--> 2012-03-08 20:12:06.032572\n\nIs there anything like this:\nSELECT CURRENT_MILLISEC\n--> 1331255526000\n\nor the only alternative is to use the DATEDIFF from the era?\n",
        "all_answers": [
            "\nTo get the Unix timestamp in seconds in MySQL:\nselect UNIX_TIMESTAMP();\n\nDetails: http://dev.mysql.com/doc/refman/5.5/en/date-and-time-functions.html#function_unix-timestamp\nNot tested PostgreSQL, but according to this site it should work: http://www.raditha.com/postgres/timestamp.php\nselect round( date_part( 'epoch', now() ) );\n\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nIn PostgreSQL you can use : \nSELECT extract(epoch from now());\n\non MySQL :\nSELECT unix_timestamp(now());\n\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n"
        ],
        "answer": "A1",
        "tags": [
            "mysql",
            "sql",
            "postgresql",
            "datetime",
            "timestamp"
        ]
    },
    {
        "question_id": "105418",
        "question": "\n\n\n\nI want to be able to figure out what port a particular program is using.  Are there any programs available online or that come with windows that will tell me which processes are using which ports on my computer?\nPS - before you downmod this for not being a programming question, I'm looking for the program to test some networking code.\n",
        "all_answers": [
            "\nWindows comes with the netstat utility, which should do exactly what you want.\n",
            "\nAt a command line, netstat -a will give you lots o' info.\n",
            "\nmost decent firewall programs should allow you to access this information. I know that Agnitum OutpostPro Firewall does.\n",
            "\nnetstat -b -a lists the ports in use and gives you the executable that's using each one. I believe you need to be in the administrator group to do this, and I don't know what security implications there are on Vista.\nI usually add -n as well to make it a little faster, but adding -b can make it quite slow.\nEdit: If you need more functionality than netstat provides, vasac suggests that you try TCPView.\n"
        ],
        "answer": "A4",
        "tags": [
            "windows",
            "networking"
        ]
    },
    {
        "question_id": "53383602",
        "question": "\nso I just started reading a book on Django (for beginners) and I came across the following code snipet:\n<header>\n\n<a href=\"{% url 'home' %}\">Home</a> | <a href=\"{% url 'about' %}\">About</a>\n\n</header>\n\n{% block content %}\n{% endblock content %}\n\nCould anyone possibly explain to me what is the use of {% block content %} and {% endblock content %}? Thank you very much in advance!\n",
        "all_answers": [
            "\nblock is used for overriding specific parts of a template. \nIn your case, you have a block named content and this is supposed to be overridden by children that inherit from this template.\nFrom the examples at The Django Docs\nTemplate to be extended, named base.html\n<head>\n    <link rel=\"stylesheet\" href=\"style.css\">\n    <title>{% block title %}My amazing site{% endblock %}</title>\n</head>\n\nOverriding Child template\n{% extends \"base.html\" %}\n\n{% block title %}My amazing blog{% endblock %}\n\n\"My amazing site\" will be overriden by the child and then display \"My amazing blog\"\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nThat's where the power of the templates comes from in a sense.\nYou can create a hierarchy of templates so start with base.html which might be like you've got above;\n<body>\n    {% block content %}\n    {% endblock content %}\n</body>\n\nThen you can create any other template, home.html for example, and do something like;\n{% extends \"base.html\" %}\n\n{% block content %}\n    <h1>Welcome</h1>\n    <p>This is the home page</p>\n{% endblock content %}\n\nThen you'd reference home.html in django and it'd include the markup from base.py with the content defined in home.html.\nThat's the basics, but if you put some templates together using blocks you'll pick it up.\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django"
        ]
    },
    {
        "question_id": "820412",
        "question": "\nI am planning on using Google to download the jQuery lib for both UI and Core. My question is, do they allow me to download the CSS for it or should I have to host it myself?\nAlso if I use Google to load how should I load other plugins?  Can I compress all plugins together or should it be its own separate file?\n",
        "all_answers": [
            "\nThe Google AJAX Libraries API, which includes jQuery UI (currently v1.10.3), also includes popular themes as per the jQuery UI blog:\nGoogle Ajax Libraries API (CDN)\n\nUncompressed: http://ajax.googleapis.com/ajax/libs/jqueryui/1.10.3/jquery-ui.js\nCompressed: http://ajax.googleapis.com/ajax/libs/jqueryui/1.10.3/jquery-ui.min.js\nThemes Uncompressed:\nblack-tie, blitzer, cupertino, dark-hive, dot-luv, eggplant, excite-bike, flick, hot-sneaks, humanity, le-frog, mint-choc, overcast,pepper-grinder, redmond, smoothness, south-street, start, sunny, swanky-purse, trontastic, ui-darkness, ui-lightness, and vader.\nThemes Compressed:\nblack-tie, blitzer, cupertino, dark-hive, dot-luv, eggplant, excite-bike, flick, hot-sneaks, humanity, le-frog, mint-choc, overcast,pepper-grinder, redmond, smoothness, south-street, start, sunny, swanky-purse, trontastic, ui-darkness, ui-lightness, and vader.\n\n",
            "\nI would think so. Why not? Wouldn't be much of a CDN w/o offering the CSS to support the script files\nThis link suggests that they are:\n\nWe find it particularly exciting that\n  the jQuery UI CSS themes are now\n  hosted on Google's Ajax Libraries CDN.\n\n",
            "\nThe documentation says:\n\nclass (Optional) String\nOne or more CSS classes to remove from the elements, these are separated by spaces.\n\nExample:\n\nRemove the class 'blue' and 'under' from the matched elements.\n$(\"p:odd\").removeClass(\"blue under\");\n\n\n",
            "\njQuery .removeClass() documentation.\nOne or more CSS classes to remove from the elements, these are separated by spaces.\n",
            "\n$(\"element\").removeClass(\"class1 class2\");\n\nFrom removeClass(), the class parameter:\n\nOne or more CSS classes to remove from\n  the elements, these are separated by\n  spaces.\n\n",
            "\nSeparate classes by white space\n$('element').removeClass('class1 class2');\n\n",
            "\nThere are many ways can do that!\njQuery\n\nremove all class\n$(\"element\").removeClass();\nOR\n$(\"#item\").removeAttr('class');\nOR\n$(\"#item\").attr('class', '');\nOR\n$('#item')[0].className = ''; \nremove multi class\n$(\"element\").removeClass(\"class1 ... classn\");\nOR\n$(\"element\").removeClass(\"class1\").removeClass(\"...\").removeClass(\"classn\");\n\nVanilla Javascript\n\nremove all class\n\n\n\n// remove all items all class  \r\nconst items = document.querySelectorAll('item');\r\nfor (let i = 0; i < items.length; i++) {\r\n    items[i].className = '';\r\n}\n\n\n\n\nremove multi class\n\n\n\n// only remove all class of first item\r\nconst item1 = document.querySelector('item');\r\nitem1.className = '';\n\n\n\n",
            "\nSince jQuery 3.3.0, it is possible to pass arrays to .addClass(), .removeClass() and toggleClass(), which makes it easier if there is any logic which determines which classes should be added or removed, as you don't need to mess around with the space-delimited strings.\n$(\"div\").removeClass([\"class1\", \"class2\"]); \n\n",
            "\n$('element').removeClass('class1 class2');\n\nHere are the docs.\n"
        ],
        "answer": "A1",
        "tags": [
            "jquery",
            "css",
            "jquery-ui",
            "cdn",
            "google-ajax-libraries"
        ]
    },
    {
        "question_id": "2608158",
        "question": "\nCan we have a nested function in C? What is the use of nested functions? If they exist in C does their implementation differ from compiler to compiler?\n",
        "all_answers": [
            "\nNo, they don't exist in C.\nThey are used in languages like Pascal for (at least) two reasons:\n\nThey allow functional decomposition without polluting namespaces. You can define a single publicly visible function that implements some complex logic by relying one or more nested functions to break the problem into smaller, logical pieces.\nThey simplify parameter passing in some cases. A nested function has access to all the parameters and some or all of the variables in the scope of the outer function, so the outer function doesn't have to explicitly pass a pile of local state into the nested function.\n\n",
            "\nYou cannot define a function within another function in standard C.  \nYou can declare a function inside of a function, but it's not a nested function.\ngcc has a language extension that allows nested functions.  They are nonstandard, and as such are entirely compiler-dependent.\n",
            "\nThere is a big difference between static functions in C and static member functions in C++.  In C, a static function is not visible outside of its translation unit, which is the object file it is compiled into.  In other words, making a function static limits its scope.  You can think of a static function as being \"private\" to its *.c file (although that is not strictly correct).\nIn C++, \"static\" can also apply to member functions and data members of classes.  A static data member is also called a \"class variable\", while a non-static data member is an \"instance variable\". This is Smalltalk terminology.  This means that there is only one copy of a static data member shared by all objects of a class, while each object has its own copy of a non-static data member.  So a static data member is essentially a global variable, that is a member of a class.\nNon-static member functions can access all data members of the class: static and non-static.  Static member functions can only operate on the static data members.\nOne way to think about this is that in C++ static data members and static member functions do not belong to any object, but to the entire class.\n",
            "\nstatic functions are functions that are only visible to other functions in the same file (more precisely the same translation unit).\nEDIT: For those who thought, that the author of the questions meant a 'class method': As the question is tagged C he means a plain old C function. For (C++/Java/...) class methods, static means that this method can be called on the class itself, no instance of that class necessary.\n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "function",
            "nested"
        ]
    },
    {
        "question_id": "11589770",
        "question": "\nI'm new to HTML5 as begun to work with HTML5's new form input fields. When I'm working with form input fields, especially <input type=\"text\" /> and <input type=\"search\" /> IMO there wasn't any difference in all major browser including Safari, Chrome, Firefox and Opera. And the search field also behaves like a regular text field.\nSo, what is the difference between input type=\"text\" and input type=\"search\" in HTML5?\nWhat is the real purpose of <input type=\"search\" />?\n",
        "all_answers": [
            "\nRight now, there isn't a huge deal between them - maybe there never will be.\nHowever, the point is to give the browser-makers the ability to do something special with it, if they want.\nThink about <input type=\"number\"> on cellphones, bringing up number pads, or type=\"email\" bringing up a special version of the keyboard, with @ and .com and the rest available.\nOn a cellphone, search could bring up an internal search applet, if they wanted.\nOn the other side, it helps current devs with css.\ninput[type=search]:after { content : url(\"magnifying-glass.gif\"); }\n\n",
            "\n\nIt does absolutely nothing in most browsers. It just behaves like a\n  text input. This isn't a problem. The spec doesn't require it to do\n  anything special. WebKit browsers do treat it a bit differently\n  though, primarily with styling.\nA search input in WebKit by default has an inset border, rounded\n  corners, and strict typographic control.\n\nAlso,\n\nThis isn't documented anywhere that I know of nor is it in the spec,\n  but you if you add a results parameter on the input, WebKit will apply\n  a little magnifying glass with a dropdown arrow showing previous\n  results.\n\n<input type=search results=5 name=s>\n\nReference\nAbove all, it provides a semantic meaning to the input type.\nUpdate:\nChrome 51 removed support for the results attribute:\n",
            "\nI would implement this exactly as you described: submit everything to the server and do a simple if/else to check what button was clicked.\nAnd then I would implement a Javascript call tying into the form's onsubmit event which would check before the form was submitted, and only submit the relevant data to the server (possibly through a second form on the page with the ID needed to process the thing as a hidden input, or refresh the page location with the data you need passed as a GET request, or do an Ajax post to the server, or...).\nThis way the people without Javascript are able to use the form just fine, but the server load is offset because the people who do have Javascript are only submitting the single piece of data needed.  Getting yourself focused on only supporting one or the other really limits your options unnecessarily.\nAlternatively, if you're working behind a corporate firewall or something and everybody has Javascript disabled, you might want to do two forms and work some CSS magic to make it look like the delete button is part of the first form.\n"
        ],
        "answer": "A1",
        "tags": [
            "forms",
            "html",
            "input"
        ]
    },
    {
        "question_id": "571900",
        "question": "\nI know there is a hr (horizontal rule) in html, but I don't believe there is a vr (vertical rule).  Am I wrong and if not, why isn't there a vertical rule?\n",
        "all_answers": [
            "\nHTML has little to no vertical positioning due to typographic nature of content layout. Vertical Rule just doesn't fit its semantics.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nNo, there is no vertical rule.\nEDIT: It's 2021 (twelve years after I answered this question), and I no longer think my original explanation is true:\n\n(original explanation)\nIt does not make logical sense to have one. HTML is parsed\nsequentially, meaning you lay out your HTML code from top to bottom,\nleft to right how you want it to appear from top to bottom, left to\nright (generally)\nA vr tag does not follow that paradigm.\n\nI'm not sure why a VR tag was never introduced, but it's likely not because of the way HTML is parsed - there are many different layout modes in HTML/CSS now that do not follow this \"paradigm\".\nIf I were to now speculate as to why there is no VR tag, I might look at MDN's definition of the HR tag as a clue:\n\nThe HTML <hr> element represents a thematic break between\nparagraph-level elements: for example, a change of scene in a story,\nor a shift of topic within a section.\n\nIn practice, however, the <hr> tag often ends up used for things other than it's semantic meaning. Although it may seem based on it's real world use that there should be a <vr> tag, it probably would not resemble anything related to the semantic definition of the <hr> tag. It was probably never thought to be introduced.\nMy hunch is that the creators would suggest that the domain of the solution for this problem lies in CSS, not HTML (and most of the answers to this SO question reflect that).\nNixinova's solution looks like the most elegant and modern solution to this problem.\n(The rest of my old answer follows below):\nThis is easy to do using CSS, however. Ex:\n<div style=\"border-left:1px solid #000;height:500px\"></div>\n\nNote that you need to specify a height or fill the container with content.\n",
            "\nThere is not. \nWhy? Probably because a table with two columns will do.\n",
            "\nThere isn't, where would it go?\nUse CSS to put a border-right on an element if you want something like that.\n"
        ],
        "answer": "A4",
        "tags": [
            "html"
        ]
    },
    {
        "question_id": "6899",
        "question": "\n\n\n\nTo illustrate, assume that I have two tables as follows:\nVehicleID Name\n1         Chuck\n2         Larry\n\nLocationID VehicleID City\n1          1         New York\n2          1         Seattle\n3          1         Vancouver\n4          2         Los Angeles\n5          2         Houston\n\nI want to write a query to return the following results:\nVehicleID Name    Locations\n1         Chuck   New York, Seattle, Vancouver\n2         Larry   Los Angeles, Houston\n\nI know that this can be done using server side cursors, ie:\nDECLARE @VehicleID int\nDECLARE @VehicleName varchar(100)\nDECLARE @LocationCity varchar(100)\nDECLARE @Locations varchar(4000)\nDECLARE @Results TABLE\n(\n  VehicleID int\n  Name varchar(100)\n  Locations varchar(4000)\n)\n\nDECLARE VehiclesCursor CURSOR FOR\nSELECT\n  [VehicleID]\n, [Name]\nFROM [Vehicles]\n\nOPEN VehiclesCursor\n\nFETCH NEXT FROM VehiclesCursor INTO\n  @VehicleID\n, @VehicleName\nWHILE @@FETCH_STATUS = 0\nBEGIN\n\n  SET @Locations = ''\n\n  DECLARE LocationsCursor CURSOR FOR\n  SELECT\n    [City]\n  FROM [Locations]\n  WHERE [VehicleID] = @VehicleID\n\n  OPEN LocationsCursor\n\n  FETCH NEXT FROM LocationsCursor INTO\n    @LocationCity\n  WHILE @@FETCH_STATUS = 0\n  BEGIN\n    SET @Locations = @Locations + @LocationCity\n\n    FETCH NEXT FROM LocationsCursor INTO\n      @LocationCity\n  END\n  CLOSE LocationsCursor\n  DEALLOCATE LocationsCursor\n\n  INSERT INTO @Results (VehicleID, Name, Locations) SELECT @VehicleID, @Name, @Locations\n\nEND     \nCLOSE VehiclesCursor\nDEALLOCATE VehiclesCursor\n\nSELECT * FROM @Results\n\nHowever, as you can see, this requires a great deal of code.  What I would like is a generic function that would allow me to do something like this:\nSELECT VehicleID\n     , Name\n     , JOIN(SELECT City FROM Locations WHERE VehicleID = Vehicles.VehicleID, ', ') AS Locations\nFROM Vehicles\n\nIs this possible?  Or something similar?\n",
        "all_answers": [
            "\nIf you're using SQL Server 2005, you could use the FOR XML PATH command.\nSELECT [VehicleID]\n     , [Name]\n     , (STUFF((SELECT CAST(', ' + [City] AS VARCHAR(MAX)) \n         FROM [Location] \n         WHERE (VehicleID = Vehicle.VehicleID) \n         FOR XML PATH ('')), 1, 2, '')) AS Locations\nFROM [Vehicle]\n\nIt's a lot easier than using a cursor, and seems to work fairly well.\nUpdate\nFor anyone still using this method with newer versions of SQL Server, there is another way of doing it which is a bit easier and more performant using the\nSTRING_AGG method that has been available since SQL Server 2017.\nSELECT  [VehicleID]\n       ,[Name]\n       ,(SELECT STRING_AGG([City], ', ')\n         FROM [Location]\n         WHERE VehicleID = V.VehicleID) AS Locations\nFROM   [Vehicle] V\n\nThis also allows a different separator to be specified as the second parameter, providing a little more flexibility over the former method.\n",
            "\nI don't belive there's a way to do it within one query, but you can play tricks like this with a temporary variable:\ndeclare @s varchar(max)\nset @s = ''\nselect @s = @s + City + ',' from Locations\n\nselect @s\n\nIt's definitely less code than walking over a cursor, and probably more efficient.\n"
        ],
        "answer": "A1",
        "tags": [
            "sql",
            "sql-server",
            "string-concatenation"
        ]
    },
    {
        "question_id": "4336713",
        "question": "\nI've got a couple small (500 or 600 lines of template code) Django sites, and I'd like to migrate them to using Jinja2… But I'd like to get some idea of how much work it will be. So, in general, about how much work is it to migrate a small Django site to Jinja2? And is it “worth it”?\n",
        "all_answers": [
            "\nWhile it's just my own experience, I found converting from Django to Jinja2 to be worthwhile for the following reasons:\n\nThe design and implementation of Jinja2 seemed more intuitive to me, both as a software developer and template designer;\nJinja2 is more extensible (at least in the ways I've sought to extend my template engine);\nJinja2 is more flexible in terms of permitting logic-code to be run (but it gives you enough rope to hang yourself with);\nJinja2 is regarded as significantly faster (though I haven't done any benchmarks, this is always subject to debate depending on the tests used, and in any event largely irrelevant in the total wait time for a query that has to do DB lookups);\nJinja2 gives significantly more helpful error output than Django (i.e. traces to the line number in the template where the error occurred). Edit: According to Dor's comment, Django gives helpful error messages that point to the line and context of a problem, much like Jinja2.\n\nIf you haven't had any trouble with Django's template engine, Jinja2's should feel relatively intuitive, if perhaps a bit more polished (or it did to me, at any rate). As well, I found the Coffin project well written and reasonably helpful when converting from Django to Jinja2 – both for its use, and as an example of how to extend Jinja2.\nAll that being said, Django's template engine is solid and quite capable for most tasks. I believe it's being improved in the next revision of Django, and there is quite a lot of effort to add to its capabilities by quite a number of dedicated developers. As a result there are no worries of it becoming unsupported in the near to medium-term future.\nAgain, that's just my experience, for what it's worth – I hope that's helpful.\n",
            "\nFrom what you have said, it's may not be worth the trouble to migrate to Jinja2. There are filters in Django Templates which could help you do any math operations. \nRegarding list operations, what exactly are you talking about? If you want some particular list operation to be supported in Template, than write a custom filter.\nThere are also some existing 3rd party math filters for Django.\nIf you think about it, it's by design that Django templates does not have too much of \"programming constructs\" in them. HTML templates should be such...\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "django",
            "django-templates",
            "jinja2"
        ]
    },
    {
        "question_id": "11862188",
        "question": "\nI've seen many times the following syntax which defines a column in a create/alter DDL statement:\nALTER TABLE tbl ADD COLUMN col VARCHAR(20) NOT NULL DEFAULT \"MyDefault\"\n\nThe question is: since a default value is specified, is it necessary to also specify that the column should not accept NULLs? In other words, doesn't DEFAULT render NOT NULL redundant?\n",
        "all_answers": [
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nEven with a default value, you can always override the column data with null.\nThe NOT NULL restriction won't let you update that row after it was created with null value\n",
            "\nDEFAULT is the value that will be inserted in the absence of an explicit value in an insert / update statement. Lets assume, your DDL did not have the NOT NULL constraint:\nALTER TABLE tbl ADD COLUMN col VARCHAR(20) DEFAULT 'MyDefault'\n\nThen you could issue these statements\n-- 1. This will insert 'MyDefault' into tbl.col\nINSERT INTO tbl (A, B) VALUES (NULL, NULL);\n\n-- 2. This will insert 'MyDefault' into tbl.col\nINSERT INTO tbl (A, B, col) VALUES (NULL, NULL, DEFAULT);\n\n-- 3. This will insert 'MyDefault' into tbl.col\nINSERT INTO tbl (A, B, col) DEFAULT VALUES;\n\n-- 4. This will insert NULL into tbl.col\nINSERT INTO tbl (A, B, col) VALUES (NULL, NULL, NULL);\n\nAlternatively, you can also use DEFAULT in UPDATE statements, according to the SQL-1992 standard:\n-- 5. This will update 'MyDefault' into tbl.col\nUPDATE tbl SET col = DEFAULT;\n\n-- 6. This will update NULL into tbl.col\nUPDATE tbl SET col = NULL;\n\nNote, not all databases support all of these SQL standard syntaxes. Adding the NOT NULL constraint will cause an error with statements 4, 6, while 1-3, 5 are still valid statements. So to answer your question: No, they're not redundant.\n"
        ],
        "answer": "A3",
        "tags": [
            "sql",
            "ddl"
        ]
    },
    {
        "question_id": "5637326",
        "question": "\nWhy is there an element <textarea> instead of <input type=\"textarea\">?\n",
        "all_answers": [
            "\nIn a nutshell what it does is refer to the id of the input, that's all:\n<label for=\"the-id-of-the-input\">Input here:</label>\n<input type=\"text\" name=\"the-name-of-input\" id=\"the-id-of-the-input\">\n\n",
            "\nMaybe this is going a bit too far back but…\n\nAlso, I’d like to suggest that multiline text fields have a different type (e.g. “textarea\") than single-line fields (\"text\"), as they really are different types of things, and imply different issues (semantics) for client-side handling.\n\n– Marc Andreessen, 11 October 1993\n",
            "\nA textarea can contain multiple lines of text, so one wouldn't be able to pre-populate it using a value attribute.\nSimilarly, the select element needs to be its own element to accommodate option sub-elements. \n",
            "\nThe for attribute associates the label with a control element, as defined in the description of label in the HTML 4.01 spec. This implies, among other things, that when the label element receives focus (e.g. by being clicked on), it passes the focus on to its associated control. The association between a label and a control may also be used by speech-based user agents, which may give the user a way to ask what the associated label is, when dealing with a control. (The association may not be as obvious as in visual rendering.)\nIn the first example in the question (without the for), the use of label markup has no logical or functional implication – it’s useless, unless you do something with it in CSS or JavaScript.\nHTML specifications do not make it mandatory to associate labels with controls, but Web Content Accessibility Guidelines (WCAG) 2.0 do. This is described in the technical document H44: Using label elements to associate text labels with form controls, which also explains that the implicit association (by nesting e.g. input inside label) is not as widely supported as the explicit association via for and id attributes,\n",
            "\nSo that its value can easily contain quotes and <> characters and respect whitespace and newlines.\nThe following HTML code successfully pass the w3c validator and displays <,> and & without the need to encode them. It also respects the white spaces.\n<!doctype html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\" />\n    <title>Yes I can</title>\n</head>\n<body>\n    <textarea name=\"test\">\n        I can put < and > and & signs in \n        my textarea without any problems.\n    </textarea>\n</body>\n</html>\n\n",
            "\nThe <label> tag allows you to click on the label, and it will be treated like clicking on the associated input element. There are two ways to create this association:\nOne way is to wrap the label element around the input element:\n<label>Input here:\n    <input type='text' name='theinput' id='theinput'>\n</label>\n\nThe other way is to use the for attribute, giving it the ID of the associated input:\n<label for=\"theinput\">Input here:</label>\n<input type='text' name='whatever' id='theinput'>\n\nThis is especially useful for use with checkboxes and buttons, since it means you can check the box by clicking on the associated text instead of having to hit the box itself.\nRead more about the <label> element on MDN.\nAssociating text with an input is very important for accessibility, as it provides an accessible name for the input, so that assistive technology can provide it to users with disabilities. A screen reader would read the label text when the user focusses the input. You could also tell your voice command software to focus that input, but it needs a (visible) name for that.\nRead more on Accessibility\n"
        ],
        "answer": "A2",
        "tags": [
            "html",
            "input",
            "types",
            "textarea"
        ]
    },
    {
        "question_id": "1005857",
        "question": "\nI need to be able to call a function, but the function name is stored in a variable, is this possible? e.g:\nfunction foo ()\n{\n    //code here\n}\n\nfunction bar ()\n{\n    //code here\n}\n\n$functionName = \"foo\";\n// I need to call the function based on what is $functionName\n\n",
        "all_answers": [
            "\nUse the call_user_func function.\n",
            "\nYes, it is possible:\nfunction foo($msg) {\n    echo $msg.\"<br />\";\n}\n$var1 = \"foo\";\n$var1(\"testing 1,2,3\");\n\nSource: http://www.onlamp.com/pub/a/php/2001/05/17/php_foundations.html?page=2\n",
            "\n$functionName() or call_user_func($functionName)\nIf you need to provide parameters stored in another variable (in the form of array), use array unpacking operator:\n$function_name = 'trim';\n$parameters = ['aaabbb','b'];\necho $function_name(...$parameters); // aaa\n\nTo dynamically create an object and call its method use\n$class = 'DateTime';\n$method = 'format';\necho (new $class)->$method('d-m-Y');\n\nor to call a static method\n$class = 'DateTime';\n$static = 'createFromFormat';\n$date = $class::$static('d-m-Y', '17-08-2023');\n\n"
        ],
        "answer": "A3",
        "tags": [
            "php",
            "dynamic-function"
        ]
    },
    {
        "question_id": "5620033",
        "question": "\nThis morning I came up with a problem trying to handle the onConfigurationChanged event. The problem is that the method, which I override, is not getting called when I change the orientation of the phone. Not getting called at all. \nI've put android:configChanges=\"orientation\" on the activity defined in the manifest as mentioned on the android documentation, but this don't make a difference.\nHave you come up with this problem? \n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nHave you got android.content.res.Configuration in your import statements? Eclipse can insert imports automatically if you press Ctrl+Shift+O.\nIf that's missing, the compiler will be unable to recognise that you're legitimately overriding the superclass method and so will throw an error.\n",
            "\n\nCheck that you are not using android:screenOrientation in an Activity or in a Application level.\nTry using android:configChanges=\"orientation|keyboardHidden\" instead.\n\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nMacarse is 100% on the money with his 2nd option.\nTry android:configChanges=\"orientation|keyboardHidden|screenSize\"\nI had  exactly  the  same  issue,  and on  the 1.6 emulator adding keyboardHidden causes onConfigurationChanged to be called during rotation. Remove it and it stops being called.\n",
            "\nThe problem was that if you use this method\nsetRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT);\n\nto force the orientation of your Activity to portrait mode, you're not candidate to receive orientation changes. \nSo the solution is to not setRequestOrientation to a particular mode. But instead use SCREEN_ORIENTATION_SENSOR.\n"
        ],
        "answer": "A9",
        "tags": [
            "android"
        ]
    },
    {
        "question_id": "48021298",
        "question": "\nWhat exactly is going on with DispatchTime.now() \nHow come I can't assign the time to wait as a variable?\nAnd How Could I use a variable ?\nGiven error >>>\n\nBinary operator '+' cannot be applied to operands of type\n  'DispatchTime' and 'Float'\n\nvar time : Float = 2.2 // <---time \n\n@IBAction func buttonPressed(_ sender: Any) {\n\n    let when = DispatchTime.now() + 2.2 // <---- THIS IS OKAY\n    DispatchQueue.main.asyncAfter(deadline: when){\n\n        print(\"Hello\")\n    }\n\n    let whenWhen = DispatchTime.now() + time // <---- THIS IS NOT OKAY\n    DispatchQueue.main.asyncAfter(deadline: whenWhen){\n\n        print(\"Hello\")\n    }\n}\n\n",
        "all_answers": [
            "\nThe error message pretty much explains it.  You can't add a float and a DispatchTime together as they are different data types.\nWhen you use this line:\nlet when = DispatchTime.now() + 2.2 // <---- THIS IS OKAY\n\nyou don't specify what type the 2.2 is and the system concludes it is of type DispatchTime and allows it.\nHowever when you use this line:\nlet whenWhen = DispatchTime.now() + time // <---- THIS IS NOT OKAY\n\nyou have already determined that time is a float and that's where the error is generated.\nIt's probably easiest to convert like this:\nDispatchTimeInterval.milliseconds(Int(time * 1000))\n\n",
            "\nYou can use DispatchTimeInterval to add time in DispatchTime.\nFor Example :\nlet whenWhen = DispatchTime.now() + DispatchTimeInterval.seconds(time)\nDispatchQueue.main.asyncAfter(deadline: whenWhen){\n\n    print(\"Hello\")\n\n}\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nDispatchTime.now() is a double. You cannot add a float and a double value together. (A small explanation about why can't you add values with different types can be found here).\nReplace \nvar time: Float = 2.2\n\nwith \nvar time: Double = 2.2\n\nAnd it will work fine.\n"
        ],
        "answer": "A4",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "2497211",
        "question": "\nI used to do all my Linux profiling with gprof.\nHowever, with my multi-threaded application, it's output appears to be inconsistent.\nNow, I dug this up:\nhttp://sam.zoy.org/writings/programming/gprof.html\nHowever, it's from a long time ago and in my gprof output, it appears my gprof is listing functions used by non-main threads.\nSo, my questions are:\n\nIn 2010, can I easily use gprof to profile multi-threaded Linux C++ applications? (Ubuntu 9.10)\nWhat other tools should I look into for profiling?\n\n",
        "all_answers": [
            "\nAs you discovered, rand is the culprit here.\nFor those who are curious, it's possible that this behavior comes from your implementation of rand using a mutex for thread safety.\nFor example, eglibc defines rand in terms of __random, which is defined as:\nlong int\n__random ()\n{\n  int32_t retval;\n\n  __libc_lock_lock (lock);\n\n  (void) __random_r (&unsafe_state, &retval);\n\n  __libc_lock_unlock (lock);\n\n  return retval;\n}\n\nThis kind of locking would force multiple threads to run serially, resulting in lower performance.\n",
            "\nThe time needed to execute the program is very small (33msec). This means that the overhead to create and handle several threads may be more than the real benefit. Try using programs that need longer times for the execution (e.g., 10 sec).\n",
            "\nGCC Atomic Built-ins\n",
            "\nEdit: added another answer on poor man's profiler, which IMHO is better for multithreaded apps.\nHave a look at oprofile. The profiling overhead of this tool is negligible and it supports multithreaded applications---as long as you don't want to profile mutex contention (which is a very important part of profiling multithreaded applications)\n",
            "\nHave a look at Valgrind.\n",
            "\nOn my system the behavior is same, but as Maxim mentioned, rand is not thread safe. When I change rand to rand_r, then the multi threaded code is faster as expected.\nvoid add_multi(int N, double& result) {\ndouble sum=0;\nunsigned int seed = time(NULL);\nfor (int i = 0; i < N; ++i){\n    sum+= sqrt(1.0*rand_r(&seed)/RAND_MAX);\n}\nresult = sum/N;\n}\n\n"
        ],
        "answer": "A4",
        "tags": [
            "c++",
            "multithreading",
            "profiling",
            "gprof"
        ]
    },
    {
        "question_id": "4643738",
        "question": "\nI am converting a Rails 2 application to Rails 3. I currently have a controller set up like the following:\nclass Api::RegionsController < ApplicationController\n  respond_to :xml, :json\nend\n\nwith and an action that looks like the following:\ndef index\n  @regions = Region.all\n\n  respond_with @regions  \nend\n\nThe implementation is pretty straightforward, api/regions, api/regions.xml and api/regions.json all respond as you would expect. The problem is that I want api/regions by default to respond via XML. I have consumers that expect an XML response and I would hate to have them change all their URLs to include .xml unless absolutely necessary. \nIn Rails 2 you would accomplish that by doing this:\nrespond_to do |format|\n  format.xml { render :xml => @region.to_xml }\n  format.json { render :json => @region.to_json }\nend\n\nBut in Rails 3 I cannot find a way to default it to an XML response. Any ideas?\n",
        "all_answers": [
            "\nAn easy but ugly solution is to override html content type handling to render xml:\n   respond_to :html, :xml, :json\n\n   def index\n      @regions = Region.all\n      respond_with @regions do |format|\n        format.html { render :xml => @regions }\n      end\n    end\n\n",
            "\nIf I understand what you are trying to do, you probably can solve the issue by setting the default resource format to XML. This will allow your users to make requests using 'api/regions' and have the response default to XML. Take a look at look at the 'Controller Namespaces and Routing' and the 'Defining Defaults' sections at: \nhttp://guides.rubyonrails.org/routing.html\nYou could do something like the following in routes.rb:\nnamespace \"api\" do\n  resources :regions, :defaults => { :format => 'xml' }\nend\n\nThen you should be able to have the following work for your controller methods:\nclass Api::RegionsController < ApplicationController\n  respond_to :xml, :json\n\n  def index \n    respond_with(@regions = Region.all)\n  end\nend\n\n",
            "\nNot what you're after but related:\ndef index\n  @regions = Region.all\n  respond_to do |format|\n    format.json { render :json => @regions }\n    format.any(:xml, :html) { render :xml => @regions }\n  end\nend\n\n\"Respond to also allows you to specify a common block for different formats by using any\"\n\nhttp://apidock.com/rails/v3.0.0/ActionController/MimeResponds/respond_to\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby-on-rails-3"
        ]
    },
    {
        "question_id": "1199176",
        "question": "\nI have a dataset objds. objds contains a table named Table1. Table1 contains column named ProcessName. This ProcessName contains repeated names.So i want to select only distinct names.Is this possible.\n  intUniqId[i] = (objds.Tables[0].Rows[i][\"ProcessName\"].ToString());\n\n",
        "all_answers": [
            "\nsthing like ?\nSELECT DISTINCT .... FROM table WHERE condition\nhttp://www.felixgers.de/teaching/sql/sql_distinct.html\nnote: Homework question ?  and god bless google..\nhttp://www.google.com/search?hl=en&rlz=1C1GGLS_enJO330JO333&q=c%23+selecting+distinct+values+from+table&aq=f&oq=&aqi=\n",
            "\nUse:\nList<Person> pList = new List<Person>();\n/* Fill list */\n\nvar result = pList.Where(p => p.Name != null).GroupBy(p => p.Id)\n    .Select(grp => grp.FirstOrDefault());\n\nThe where helps you filter the entries (could be more complex) and the groupby and select perform the distinct function.\n",
            "\nDataView view = new DataView(table);\nDataTable distinctValues = view.ToTable(true, \"Column1\", \"Column2\" ...);\n\n",
            "\nDataTable dt = new DataTable();\ndt.Columns.Add(\"IntValue\", typeof(int));\ndt.Columns.Add(\"StringValue\", typeof(string));\ndt.Rows.Add(1, \"1\");\ndt.Rows.Add(1, \"1\");\ndt.Rows.Add(1, \"1\");\ndt.Rows.Add(2, \"2\");\ndt.Rows.Add(2, \"2\");\n\nvar x = (from r in dt.AsEnumerable()\n        select r[\"IntValue\"]).Distinct().ToList();\n\n",
            "\n\nWhat if I want to obtain a distinct list based on one or more properties?\n\nSimple! You want to group them and pick a winner out of the group.\nList<Person> distinctPeople = allPeople\n  .GroupBy(p => p.PersonId)\n  .Select(g => g.First())\n  .ToList();\n\nIf you want to define groups on multiple properties, here's how:\nList<Person> distinctPeople = allPeople\n  .GroupBy(p => new {p.PersonId, p.FavoriteColor} )\n  .Select(g => g.First())\n  .ToList();\n\nNote: Certain query providers are unable to resolve that each group must have at least one element, and that First is the appropriate method to call in that situation. If you find yourself working with such a query provider, FirstOrDefault may help get your query through the query provider.\nNote2: Consider this answer for an EF Core (prior to EF Core 6) compatible approach. https://stackoverflow.com/a/66529949/8155\n",
            "\nEDIT: This is now part of MoreLINQ.\nWhat you need is a \"distinct-by\" effectively. I don't believe it's part of LINQ as it stands, although it's fairly easy to write:\npublic static IEnumerable<TSource> DistinctBy<TSource, TKey>\n    (this IEnumerable<TSource> source, Func<TSource, TKey> keySelector)\n{\n    HashSet<TKey> seenKeys = new HashSet<TKey>();\n    foreach (TSource element in source)\n    {\n        if (seenKeys.Add(keySelector(element)))\n        {\n            yield return element;\n        }\n    }\n}\n\nSo to find the distinct values using just the Id property, you could use:\nvar query = people.DistinctBy(p => p.Id);\n\nAnd to use multiple properties, you can use anonymous types, which implement equality appropriately:\nvar query = people.DistinctBy(p => new { p.Id, p.Name });\n\nUntested, but it should work (and it now at least compiles).\nIt assumes the default comparer for the keys though - if you want to pass in an equality comparer, just pass it on to the HashSet constructor.\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "select",
            "datatable",
            "distinct"
        ]
    },
    {
        "question_id": "3469979",
        "question": "\nI have a custom TagField form field.\nclass TagField(forms.CharField):\n    def __init__(self, *args, **kwargs):\n        super(TagField, self).__init__(*args, **kwargs)\n        self.widget = forms.TextInput(attrs={'class':'tag_field'})\n\nAs seen above, it uses a TextInput form field widget. But in admin I would like it to be displayed using Textarea widget. For this, there is formfield_overrides hook but it does not work for this case.\nThe admin declaration is:\nclass ProductAdmin(admin.ModelAdmin):\n    ...\n    formfield_overrides = {\n        TagField: {'widget': admin.widgets.AdminTextareaWidget},\n    }\n\nThis has no effect on the form field widget and tags are still rendered with a TextInput widget.\nAny help is much appreciated.\n--omat\n",
        "all_answers": [
            "\nThe django admin uses custom widgets for many of its fields. The way to override fields is to create a Form for use with the ModelAdmin object.\n# forms.py\n\nfrom django import forms\nfrom django.contrib import admin\n\nclass ProductAdminForm(forms.ModelForm):\n    def __init__(self, *args, **kwargs):\n        super(ProductAdminForm, self).__init__(*args, **kwargs)\n        self.fields['tags'].widget = admin.widgets.AdminTextareaWidget()\n\nThen, in your ModelAdmin object, you specify the form:\nfrom django.contrib import admin\nfrom models import Product\nfrom forms import ProductAdminForm\n\nclass ProductAdmin(admin.ModelAdmin):\n    form = ProductAdminForm\n\nadmin.site.register(Product, ProductAdmin)\n\nYou can also override the queryset at this time: to filter objects according to another field in the model, for instance (since limit_choices_to cannot handle this)\n",
            "\nnull=True sets NULL (versus NOT NULL) on the column in your DB. Blank values for Django field types such as DateTimeField or ForeignKey will be stored as NULL in the DB.\nblank determines whether the field will be required in forms. This includes the admin and your custom forms. If blank=True then the field will not be required, whereas if it's False the field cannot be blank.\nThe combo of the two is so frequent because typically if you're going to allow a field to be blank in your form, you're going to also need your database to allow NULL values for that field. The exception is CharFields and TextFields, which in Django are never saved as NULL. Blank values are stored in the DB as an empty string ('').\nA few examples:\nmodels.DateTimeField(blank=True) # raises IntegrityError if blank\n\nmodels.DateTimeField(null=True) # NULL allowed, but must be filled out in a form\n\nObviously, Those two options don't make logical sense to use (though there might be a use case for null=True, blank=False if you want a field to always be required in forms, optional when dealing with an object through something like the shell.)\nmodels.CharField(blank=True) # No problem, blank is stored as ''\n\nmodels.CharField(null=True) # NULL allowed, but will never be set as NULL\n\nCHAR and TEXT types are never saved as NULL by Django, so null=True is unnecessary. However, you can manually set one of these fields to None to force set it as NULL. If you have a scenario where that might be necessary, you should still include null=True.\n",
            "\nTry to change your field like this:\nclass TagField(forms.CharField):\n    def __init__(self, *args, **kwargs):\n        self.widget = forms.TextInput(attrs={'class':'tag_field'})\n        super(TagField, self).__init__(*args, **kwargs)\n\nThis would allow to use the widget which comes from **kwargs. Otherwise your field will always use form.TextInput widget.\n"
        ],
        "answer": "A1",
        "tags": [
            "django",
            "django-admin",
            "overriding",
            "widget"
        ]
    },
    {
        "question_id": "14502236",
        "question": "\nSuppose defined: int a[100]  Type print a then gdb will automatically display it as an array:1, 2, 3, 4.... However, if a is passed to a function as a parameter, then gdb will treat it as a normal int pointer, type print a will display:(int *)0x7fffffffdaa0. What should I do if I want to view a as an array?\n",
        "all_answers": [
            "\nFunctional programming is not about lambdas, it is all about pure functions.  So the following broadly promote functional style:\n\nOnly use function arguments, do not use global state.\nMinimise side effects i.e. printf, or any IO.  Return data describing IO which can be executed instead of causing the side effects directly in all functions.  \n\nThis can be achieved in plain c, no need for magic.\n",
            "\nUse the x command.\n(gdb) x/100w a\n\n",
            "\nFFCALL lets you build closures in C -- callback = alloc_callback(&function, data) returns a function pointer such that callback(arg1, ...) is equivalent to calling function(data, arg1, ...).  You will have to handle garbage collection manually, though.\nRelatedly, blocks have been added to Apple's fork of GCC; they're not function pointers, but they let you pass around lambdas while avoiding the need to build and free storage for captured variables by hand (effectively, some copying and reference counting happens, hidden behind some syntactic sugar and runtime libraries).\n",
            "\nSee here. In short you should do:\np *array@len\n\n",
            "\nYou can use GCC's nested functions to simulate lambda expressions, in fact, I have a macro to do it for me:\n#define lambda(return_type, function_body) \\\n  ({ \\\n    return_type anon_func_name_ function_body \\\n    anon_func_name_; \\\n  })\n\nUse like this:\nint (*max)(int, int) = lambda (int, (int x, int y) { return x > y ? x : y; });\n\n",
            "\nHartel & Muller's book, Functional C, can nowadays (2012-01-02) be found at: http://eprints.eemcs.utwente.nl/1077/ (there is a link to PDF version).\n"
        ],
        "answer": "A4",
        "tags": [
            "c",
            "gdb"
        ]
    },
    {
        "question_id": "23344776",
        "question": "\nI have a html code like this:\n<input type=\"file\" id=\"up\" />\n<input type=\"submit\" id=\"btn\" />\n\nAnd I have a JSON file like this:\n{\n \"name\": \"John\",\n \"family\": \"Smith\"\n}\n\nAnd a simple JavaScript function:\nalert_data(name, family)\n{\n     alert('Name : ' + name + ', Family : '+ family)\n}\n\nNow I want to call alert_data() with name and family that stored in JSON file which uploaded using my HTML input.\nIs there any way to use an HTML5 file reader or something else?\nI'm not using server-side programming, all of them are client-side.\n",
        "all_answers": [
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n",
            "\nYep! It can be done with HTML5 FileReader. And it's actually pretty simple. \nSave the json as a .js file and load it in my example\n{\n \"name\": \"John\",\n \"family\": \"Smith\"\n}\n\nThis is where the magic happens:\n$(\"#up\").change(function(event){\n    var uploadedFile = event.target.files[0]; \n    \n     if(uploadedFile.type !== \"text/javascript\" && uploadedFile.type !== \"application/x-javascript\") { \n        alert(\"Wrong file type == \" + uploadedFile.type); \n        return false;\n    }\n    \n    if (uploadedFile) {\n        var readFile = new FileReader();\n        readFile.onload = function(e) { \n            var contents = e.target.result;\n            var json = JSON.parse(contents);\n            alert_data(json);\n        };\n        readFile.readAsText(uploadedFile);\n    } else { \n        console.log(\"Failed to load file\");\n    }\n});\n\nfunction alert_data(json)\n{\n     alert('Name : ' + json.name + ', Family : '+ json.family)\n}\n\nFiddle link with this code: http://jsfiddle.net/thomas_kingo/dfej7p3r/3/\n\n(The uploadedFile.type check is only tested in Chrome and firefox)\n",
            "\nYou will need an HTML5 browser, but this is possible.\n\n\n(function(){\r\n    \r\n    function onChange(event) {\r\n        var reader = new FileReader();\r\n        reader.onload = onReaderLoad;\r\n        reader.readAsText(event.target.files[0]);\r\n    }\r\n\r\n    function onReaderLoad(event){\r\n        console.log(event.target.result);\r\n        var obj = JSON.parse(event.target.result);\r\n        alert_data(obj.name, obj.family);\r\n    }\r\n    \r\n    function alert_data(name, family){\r\n        alert('Name : ' + name + ', Family : ' + family);\r\n    }\r\n \r\n    document.getElementById('file').addEventListener('change', onChange);\r\n\r\n}());\n<input id=\"file\" type=\"file\" />\r\n\r\n<p>Select a file with the following format.</p>\r\n<pre>\r\n{\r\n  \"name\": \"testName\",\r\n  \"family\": \"testFamily\"\r\n}    \r\n</pre>\n\n\n\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "html",
            "json"
        ]
    },
    {
        "question_id": "33276921",
        "question": "\nI need to write a script to work in Windows, that when executed will run a command in some of sub-directories, but unfortunately I have never done anything in batch, and I don't know where to start.\nWith the example structure of folders:\n\\root\n   \\one\n   \\two\n   \\three\n   \\four\n\nI want the script to enter the specified folders (e.g. only 'one' and 'four') and then run some command inside every child directories of that folders.\nIf you could provide any help, maybe some basic tutorial or just names of the commands I will need, I would be very grateful.\n",
        "all_answers": [
            "\nYou should take a look at this. The command you are looking for is FOR /R. Looks something like this:\nFOR /R \"C:\\SomePath\\\" %%F IN (.) DO (\n    some command\n)\n\n",
            "\nYou can tell the batch to iterate directories:\nfor /d %i in (C:\\temp\\*) do ( cd \"%i\" &  *enter your command here* ) \n\nUse a percent sign when run directly on the command line, two when run from a batch\nIn a batch this would look something like this:\n@echo off\nset back=%cd%\nfor /d %%i in (C:\\temp\\*) do (\ncd \"%%i\"\necho current directory:\ncd\npause\n)\ncd %back%\n\nPut the commands you need in the lines between ( and ).\nIf you replace C:\\temp\\ with %1 you can tell the batch to take the value of the directory from the first parameter when you call it.\nDepending of the amount of directories you then either call the batch for each directory or read them from a list:\nfor /f %i in (paths.lst) do call yourbatch %i\n\nThe paths.lstwill look like this:\nC:\\\nD:\\\nY:\\\nC:\\foo\n\nAll of this is written from memory, so you might need to add some quotations marks ;-)\nPlease note that this will only process the first level of directories, that means no child folders of a selected child folder.\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "batch-file"
        ]
    },
    {
        "question_id": "20180543",
        "question": "\nI installed the Python modules construct and statlib using setuptools:\nsudo apt-get install python-setuptools\n\nsudo easy_install statlib\nsudo easy_install construct\n\nHow do I check their versions from the command line?\n",
        "all_answers": [
            "\nUse pip instead of easy_install.\nWith pip, list all installed packages and their versions via:\npip freeze\n\nOn most Linux systems, you can pipe this to grep (or findstr on Windows) to find the row for the particular package you're interested in.\n\nLinux:\npip freeze | grep lxml\n\n\nlxml==2.3\n\nWindows:\npip freeze | findstr lxml\n\n\nlxml==2.3\n\n\nFor an individual module, you can try the __version__ attribute. However, there are modules without it:\npython -c \"import requests; print(requests.__version__)\"\n2.14.2\n\npython -c \"import lxml; print(lxml.__version__)\"\n\n\nTraceback (most recent call last): \nFile \"<string>\", line 1, in <module> \nAttributeError: 'module' object has no attribute 'version'\n\nLastly, as the commands in your question are prefixed with sudo, it appears you're installing to the global python environment. I strongly advise to take look into Python virtual environment managers, for example virtualenvwrapper.\n",
            "\nYou can try\n>>> import statlib\n>>> print statlib.__version__\n\n>>> import construct\n>>> print contruct.__version__\n\nThis is the approach recommended by PEP 396. But that PEP was never accepted and has been deferred. In fact, there appears to be increasing support amongst Python core developers to recommend not including a __version__ attribute, e.g. in Remove importlib_metadata.version..\n"
        ],
        "answer": "A1",
        "tags": [
            "python"
        ]
    },
    {
        "question_id": "3300464",
        "question": "\ndb = sqlite.connect(\"test.sqlite\")\nres = db.execute(\"select * from table\")\n\nWith iteration I get lists coresponding to the rows.\nfor row in res:\n    print row\n\nI can get name of the columns\ncol_name_list = [tuple[0] for tuple in res.description]\n\nBut is there some function or setting to get dictionaries instead of list?\n{'col1': 'value', 'col2': 'value'}\n\nor I have to do myself?\n",
        "all_answers": [
            "\nYou could use row_factory, as in the example in the docs:\nimport sqlite3\n\ndef dict_factory(cursor, row):\n    d = {}\n    for idx, col in enumerate(cursor.description):\n        d[col[0]] = row[idx]\n    return d\n\ncon = sqlite3.connect(\":memory:\")\ncon.row_factory = dict_factory\ncur = con.cursor()\ncur.execute(\"select 1 as a\")\nprint cur.fetchone()[\"a\"]\n\nor follow the advice that's given right after this example in the docs:\n\nIf returning a tuple doesn’t suffice\nand you want name-based access to\ncolumns, you should consider setting\nrow_factory to the highly-optimized\nsqlite3.Row type. Row provides both\nindex-based and case-insensitive\nname-based access to columns with\nalmost no memory overhead. It will\nprobably be better than your own\ncustom dictionary-based approach or\neven a db_row based solution.\n\nHere is the code for this second solution:\ncon = sqlite3.connect(…)\ncon.row_factory = sqlite3.Row   #   add this row\ncursor = con.cursor()\n\n",
            "\nFrom PEP 249:\nQuestion: \n\n   How can I construct a dictionary out of the tuples returned by\n   .fetch*():\n\nAnswer:\n\n   There are several existing tools available which provide\n   helpers for this task. Most of them use the approach of using\n   the column names defined in the cursor attribute .description\n   as basis for the keys in the row dictionary.\n\n   Note that the reason for not extending the DB API specification\n   to also support dictionary return values for the .fetch*()\n   methods is that this approach has several drawbacks:\n\n   * Some databases don't support case-sensitive column names or\n     auto-convert them to all lowercase or all uppercase\n     characters.\n\n   * Columns in the result set which are generated by the query\n     (e.g.  using SQL functions) don't map to table column names\n     and databases usually generate names for these columns in a\n     very database specific way.\n\n   As a result, accessing the columns through dictionary keys\n   varies between databases and makes writing portable code\n   impossible.\n\nSo yes, do it yourself.\n",
            "\nTo solve this problem, I store dates as YYYYMMDD. Thus,\n   where mydate >= '20090101' and mydate <= '20050505'\nIt just plain WORKS all the time.  You may only need to write a parser to handle how users might enter their dates so you can convert them to YYYYMMDD.\n",
            "\nI had the same issue recently, and I solved it like this:\nSELECT * FROM table WHERE \n    strftime('%s', date) BETWEEN strftime('%s', start_date) AND strftime('%s', end_date)\n\n",
            "\nSQLite doesn't have dedicated datetime types, but does have a few datetime functions.  Follow the string representation formats (actually only formats 1-10) understood by those functions (storing the value as a string) and then you can use them, plus lexicographical comparison on the strings will match datetime comparison (as long as you don't try to compare dates to times or datetimes to times, which doesn't make a whole lot of sense anyway).\nDepending on which language you use, you can even get automatic conversion.  (Which doesn't apply to comparisons in SQL statements like the example, but will make your life easier.)\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "sql",
            "sqlite",
            "dictionary",
            "dataformat"
        ]
    },
    {
        "question_id": "3474875",
        "question": "\nWhy does Mac OS X come with ruby and ruby on rails pre-installed? Does the OS actually use it at all? Can I update my Ruby, Rails or Gem versions safely without something spitting the dummy?\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nAs others have noted, OS X comes with various open source packages pre-installed.  While this can be a nice convenience, the packages often are only updated to new versions as part of a major OS X release (like 10.5 to 10.6).  Also, some packages are used elsewhere by other parts of OS X and there is no easy way to know which.  In general, Apple assumes (and you should, too) that everything under /System/Library and /usr/, except for /usr/local/, is part of OS X and is administered by Apple.  You should not attempt to remove or modify files in those hierarchies.  That includes just about all of the open source packages, including Ruby.\nInstead, to upgrade an existing package, the right approach is to install a new version in a separate location (say, /usr/local/) and invoke the new version by an absolute path reference (/usr/local/bin/ruby) or manipulating the shell PATH environment variable, if necessary.  /usr/local/ is often used if installing directly from source.  Many people prefer to use one of the 3rd-party open source package distributors, such as MacPorts, Fink, or Homebrew, each of which has its own package manager and installation locations.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nNo the OS does not use, it is just that Apple wants to make her products a bit more appealing to developers. (there is also Python preinstalled along with some other packets).\nYou can safely update your Ruby, Rails, Gems but the default Ruby version is a bit outdated. Check RVM so that you can install different Rubies in your system\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "macos",
            "rubygems"
        ]
    },
    {
        "question_id": "11657835",
        "question": "\nI want to get an array of values from the id column of the Auction table.\nIf this was a raw SQL I would write:\nSELECT id FROM auction\n\nBut when I do this in Doctrine and execute:\n$em->createQuery(\"SELECT a.id FROM Auction a\")->getScalarResult(); \n\nI get an array like this:\narray(\n    array('id' => 1),\n    array('id' => 2),\n)\n\nInstead, i'd like to get an array like this:\narray(\n    1,\n    2\n)\n\nHow can I do that using Doctrine?\n",
        "all_answers": [
            "\nI think it's impossible in Doctrine.\nJust transform result array into the data structure you want using PHP:\n$transform = function($item) {\n    return $item['id'];\n};\n$result = array_map($transform, $em->createQuery(\"SELECT a.id FROM Auction a\")->getScalarResult());\n\n",
            "\nPHP < 5.5\nYou can use array_map, and since you only have on item per array, you can elegantly use \n'current' as callback, instead of writing a closure.\n$result = $em->createQuery(\"SELECT a.id FROM Auction a\")->getScalarResult();\n$ids = array_map('current', $result);\n\n\nSee Petr Sobotka's answer below for additional info regarding memory usage. \n\nPHP >= 5.5\nAs jcbwlkr's answered below, the recommended way it to use array_column.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "doctrine-orm"
        ]
    },
    {
        "question_id": "6063347",
        "question": "\nWhat is a best practice? To use try or use rescue?\nuser.try(:email)\n\nVS\nuser.email rescue nil\n\n\npost.try(:comments).try(:first).try(:author)\n\nVS\npost.comments.first.author rescue nil\n\nIs there any difference in using any of these?\n",
        "all_answers": [
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nTry and rescue serve different purposes. The purpose of try is to save you from having to do:\nif user && user.email\n\nOr any situation where the parent object can possibly be nil, which would cause a NoMethodError on NilClass. The purpose of rescue is to handle exceptions that get thrown by your method invocation. If you expect an exception from calling user.email, then you can rescue nil it to prevent the exception from bubbling up.\nIn general, I'd say avoid using rescue nil unless you know explicitly what exceptions you are rescuing because you could be rescuing a different exception, and you would never know it because rescue nil would prevent you from seeing it. At the very least maybe you could log it:\nbegin\n  ...some code...\nrescue => ex\n  logger.error ex.message\nend\n\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nBoth seem fishy and can mask other bugs. Are you sure you really want to get nil there? Maybe it would be better to check whether there are any comments first, and cover the empty case explicitly?\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby"
        ]
    },
    {
        "question_id": "10053678",
        "question": "\nI'm using git, then posting the commit message and other bits as a JSON payload to a server.\nCurrently I have:\nMSG=`git log -n 1 --format=oneline | grep -o ' .\\+'`\n\nwhich sets MSG to something like:\nCalendar can't go back past today\n\nthen\ncurl -i -X POST \\\n  -H 'Accept: application/text' \\\n  -H 'Content-type: application/json' \\\n  -d \"{'payload': {'message': '$MSG'}}\" \\\n  'https://example.com'\n\nMy real JSON has another couple of fields.\nThis works fine, but of course when I have a commit message such as the one above with an apostrophe in it, the JSON is invalid.\nHow can I escape the characters required in bash? I'm not familiar with the language, so am not sure where to start. Replacing ' with \\' would do the job at minimum I suspect.\n",
        "all_answers": [
            "\nI found something like that :\nMSG=`echo $MSG | sed \"s/'/\\\\\\\\\\'/g\"`\n\n",
            "\nPosting it here as it might help others. In string it might be necessary to pass the quotes to jq. To do the following with jq:\n.items[] | select(.name==\"string\")\n\nin bash you could do\nEMAILID=$1\nprojectID=$(cat file.json | jq -r '.resource[] | select(.username=='\\\"$EMAILID\\\"') | .id')\n\nessentially escaping the quotes and passing it on to jq\n",
            "\nConsider also passing in the shell variable (EMAILID) as a jq variable (here also EMAILID, for the sake of illustration):\n   projectID=$(jq -r --arg EMAILID \"$EMAILID\" '\n        .resource[]\n        | select(.username==$EMAILID) \n        | .id' file.json)\n\nPostscript\nFor the record, another possibility would be to use jq's env function for accessing environment variables.  For example, consider this sequence of bash commands:\n[email protected]  # not exported\nEMAILID=\"$EMAILID\" jq -n 'env.EMAILID'\n\nThe output is a JSON string:\n\"[email protected]\"\n\nshell arrays\nUnfortunately, shell arrays are a different kettle of fish.\nHere are two SO resources regarding the ingestion of such arrays:\nJQ - create JSON array using bash array with space\nConvert bash array to json array and insert to file using jq\n",
            "\nI resolved this issue by escaping the inner double quotes\nprojectID=$(cat file.json | jq -r \".resource[] | select(.username==\\\"$EMAILID\\\") | .id\")\n\n",
            "\nLittle unrelated but I will still put it here,\nFor other practical purposes shell variables can be used as - \nvalue=10\njq  '.\"key\" = \"'\"$value\"'\"' file.json\n\n",
            "\nOK, found out what to do. Bash supports this natively as expected, though as always, the syntax isn't really very guessable!\nEssentially ${string//substring/replacement} returns what you'd image, so you can use\nMSG=${MSG//\\'/\\\\\\'}\n\nTo do this. The next problem is that the first regex doesn't work anymore, but that can be replaced with\ngit log -n 1 --pretty=format:'%s'\n\nIn the end, I didn't even need to escape them. Instead, I just swapped all the ' in the JSON to \\\". Well, you learn something every day.\n"
        ],
        "answer": "A6",
        "tags": [
            "json",
            "bash",
            "escaping"
        ]
    },
    {
        "question_id": "222649",
        "question": "\n\n\n\nWe are seeing this error in a Winform application.  Can anyone help on why you would see this error, and more importantly how to fix it or avoid it from happening.\n\nSystem.ComponentModel.Win32Exception: Error creating window handle.\n   at System.Windows.Forms.NativeWindow.CreateHandle(CreateParams cp)\n   at System.Windows.Forms.Control.CreateHandle()\n   at System.Windows.Forms.Control.CreateControl(Boolean fIgnoreVisible)\n   at System.Windows.Forms.Control.CreateControl()\n   at System.Windows.Forms.Control.OnVisibleChanged(EventArgs e)\n   at System.Windows.Forms.ButtonBase.OnVisibleChanged(EventArgs e)\n\n",
        "all_answers": [
            "\nHave you run Process Explorer or the Windows Task Manager to look at the GDI Objects, Handles, Threads and USER objects?  If not, select those columns to be viewed (Task Manager choose View->Select Columns...    Then run your app and take a look at those columns for that app and see if one of those is growing really large.\nIt might be that you've got UI components that you think are cleaned up but haven't been Disposed.\nHere's a link about this that might be helpful.\nGood Luck!\n",
            "\nI think it's normally related to the computer running out of memory so it's not able to create any more window handles.  Normally windows starts to show some strange behavior at this point as well.\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "windows",
            "winforms",
            "window-handles"
        ]
    },
    {
        "question_id": "4394309",
        "question": "\nI have a 48x48 div and inside it there is an img element, I want to fit it into the div without losing any part, in the mean time the ratio is kept, is it achievable using html and css?\n",
        "all_answers": [
            "\nYou will need some JavaScript to prevent cropping if you don't know the dimension of the image at the time you're writing the css.\nHTML & JavaScript\n<div id=\"container\">\n    <img src=\"something.jpg\" alt=\"\" />\n</div>\n\n<script type=\"text/javascript\">\n(function() {\n\nvar img = document.getElementById('container').firstChild;\nimg.onload = function() {\n    if(img.height > img.width) {\n        img.height = '100%';\n        img.width = 'auto';\n    }\n};\n\n}());\n</script>\n\nCSS\n#container {\n   width: 48px;\n   height: 48px;\n}\n\n#container img {\n   width: 100%;\n}\n\nIf you use a JavaScript Library you might want to take advantage of it.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nHTML\n<div>\n    <img src=\"something.jpg\" alt=\"\" />\n</div>\n\nCSS\ndiv {\n   width: 48px;\n   height: 48px;\n}\n\ndiv img {\n   display: block;\n   width: 100%;\n}\n\nThis will make the image expand to fill its parent, of which its size is set in the div CSS.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n"
        ],
        "answer": "A1",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "7545365",
        "question": "\nI came across the following C puzzle:\nQ: Why does the following program segfault on IA-64, but work fine on IA-32?\n  int main()\n  {\n      int* p;\n      p = (int*)malloc(sizeof(int));\n      *p = 10;\n      return 0;\n  }\n\nI know that the size of int on a 64 bit machine may not be the same as the size of a pointer (int could be 32 bits and pointer could be 64 bits). But I am not sure how this relates to the above program.\nAny ideas?\n",
        "all_answers": [
            "\nMost likely because you're not including the header file for malloc and, while the compiler would normally warn you of this, the fact that you're explicitly casting the return value means you're telling it you know what you're doing.\nThat means the compiler expects an int to be returned from malloc which it then casts to a pointer. If they're different sizes, that's going to cause you grief.\nThis is why you never cast the malloc return in C. The void* that it returns will be implicitly converted to a pointer of the correct type (unless you haven't included the header in which case it probably would have warned you of the potentially unsafe int-to-pointer conversion).\n",
            "\nThe cast to int* masks the fact that without the proper #include the return type of malloc is assumed to be int. IA-64 happens to have sizeof(int) < sizeof(int*) which makes this problem obvious. \n(Note also that because of the undefined behaviour it could still fail even on a platform where sizeof(int)==sizeof(int*) holds true, for example if the calling convention used different registers for returning pointers than integers)\nThe comp.lang.c FAQ has an entry discussing why casting the return from malloc is never needed and potentially bad.\n",
            "\nThe order of precedence for the 3 operators involved in your question is the following :\npost-increment ++ > dereference * > assignment +=\nYou can check this page for further details on the subject.\n\nWhen parsing an expression, an operator which is listed on some row will be bound tighter (as if by parentheses) to its arguments than any operator that is listed on a row further below it. For example, the expression *p++ is parsed as *(p++), and not as (*p)++.\n\nLong story short, in order to express this assignment *ptr+=1 using the post-increment operator you need to add parentheses to the dereference operator to give that operation precedence over ++ as in this (*ptr)++\n",
            "\nThe difference is due to operator precedence.\nThe post-increment operator ++ has higher precedence than the dereference operator *. So *ptr++ is equivalent to *(ptr++). In other words, the post increment modifies the pointer, not what it points to.\nThe assignment operator += has lower precedence than the dereference operator *, so *ptr+=1 is equivalent to (*ptr)+=1. In other words, the assignment operator modifies the value that the pointer points to, and does not change the pointer itself. \n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "pointers",
            "segmentation-fault"
        ]
    },
    {
        "question_id": "32136973",
        "question": "\nI'm trying to use picasso library to be able to load url to imageView, but I'm not able to get the context to use the picasso library correctly.\npublic class FeedAdapter extends RecyclerView.Adapter<FeedAdapter.ViewHolder> {\n    private List<Post> mDataset;\n\n\n\n    // Provide a reference to the views for each data item\n    // Complex data items may need more than one view per item, and\n    // you provide access to all the views for a data item in a view holder\n    public class ViewHolder extends RecyclerView.ViewHolder {\n        // each data item is just a string in this case\n        public TextView txtHeader;\n        public ImageView pub_image;\n        public ViewHolder(View v) {\n            super(v);\n            txtHeader = (TextView) v.findViewById(R.id.firstline);\n            pub_image = (ImageView) v.findViewById(R.id.imageView);\n\n\n        }\n    }\n\n\n\n\n    // Provide a suitable constructor (depends on the kind of dataset)\n    public FeedAdapter(List<Post> myDataset) {\n        mDataset = myDataset;\n    }\n\n    // Create new views (invoked by the layout manager)\n    @Override\n    public FeedAdapter.ViewHolder onCreateViewHolder(ViewGroup parent,\n                                                   int viewType) {\n        // create a new view\n        View v = LayoutInflater.from(parent.getContext()).inflate(R.layout.feedholder, parent, false);\n        // set the view's size, margins, paddings and layout parameters\n        ViewHolder vh = new ViewHolder(v);\n        return vh;\n    }\n\n    // Replace the contents of a view (invoked by the layout manager)\n    @Override\n    public void onBindViewHolder(ViewHolder holder, int position) {\n        // - get element from your dataset at this position\n        // - replace the contents of the view with that element\n\n        holder.txtHeader.setText(mDataset.get(position).getPost_text());\n\n        Picasso.with(this.context).load(\"http://i.imgur.com/DvpvklR.png\").into(holder.pub_image);\n\n\n    }\n\n    // Return the size of your dataset (invoked by the layout manager)\n    @Override\n    public int getItemCount() {\n        return mDataset.size();\n    }\n\n}\n\n",
        "all_answers": [
            "\nFirst globally declare \nContext mContext; \npass context with the constructor, by modifying it.\npublic FeedAdapter(List<Post> myDataset, Context context) {\n    mDataset = myDataset;\n    this.mContext = context;\n}\n\nthen use the mContext whereever you need it\n",
            "\nUpdate\nMany issues relating to this feature in version 23.2.0 have been fixed in 23.2.1, update to that instead.\nWith the release of Support Library version 23.2, RecyclerView now supports that!\nUpdate build.gradle to:\ncompile 'com.android.support:recyclerview-v7:23.2.1'\n\nor any version beyond that.\n\nThis release brings an exciting new feature to the LayoutManager API: auto-measurement! This allows a RecyclerView to size itself based on the size of its contents. This means that previously unavailable scenarios, such as using WRAP_CONTENT for a dimension of the RecyclerView, are now possible. You’ll find all built in LayoutManagers now support auto-measurement.\n\nThis can be disabled via setAutoMeasurementEnabled() if need be. Check in detail here.\n",
            "\nYou have a few options here:\n\nPass Context as an argument to FeedAdapter and keep it as class field\nUse dependency injection to inject Context when you need it.  I strongly suggest reading about it.  There is a great tool for that -- Dagger by Square\nGet it from any View object. In your case this might work for you:\nholder.pub_image.getContext()\nAs pub_image is a ImageView.\n\n",
            "\nCreate a constructor of FeedAdapter :\nContext context; //global\npublic FeedAdapter(Context context)\n{\n   this.context = context;  \n}\n\nand in Activity \nFeedAdapter obj = new FeedAdapter(this);\n\n"
        ],
        "answer": "A3",
        "tags": [
            "java",
            "android",
            "android-recyclerview",
            "picasso",
            "android-context"
        ]
    },
    {
        "question_id": "14536165",
        "question": "\nHow can I retrieve the raw executed SQL query in Laravel 3/4 using Laravel Query Builder or Eloquent ORM?\nFor example, something like this:\nDB::table('users')->where_status(1)->get();\n\nOr:\n(posts (id, user_id, ...))\n\nUser::find(1)->posts->get();\n\nOtherwise, at the very least how can I save all queries executed to laravel.log?\n",
        "all_answers": [
            "\nIf you want to add item to the beginning of the collection you can use prepend:\n$item->prepend($product, 'key');\n\n",
            "\nYou can enable the \"Profiler\" in Laravel 3 by setting \n'profiler' => true,\n\nIn your application/config/application.php and application/config/database.php\nThis enables a bar at the bottom of each page. One of its features is listing the executed queries and how long each one took.\n\n",
            "\nAs mentioned above  if you wish to add as a new element your queried collection you can use:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n        $product = DB::select(DB::raw(' select * from product\n               where product_id = '. $id.';' ));\n\n        $items->push($product);\n        // or \n        // $items->put('products', $product);\n    }\n\nbut if you wish to add new element to each queried element you need to do like:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n           $product = DB::select(DB::raw(' select * from product\n                 where product_id = '. $id.';' ));\n    \n          $item->add_whatever_element_you_want = $product;\n    }\n\nadd_whatever_element_you_want can be whatever you wish that your element is named (like product for example).\n",
            "\nIf you want to add a product into the array you can use:\n$item['product'] = $product;\n\n",
            "\nIt looks like you have everything correct according to Laravel docs, but you have a typo\n$item->push($product);\n\nShould be\n$items->push($product);\n\npush method appends an item to the end of the collection:\nI also want to think the actual method you're looking for is put\n$items->put('products', $product);\n\nput method sets the given key and value in the collection\n",
            "\nLaravel 4+\n\nNote for Laravel 5 users: You'll need to call DB::enableQueryLog() before executing the query. Either just above the line that runs the query or inside a middleware.\n\nIn Laravel 4 and later, you have to call DB::getQueryLog() to get all ran queries.\n$queries = DB::getQueryLog();\n$last_query = end($queries);\n\nOr you can download a profiler package. I'd recommend barryvdh/laravel-debugbar, which is pretty neat. You can read for instructions on how to install in their repository.\n\nLaravel 3\nIn Laravel 3, you can get the last executed query from an Eloquent model calling the static method last_query on the DB class.\nDB::last_query();\n\nThis, however, requires that you enable the profiler option in application/config/database.php. Alternatively you could, as @dualed mentioned, enable the profiler option, in application/config/application.php or call DB::profile() to get all queries ran in the current request and their execution time.\n"
        ],
        "answer": "A6",
        "tags": [
            "php",
            "laravel",
            "orm",
            "eloquent",
            "laravel-query-builder"
        ]
    },
    {
        "question_id": "10372369",
        "question": "\nConsider the following example: (live demo here)\n\n\n$(function() {\r\n  console.log(\"width = \" + $(\"td\").width());\r\n});\ntd {\r\n  border: 1px solid black;\r\n  width: 50px;\r\n  overflow: hidden;\r\n  text-overflow: ellipsis;\r\n  white-space: nowrap;\r\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n<table>\r\n  <tbody>\r\n    <tr>\r\n      <td>Hello Stack Overflow</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\n\n\n\nThe output is: width = 139, and the ellipsis doesn't appear.\nWhat am I missing here?\n",
        "all_answers": [
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nApparently, adding:\ntd {\n  display: block; /* or inline-block */\n}\n\nsolves the problem as well.\n\nAnother possible solution is to set table-layout: fixed; for the table, and also set it's width. For example: http://jsfiddle.net/fd3Zx/5/\n",
            "\nTry using max-width instead of width, the table will still calculate the width automatically.\nWorks even in ie11 (with ie8 compatibility mode).\n\n\ntd.max-width-50 {\r\n  border: 1px solid black;\r\n  max-width: 50px;\r\n  overflow: hidden;\r\n  text-overflow: ellipsis;\r\n  white-space: nowrap;\r\n}\n<table>\r\n  <tbody>\r\n    <tr>\r\n      <td class=\"max-width-50\">Hello Stack Overflow</td>\r\n    </tr>\r\n    <tr>\r\n      <td>Hello Stack Overflow</td>\r\n    </tr>\r\n    <tr>\r\n      <td>Hello Stack Overflow</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\n\n\n\njsfiddle.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n"
        ],
        "answer": "A3",
        "tags": [
            "html",
            "css",
            "ellipsis"
        ]
    },
    {
        "question_id": "722221",
        "question": "\nHow to enable logging of all SQL executed by PostgreSQL 8.3?\nEdited (more info)\nI changed these lines :\nlog_directory = 'pg_log'                    \nlog_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\nlog_statement = 'all'\n\nAnd restart PostgreSQL service... but no log was created...\nI'm using Windows Server 2003.\nAny ideas?\n",
        "all_answers": [
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nThis will work for sure, and I actually tried it out:\nlwdba@localhost (DB test) :: DROP TABLE IF EXISTS shirts;\nQuery OK, 0 rows affected (0.08 sec)\n\nlwdba@localhost (DB test) :: CREATE TABLE shirts\n    -> (<BR>\n    -> id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    -> ticketnumber INT,\n    -> colors VARCHAR(30)\n    -> );<BR>\nQuery OK, 0 rows affected (0.19 sec)\n\nlwdba@localhost (DB test) :: INSERT INTO shirts (ticketnumber,colors) VALUES\n    -> (32423,'1,2,5,12,15'),\n    -> (32424,'1,5,12,15,30'),\n    -> (32425,'2,5,11,15,28'),\n    -> (32426,'1,2,7,12,15'),\n    -> (32427,'2,4,8,12,15');\nQuery OK, 5 rows affected (0.06 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nlwdba@localhost (DB test) :: SELECT * FROM shirts WHERE LOCATE(CONCAT(',', 1 ,','),CONCAT(',',colors,',')) > 0;\n+----+--------------+--------------+\n| id | ticketnumber | colors       |\n+----+--------------+--------------+\n|  1 |        32423 | 1,2,5,12,15  |\n|  2 |        32424 | 1,5,12,15,30 |\n|  4 |        32426 | 1,2,7,12,15  |\n+----+--------------+--------------+\n3 rows in set (0.00 sec)\n\nGive it a Try !!!\n",
            "\nSet log_statement to all:\nError Reporting and Logging - log_statement\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nIn your data/postgresql.conf file, change the log_statement setting to 'all'.\n\nEdit\nLooking at your new information, I'd say there may be a few other settings to verify:\n\nmake sure you have turned on the log_destination variable\nmake sure you turn on the logging_collector\nalso make sure that the log_directory directory already exists inside of the data directory, and that the postgres user can write to it.\n\n"
        ],
        "answer": "A6",
        "tags": [
            "sql",
            "database",
            "postgresql",
            "logging"
        ]
    },
    {
        "question_id": "44382841",
        "question": "\nWireless debugging was recently added as a feature in Xcode 9, iOS 11, and tvOS 11. Apple TV 4K doesn't have a USB port, so it requires wireless debugging. How do you perform this wireless debugging in Xcode?\n",
        "all_answers": [
            "\nSet up a device for network debugging\nfrom help.apple.com\nDebug your app running on an iOS or tvOS device over a Wi-Fi or other network connection.\nSteps to set up iPhone, iPad, or iPod touch\n\nCheck that your device has a passcode and add one if it doesn't. Your device must have a passcode to enable remote debugging\n\nThe Mac and the iPhone/iPad need to be on the same network to use wireless debugging.\n\n\nNext, in Xcode\n\nChoose Window > Devices and Simulators, then in the window that appears, click Devices.\nConnect your device to your Mac with a Lightning cable.\nIn the left column, select the device, and in the detail area, select Connect via network.\n\n\nXcode pairs with your device. If Xcode can connect with the device using a network, a network icon appears next to the device in the left column.\n\n\nDisconnect your device.\n\nNow you are ready for debugging over the network.\nSometimes it doesn't work. You might need to restart the device or network connection.\nNote: Network debugging requires Xcode 9.0 or later running on macOS 10.12.4 or later, and on the device, requires iOS 11.0 or later, or tvOS 11.0 or later.\n\nSteps to set up Apple TV:\n\nMake sure your Mac and your Apple TV are on the same network.\n\nChoose Window > Devices and Simulators, then in the window that appears, click Devices.\n\nOn your Apple TV, open the Settings app and choose Remotes and Devices > Remote App and Devices.\n\nThe Apple TV searches for possible devices including the Mac. (If you have any firewall or Internet security, disable/turn it off to allow searching.)\n\nOn your Mac, select the Apple TV in the Devices pane. The pane for the Apple TV is displayed and shows the current status of the connection request.\n\nEnter the verification code displayed on your AppleTV into the Device window pane for the device and click Connect.\n\n\nXcode sets up the Apple TV for wireless debugging and pairs with the device.\n\n\n",
            "\nYou can open Xcode Help -> Run and debug -> Network debugging for more info. Hope it helps.\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "xcode",
            "ios11",
            "xcode9"
        ]
    },
    {
        "question_id": "1050720",
        "question": "\nIt amazes me that JavaScript's Date object does not implement an add function of any kind.\nI simply want a function that can do this:\n\n\nvar now = Date.now();\nvar fourHoursLater = now.addHours(4);\n\nfunction Date.prototype.addHours(h) {\n  // How do I implement this?\n}\n\n\n\nI would simply like some pointers in a direction.\n\nDo I need to do string parsing?\n\nCan I use setTime?\n\nHow about milliseconds?\n\n\nLike this:\nnew Date(milliseconds + 4*3600*1000 /* 4 hours in ms */)?\n\nThis seems really hackish though - and does it even work?\n",
        "all_answers": [
            "\nThere is an add in the Datejs library.\nAnd here are the JavaScript date methods. kennebec wisely mentioned getHours() and setHours();\n",
            "\nJavaScript itself has terrible Date/Time API's. Nonetheless, you can do this in pure JavaScript:\nDate.prototype.addHours = function(h) {\n  this.setTime(this.getTime() + (h*60*60*1000));\n  return this;\n}\n\n",
            "\nIntroducing npx: an npm package runner\nNPM - Manages packages but doesn't make life easy executing any.NPX - A tool for executing Node packages.\n\nNPX comes bundled with NPM version 5.2+ \n\nNPM by itself does not simply run any package. It doesn't run any package as a matter of fact. If you want to run a package using NPM, you must specify that package in your package.json file.\nWhen executables are installed via NPM packages, NPM links to them:\n\nlocal installs have \"links\" created at ./node_modules/.bin/ directory.\nglobal installs have \"links\" created from the global bin/ directory (e.g. /usr/local/bin) on Linux or at %AppData%/npm on Windows.\n\nDocumentation you should read\n\nNPM:\nOne might install a package locally on a certain project:\nnpm install some-package\n\nNow let's say you want NodeJS to execute that package from the command line:\n$ some-package\n\nThe above will fail. Only globally installed packages can be executed by typing their name only.\nTo fix this, and have it run, you must type the local path:\n$ ./node_modules/.bin/some-package\n\nYou can technically run a locally installed package by editing your packages.json file and adding that package in the scripts section:\n{\n  \"name\": \"whatever\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"some-package\": \"some-package\"\n  }\n}\n\nThen run the script using npm run-script (or npm run):\nnpm run some-package\n\n\nNPX:\nnpx will check whether <command> exists in $PATH, or in the local project binaries, and execute it. So, for the above example, if you wish to execute the locally-installed package some-package all you need to do is type:\nnpx some-package\n\nAnother major advantage of npx is the ability to execute a package which wasn't previously installed:\n$ npx create-react-app my-app\n\nThe above example will generate a react app boilerplate within the path the command had run in, and ensures that you always use the latest version of a generator or build tool without having to upgrade each time you’re about to use it.\n\nUse-Case Example:\nnpx command may be helpful in the script section of a package.json file,\nwhen it is unwanted to define a dependency which might not be commonly used or any other reason:\n\"scripts\": {\n    \"start\": \"npx gulp@3.9.1\",\n    \"serve\": \"npx http-server\"\n}\n\nCall with: npm run serve\n\nRelated questions:\n\nHow to use package installed locally in node_modules?\nNPM: how to source ./node_modules/.bin folder?\nHow do you run a js file using npm scripts?\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "datetime"
        ]
    },
    {
        "question_id": "440571",
        "question": "\nI'm trying to build some unit tests for testing my Rails helpers, but I can never remember how to access them. Annoying. Suggestions?\n",
        "all_answers": [
            "\nIn rails 3 you can do this (and in fact it's what the generator creates):\nrequire 'test_helper'\n\nclass YourHelperTest < ActionView::TestCase\n  test \"should work\" do\n    assert_equal \"result\", your_helper_method\n  end\nend\n\nAnd of course the rspec variant by Matt Darby works in rails 3 too\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nStolen from here: http://joakimandersson.se/archives/2006/10/05/test-your-rails-helpers/\nrequire File.dirname(__FILE__) + ‘/../test_helper’\nrequire ‘user_helper’\n\nclass UserHelperTest < Test::Unit::TestCase\n\ninclude UserHelper\n\ndef test_a_user_helper_method_here\nend\n\nend\n\n[Stolen from Matt Darby, who also wrote in this thread.] You can do the same in RSpec as:\nrequire File.dirname(__FILE__) + '/../spec_helper'\n\ndescribe FoosHelper do\n\n  it \"should do something\" do\n    helper.some_helper_method.should == @something\n  end\n\nend\n\n",
            "\nYou can do the same in RSpec as:\nrequire File.dirname(__FILE__) + '/../spec_helper'\n\ndescribe FoosHelper do\n\n  it \"should do something\" do\n    helper.some_helper_method.should == @something\n  end\n\nend\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "helper"
        ]
    },
    {
        "question_id": "11584426",
        "question": "\nThat's much the question. I have PHP 5.2.9 on Apache and I cannot upgrade PHP. Is there a way for me to enable SOAP in PHP 5.2.9? The PHP manual did not help at all when it said, \"To enable SOAP support, configure PHP with --enable-soap .\"  How do I configure? \n",
        "all_answers": [
            "\nAs far as your question goes: no, if activating from .ini is not enough and you can't upgrade PHP, there's not much you can do. Some modules, but not all, can be added without recompilation (zypper install php5-soap, yum install php-soap). If it is not enough, try installing some PEAR class for interpreted SOAP support (NuSOAP, etc.).\nIn general, the double-dash --switches are designed to be used when recompiling PHP from scratch.\nYou would download the PHP source package (as a compressed .tgz tarball, say), expand it somewhere and then, e.g. under Linux, run the configure script\n./configure --prefix ...\n\nThe configure command used by your PHP may be shown with phpinfo(). Repeating it identical should give you an exact copy of the PHP you now have installed. Adding --enable-soap will then enable SOAP in addition to everything else.\nThat said, if you aren't familiar with PHP recompilation, don't do it. It also requires several ancillary libraries that you might, or might not, have available - freetype, gd, libjpeg, XML, expat, and so on and so forth (it's not enough they are installed; they must be a developer version, i.e. with headers and so on; in most distributions, having libjpeg installed might not be enough, and you might need libjpeg-dev also).\nI have to keep a separate virtual machine with everything installed for my recompilation purposes.\n",
            "\nGetting SOAP working usually does not require compiling PHP from source. I would recommend trying that only as a last option.\nFor good measure, check to see what your phpinfo says, if anything, about SOAP extensions:\n$ php -i | grep -i soap\n\nto ensure that it is the PHP extension that is missing.\nAssuming you do not see anything about SOAP in the phpinfo, see what PHP SOAP packages might be available to you.\nIn Ubuntu/Debian you can search with:\n$ apt-cache search php | grep -i soap\n\nor in RHEL/Fedora you can search with:\n$ yum search php | grep -i soap\n\nThere are usually two PHP SOAP packages available to you, usually php-soap and php-nusoap. php-soap is typically what you get with configuring PHP with --enable-soap.\nIn Ubuntu/Debian you can install with:\n$ sudo apt-get install php-soap\n\nOr in RHEL/Fedora you can install with:\n$ sudo yum install php-soap\n\nAfter the installation, you might need to place an ini file and restart Apache.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "linux",
            "soap",
            "fedora"
        ]
    },
    {
        "question_id": "1586536",
        "question": "\nI'd like to create a callback function in rails that executes after a model is saved.\nI have this model, Claim that has a attribute 'status' which changes depending on the state of the claim, possible values are pending, endorsed, approved, rejected\nThe database has 'state' with the default value of 'pending'.\nI'd like to perform certain tasks after the model is created on the first time or updated from one state to another, depending on which state it changes from.\nMy idea is to have a function in the model:\n    after_save :check_state\n\n    def check_state\n      # if status changed from nil to pending (created)\n      do this\n\n      # if status changed from pending to approved\n      performthistask\n     end\n\nMy question is how do I check for the previous value before the change within the model?\n",
        "all_answers": [
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nYou should look at ActiveModel::Dirty module.\nYou should be able to perform following actions on your Claim model:\nclaim.status_changed?  # returns true if 'status' attribute has changed\nclaim.status_was       # returns the previous value of 'status' attribute\nclaim.status_change    # => ['old value', 'new value'] returns the old and \n                       # new value for 'status' attribute\n\nclaim.name = 'Bob'\nclaim.changed # => [\"name\"]\nclaim.changes # => {\"name\" => [\"Bill\", \"Bob\"]}\n\n",
            "\nI recommend you have a look at one of the available state machine plugins:\n\nacts_as_state_machine\nalter_ego\n\nEither one will let you setup states and transitions between states. Very useful and easy way of handling your requirements.\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails"
        ]
    },
    {
        "question_id": "6195424",
        "question": "\nI've a settings page where users can select if they want to receive a newsletter or not.\nI want a checkbox for this, and I want that Django select it if 'newsletter' is true in database. How can I implement in Django?\n",
        "all_answers": [
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n",
            "\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['62.63.141.41', 'namjoosadr.com']\n\nand then restart your apache. in ubuntu:\n/etc/init.d/apache2 restart\n\n",
            "\nYou use a CheckBoxInput widget on your form:\nhttps://docs.djangoproject.com/en/dev/ref/forms/widgets/#django.forms.CheckboxInput\nIf you're directly using ModelForms, you just want to use a BooleanField in your model.\nhttps://docs.djangoproject.com/en/stable/ref/models/fields/#booleanfield\n",
            "\nmodels.py:\nclass Settings(models.Model):\n    receive_newsletter = models.BooleanField()\n    # ...\n\nforms.py:\nclass SettingsForm(forms.ModelForm):\n    receive_newsletter = forms.BooleanField()\n\n    class Meta:\n        model = Settings\n\nAnd if you want to automatically set receive_newsletter to True according to some criteria in your application, you account for that in the forms __init__:\nclass SettingsForm(forms.ModelForm):\n\n    receive_newsletter = forms.BooleanField()\n\n    def __init__(self):\n        if check_something():\n            self.fields['receive_newsletter'].initial  = True\n\n    class Meta:\n        model = Settings\n\nThe boolean form field uses a CheckboxInput widget by default. \n",
            "\nsettings.py\nALLOWED_HOSTS = ['*'] // if you are in dev or docker\n\nEdited\nOk guys, dont do this in production if you are not using docker, just put the IP addr.\nGrettings\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "django",
            "django-forms"
        ]
    },
    {
        "question_id": "17724017",
        "question": "\nPossible duplicate Nested elements\nI'm getting from server-side ajax response (Json) and I'm trying to dynamically create table rows and append them to an existing table with id=records_table.\nI tried to implement the solution in possible duplicate but it failed.\nMy response looks like that:\n    '[{\n      \"rank\":\"9\",\n      \"content\":\"Alon\",\n      \"UID\":\"5\"\n     },\n     {\n       \"rank\":\"6\",\n       \"content\":\"Tala\",\n       \"UID\":\"6\"\n    }]'\n\nthe require result is something like that:\n<tr>\n   <td>9</td>\n   <td>Alon</td>\n   <td>5</td>  \n</tr>\n<tr>\n   <td>6</td>\n   <td>Tala</td>\n   <td>5</td>  \n</tr>\n\nI want to do something without parsing the Json so I tried to do the following, which of course was a disaster:\n    function responseHandler(response)\n    {\n\n        $(function() {\n            $.each(response, function(i, item) {\n                $('<tr>').html(\n                    $('td').text(item.rank),\n                    $('td').text(item.content),\n                    $('td').text(item.UID)\n                ).appendTo('#records_table');\n\n            });\n        });\n\n\n    }\n\nFrom my solution I get only one row with the number 6 in all cells. What am I doing wrong?\n",
        "all_answers": [
            "\nYou have to parse the string as JSON (data[0] == \"[\" is an indication that data is actually a string, not an object):\ndata = $.parseJSON(data);\n$.each(data, function(i, item) {\n    alert(item);\n});\n\n",
            "\nTry it like this:\n$.each(response, function(i, item) {\n    $('<tr>').html(\"<td>\" + response[i].rank + \"</td><td>\" + response[i].content + \"</td><td>\" + response[i].UID + \"</td>\").appendTo('#records_table');\n});\n\nDemo: http://jsfiddle.net/R5bQG/\n",
            "\nUse .append instead of .html\nvar response = \"[{\n      \"rank\":\"9\",\n      \"content\":\"Alon\",\n      \"UID\":\"5\"\n     },\n     {\n       \"rank\":\"6\",\n       \"content\":\"Tala\",\n       \"UID\":\"6\"\n    }]\";\n\n// convert string to JSON\nresponse = $.parseJSON(response);\n\n$(function() {\n    $.each(response, function(i, item) {\n        var $tr = $('<tr>').append(\n            $('<td>').text(item.rank),\n            $('<td>').text(item.content),\n            $('<td>').text(item.UID)\n        ); //.appendTo('#records_table');\n        console.log($tr.wrap('<p>').html());\n    });\n});\n\n",
            "\nI dont think youre returning json object from server. just a string.\nyou need the dataType of the return object to be json\n",
            "\nyou could also change from the .get() method to the .getJSON() method, jQuery will then parse the string returned as data to a javascript object and/or array that you can then reference like any other javascript object/array.\nusing your code above, if you changed .get to .getJSON, you should get an alert of [object Object] for each element in the array. If you changed the alert to alert(item.name) you will get the names.\n"
        ],
        "answer": "A3",
        "tags": [
            "jquery",
            "json",
            "html-table"
        ]
    },
    {
        "question_id": "8318914",
        "question": "\nOne of my fields in one of my entities is a \"datetime\" variable.\nHow can I convert this field into a string to render in a browser?\nHere is a code snippet:\n{% for game in games %}\n    ...\n        <td> {{game.gameTeamIdOne.teamName}} </td>\n        <td> {{game.gameTeamIdTwo.teamName}} </td>\n        <td> {{game.gameDate}}</td>\n    </tr>\n{% endfor %}\n\nHere is the variable in my entity class:\n/**\n * @var date $gameDate\n *\n * @ORM\\Column(name=\"GAME_DATE\", type=\"datetime\", nullable=true)\n */\nprivate $gameDate;\n\nAnd here is the error message I am getting:\n\nAn exception has been thrown during the rendering of a template (\"Catchable Fatal Error:      Object of class DateTime could not be converted to string in ...\\app\\cache\\dev\\twig\\9b\\ad\\58fd3bb1517632badf1fdc7fa4a8.php line 33\") in \"BeerBundle:Games:gameTable.html.twig\" at line 10.\n\n",
        "all_answers": [
            "\n# For Laravel 6x/7x:    \ncomposer require doctrine/dbal:\"^2.0\"\n    \n# For Laravel >= 8x:    \ncomposer require doctrine/dbal\n\n",
            "\nThe doctrine/dbal dependency needs to be added to your composer.json\ncomposer require doctrine/dbal\n\nFor more information check laravel #Modifying Columns\n",
            "\nIf you using doctrine 3, downgrade to \"doctrine/dbal\": \"^2.10.3\"(I don't know does laravel updated migration tools for doctrine 3. If do, you should update laravel tools).\nThey renamed class and  Doctrine\\\\DBAL\\\\Driver\\\\PDOMySql\\\\Driver not exists\n",
            "\nYou have to downgrade the current version, this is what worked for me:\ncomposer require doctrine/dbal:2.*\n\n",
            "\nAlthough you can use the\n{{ game.gameDate|date('Y-m-d') }}\n\napproach, keep in mind that this version does not honor the user locale, which should not be a problem with a site used by only users of one nationality. International users should display the game date totally different, like extending the \\DateTime class, and adding a __toString() method to it that checks the locale and acts accordingly.\nEdit:\nAs pointed out by @Nic in a comment, if you use the Intl extension of Twig, you will have a localizeddate filter available, which shows the date in the user’s locale. This way you can drop my previous idea of extending \\DateTime.\n",
            "\nYou can use date filter:\n{{ game.gameDate|date(\"m/d/Y\") }}\n\n",
            "\nLaravel\nWho ever is facing this issue while having\ndoctrine/dbal\": \"3.0\" aleady required:\ndowngrade it back to\n\"doctrine/dbal\": \"^2.10\".\n\nIf you still face issues for example getting\n\nLaravel\\Passport\\Bridge\\AccessToken::__toString() must not throw an\nexception\n\nYou should require a prev version of lcobucci/jwt. It just got auto updated to 3.4, which caused these issues for me.\nTook me around 3-4 hours to track everything down to this.\nHope it helps someone else too.\ncomposer require lcobucci/jwt 3.3.3\n\n",
            "\nIn my case  both composer install and composer install was not working giving a same error “Class 'Doctrine\\DBAL\\Driver\\PDOMySql\\Driver' not found”,\nThe changes that i made to make this workable are given below\ncomposer.json file changed\n \"doctrine/dbal\": \"^3.0\",\n\nthis changed with\n\"doctrine/dbal\": \"^2.0\",\n\nthen run the command\ncomposer update \n\n"
        ],
        "answer": "A5",
        "tags": [
            "php",
            "symfony",
            "datetime",
            "twig"
        ]
    },
    {
        "question_id": "37948764",
        "question": "\nI am trying to generate a UUID (not as primary key, just generate one) with the laravel-uuid package. The docs are pretty straightforward, so according to the readme file a UUID should be generated just by calling $uuid = Uuid::generate();, but it returns an empty object. (I also tried $uuid = Uuid::generate(1);)\nI followed the installation instructions as provided there (nothing out of the ordinary), the app doesn't throw any errors, so I guess everything is right.\nAlternative packages for this are also welcome.\n",
        "all_answers": [
            "\nAfter laravel 5.6 a new helper was added to generate Universal Unique Identifiers (UUID)\nuse Illuminate\\Support\\Str;\n\nreturn (string) Str::uuid();\n\nreturn (string) Str::orderedUuid();\n\nThe methods return a Ramsey\\Uuid\\Uuid object\nThe orderedUuid() method will generate a timestamp first UUID for easier and more efficient database indexing.\n",
            "\nIt looks like you have everything correct according to Laravel docs, but you have a typo\n$item->push($product);\n\nShould be\n$items->push($product);\n\npush method appends an item to the end of the collection:\nI also want to think the actual method you're looking for is put\n$items->put('products', $product);\n\nput method sets the given key and value in the collection\n",
            "\nIt's possible that $uuid is empty because your system doesn't provide the right kind of entropy. You might try these library implementations for either a v4 or v5 UUID:\n// https://tools.ietf.org/html/rfc4122#section-4.4\nfunction v4() {\n    $data = openssl_random_pseudo_bytes(16, $secure);\n    if (false === $data) { return false; }\n    $data[6] = chr(ord($data[6]) & 0x0f | 0x40); // set version to 0100\n    $data[8] = chr(ord($data[8]) & 0x3f | 0x80); // set bits 6-7 to 10\n    return vsprintf('%s%s-%s-%s-%s-%s%s%s', str_split(bin2hex($data), 4));\n}\n\n// https://tools.ietf.org/html/rfc4122#section-4.3\nfunction v5($name) {\n    $hash = sha1($name, false);\n    return sprintf(\n        '%s-%s-5%s-%s-%s',\n        substr($hash,  0,  8),\n        substr($hash,  8,  4),\n        substr($hash, 17,  3),\n        substr($hash, 24,  4),\n        substr($hash, 32, 12)\n    );\n}\n\n",
            "\nTry to use this package will automatically generate and assign UUID field in your model, also can show and update by UUIDs key.\nhttps://github.com/EmadAdly/laravel-uuid\n",
            "\nTurns out I had to use $uuid->string to get the actual ID, the whole object shows empty if you try to return it in a json response.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "laravel",
            "uuid"
        ]
    },
    {
        "question_id": "9841026",
        "question": "\nIs there a possibility to misuse grab files from a github repo as external resources in jsFiddle?\n",
        "all_answers": [
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nAnother possibility is to add the Git library to the cdnJS Script Repository (they write that any library that is resonably popular on GitHub will be accepted) and then use it as external resource.\nJust found out: there are lots of Javascript libraries at http://jsdb.io/ and it's very easy to add new ones there--i's just a matter of entering the URL of a Github repository.\n",
            "\nThis is an updated answer, since the url's have changed slightly for Github... I ran into this issue and figured it out for present day. Hopefully this helps people out finding this post recently. Example for Bootstrap Slate theme from Bootswatch:\n\nRaw file url:  https://raw2.github.com/thomaspark/bootswatch/gh-pages/slate/bootstrap.css\nRemove the 2. after raw: https://rawgithub.com/thomaspark/bootswatch/gh-pages/slate/bootstrap.css\n\nThat's it! :D\n"
        ],
        "answer": "A3",
        "tags": [
            "github",
            "jsfiddle"
        ]
    },
    {
        "question_id": "10748082",
        "question": "\nCouldn't find anything in the github documentation and also here on SO. But I was wondering if there could be a http://foo.github.com for a private repository named foo which is accessible only one had access to the foo repository itself.\nI remember having read something about github pages always being public but can't seem to find that anymore.\nAnd surprisingly, I can't seem to find anyone else asking the question either.\n",
        "all_answers": [
            "\nThe page.github.com does mention:\n\nGithub Pages are hosted free and easily published through our site,\n\nWithout ever mentioning access control.\nThe GitHub page help doesn't mention any ACL either.\nThey are best managed in a gh-pages branch, and can be managed in their own submodule.\nBut again, without any restriction in term of visibility once published by GitHub.\n",
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nI had raised a support ticket against Github and got a response confirming the fact that ALL pages are public. I've now requested them to add a note to help.github.com/pages.\n",
            "\nIf you press admin on a private repo and scroll down to the part about pages, it writes that it'll be public. I'll check later if .htaccess control or similar is possible, but I don't have much hope for it.\n"
        ],
        "answer": "A3",
        "tags": [
            "github",
            "github-pages"
        ]
    },
    {
        "question_id": "87561",
        "question": "\nI'd like to add some pie, bar and scatter charts to my Ruby on Rails web application. I want want them to be atractive, easy to add and not introduce much overhead. \nWhat charting solution would you recommend?\nWhat are its drawbacks (requires Javascript, Flash, expensive, etc)?\n",
        "all_answers": [
            "\nGoogle charts is very nice, but it's not a rails only solution.  You simple use the programming language of your choice to dynamically produce urls that contain the data and google returns you back a nice image with your chart.\nhttp://code.google.com/apis/chart/\n",
            "\nHave you tried the Google Charts API? - web service APIs don't really come much simpler. It's free to use, simple to implement, and the charts don't look too shoddy.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nOpen Flash Chart II is a free option that gives very nice output. It does, as you'd expect, require Flash.\nFusion Charts is even nicer, but is $499. In researching this, I found a cut-down free version that might serve your needs.\n",
            "\nGoogle Charts is an excellent choice if you don't want to use Flash. It's pretty easy to use on its own, but for Rails, it's even easier with the gchartrb gem. An example:\nGoogleChart::PieChart.new('320x200', \"Things I Like To Eat\", false) do |pc| \n  pc.data \"Broccoli\", 30\n  pc.data \"Pizza\", 20\n  pc.data \"PB&J\", 40 \n  pc.data \"Turnips\", 10 \n  puts pc.to_url \nend\n\n"
        ],
        "answer": "A6",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "charts"
        ]
    },
    {
        "question_id": "1388025",
        "question": "\nHow do I get the ID of the last updated row in MySQL using PHP?\n",
        "all_answers": [
            "\nID  of the last updated row is the same ID that you use in the 'updateQuery' to found & update that row. So, just save(call) that ID on anyway you want.\nlast_insert_id() depends of the AUTO_INCREMENT, but the last updated ID not. \n",
            "\nI've found an answer to this problem :)\nSET @update_id := 0;\nUPDATE some_table SET column_name = 'value', id = (SELECT @update_id := id)\nWHERE some_other_column = 'blah' LIMIT 1; \nSELECT @update_id;\n\nEDIT by aefxx\nThis technique can be further expanded to retrieve the ID of every row affected by an update statement:\nSET @uids := null;\nUPDATE footable\n   SET foo = 'bar'\n WHERE fooid > 5\n   AND ( SELECT @uids := CONCAT_WS(',', fooid, @uids) );\nSELECT @uids;\n\nThis will return a string with all the IDs concatenated by a comma.\n",
            "\nIf you are only doing insertions, and want one from the same session, do as per peirix's answer. If you are doing modifications, you will need to modify your database schema to store which entry was most recently updated.\nIf you want the id from the last modification, which may have been from a different session (i.e. not the one that was just done by the PHP code running at present, but one done in response to a different request), you can add a TIMESTAMP column to your table called last_modified (see http://dev.mysql.com/doc/refman/5.1/en/datetime.html for information), and then when you update, set last_modified=CURRENT_TIME.\nHaving set this, you can then use a query like:\n  SELECT id FROM table ORDER BY last_modified DESC LIMIT 1;\nto get the most recently modified row.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "mysql"
        ]
    },
    {
        "question_id": "4061293",
        "question": "\nI am trying to import a .sql file and its failing on creating tables.\nHere's the query that fails:\nCREATE TABLE `data` (\n`id` int(10) unsigned NOT NULL,\n`name` varchar(100) NOT NULL,\n`value` varchar(15) NOT NULL,\nUNIQUE KEY `id` (`id`,`name`),\nCONSTRAINT `data_ibfk_1` FOREIGN KEY (`id`) REFERENCES `keywords` (`id`) ON DELETE CASCADE ON UPDATE CASCADE\n) ENGINE=InnoDB DEFAULT CHARSET=latin1;    \n\nI exported the .sql from the same database, I dropped all the tables and now im trying to import it, why is it failing?\n\nMySQL: Can't create table './dbname/data.frm' (errno: 150)\n\n",
        "all_answers": [
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nFrom the MySQL - FOREIGN KEY Constraints Documentation:\n\nIf you re-create a table that was dropped, it must have a definition that conforms to the foreign key constraints referencing it. It must have the correct column names and types, and it must have indexes on the referenced keys, as stated earlier. If these are not satisfied, MySQL returns Error 1005 and refers to Error 150 in the error message, which means that a foreign key constraint was not correctly formed. Similarly, if an ALTER TABLE fails due to Error 150, this means that a foreign key definition would be incorrectly formed for the altered table. \n\n",
            "\nError 150 means you have a problem with your foreign key. Possibly the key on the foreign table isn't the exact same type?\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nError no. 150 means a foreign key constraint failure. You are probably creating this table before the table the foreign key depends on (table keywords). Create that table first and it should work fine. \nIf it doesn't, remove the foreign key statement and add it after the table is created - you will get a more meaningful error message about the specific constraint failure.\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "mysql",
            "sql",
            "phpmyadmin",
            "mysql-error-150"
        ]
    },
    {
        "question_id": "846585",
        "question": "\nThe code in question is here: \nvar $item = $(this).parent().parent().find('input');\n\nWhat is the purpose of the dollar sign in the variable name, why not just exclude it?\n",
        "all_answers": [
            "\nA '$' in a variable means nothing special to the interpreter, much like an underscore.\nFrom what I've seen, many people using jQuery (which is what your example code looks like to me) tend to prefix variables that contain a jQuery object with a $ so that they are easily identified and not mixed up with, say, integers.\nThe dollar sign function $() in jQuery is a library function that is frequently used, so a short name is desirable.\n",
            "\nNo reason. Maybe the person who coded it came from PHP. It has the same effect as if you had named it \"_item\" or \"item\" or \"item$$\". \nAs a suffix (like \"item$\", pronounced \"items\"), it can signify an observable such as a DOM element as a convention called \"Finnish Notation\" similar to the Hungarian Notation.\n",
            "\nThe $ sign is an identifier for variables and functions.\nhttps://web.archive.org/web/20160529121559/http://www.authenticsociety.com/blog/javascript_dollarsign\nThat has a clear explanation of what the dollar sign is for.\nHere's an alternative explanation: http://www.vcarrer.com/2010/10/about-dollar-sign-in-javascript.html\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "naming-conventions"
        ]
    },
    {
        "question_id": "8698534",
        "question": "\nI'm having trouble with a variable (config) declared in a jade template file (index.jade) that isn't passed to a javascript file, which then makes my javascript crash. Here is the file (views/index.jade):\nh1 #{title}\n\nscript(src='./socket.io/socket.io.js')\nscript(type='text/javascript')\n  var config = {};\n  config.address = '#{address}';\n  config.port = '#{port}';\nscript(src='./javascripts/app.js')\n\nHere is a part of my app.js (server side):\n  app.use(express.bodyParser());\n  app.use(express.methodOverride());\n  app.use(app.router);\n  app.use(express.static(__dirname + '/public'));\n});\n\napp.configure('development', function(){\n  app.set('address', 'localhost');\n  app.use(express.errorHandler({ dumpExceptions: true, showStack: true }));\n});\n\napp.configure('production', function(){\n  app.use(express.errorHandler());\n});\n\n// Routes\n\napp.get('/', function(req, res){\n  res.render('index', {\n    address: app.settings.address,\n    port: app.settings.port\n});\n});\n\nif (!module.parent) {\n  app.listen(app.settings.port);\n  console.log(\"Server listening on port %d\",\napp.settings.port);\n}\n\n// Start my Socket.io app and pass in the socket\nrequire('./socketapp').start(io.listen(app));\n\nAnd here is a part of my javascript file that crashes (public/javascripts/app.js):\n(function() {\n        var socket = new io.Socket(config.address, {port: config.port, rememberTransport: false});\n\nI'm running the site on development mode (NODE_ENV=development) on localhost (my own machine). I'm using node-inspector for debugging, which told me that the config variable is undefined in public/javascripts/app.js.\nAny ideas?? Thanks!!\n",
        "all_answers": [
            "\nSee this question: JADE + EXPRESS: Iterating over object in inline JS code (client-side)?\nI'm having the same problem. Jade does not pass local variables in (or do any templating at all) to javascript scripts, it simply passes the entire block in as literal text. If you use the local variables 'address' and 'port' in your Jade file above the script tag they should show up.\nPossible solutions are listed in the question I linked to above, but you can either:\n  - pass every line in as unescaped text (!= at the beginning of every line), and simply put \"-\" before every line of javascript that uses a local variable, or:\n  - Pass variables in through a dom element and access through JQuery (ugly)\nIs there no better way? It seems the creators of Jade do not want multiline javascript support, as shown by this thread in GitHub: https://github.com/visionmedia/jade/pull/405\n",
            "\nIt's a little late but...\nscript.\n  loginName=\"#{login}\";\n\nThis is working fine in my script. In Express, I am doing this:\nexports.index = function(req, res){\n  res.render( 'index',  { layout:false, login: req.session.login } );\n};\n\nI guess the latest jade is different?\nMerc.\nedit: added \".\" after script to prevent Jade warning.\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "node.js",
            "pug"
        ]
    },
    {
        "question_id": "4007171",
        "question": "\nI'm running Mac OSX 10.6.4 and have installed RVM.  Its been great so far, I really love the way it lets me manage having multiple versions of rails and ruby on the same machine without headaches!\nHowever, I don't want to have to install certain gems (such as passenger) for each setup. Is there a way to share gems between gemsets?  I have a [email protected] and 1.9.2@rails3, can I have gems such as passenger, mysql, and capistrano installed once and used with all versions?\n",
        "all_answers": [
            "\nadd the the gems you want for every gemset in a \"global\" rvm gemset name i.e.\nrvm 1.9.2@global\n\nthen project specific gemsets rvm 1.9.2@myProject will already have you're \"default\" gems from your global list\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nThere is something called the global gemset, and it is shared between all your gemsets of a certain ruby-version. But you can't share gems between ruby-versions.\nHowever, what you can do is create a list of gems that will be installed automatically when adding a new ruby version. That is described here. In short: edit a file called ~/.rvm/gemsets/global.gems to contain the list of gems you want to be there for each ruby-version.\nHope it helps.\n",
            "\nYou can create and use global gemsets with the following commands:\nrvm gemset create global\nrvm gemset use global\n\nAfter you've created and execute use for the global gemset simply install gems as usual:\ngem install mysql passenger\n\n"
        ],
        "answer": "A4",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "macos",
            "rubygems"
        ]
    },
    {
        "question_id": "25106603",
        "question": "\nI have an issue with converting character type to String type. First of all, I have below extension of String for finding nth character within String.\nextension String {\n    func characterAtIndex(index: Int) -> Character? {\n        var cur = 0\n        for char in self {\n            if cur == index {\n                return char\n            }\n            cur++\n        }\n        return nil\n    }\n}\n\nI get what I want with this class extension. However when I use that nth character for title of my custom UIButton, gives an error. My Uibutton Class is\nclass hareketliHarfler: UIButton {\n    init(frame: CGRect) {\n        super.init(frame: frame)\n        // Initialization code\n    }\n    func getLetter(letter:String!){\n        self.titleLabel.text = letter \n    }\n}\n\nThe error show when i try to access \"getLetter(letter:String)\" function. Here is example of main view Controller codes:\n    var harfim = hareketliHarfler(frame: CGRectMake(100,100,100,100))\nvar str=\"This is my String\"\nvar bufi=str.characterAtIndex(3)\n    harfim.getLetter(bufi as AnyObject) ****\n\nIn * section I try .getLetter(bufi), .getLetter(bufi as String) also I try to change parameter type of function. Look like: func getLetter(letter:Character!) or func getLetter(letter:AnyObject!)...etc\nDidn't find a way. Need a help on that. Thank you\n",
        "all_answers": [
            "\nChange this:\nvar bufi=str.characterAtIndex(3)\nharfim.getLetter(bufi as AnyObject)\n\nto this:\nharfim.getLetter(String(Array(str)[3]))\n\nSo what happening here:\n\nwe create an array from our string. Array elements are symbols from original string. Such break down correctly tracks symbols that are presented with a sequences of two or more code points. E.g. emoji or flag as noted by @MartinR.\nWe access element at 4-th position.\n\nNote that as we crate an array from initial string then performance wise is better to use this method only with short strings and avoid it in  oft-repeated routines. But in your case it seems to be OK.\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nYour problem is quite simple: your characterAtIndex function returns a Character, and self.titleLabel.text is a String. You can't convert between the two implicitly. The easiest way would be to turn the Character into a String using the String initialiser:\n// ch will be Character? type.\nif let ch = str.characterAtIndex(3) {\n    // Initialise a new String containing the single character 'ch'\n    harfim.getLetter(String(ch))\n} else {\n    // str didn't have a third character.\n}\n\nUnlike other solutions, this is safe for unusual Unicode characters, and won't initialise a potentially large array or iterate the whole String just to get the third character.\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "swift"
        ]
    },
    {
        "question_id": "4861224",
        "question": "\nI would like to surround a number in a circle like in this image:  \n\nIs this possible and how is it achieved?\n",
        "all_answers": [
            "\nHere's a demo on JSFiddle and a snippet:\n\n\n.numberCircle {\r\n    border-radius: 50%;\r\n    width: 36px;\r\n    height: 36px;\r\n    padding: 8px;\r\n\r\n    background: #fff;\r\n    border: 2px solid #666;\r\n    color: #666;\r\n    text-align: center;\r\n\r\n    font: 32px Arial, sans-serif;\r\n}\n<div class=\"numberCircle\">30</div>\n\n\n\nMy answer is a good starting point, some of the other answers provide flexibility for different situations. If you care about IE8, look at the old version of my answer.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nDo something like this in your css\n\n div {\n    width: 10em; height: 10em; \n    -webkit-border-radius: 5em; -moz-border-radius: 5em;\n  }\n  p {\n    text-align: center; margin-top: 4.5em;\n  }\n\nUse the paragraph tag to write the text. Hope that helps\n",
            "\nYou can use the border-radius for this:\n<html>\n  <head>\n    <style type=\"text/css\">\n\n    .round\n    {\n        -moz-border-radius: 15px;\n        border-radius: 15px;\n        padding: 5px;\n        border: 1px solid #000;\n    }\n\n  </style>\n  </head>  \n  <body>   \n    <span class=\"round\">30</span>\n  </body>\n</html>  \n\nPlay with the border radius and the padding values until you are satisfied with the result.\nBut this won't work in all browsers. I guess IE still does not support rounded corners.\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n"
        ],
        "answer": "A1",
        "tags": [
            "html",
            "css",
            "css-shapes"
        ]
    },
    {
        "question_id": "534700",
        "question": "\nOkay, how would I do this?\nclass Example(models.Model):\n  parent_example = models.ForeignKey(Example)\n\nI want to have a model have a foreign key reference to itself.  When I try to create this I get a django validation error that Example is not yet defined.\n",
        "all_answers": [
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nYes, just do this:\nclass Example(models.Model):\n  parent_example = models.ForeignKey('self')\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nYou should use\nmodels.ForeignKey('self')\n\nas mentioned here.\n",
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nAnother way to avoid the SerializerMethodField solution and therefore still allow writing to the serializer as well would be to subclass the RelatedField and do the filtering there.\nTo only allow active users as values for the field, the example would look like:\nclass ActiveUsersPrimaryKeyField(serializers.PrimaryKeyRelatedField):\n    def get_queryset(self):\n        return super().get_queryset().filter(active=True)\n\nclass MySerializer(serializers.ModelSerializer):\n    users = ActiveUsersPrimaryKeyField(many=True)\n    class Meta:\n        model = MyModel\n        fields = ('users',)\n\nAlso see this response.\nNote that this only restricts the set of input values to active users, though, i.e. only when creating or updating model instances, inactive users will be disallowed.\n\nIf you also use your serializer for reading and MyModel already has a relation to a user that has become inactive in the meantime, it will still be serialized. To prevent this, one way is to filter the relation using django's Prefetch objects. Basically, you'll filter out inactive users before they even get into the serializer:\nfrom django.db.models import Prefetch\n\n# Fetch a model instance, eagerly prefetching only those users that are active\nmodel_with_active_users = MyModel.objects.prefetch_related(\n    Prefetch(\"users\", queryset=User.objects.filter(active=True))\n).first()\n\n# serialize the data with the serializer defined above and see that only active users are returned\ndata = MyModelSerializer(model_with_active_users).data\n\n\n"
        ],
        "answer": "A4",
        "tags": [
            "django",
            "django-models"
        ]
    },
    {
        "question_id": "6364783",
        "question": "\nLet's say that I have a two word string and I want to capitalize\nboth of them.\nname <- c(\"zip code\", \"state\", \"final count\")\n\nThe Hmisc package has a function capitalize which capitalized the first word, but I'm not sure\nhow to get the second word capitalized. The help page for capitalize doesn't suggest that it can perform that task.\nlibrary(Hmisc)\ncapitalize(name)\n# [1] \"Zip code\"    \"State\"       \"Final count\"\n\nI want to get:\nc(\"Zip Code\", \"State\", \"Final Count\")\n\nWhat about three-word strings:\nname2 <- c(\"I like pizza\")\n\n",
        "all_answers": [
            "\nYou can use gsubfn\nlibrary(gsubfn)\ngsubfn(\".\", list(\"'\" = \"\", \" \" = \"_\"), x)\n# [1] \"ab_c\"\n\nSimilarly, we can also use mgsub which allows multiple replacement with multiple pattern to search\nmgsub::mgsub(x, c(\"'\", \" \"), c(\"\", \"_\"))\n#[1] \"ab_c\"\n\n",
            "\nTry:\nrequire(Hmisc)\nsapply(name, function(x) {\n  paste(sapply(strsplit(x, ' '), capitalize), collapse=' ')\n})\n\n",
            "\nI am a fan of the syntax that the %<>% and %>% opperators from the magrittr package provide.\nlibrary(magrittr)\n\nx <- \"a'b c\"\n\nx %<>%\n  gsub(\"'\", \"\", .) %>%\n  gsub(\" \", \"_\", .) \nx\n##[1] \"ab_c\"\n\ngusbfn is wonderful, but I like the chaining %>% allows.\n",
            "\nThe base R function to perform capitalization is toupper(x).  From the help file for ?toupper there is this function that does what you need:\nsimpleCap <- function(x) {\n  s <- strsplit(x, \" \")[[1]]\n  paste(toupper(substring(s, 1,1)), substring(s, 2),\n      sep=\"\", collapse=\" \")\n}\n\nname <- c(\"zip code\", \"state\", \"final count\")\n\nsapply(name, simpleCap)\n\n     zip code         state   final count \n   \"Zip Code\"       \"State\" \"Final Count\" \n\nEdit This works for any string, regardless of word count:\nsimpleCap(\"I like pizza a lot\")\n[1] \"I Like Pizza A Lot\"\n\n"
        ],
        "answer": "A4",
        "tags": [
            "r",
            "string",
            "title-case"
        ]
    },
    {
        "question_id": "1649793",
        "question": "\nI understand why \"REST framework\" vendors want to provide the support for returning both Json based representations and XML based representations, but why do people want to return both from the same service?\n\nIs it because you will have client       applications that are built on a platform that has no available Json parser? \nIs it because you are hoping for       wider adoption of the interface       because you can appeal to more people?\nIs it because you feel that it a    standard convention that all RESTful    interfaces follow?\n\nIf you do deliver both:\nDo you avoid namespaces in the XML so    that    it can be compatible with the    Json    format?  Or do you have just    one    namespace for all of your data    elements?\nDo you have some kind of standardized mechanism for mapping attributes and elements into some kind of consistent Json format, or do you just avoid attributes in your XML? \nDo you create different endpoints for each representation, or do you use content negotiation to deliver the requested format?  Do you have a default format?\nIf you use caching on editable resources and use different URLs, how do you ensure that when one representation is invalidated that the other representations are also invalidation?\nDo you feel the benefit of supporting multiple formats is worth the effort required?\nSummary of responses:\nSo the primary reason seems to be one of preference.  Some developers prefer curly braces and some prefer angle brackets.\nSome people want to migrate from XML to Json and therefore supporting both is required for backward compatibility.\nSome want to use Json, but are concerned that some developers are scared of Json, so they support both so as not to offend anyone.\nIt is easy to turn the feature on in framework XYZ so why not!\nAnother interesting suggested reason, is JSON can be used to provide a quick a dirty data summary and XML can be used as a semantically rich complete representation.\n",
        "all_answers": [
            "\nI wouldn't read too much into it. I think some developers prefer one over the other and (especially depending on your framework) it's pretty easy to provide both.\nMost of the APIs I've seen that take this approach don't bother with XML namespaces\n",
            "\nJson is often suitable for client side scripts. It is a super-lightweight response and the most part of JavaScript frameworks come with a parser built-in.\nOn the other side, many server side applications and languages still rely heavily on XML. Just to name one: Java.\nOf course, XML can be parsed with JavaScript and Java (and the most part of other programming languages) has at least one Json parser. But at the moment this seems to be the most common practice.\nTalking about the \"implementation vs benefit\" topic, I mostly work with Ruby and I can tell you Ruby on Rails provides the ability to create a Json or XML response in less than a couple of seconds from the same source. In this case it's not a problem and I usually add that feature if I think it could be useful.\nWith other technologies, for example PHP, it would require more effort and the implementation would have a different cost. Unless this would be a fundamental feature, I would probably stick with one response until I don't find the need to provide to different versions.\n"
        ],
        "answer": "A2",
        "tags": [
            "xml",
            "web-services",
            "json",
            "rest"
        ]
    },
    {
        "question_id": "5951157",
        "question": "\nSELECT id, amount FROM report\n\nI need amount to be amount if report.type='P' and -amount if report.type='N'. How do I add this to the above query?\n",
        "all_answers": [
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nSELECT id, \n       IF(type = 'P', amount, amount * -1) as amount\nFROM report\n\nSee https://dev.mysql.com/doc/refman/8.0/en/flow-control-functions.html.\nAdditionally, you could handle when the condition is null. In the case of a null amount:\nSELECT id, \n       IF(type = 'P', IFNULL(amount,0), IFNULL(amount,0) * -1) as amount\nFROM report\n\nThe part IFNULL(amount,0) means when amount is not null return amount else return 0.\n",
            "\nUse a case statement:\nselect id,\n    case report.type\n        when 'P' then amount\n        when 'N' then -amount\n    end as amount\nfrom\n    `report`\n\n"
        ],
        "answer": "A8",
        "tags": [
            "mysql",
            "sql",
            "database"
        ]
    },
    {
        "question_id": "7347327",
        "question": "\nI am using the Pry gem in my Rails console, but the pry flavored rails-console seems to have lost the reload! method for reloading models and stuff.\nHere's how I start the pry console\nc:\\rails\\app> pry -r ./config/environment\n\nThank You\n",
        "all_answers": [
            "\nDo you mean ./config/environment?\nIn any case, I think that's different than actually launching a rails console, which is where reload! comes from. I redefine IRB = Pry in my env-specific config file, which ensures a full console, and it all works like a charm.\n",
            "\nI've recently written a post about pry and rails. You can find it here http://lucapette.com/pry/pry-everywhere/. By the way, as dave already said, you would like to use pry with:\npry -r ./config/environment\n\nI recommend you to try what I wrote in the article, it works really fine. \n",
            "\nYou could tell Pry to load your Rails environment in your .pryrc\nrails = File.join Dir.getwd, 'config', 'environment.rb'\n\nif File.exist?(rails) && ENV['SKIP_RAILS'].nil?\n  require rails\n\n  if Rails.version[0..0] == \"2\"\n    require 'console_app'\n    require 'console_with_helpers'\n  elsif Rails.version[0..0] == \"3\"\n    require 'rails/console/app'\n    require 'rails/console/helpers'\n  else\n    warn \"[WARN] cannot load Rails console commands (Not on Rails2 or Rails3?)\"\n  end\nend\n\nThis will give your reload! back.\n",
            "\nYou could check out this page on the Pry wiki: https://github.com/pry/pry/wiki/Setting-up-Rails-or-Heroku-to-use-Pry\nAlso check out the pry-rails plugin: https://github.com/rweng/pry-rails\nThere's also a lot of other content on that wiki, it's a great resource.\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A4",
        "tags": [
            "ruby-on-rails",
            "pry"
        ]
    },
    {
        "question_id": "792410",
        "question": "\nShort version:\nIs there a simple, built-in way to identify the calling view in a Django template, without passing extra context variables?\nLong (original) version:\nOne of my Django apps has several different views, each with its own named URL pattern, that all render the same template. There's a very small amount of template code that needs to change depending on the called view, too small to be worth the overhead of setting up separate templates for each view, so ideally I need to find a way to identify the calling view in the template.\nI've tried setting up the views to pass in extra context variables (e.g. \"view_name\") to identify the calling view, and I've also tried using {% ifequal request.path \"/some/path/\" %} comparisons, but neither of these solutions seems particularly elegant. Is there a better way to identify the calling view from the template? Is there a way to access to the view's name, or the name of the URL pattern?\n\nUpdate 1: Regarding the comment that this is simply a case of me misunderstanding MVC, I understand MVC, but Django's not really an MVC framework. I believe the way my app is set up is consistent with Django's take on MVC: the views describe which data is presented, and the templates describe how the data is presented. It just happens that I have a number of views that prepare different data, but that all use the same template because the data is presented the same way for all the views. I'm just looking for a simple way to identify the calling view from the template, if this exists.\nUpdate 2: Thanks for all the answers. I think the question is being overthought -- as mentioned in my original question, I've already considered and tried all of the suggested solutions -- so I've distilled it down to a \"short version\" now at the top of the question. And right now it seems that if someone were to simply post \"No\", it'd be the most correct answer :)\nUpdate 3: Carl Meyer posted \"No\" :) Thanks again, everyone.\n",
        "all_answers": [
            "\none simple solution is :\ndef view1(req):\n   viewname = \"view1\"\n   and pass this viewname to the template context   \n\ndef view2(req):\n   viewname = \"view2\"\n   and pass this viewname to the template context   \n\nin template access the viewname as \n{{viewname}} \n\nand also you can use this in comparisons.\n",
            "\nThis sounds like the perfect example of a generic view that you can set up.\nSee the following resources:\n\nDjango Book - Chapter 11: Generic Views\nDjango Docs  -Tutorial: Chapter 4\nDjango Docs - Generic Views\n\nThese links should help you simplify your views and your templates accordingly.\n",
            "\nNo, and it would be a bad idea.  To directly refer to a view function name from the template introduces overly tight coupling between the view layer and the template layer.\nA much better solution here is Django's template inheritance system.  Define a common parent template, with a block for the (small) area that needs to change in each view's version.  Then define each view's template to extend from the parent and define that block appropriately.\n",
            "\nWhy not trying setting up a session cookie, then read the cookie from your template.\non your views set cookies\ndef view1(request):\n ...\n#set cookie\n request.session[\"param\"]=\"view1\"\n\ndef view2(request):\n  request.session[\"param\"]=\"view2\"\n\n\nthen in your ONE template check something like..\n\n{% ifequal request.session.param \"view1\" %}\n   ... do stuff related to view1\n{% endifequal %}\n\n{% ifequal request.session.param \"view2\" %}\n  ... do stuff related to \"view2\"\n{% endifequal %}\n\nGath\n"
        ],
        "answer": "A3",
        "tags": [
            "django"
        ]
    },
    {
        "question_id": "10489298",
        "question": "\nTrying to grasp some basics of Redis I came across an interesting blog post .\nThe author states:\n\nRedis is single-threaded with epoll/kqueue and scale indefinitely in terms of I/O concurrency. \n\nI surely misunderstand the whole threading thing, because I find this statement puzzling. If a program is single-threaded, how does it do anything concurrently? Why it is so great that Redis operations are atomic, if the server is single-threaded anyway?\nCould anybody please shed some light on the issue?\n",
        "all_answers": [
            "\nOK, Redis is single-threaded at user-level, OTOH, all asynchronous I/O is supported by kernel thread pools and/or split-level drivers.\n'Concurrent', to some, includes distributing network events to socket state-machines.  It's single-threaded, runs on one core, (at user level), so I would not refer to this as concurrent.  Others differ..\n'scale indefinitely in terms of I/O concurrency' is just being economical with the truth.  They may get more belief if they said 'can scale better than one-thread-per-client, providing the clients don't ask for much', though they may then feel obliged to add 'blown away on heavy loading by other async solutions that use all cores at user level'.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nWell it depends on how you define concurrency.\nIn server-side software, concurrency and parallelism are often considered as different concepts. In a server, supporting concurrent I/Os means the server is able to serve several clients by executing several flows corresponding to those clients with only one computation unit. In this context, parallelism would mean the server is able to perform several things at the same time (with multiple computation units), which is different.\nFor instance a bartender is able to look after several customers while he can only prepare one beverage at a time. So he can provide concurrency without parallelism.\nThis question has been debated here:\nWhat is the difference between concurrency and parallelism?\nSee also this presentation from Rob Pike.\nA single-threaded program can definitely provide concurrency at the I/O level by using an I/O (de)multiplexing mechanism and an event loop (which is what Redis does).\nParallelism has a cost: with the multiple sockets/multiple cores you can find on modern hardware, synchronization between threads is extremely expensive. On the other hand, the bottleneck of an efficient storage engine like Redis is very often the network, well before the CPU. Isolated event loops (which require no synchronization) are therefore seen as a good design to build efficient, scalable, servers.\nThe fact that Redis operations are atomic is simply a consequence of the single-threaded event loop. The interesting point is atomicity is provided at no extra cost (it does not require synchronization). It can be exploited by the user to implement optimistic locking and other patterns without paying for the synchronization overhead.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n"
        ],
        "answer": "A3",
        "tags": [
            "multithreading",
            "redis"
        ]
    },
    {
        "question_id": "34744783",
        "question": "\nI'm working on a game for iOS coded in Swift. I've tried to find a way to detect when the app enters background mode or is interrupted for other reasons, for example a phone call but can't find anything. How do I do it?\n",
        "all_answers": [
            "\nYou can add an observer to your view controller:\nedit/update: Xcode 11 • Swift 5\niOS13 or later\nUIScene.willDeactivateNotification\n\niOS12 or earlier\nUIApplication.willResignActiveNotification\n\n\nif #available(iOS 13.0, *) {\n    NotificationCenter.default.addObserver(self, selector: #selector(willResignActive), name: UIScene.willDeactivateNotification, object: nil)\n} else {\n    NotificationCenter.default.addObserver(self, selector: #selector(willResignActive), name: UIApplication.willResignActiveNotification, object: nil)\n}\n\nand add a selector method to your view controller that will be executed when your app receives that notification:\n@objc func willResignActive(_ notification: Notification) {\n    // code to execute\n}\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nTake a look at the delegate methods defined in your instance of UIApplicationDeletegate (called AppDelegate.m by default). Specifically the following would be useful:\n- (void)applicationWillResignActive:(UIApplication *)application\n\n\nThis method is called to let your app know that it is about to move from the active to inactive state. This can occur for certain types of temporary interruptions (such as an incoming phone call or SMS message) or when the user quits the app and it begins the transition to the background state. An app in the inactive state continues to run but does not dispatch incoming events to responders.\n\nTaken from the Apple Documentation - here\n",
            "\nTo detect the app enters background, you can check in the appDelegate.m\nfind the application delegate method \n\napplicationDidEnterBackground\n\nThis method will get called, once the app enters background.\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "iphone",
            "swift"
        ]
    },
    {
        "question_id": "56277661",
        "question": "\nI am using Google Drive API with my Rails application. The API is working fine. I have the following client_secret.json file:\n{\n  \"type\": \"service_account\",\n  \"project_id\": \"gobirdie-landing-page\",\n  \"private_key_id\": \"xxxxx\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY----- xxxxx -----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"[email protected]\",\n  \"client_id\": \"xxxxxxxxx\",\n  \"auth_uri\": \"xxxxxx\",\n  \"token_uri\": \"xxxxxxx\": \"xxxxxxxx\": \"xxxxxxxxx\"\n}\n\nwhich is called in my controller\n@session = GoogleDrive::Session.from_service_account_key(\"client_secret.json\")\n\n\nWith this configuration no problem, I manage to use the API. However, I would like to store my JSON in the .env file like: \nCLIENT_SECRET = \"{\n  \"type\": \"service_account\",\n  \"project_id\": \"gobirdie-landing-page\",\n  \"private_key_id\": \"xxxxx\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY----- xxxxx -----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"[email protected]\",\n  \"client_id\": \"xxxxxxxxx\",\n  \"auth_uri\": \"xxxxxx\",\n  \"token_uri\": \"xxxxxxx\": \"xxxxxxxx\": \"xxxxxxxxx\"\n}\" \n\nAnd call it in the controller in this way \n@session = GoogleDrive::Session.from_service_account_key(ENV['CLIENT_SECRET'])\n\nOr in this way \n@session = GoogleDrive::Session.from_service_account_key(JSON.parse(ENV['CLIENT_SECRET']))\n\nBut neither methods are working. So my question is : \"Is it possible to store JSON file in an ENV variable ?\"\n",
        "all_answers": [
            "\nYes. It is possible to store json file in variable. \nHowever there is one small change needed :\n\\\\\\\"type\\\\\\\": \\\\\\\"service_account\\\\\\\",\n\nDo this for every double quote inside the curly braces of json.\n",
            "\nConvert the JSON object to string and store it in the ENV \nYou can use JSON.dump to convert JSON object to string\nand then in your controller JSON.parse(ENV['CLIENT_SECRET'])\nAlternatively\nyou can create a google_session.rb inside initializers folder\n$google_session = GoogleDrive::Session.from_service_account_key(\n   # config goes here\n)\n\nand in your controller you will have access to $google_session global variable\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "json",
            "ruby-dotenv"
        ]
    },
    {
        "question_id": "6472233",
        "question": "\n\n\n\n\nPossible Duplicates:\nImages in MySQL\nStoring images in MySQL \n\nI'm trying to develop a website where users upload their images as part of registration. I want it that for each image, there should be a thumb created with PHP (which is not that difficult). I want to save the thumbs (since they are very small) in the database and I use MySQL. (I don't want to save the thumbs as physical files on the drive.)\nDoes MySQL allow saving and retrieving image data and how do I go about it? If it doesn't support image data, is there any free database that does? I will be happy if a link can be provided.\nThanks.\n",
        "all_answers": [
            "\nYou can store images in MySQL as blobs. However, this is problematic for a couple of reasons:\n\nThe images can be harder to manipulate: you must first retrieve them from the database before bulk operations can be performed.\nExcept in very rare cases where the entire database is stored in RAM, MySQL databases are ultimately stored on disk. This means that your DB images are converted to blobs, inserted into a database, and then stored on disk; you can save a lot of overhead by simply storing them on disk.\n\nInstead, consider updating your table to add an image_path field. For example:\nALTER TABLE `your_table`\nADD COLUMN `image_path` varchar(1024)\n\nThen store your images on disk, and update the table with the image path. When you need to use the images, retrieve them from disk using the path specified. \nAn advantageous side-effect of this approach is that the images do not necessarily be stored on disk; you could just as easily store a URL instead of an image path, and retrieve images from any internet-connected location.\n",
            "\nYes, you can store images in the database, but it's not advisable in my opinion, and it's not general practice. \nA general practice is to store images in directories on the file system and store references to the images in the database. e.g. path to the image,the image name, etc.. Or alternatively, you may even store images on a content delivery network (CDN) or numerous hosts across some great expanse of physical territory, and store references to access those resources in the database.\nImages can get quite large, greater than 1MB. And so storing images in a database can potentially put unnecessary load on your database and the network between your database and your web server if they're on different hosts. \nI've worked at startups, mid-size companies and large technology companies with 400K+ employees. In my 13 years of professional experience, I've never seen anyone store images in a database. I say this to support the statement it is an uncommon practice.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "mysql",
            "image"
        ]
    },
    {
        "question_id": "2828059",
        "question": "\nHow do I sort a NumPy array by its nth column?\nFor example, given:\na = array([[9, 2, 3],\n           [4, 5, 6],\n           [7, 0, 5]])\n\nI want to sort the rows of a by the second column to obtain:\narray([[7, 0, 5],\n       [9, 2, 3],\n       [4, 5, 6]])\n\n",
        "all_answers": [
            "\n@steve's answer is actually the most elegant way of doing it.\nFor the \"correct\" way see the order keyword argument of numpy.ndarray.sort \nHowever, you'll need to view your array as an array with fields (a structured array).\nThe \"correct\" way is quite ugly if you didn't initially define your array with fields...\nAs a quick example, to sort it and return a copy:\nIn [1]: import numpy as np\n\nIn [2]: a = np.array([[1,2,3],[4,5,6],[0,0,1]])\n\nIn [3]: np.sort(a.view('i8,i8,i8'), order=['f1'], axis=0).view(np.int)\nOut[3]: \narray([[0, 0, 1],\n       [1, 2, 3],\n       [4, 5, 6]])\n\nTo sort it in-place:\nIn [6]: a.view('i8,i8,i8').sort(order=['f1'], axis=0) #<-- returns None\n\nIn [7]: a\nOut[7]: \narray([[0, 0, 1],\n       [1, 2, 3],\n       [4, 5, 6]])\n\n@Steve's really is the most elegant way to do it, as far as I know... \nThe only advantage to this method is that the \"order\" argument is a list of the fields to order the search by. For example, you can sort by the second column, then the third column, then the first column by supplying order=['f1','f2','f0'].\n",
            "\nA key can be a function that returns a tuple:\ns = sorted(s, key = lambda x: (x[1], x[2]))\n\nOr you can achieve the same using itemgetter (which is faster and avoids a Python function call):\nimport operator\ns = sorted(s, key = operator.itemgetter(1, 2))\n\nAnd notice that here you can use sort instead of using sorted and then reassigning:\ns.sort(key = operator.itemgetter(1, 2))\n\n",
            "\nTo sort by the second column of a:\na[a[:, 1].argsort()]\n\n",
            "\nI'm not sure if this is the most pythonic method ...\nI had a list of tuples that needed sorting 1st by descending integer values and 2nd alphabetically. This required reversing the integer sort but not the alphabetical sort. Here was my solution: (on the fly in an exam btw, I was not even aware you could 'nest' sorted functions)\na = [('Al', 2),('Bill', 1),('Carol', 2), ('Abel', 3), ('Zeke', 2), ('Chris', 1)]  \nb = sorted(sorted(a, key = lambda x : x[0]), key = lambda x : x[1], reverse = True)  \nprint(b)  \n[('Abel', 3), ('Al', 2), ('Carol', 2), ('Zeke', 2), ('Bill', 1), ('Chris', 1)]\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "arrays",
            "sorting",
            "numpy",
            "scipy"
        ]
    },
    {
        "question_id": "97694",
        "question": "\nI've been somewhat spoiled using Eclipse and java.  I started using vim to do C coding in a linux environment, is there a way to have vim automatically do the proper spacing for blocks?  \nSo after typing a { the next line will have 2 spaces indented in, and a return on that line will keep it at the same indentation, and a } will shift back 2 spaces?\n",
        "all_answers": [
            "\nSetting unused pointers to NULL is a defensive style, protecting against dangling pointer bugs. If a dangling pointer is accessed after it is freed, you may read or overwrite random memory. If a null pointer is accessed, you get an immediate crash on most systems, telling you right away what the error is.\nFor local variables, it may be a little bit pointless if it is \"obvious\" that the pointer isn't accessed anymore after being freed, so this style is more appropriate for member data and global variables. Even for local variables, it may be a good approach if the function continues after the memory is released.\nTo complete the style, you should also initialize pointers to NULL before they get assigned a true pointer value.\n",
            "\nThese two commands should do it:\n:set autoindent\n:set cindent\n\nFor bonus points put them in a file named .vimrc located in your home directory on linux\n",
            "\nMost of the responses have focused on preventing a double free, but setting the pointer to NULL has another benefit.  Once you free a pointer, that memory is available to be reallocated by another call to malloc.  If you still have the original pointer around you might end up with a bug where you attempt to use the pointer after free and corrupt some other variable, and then your program enters an unknown state and all kinds of bad things can happen (crash if you're lucky, data corruption if you're unlucky).  If you had set the pointer to NULL after free, any attempt to read/write through that pointer later would result in a segfault, which is generally preferable to random memory corruption.\nFor both reasons, it can be a good idea to set the pointer to NULL after free().  It's not always necessary, though.  For example, if the pointer variable goes out of scope immediately after free(), there's not much reason to set it to NULL.\n",
            "\nTry:\nset sw=2\nset ts=2\nset smartindent\n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "vim",
            "coding-style",
            "vi"
        ]
    },
    {
        "question_id": "24644656",
        "question": "\nI want to print the whole dataframe, but I don't want to print the index\nBesides, one column is datetime type, I just want to print time, not date.\nThe dataframe looks like:\n   User ID           Enter Time   Activity Number\n0      123  2014-07-08 00:09:00              1411\n1      123  2014-07-08 00:18:00               893\n2      123  2014-07-08 00:49:00              1041\n\nI want it print as\nUser ID   Enter Time   Activity Number\n123         00:09:00              1411\n123         00:18:00               893\n123         00:49:00              1041\n\n",
        "all_answers": [
            "\nprint(df.to_string(index=False))\n\n",
            "\nI'm not entirely sure what you want, and your last line of code does not help either, but anyway:\n\"Chained\" filtering is done by \"chaining\" the criteria in the boolean index.\nIn [96]: df\nOut[96]:\n   A  B  C  D\na  1  4  9  1\nb  4  5  0  2\nc  5  5  1  0\nd  1  3  9  6\n\nIn [99]: df[(df.A == 1) & (df.D == 6)]\nOut[99]:\n   A  B  C  D\nd  1  3  9  6\n\nIf you want to chain methods, you can add your own mask method and use that one.\nIn [90]: def mask(df, key, value):\n   ....:     return df[df[key] == value]\n   ....:\n\nIn [92]: pandas.DataFrame.mask = mask\n\nIn [93]: df = pandas.DataFrame(np.random.randint(0, 10, (4,4)), index=list('abcd'), columns=list('ABCD'))\n\nIn [95]: df.ix['d','A'] = df.ix['a', 'A']\n\nIn [96]: df\nOut[96]:\n   A  B  C  D\na  1  4  9  1\nb  4  5  0  2\nc  5  5  1  0\nd  1  3  9  6\n\nIn [97]: df.mask('A', 1)\nOut[97]:\n   A  B  C  D\na  1  4  9  1\nd  1  3  9  6\n\nIn [98]: df.mask('A', 1).mask('D', 6)\nOut[98]:\n   A  B  C  D\nd  1  3  9  6\n\n",
            "\nprint(df.to_csv(sep='\\t', index=False))\n\nOr possibly:\nprint(df.to_csv(columns=['A', 'B', 'C'], sep='\\t', index=False))\n\n",
            "\nFilters can be chained using a Pandas query:\ndf = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\ndf_filtered = df.query('a > 0').query('0 < b < 2')\n\nFilters can also be combined in a single query:\ndf_filtered = df.query('a > 0 and 0 < b < 2')\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "datetime",
            "pandas",
            "dataframe"
        ]
    },
    {
        "question_id": "18473011",
        "question": "\nI am using the Retrofit library for my REST calls. Most of what I have done has been smooth as butter but for some reason I am having issues converting JSON timestamp strings into java.util.Date objects. The JSON that is coming in looks like this. \n{\n    \"date\": \"2013-07-16\",\n    \"created_at\": \"2013-07-16T22:52:36Z\",\n} \n\nHow can I tell Retrofit or Gson to convert these strings into java.util.Date objects?\n",
        "all_answers": [
            "\nGson can handle only one datetime format (those specified in builder) plus the iso8601 if parsing with custom format is not possible. So, a solution could be to write your custom deserializer. To solve your problem I defined:\npackage stackoverflow.questions.q18473011;\n\nimport java.util.Date;\n\npublic class Foo {\n\n    Date date;\n    Date created_at;\n\n    public Foo(Date date, Date created_at){\n       this.date = date;\n       this.created_at = created_at;\n    }\n\n    @Override\n    public String toString() {\n       return \"Foo [date=\" + date + \", created_at=\" + created_at + \"]\";\n    }\n\n}\n\nwith this deserializer:\npackage stackoverflow.questions.q18473011;\n\nimport java.lang.reflect.Type;\nimport java.text.*;\nimport java.util.Date;\n\nimport com.google.gson.*;\n\npublic class FooDeserializer implements JsonDeserializer<Foo> {\n\n     public Foo deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context) throws JsonParseException {\n\n        String a = json.getAsJsonObject().get(\"date\").getAsString();\n        String b = json.getAsJsonObject().get(\"created_at\").getAsString();\n\n        SimpleDateFormat sdfDate = new SimpleDateFormat(\"yyyy-MM-dd\");\n        SimpleDateFormat sdfDateWithTime = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss'Z'\");\n\n        Date date, created;\n        try {\n           date = sdfDate.parse(a);\n           created = sdfDateWithTime.parse(b);\n        } catch (ParseException e) {\n           throw new RuntimeException(e);\n        }\n\n        return new Foo(date, created);\n    }\n\n}\n\nFinal step is to create a Gson instance with right adapter:\npackage stackoverflow.questions.q18473011;\n\nimport com.google.gson.*;\n\npublic class Question {\n\n    /**\n     * @param args\n     */\n    public static void main(String[] args) {\n      String s = \"{ \\\"date\\\": \\\"2013-07-16\\\",    \\\"created_at\\\": \\\"2013-07-16T22:52:36Z\\\"}\";\n\n\n      GsonBuilder builder = new GsonBuilder();\n      builder.registerTypeAdapter(Foo.class, new FooDeserializer());\n\n      Gson gson = builder.create();\n      Foo myObject = gson.fromJson(s, Foo.class);\n\n      System.out.println(\"Result: \"+myObject);\n    }\n\n}\n\nMy result:\nResult: Foo [date=Tue Jul 16 00:00:00 CEST 2013, created_at=Tue Jul 16 22:52:36 CEST 2013]\n\n",
            "\nGson gson = new GsonBuilder()\n    .setDateFormat(\"yyyy-MM-dd'T'HH:mm:ss\")\n    .create();\n\nRestAdapter restAdapter = new RestAdapter.Builder()\n    .setEndpoint(API_BASE_URL)\n    .setConverter(new GsonConverter.create(gson))\n    .build();\n\nOr the Kotlin equivalent:\nval gson = GsonBuilder().setDateFormat(\"yyyy-MM-dd'T'HH:mm:ss\").create()\nRestAdapter restAdapter = Retrofit.Builder()\n    .baseUrl(API_BASE_URL)\n    .addConverterFactory(GsonConverterFactory.create(gson))\n    .build()\n    .create(T::class.java)\n\nYou can set your customized Gson parser to retrofit. More here: Retrofit Website\nLook at Ondreju's response to see how to implement this in retrofit 2.\n"
        ],
        "answer": "A2",
        "tags": [
            "java",
            "android",
            "json",
            "gson",
            "retrofit"
        ]
    },
    {
        "question_id": "18128863",
        "question": "\nI'm wondering if we should be tracking node_modules in our repo or doing an npm install when checking out the code?\n",
        "all_answers": [
            "\nThe answer is not as easy as Alberto Zaccagni suggests. If you develop applications (especially enterprise applications), including node_modules in your git repo is a viable choice and which alternative you choose depends on your project.\nBecause he argued very well against node_modules I will concentrate on arguments for them.\nImagine that you have just finished enterprise app and you will have to support it for 3-5 years. You definitely don't want to depend on someone's npm module which can tomorrow disappear and you can't update your app anymore.\nOr you have your private modules which are not accessible from the internet and you can't build your app on the internet. Or maybe you don't want to depend on your final build on npm service for some reason.\nYou can find pros and cons in this Addy Osmani article (although it is about Bower, it is almost the same situation). And I will end with a quote from Bower homepage and Addy's article:\n\n“If you aren’t authoring a package that is intended to be consumed by others (e.g., you’re building a web app), you should always check installed packages into source control.”\n\n",
            "\nModules details are stored in packages.json, that is enough. There's no need to checkin node_modules.\nPeople used to store node_modules in version control to lock dependencies of modules, but with npm shrinkwrap that's not needed anymore.\nAnother justification for this point, as @ChrisCM wrote in the comment:\n\nAlso worth noting, any modules that involve native extensions will not work architecture to architecture, and need to be rebuilt. Providing concrete justification for NOT including them in the repo.\n\n"
        ],
        "answer": "A1",
        "tags": [
            "git",
            "node.js",
            "version-control",
            "npm"
        ]
    },
    {
        "question_id": "27390656",
        "question": "\nI am making url calls thru an API that I created using swift as follows:\nclass API {\n\n  let apiEndPoint = \"endpoint\"\n  let apiUrl:String!\n  let consumerKey:String!\n  let consumerSecret:String!\n\n  var returnData = [:]\n\n  init(){\n    self.apiUrl = \"https://myurl.com/\"\n    self.consumerKey = \"my consumer key\"\n    self.consumerSecret = \"my consumer secret\"\n  }\n\n  func getOrders() -> NSDictionary{\n    return makeCall(\"orders\")\n  }\n\n  func makeCall(section:String) -> NSDictionary{\n\n    let params = [\"consumer_key\":\"key\", \"consumer_secret\":\"secret\"]\n\n    Alamofire.request(.GET, \"\\(self.apiUrl)/\\(self.apiEndPoint + section)\", parameters: params)\n        .authenticate(user: self.consumerKey, password: self.consumerSecret)\n        .responseJSON { (request, response, data, error) -> Void in\n            println(\"error \\(request)\")\n            self.returnData = data! as NSDictionary\n    }\n    return self.returnData\n  }\n\n}\n\nI call this API in my UITableViewController to populate the table with SwiftyJSON library. However my returnData from the API is always empty. There is no problem with Alomofire calls as I can successfully retrieve value. My problem is how I am supposed to carry this data over to my table view controller? \nvar api = API()\napi.getOrders()\nprintln(api.returnData) // returnData is empty\n\n",
        "all_answers": [
            "\nAs mattt points out, Alamofire is returning data asynchronously via a “completion handler” pattern, so you must do the same. You cannot just return the value immediately, but you instead want to change your method to not return anything, but instead use a completion handler closure pattern.\nNowadays, that might look like:\nfunc getOrders(completionHandler: @escaping (Result<[String: Any]>) -> Void) {\n    performRequest(\"orders\", completion: completionHandler)\n}\n\nfunc performRequest(_ section: String, completion: @escaping (Result<[String: Any]>) -> Void) {\n    let url = baseURL.appendingPathComponent(section)\n    let params = [\"consumer_key\": \"key\", \"consumer_secret\": \"secret\"]\n\n    Alamofire.request(url, parameters: params)\n        .authenticate(user: consumerKey, password: consumerSecret)\n        .responseJSON { response in\n            switch response.result {\n            case .success(let value as [String: Any]):\n                completion(.success(value))\n\n            case .failure(let error):\n                completion(.failure(error))\n\n            default:\n                fatalError(\"received non-dictionary JSON response\")\n            }\n    }\n}\n\nThen, when you want to call it, you use this completion closure parameter (in trailing closure, if you want):\napi.getOrders { result in\n    switch result {\n    case .failure(let error):\n        print(error)\n\n    case .success(let value):\n        // use `value` here\n    }\n}\n\n// but don't try to use the `error` or `value`, as the above closure\n// has not yet been called\n//\n\n",
            "\nFrom the Alamofire README (emphasis added):\n\nNetworking in Alamofire is done asynchronously. Asynchronous programming may be a source of frustration to programmers unfamiliar with the concept, but there are very good reasons for doing it this way.\nRather than blocking execution to wait for a response from the server, a callback is specified to handle the response once it's received. The result of a request is only available inside the scope of a response handler. Any execution contingent on the response or data received from the server must be done within a handler.\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "swift",
            "alamofire"
        ]
    },
    {
        "question_id": "4308989",
        "question": "\nSomething I've been wondering for a while whilst doing CSS design.\nAre decimal places in CSS widths respected? Or are they rounded?\n.percentage {\n  width: 49.5%;\n}\n\nor\n.pixel {\n  width: 122.5px;\n}\n\n",
        "all_answers": [
            "\nThe width will be rounded to an integer number of pixels.\nI don't know if every browser will round it the same way though. They all seem to have a different strategy when rounding sub-pixel percentages. If you're interested in the details of sub-pixel rounding in different browsers, there's an excellent article on ElastiCSS.\nedit: I tested @Skilldrick's demo in some browsers for the sake of curiosity. When using fractional pixel values (not percentages, they work as suggested in the article I linked) IE9p7 and FF4b7 seem to round to the nearest pixel, while Opera 11b, Chrome 9.0.587.0 and Safari 5.0.3 truncate the decimal places. Not that I hoped that they had something in common after all...\n",
            "\nIf it's a percentage width, then yes, it is respected:\n\n\n#outer {\n    width: 200px;\n}\n\n#first {\n    width: 50%;\n    height: 20px;\n    background-color: red;\n}\n\n#second {\n    width: 50.5%;\n    height: 20px;\n    background-color:green;\n}\n\n#third {\n    width: 51%;\n    height: 20px;\n    background-color:blue;\n}\n<div id=\"outer\">\n    <div id=\"first\">&nbsp;</div>\n    <div id=\"second\">&nbsp;</div>\n    <div id=\"third\">&nbsp;</div>\n</div>\n\n\n\nAs Martin pointed out, things break down when you get to fractional pixels, but if your percentage values yield integer pixel value (e.g. 50.5% of 200px in the example) you'll get sensible, expected behaviour.\nEdit: I've updated the example to show what happens to fractional pixels (in Chrome the values are truncated, so 50, 50.5 and 50.6 all show the same width.)\n\n\n#percentage {\n    width: 200px;\n    color: white;\n}\n\n#percentage .first {\n    width: 50%;\n    height: 20px;\n    background-color: red;\n}\n\n#percentage .second {\n    width: 50.5%;\n    height: 20px;\n    background-color:green;\n}\n\n#percentage .third {\n    width: 51%;\n    height: 20px;\n    background-color:blue;\n}\n\n#pixels {\n    color: white;\n}\n\n#pixels .first {\n    width: 50px;\n    height: 20px;\n    background-color: red;\n}\n\n#pixels .second {\n    width: 50.5px;\n    height: 20px;\n    background-color:green;\n}\n\n#pixels .third {\n    width: 50.6px;\n    height: 20px;\n    background-color:blue;\n}\n\n#pixels .fourth {\n    width: 51px;\n    height: 20px;\n    background-color:red;\n}\n<div id=\"percentage\">\n    <div class=\"first\">50%=100px</div>\n    <div class=\"second\">50.5%=101px</div>\n    <div class=\"third\">51%=102px</div>\n</div>\n<br />\n<div id=\"pixels\">\n    <div class=\"first\">50px</div>\n    <div class=\"second\">50.5px</div>\n    <div class=\"third\">50.6px</div>\n    <div class=\"fourth\">51px</div>\n</div>\n\n\n\n"
        ],
        "answer": "A2",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "1156601",
        "question": "\nWhat are you using to validate users' email addresses, and why?\nI had been using validates_email_veracity_of which actually queries the MX servers. But that is full of fail for various reasons, mostly related to network traffic and reliability. \nI looked around and I couldn't find anything obvious that a lot of people are using to perform a sanity check on an email address. Is there a maintained, reasonably accurate plugin or gem for this?\nP.S.: Please don't tell me to send an email with a link to see if the email works. I'm developing a \"send to a friend\" feature, so this isn't practical.\n",
        "all_answers": [
            "\nI currently use this solution, placed in an initializer:\nActionView::Base.field_error_proc = Proc.new do |html_tag, instance|\n  class_attr_index = html_tag.index 'class=\"'\n\n  if class_attr_index\n    html_tag.insert class_attr_index+7, 'error '\n  else\n    html_tag.insert html_tag.index('>'), ' class=\"error\"'\n  end\nend\n\nThis allows me to merely add a class name to the appropriate tag, without creating additional elements.\n",
            "\nWith Rails 3.0 you can use a email validation without regexp using the Mail gem.\nHere is my implementation (packaged as a gem).\n",
            "\nThere are basically 3 most common options:\n\nRegexp (there is no works-for-all e-mail address regexp, so roll your own)\nMX query (that is what you use)\nGenerating an activation token and mailing it (restful_authentication way)\n\nIf you don't want to use both validates_email_veracity_of and token generation, I'd go with old school regexp checking.\n",
            "\nThe visual difference you are seeing is happening because the div element is a block element. Add this style to your CSS file to make it behave like an inline element:\n.field_with_errors { display: inline; }\n\n",
            "\nDon't make this harder than it needs to be.  Your feature is non-critical; validation's just a basic sanity step to catch typos.  I would do it with a simple regex, and not waste the CPU cycles on anything too complicated:\n/\\A[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]+\\z/\n\nThat was adapted from http://www.regular-expressions.info/email.html -- which you should read if you really want to know all the tradeoffs.  If you want a more correct and much more complicated fully RFC822-compliant regex, that's on that page too.  But the thing is this: you don't have to get it totally right. \nIf the address passes validation, you're going to send an email.  If the email fails, you're going to get an error message.  At which point you can tell the user \"Sorry, your friend didn't receive that, would you like to try again?\" or flag it for manual review, or just ignore it, or whatever.\nThese are the same options you'd have to deal with if the address did pass validation.  Because even if your validation is perfect and you acquire absolute proof that the address exists, sending could still fail.\nThe cost of a false positive on validation is low.  The benefit of better validation is also low.  Validate generously, and worry about errors when they happen.\n",
            "\nYou should override ActionView::Base.field_error_proc. It's currently defined as this within ActionView::Base:\n @@field_error_proc = Proc.new{ |html_tag, instance| \n   \"<div class=\\\"field_with_errors\\\">#{html_tag}</div>\".html_safe\n }\n\nYou can override it by putting this in your application's class inside config/application.rb:\nconfig.action_view.field_error_proc = Proc.new { |html_tag, instance| \n  html_tag\n}\n\nRestart rails server for this change to take effect.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "validation",
            "email"
        ]
    },
    {
        "question_id": "242841",
        "question": "\nDo you think there is a big difference in for...in and for loops? What kind of \"for\" do you prefer to use and why?\nLet's say we have an array of associative arrays:\nvar myArray = [{'key': 'value'}, {'key': 'value1'}];\n\nSo we can iterate:\nfor (var i = 0; i < myArray.length; i++)\n\nAnd:\nfor (var i in myArray)\n\nI don't see a big difference. Are there any performance issues?\n",
        "all_answers": [
            "\nI'd use the different methods based on how I wanted to reference the items.\nUse foreach if you just want the current item.\nUse for if you need an indexer to do relative comparisons. (I.e. how does this compare to the previous/next item?)\nI have never noticed a performance difference. I'd wait until having a performance issue before worrying about it.\n",
            "\nWith for (var i in myArray) you can loop over objects too, i will contain the key name and you can access the property via myArray[i]. Additionaly, any methods you will have added to the object will be included in the loop, too, i.e., if you use any external framework like jQuery or prototype, or if you add methods to object prototypes directly, at one point i will point to those methods.\n",
            "\nThe choice should be based on the which idiom is best understood.\nAn array is iterated using:\nfor (var i = 0; i < a.length; i++)\n   //do stuff with a[i]\n\nAn object being used as an associative array is iterated using:\nfor (var key in o)\n  //do stuff with o[key]\n\nUnless you have earth shattering reasons, stick to the established pattern of usage.\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript"
        ]
    },
    {
        "question_id": "5113847",
        "question": "\nHere's my json:\n{\"d\":{\"key1\":\"value1\",\n      \"key2\":\"value2\"}}\n\nIs there any way of accessing the keys and values (in javascript) in this array without knowing what the keys are?\nThe reason my json is structured like this is that the webmethod that I'm calling via jquery is returning a dictionary. If it's impossible to work with the above, what do I need to change about the way I'm returning the data?\nHere's an outline of my webmethod:\n<WebMethod()> _\nPublic Function Foo(ByVal Input As String) As Dictionary(Of String, String)\n    Dim Results As New Dictionary(Of String, String)\n\n    'code that does stuff\n\n    Results.Add(key,value)\n    Return Results\nEnd Function\n\n",
        "all_answers": [
            "\nYou can use the for..in construct to iterate through arbitrary properties of your object:\nfor (var key in obj.d) {\n    console.log(\"Key: \" + key);\n    console.log(\"Value: \" + obj.d[key]);\n}\n\n",
            "\nThat is an object, not an array. So you would do:\nvar json = { cool: 34.33, alsocool: 45454 };\njson.supercool = 3.14159;\nconsole.dir(json);\n\n",
            "\nIs this what you're looking for?\nvar data;\nfor (var key in data) {\n   var value = data[key];\n   alert(key + \", \" + value);\n}\n\n",
            "\nvar array = new Array(); // or the shortcut: = []\narray.push ( {\"cool\":\"34.33\",\"also cool\":\"45454\"} );\narray.push (  {\"cool\":\"34.39\",\"also cool\":\"45459\"} );\n\nYour variable is a javascript object {} not an array [].\nYou could do:\nvar o = {}; // or the longer form: = new Object()\no.SomeNewProperty = \"something\";\no[\"SomeNewProperty\"] = \"something\";\n\nand\nvar o = { SomeNewProperty: \"something\" };\nvar o2 = { \"SomeNewProperty\": \"something\" };\n\nLater, you add those objects to your array: array.push (o, o2);\nAlso JSON is simply a string representation of a javascript object, thus:\nvar json = '{\"cool\":\"34.33\",\"alsocool\":\"45454\"}'; // is JSON\nvar o = JSON.parse(json); // is a javascript object\njson = JSON.stringify(o); // is JSON again\n\n",
            "\nobject[\"property\"] = value;\n\nor\nobject.property = value;\n\nObject and Array in JavaScript are different in terms of usage.  Its best if you understand them:  \nObject vs Array: JavaScript\n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "asp.net",
            "json",
            "vb.net",
            "for-loop"
        ]
    },
    {
        "question_id": "41278385",
        "question": "\n\n\n\nI would like to ask why my state is not changing when I do an onClick event. I've search a while ago that I need to bind the onClick function in constructor but still the state is not updating.\nHere's my code:\nimport React from 'react';\nimport Grid from 'react-bootstrap/lib/Grid';\nimport Row from 'react-bootstrap/lib/Row';\nimport Col from 'react-bootstrap/lib/Col';\nimport BoardAddModal from 'components/board/BoardAddModal.jsx';    \nimport style from 'styles/boarditem.css';\n\nclass BoardAdd extends React.Component {\n    constructor(props) {\n        super(props);    \n        this.state = {\n            boardAddModalShow: false\n        };    \n        this.openAddBoardModal = this.openAddBoardModal.bind(this);\n    }\n\n    openAddBoardModal() {\n        this.setState({ boardAddModalShow: true }); // set boardAddModalShow to true\n\n        /* After setting a new state it still returns a false value */\n        console.log(this.state.boardAddModalShow);   \n    }\n\n    render() {    \n        return (\n            <Col lg={3}>\n                <a href=\"javascript:;\" \n                   className={style.boardItemAdd} \n                   onClick={this.openAddBoardModal}>\n                    <div className={[style.boardItemContainer,\n                                     style.boardItemGray].join(' ')}>\n                        Create New Board\n                    </div>\n                </a>\n            </Col>\n        );\n    }\n}\n\nexport default BoardAdd\n\n",
        "all_answers": [
            "\nFortunately setState() takes a callback. And this is where we get updated state.\nConsider this example.\nthis.setState({ name: \"myname\" }, () => {                              \n        //callback\n        console.log(this.state.name) // myname\n      });\n\nSo When callback fires, this.state is the updated state.\nYou can get mutated/updated data in callback.\n",
            "\nThis callback is really messy. Just use async await instead:\nasync openAddBoardModal(){\n    await this.setState({ boardAddModalShow: true });\n    console.log(this.state.boardAddModalShow);\n}\n\n",
            "\nYour state needs some time to mutate, and since console.log(this.state.boardAddModalShow) executes before the state mutates, you get the previous value as output. So you need to write the console in the callback to the setState function\nopenAddBoardModal() {\n  this.setState({ boardAddModalShow: true }, function () {\n    console.log(this.state.boardAddModalShow);\n  });\n}\n\nsetState is asynchronous. It means you can’t call it on one line and assume the state has changed on the next.\nAccording to React docs\n\nsetState() does not immediately mutate this.state but creates a\n  pending state transition. Accessing this.state after calling this\n  method can potentially return the existing value. There is no\n  guarantee of synchronous operation of calls to setState and calls may\n  be batched for performance gains.\n\nWhy would they make setState async\n\nThis is because setState alters the state and causes rerendering. This\n  can be an expensive operation and making it synchronous might leave\n  the browser unresponsive. \nThus the setState calls are asynchronous as well as batched for better\n  UI experience and performance.\n\n",
            "\nIf you want to track the state is updating or not then the another way of doing the same thing is \n_stateUpdated(){\n  console.log(this.state. boardAddModalShow);\n}\n\nopenAddBoardModal(){\n  this.setState(\n    {boardAddModalShow: true}, \n    this._stateUpdated.bind(this)\n  );\n}\n\nThis way you can call the method \"_stateUpdated\" every time you try to update the state for debugging.\n",
            "\nSince setSatate is a asynchronous function so you need to console the state as a callback like this. \nopenAddBoardModal(){\n    this.setState({ boardAddModalShow: true }, () => {\n        console.log(this.state.boardAddModalShow)\n    });\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "node.js",
            "reactjs",
            "ecmascript-6"
        ]
    },
    {
        "question_id": "35796195",
        "question": "\nI face a problem which I can't find a solution for. I have a button in navbar which is available on all pages and it is a button responsible for creating some content. \nView that links with button:\ndef createadv(request):\n    uw = getuw(request.user.username)\n    if request.method =='POST':\n    form = AdverForm(request.POST, request.FILES)\n    if form.is_valid():\n        form.instance.user = request.user\n        form.save()\n        return HttpResponseRedirect('/', {'username': request.user.username, 'uw': uw})\n    args = {}\n    args.update(csrf(request))\n    args['username'] = request.user.username\n    args['form'] = AdverForm()\n    args['uw'] = uw\n    return  render_to_response('createadv.html', args)\n\nIf you can see now I always redirect to main page '/' after creating content but I want to go back to the page with which I launched the creation of content.\n",
        "all_answers": [
            "\nYou can add a next field to your form, and set it to request.path. After you processed your form you can redirect to the value of this path.\ntemplate.html\n<form method=\"POST\">\n    {% csrf_token %}\n    {{ form }}\n    <input type=\"hidden\" name=\"next\" value=\"{{ request.path }}\">\n    <button type=\"submit\">Let's Go</button>\n</form>\n\nviews.py\nnext = request.POST.get('next', '/')\nreturn HttpResponseRedirect(next)\n\nThis is roughly what django.contrib.auth does for the login form if I remember well.\nIf you pass through an intermediate page, you can pass the 'next' value via the querystring:\nsome_page.html\n<a href=\"{% url 'your_form_view' %}?next={{ request.path|urlencode }}\">Go to my form!</a>\n\ntemplate.html\n<form method=\"POST\">\n    {% csrf_token %}\n    {{ form }}\n    <input type=\"hidden\" name=\"next\" value=\"{{ request.GET.next }}\">\n    <button type=\"submit\">Let's Go</button>\n</form>\n\n",
            "\nFor python3 you have to decode body first:\nreceived_json_data = json.loads(request.body.decode(\"utf-8\"))\n\n",
            "\nYou're confusing form-encoded and JSON data here. request.POST['foo'] is for form-encoded data. You are posting raw JSON, so you should use request.body.\nreceived_json_data=json.loads(request.body)\n\n",
            "\nYou can use the HTTP_REFERER value:\nreturn HttpResponseRedirect(request.META.get('HTTP_REFERER', '/'))\n\nNote that this will not work if the client disabled sending referrer information (for example, using a private/incognito browser Window). In such a case it will redirect to /.\n"
        ],
        "answer": "A1",
        "tags": [
            "django",
            "redirect",
            "django-views"
        ]
    },
    {
        "question_id": "9567673",
        "question": "\nI want to take a date and work out its week number.\nSo far, I have the following. It is returning 24 when it should be 42.\n<?php\n$ddate = \"2012-10-18\";\n$duedt = explode(\"-\",$ddate);\n$date = mktime(0, 0, 0, $duedt[2], $duedt[1],$duedt[0]);\n$week = (int)date('W', $date);\necho \"Weeknummer: \".$week;\n?>\n\nIs it wrong and a coincidence that the digits are reversed? Or am I nearly there?\n",
        "all_answers": [
            "\n<?php\n$ddate = \"2012-10-18\";\n$duedt = explode(\"-\",$ddate);\n$date = mktime(0, 0, 0, $duedt[1], $duedt[2],$duedt[0]);\n$week = (int)date('W', $date);\necho \"Weeknummer: \".$week;\n?>\n\nYou had the params to mktime wrong - needs to be Month/Day/Year, not Day/Month/Year\n",
            "\nToday, using PHP's DateTime objects is better:\n<?php\n$ddate = \"2012-10-18\";\n$date = new DateTime($ddate);\n$week = $date->format(\"W\");\necho \"Weeknummer: $week\";\n\n\nIt's because in mktime(), it goes like this:\nmktime(hour, minute, second, month, day, year);\n\nHence, your order is wrong.\n<?php\n$ddate = \"2012-10-18\";\n$duedt = explode(\"-\", $ddate);\n$date  = mktime(0, 0, 0, $duedt[1], $duedt[2], $duedt[0]);\n$week  = (int)date('W', $date);\necho \"Weeknummer: \" . $week;\n?>\n\n",
            "\nThe rule is that the first week of a year is the week that contains the first Thursday of the year.\nI personally use Zend_Date for this kind of calculation and to get the week for today is this simple. They have a lot of other useful functions if you work with dates.\n$now = Zend_Date::now();\n$week = $now->get(Zend_Date::WEEK);\n// 10\n\n",
            "\nYour code will work but you need to flip the 4th and the 5th argument.\nI would do it this way\n$date_string = \"2012-10-18\";\n$date_int = strtotime($date_string);\n$date_date = date($date_int);\n$week_number = date('W', $date_date);\necho \"Weeknumber: {$week_number}.\";\n\nAlso, your variable names will be confusing to you after a week of not looking at that code, you should consider reading http://net.tutsplus.com/tutorials/php/why-youre-a-bad-php-programmer/\n",
            "\nUse PHP's date function\nhttp://php.net/manual/en/function.date.php\ndate(\"W\", $yourdate)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "date",
            "mktime"
        ]
    },
    {
        "question_id": "3227180",
        "question": "\nI am using thread locals to store the current user and request objects.  This way I can have easy access to the request from anywhere in the programme (e.g. dynamic forms) without having to pass them around.\nTo implement the thread locals storage in a middleware, I followed a tutorial on the Django site:\nhttps://web.archive.org/web/20091128195932/http://code.djangoproject.com:80/wiki/CookBookThreadlocalsAndUser\nThis document has since been modified to suggest avoiding this technique:\nhttps://web.archive.org/web/20110504132459/http://code.djangoproject.com/wiki/CookBookThreadlocalsAndUser\nFrom the article:\n\nFrom a design point of view, threadlocals are essentially global variables, and are subject to all the usual problems of portability and predictability that global variables usually entail.\nMore importantly, from a security point of view, threadlocals pose a huge risk. By providing an data store that exposes the state of other threads, you provide a way for one thread in your web server to potentially modify the state of another thread in the system. If the threadlocal data contains descriptions of users or other authentication-related data, that data could be used as the basis for an attack that grants access to an unauthorized user, or exposes private details of a user. While it is possible to build a threadlocal system that is safe from this sort of attack, it's a lot easier to be defensive and build a system that isn't subject to any such vulnerability in the first place.\n\nI understand why global variables can be bad, but in this case I'm running my own code on my own server so I can't see what danger two global variables pose.\nCan someone explain the security issue involved?  I have asked many people how they would hack my application if they read this article and know I'm using thread locals, yet no one has been able to tell me.  I am starting to suspect that this is an opinion held by hair-splitting purists who love to pass objects explicitly.\n",
        "all_answers": [
            "\nDespite the fact that you could mix up data from different users, thread locals should be avoided because they hide a dependency. If you pass arguments to a method you see and know what you're passing. But a thread local is something like a hidden channel in the background and you may wonder, that a method doesn't work correctly in some cases.\nThere are some cases where thread locals are a good choice, but they should be used rarely and carefully! \n",
            "\nI disagree entirely.  TLS is extremely useful.  It should be used with care, just as globals should be used with care; but saying it shouldn't be used at all is just as ridiculous as saying globals should never be used.\nFor example, I store the currently active request in TLS.  This makes it accessible from my logging class, without having to pass the request around through every single interface--including many that don't care about Django at all.  It lets me make log entries from anywhere in the code; the logger outputs to a database table, and if a request happens to be active when a log is made, it logs things like the active user and what was being requested.\nIf you don't want one thread to have the capability of modifying another thread's TLS data, then set your TLS up to prohibit this, which probably requires using a native TLS class.  I don't find that argument convincing, though; if an attacker can execute arbitrary Python code as your backend, your system is already fatally compromised--he could monkey patch anything to be run later as a different user, for example.\nObviously, you'll want to clear any TLS at the end of a request; in Django, that means clearing it in process_response and process_exception in a middleware class.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django",
            "thread-local"
        ]
    },
    {
        "question_id": "807878",
        "question": "\nI'm executing an external script, using a <script> inside <head>.\nNow since the script executes before the page has loaded, I can't access the <body>, among other things. I'd like to execute some JavaScript after the document has been \"loaded\" (HTML fully downloaded and in-RAM). Are there any events that I can hook onto when my script executes, that will get triggered on page load?\n",
        "all_answers": [
            "\nYou can just bind all necessary arguments with 'bind':\nroot.addEventListener('click', myPrettyHandler.bind(null, event, arg1, ... ));\n\nIn this way you'll always get the event, arg1, and other stuff passed to myPrettyHandler.\nhttp://passy.svbtle.com/partial-application-in-javascript-using-bind\n",
            "\nnice one line alternative\nelement.addEventListener('dragstart',(evt) => onDragStart(param1, param2, param3, evt));\n\nfunction onDragStart(param1, param2, param3, evt) {\n\n //some action...\n\n}\n\n",
            "\nJust define <body onload=\"aFunction()\"> that will be called after the page has been loaded. Your code in the script is than enclosed by aFunction() { }.\n",
            "\nQuite and old question but I had the same issue today. Cleanest solution I found is to use the concept of currying.\nThe code for that:\nsomeObj.addEventListener('click', some_function(someVar));\n\nvar some_function = function(someVar) {\n    return function curried_func(e) {\n        // do something here\n    }\n}\n\nBy naming the curried function it allows you to call Object.removeEventListener to unregister the eventListener at a later execution time.\n",
            "\nLook at hooking document.onload or in jQuery $(document).load(...).\n",
            "\nThis question is old but I thought I'd offer an alternative using ES5's .bind() - for posterity. :)\nfunction some_func(otherFunc, ev) {\n    // magic happens\n}\nsomeObj.addEventListener(\"click\", some_func.bind(null, some_other_func), false);\n\nJust be aware that you need to set up your listener function with the first param as the argument you're passing into bind (your other function) and the second param is now the event (instead of the first, as it would have been).\n",
            "\nThese solutions will work:\nAs mentioned in comments use defer:\n<script src=\"deferMe.js\" defer></script>\n\nor\n<body onload=\"script();\">\n\nor\ndocument.onload = function ...\n\nor even\nwindow.onload = function ...\n\nNote that the last option is a better way to go since it is unobstrusive and is considered more standard.\n",
            "\nThere is absolutely nothing wrong with the code you've written. Both some_function and someVar should be accessible, in case they were available in the context where anonymous   \nfunction() { some_function(someVar); } \n\nwas created. \nCheck if the alert gives you the value you've been looking for, be sure it will be accessible in the scope of anonymous function (unless you have more code that operates on the same someVar variable next to the call to addEventListener)\nvar someVar; \nsomeVar = some_other_function();\nalert(someVar);\nsomeObj.addEventListener(\"click\", function(){\n    some_function(someVar);\n}, false);\n\n",
            "\nWhy not just get the arguments from the target attribute of the event?\nExample:\n\n\nconst someInput = document.querySelector('button');\r\nsomeInput.addEventListener('click', myFunc, false);\r\nsomeInput.myParam = 'This is my parameter';\r\nfunction myFunc(evt)\r\n{\r\n  window.alert(evt.currentTarget.myParam);\r\n}\n<button class=\"input\">Show parameter</button>\n\n\n\nJavaScript is a prototype-oriented language, remember!\n"
        ],
        "answer": "A7",
        "tags": [
            "javascript",
            "html",
            "dom",
            "dom-events",
            "pageload"
        ]
    },
    {
        "question_id": "17341122",
        "question": "\nWhen I try to change the linked reference of a local JavaScript file to a GitHub raw version my test file stops working. The error is: \n\nRefused to execute script from ... because its MIME type (text/plain) is not executable, and strict MIME type checking is enabled. \n\nIs there a way to disable this behavior or is there a service that allows linking to GitHub raw files?\nWorking code:\n<script src=\"bootstrap-wysiwyg.js\"></script>\n\nNon-working code:\n<script src=\"https://raw.github.com/mindmup/bootstrap-wysiwyg/master/bootstrap-wysiwyg.js\"></script>\n\n",
        "all_answers": [
            "\nThere is a good workaround for this, now, by using jsdelivr.net.\nSteps:\n\nFind your link on GitHub, and click to the \"Raw\" version.\nCopy the URL.\nChange raw.githubusercontent.com to cdn.jsdelivr.net\nInsert /gh/ before your username.\nRemove the branch name.\n(Optional) Insert the version you want to link to, as @version (if you do not do this, you will get the latest - which may cause long-term caching)\n\n\nExamples:\nhttp://raw.githubusercontent.com/<username>/<repo>/<branch>/path/to/file.js\n\nUse this URL to get the latest version:\nhttp://cdn.jsdelivr.net/gh/<username>/<repo>/path/to/file.js\n\nUse this URL to get a specific version or commit hash:\nhttp://cdn.jsdelivr.net/gh/<username>/<repo>@<version or hash>/path/to/file.js\n\nFor production environments, consider targeting a specific tag or commit-hash rather than the branch. Using the latest link may result in long-term caching of the file, causing your link to not be updated as you push new versions. Linking to a file by commit-hash or tag makes the link unique to version.\n\nWhy is this needed?\nIn 2013, GitHub started using X-Content-Type-Options: nosniff, which instructs more modern browsers to enforce strict MIME type checking. It then returns the raw files in a MIME type returned by the server, preventing the browser from using the file as-intended (if the browser honors the setting).\nFor background on this topic, please refer to this discussion thread.\n",
            "\nThis is no longer possible. GitHub has explicitly disabled JavaScript\nhotlinking, and newer versions of browsers respect that setting.\nHeads up: nosniff header support coming to Chrome and Firefox\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "github"
        ]
    },
    {
        "question_id": "409351",
        "question": "\nSome guy called one of my Snipplr submissions \"crap\" because I used if ($_SERVER['REQUEST_METHOD'] == 'POST') instead of if ($_POST)\nChecking the request method seems more correct to me because that's what I really want to do. Is there some operational difference between the two or is this just a code clarity issue?\n",
        "all_answers": [
            "\nThey are both correct. Personally I prefer your approach better for its verbosity but it's really down to personal preference.\nOff hand, running if($_POST) would not throw an error - the $_POST array exists regardless if the request was sent with POST headers. An empty array is cast to false in a boolean check.\n",
            "\nWell, they don't do the same thing, really.\n$_SERVER['REQUEST_METHOD'] contains the request method (surprise).\n$_POST contains any post data.\nIt's possible for a POST request to contain no POST data.\nI check the request method — I actually never thought about testing the $_POST array. I check the required post fields, though. So an empty post request would give the user a lot of error messages - which makes sense to me.\n"
        ],
        "answer": "A2",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "2002940",
        "question": "\nI have an object which has a circular reference to another object. Given the relationship between these objects this is the right design.\nTo Illustrate\nMachine => Customer => Machine\n\nAs is expected I run into an issue when I try to use Json to serialize a machine or customer object. What I am unsure of is how to resolve this issue as I don't want to break the relationship between the Machine and Customer objects. What are the options for resolving this issue?\nEdit\nPresently I am using Json method provided by the Controller base class. So the serialization I am doing is as basic as:\nJson(machineForm);\n\n",
        "all_answers": [
            "\nYou need to decide which is the \"root\" object.  Say the machine is the root, then the customer is a sub-object of machine.  When you serialise machine, it will serialise the customer as a sub-object in the JSON, and when the customer is serialised, it will NOT serialise it's back-reference to the machine.  When your code deserialises the machine, it will deserialise the machine's customer sub-object and reinstate the back-reference from the customer to the machine.\nMost serialisation libraries provide some kind of hook to modify how deserialisation is performed for each class. You'd need to use that hook to modify deserialisation for the machine class to reinstate the backreference in the machine's customer.  Exactly what that hook is depends on the JSON library you are using.\n",
            "\nUpdate:\nDo not try to use NonSerializedAttribute, as the JavaScriptSerializer apparently ignores it.\nInstead, use the ScriptIgnoreAttribute in System.Web.Script.Serialization.\npublic class Machine\n{\n    public string Customer { get; set; }\n\n    // Other members\n    // ...\n}\n\npublic class Customer\n{\n    [ScriptIgnore]\n    public Machine Machine { get; set; }    // Parent reference?\n\n    // Other members\n    // ...\n}\n\nThis way, when you toss a Machine into the Json method, it will traverse the relationship from Machine to Customer but will not try to go back from Customer to Machine.\nThe relationship is still there for your code to do as it pleases with, but the JavaScriptSerializer (used by the Json method) will ignore it.\n",
            "\nSince, to my knowledge, you cannot serialize object references, but only copies you could try employing a bit of a dirty hack that goes something like this:\n\nCustomer should serialize its Machine reference as the machine's id\nWhen you deserialize the json code you can then run a simple function on top of it that transforms those id's into proper references.\n\n"
        ],
        "answer": "A2",
        "tags": [
            "asp.net-mvc",
            "json",
            "serialization",
            "circular-reference"
        ]
    },
    {
        "question_id": "16531093",
        "question": "\nHow do I conditionally format a cell so if not blank it is grey?  \nI tried to do 'not equal', but it didn't work.\nI am using Windows Office 2003 with Windows XP at work. I don't see the same feature as below:\n\nWhat I have tried so far:  \n\nEdit: Figured what was wrong. In my production (actual work Excel), they were filled with white color. It wasn't my Excel file, so I was not aware of this before.\n",
        "all_answers": [
            "\nFollow these steps and your problem will be solved ;)\n\nSet your formula to =$B2=1\nSelect the fill color Yellow\nApplies to =$A$2:$A$7\nOnce you click Apply, make sure your formula hasn't changed! (always happens to me)\n\n\n\n",
            "\nYou can use Conditional formatting with the option \"Formula Is\". One possible formula is\n=NOT(ISBLANK($B1))\n\n\nAnother possible formula is\n=$B1<>\"\"\n\n\n",
            "\n\nSelect your range from cell A (or the whole columns by first selecting column A). Make sure that the 'lighter coloured' cell is A1 then go to conditional formatting, new rule:\n\nPut the following formula and the choice of your formatting (notice that the 'lighter coloured' cell comes into play here, because it is being used in the formula):\n=$A1<>$B1\n\n\nThen press OK and that should do it.\n\n\n",
            "\nIn Excel 2003 you should be able to create a formatting rule like:\n=A1<>\"\" and then drag/copy this to other cells as needed.\nIf that doesn't work, try =Len(A1)>0.\nIf there may be spaces in the cell which you will consider blank, then do:\n=Len(Trim(A1))>0\nLet me know if you can't get any of these to work. I have an old machine running XP and Office 2003, I can fire it up to troubleshoot if needed.\n",
            "\nWorksheets(\"Get Address\").Range(\"A33\").Copy _\n       Destination := Worksheets(\"Label\").Range(\"A1\")\n\n",
            "\nYou can loop thru each cell of the range to copy and set each cell's value, comment, etc in the target destination.\nHere's an example.\nSub CopySpecial(p_RangeFrom As String, p_OffsetRow As Integer, p_OffsetColumn As Integer)\n\n    Dim l_Row As Integer\n    Dim l_Column As Integer\n    Dim thisCell As Range\n    Dim l_TargetCell As Range\n\n    l_Row = Range(p_RangeFrom).Row\n    l_Column = Range(p_RangeFrom).Column\n\n    For Each thisCell In Range(p_RangeFrom)\n\n        Set l_TargetCell = Range(Cells(thisCell.Row + p_OffsetRow, thisCell.Column + p_OffsetColumn).Address)\n\n        ' Copy the text\n        l_TargetCell.Value = thisCell.Value\n\n        ' Copy the comment only if we have a comment to copy\n        If Not thisCell.Comment Is Nothing Then\n\n            ' Delete any existing comment in the target cell, if any.\n            ' If you don't to this the .AddComment Method below will fail.\n            If Not l_TargetCell.Comment Is Nothing Then l_TargetCell.Comment.Delete\n            Call l_TargetCell.AddComment(thisCell.Comment.Text)\n\n        End If\n\n        ' Add more items to copy here, such as color, etc.\n\n    Next\n\nEnd Sub\n\nSub TestCall()\n    Call CopySpecial(\"A1:B2\", 3, 3)\nEnd Sub\n\n",
            "\nDoes this work for you:\n\nYou find this dialog on the Home ribbon, under the Styles group, the Conditional Formatting menu, New rule....\n",
            "\nto copy and paste values only then use following\nWorksheets(\"Label\").Range(\"A1\").value = _\n   Worksheets(\"Get Address\").Range(\"A33\").value\n\nthis statement will not use clip board\n"
        ],
        "answer": "A2",
        "tags": [
            "excel",
            "excel-2003",
            "conditional-formatting"
        ]
    },
    {
        "question_id": "13008255",
        "question": "\nHow to run a simple Windows command?\nThis command:\nexec.Command(\"del\", \"c:\\\\aaa.txt\")\n\n.. outputs this message:\n\ndel: executable file not found in %path%\n\nWhat am I doing wrong?\n",
        "all_answers": [
            "\nYou need a Windows cmd to execute your dir command.\nTry this :\ncmd := exec.Command(\"cmd\", \"/C\", \"dir\").Output()\n\n(sorry, no Windows computer to check it right now)\n",
            "\nI got the same error as you.\nBut dystroy is correct: You can't run del or any other command built into cmd because there is no del.exe file (or any other del-executable for that matter).\nI got it to work with:\npackage main\n    \nimport(\n    \"fmt\"\n    \"os/exec\"\n)\n    \nfunc main() {\n    var c *exec.Cmd\n\n    switch runtime.GOOS{\n    case \"windows\":\n        c = exec.Command(\"cmd\", \"/C\", \"del\", \"D:\\\\a.txt\")\n\n    default://Mac & Linux\n        c = exec.Command(\"rm\", \"-f\", \"/d/a.txt\")\n    }\n\n    if err := c.Run(); err != nil { \n        fmt.Println(\"Error: \", err)\n    }\n}\n\n",
            "\nAs others have already said, parameters passed through the command line can be accessed in batch files with the notation %1 to %9. There are also two other tokens that you can use:\n\n%0 is the executable (batch file) name as specified in the command line.\n%* is all parameters specified in the command line -- this is very useful if you want to forward the parameters to another program.\n\nThere are also lots of important techniques to be aware of in addition to simply how to access the parameters.\nChecking if a parameter was passed\nThis is done with constructs like IF \"%~1\"==\"\", which is true if and only if no arguments were passed at all. Note the tilde character which causes any surrounding quotes to be removed from the value of %1; without a tilde you will get unexpected results if that value includes double quotes, including the possibility of syntax errors.\nHandling more than 9 arguments (or just making life easier)\nIf you need to access more than 9 arguments you have to use the command SHIFT. This command shifts the values of all arguments one place, so that %0 takes the value of %1, %1 takes the value of %2, etc. %9 takes the value of the tenth argument (if one is present), which was not available through any variable before calling SHIFT (enter command SHIFT /? for more options).\nSHIFT is also useful when you want to easily process parameters without requiring that they are presented in a specific order. For example, a script may recognize the flags -a and -b in any order. A good way to parse the command line in such cases is\n:parse\nIF \"%~1\"==\"\" GOTO endparse\nIF \"%~1\"==\"-a\" REM do something\nIF \"%~1\"==\"-b\" REM do something else\nSHIFT\nGOTO parse\n:endparse\nREM ready for action!\n\nThis scheme allows you to parse pretty complex command lines without going insane.\nSubstitution of batch parameters\nFor parameters that represent file names the shell provides lots of functionality related to working with files that is not accessible in any other way. This functionality is accessed with constructs that begin with %~.\nFor example, to get the size of the file passed in as an argument use\nECHO %~z1\n\nTo get the path of the directory where the batch file was launched from (very useful!) you can use\nECHO %~dp0\n\nYou can view the full range of these capabilities by typing CALL /? in the command prompt.\n"
        ],
        "answer": "A2",
        "tags": [
            "windows",
            "go",
            "cmd"
        ]
    },
    {
        "question_id": "45469214",
        "question": "\nI'm learning about function overloading in C++ and came across this:\nvoid display(int a)\n{\n    cout << \"int\" << endl;\n}\n\nvoid display(unsigned a)\n{\n    cout << \"unsigned\" << endl;\n}\n\nint main()\n{\n    int i = -2147483648;\n    cout << i << endl; //will display -2147483648\n    display(-2147483648);\n}\n\nFrom what I understood, any value given in the int range (in my case int is 4 byte) will call display(int) and any value outside this range will be ambiguous (since the compiler cannot decide which function to call). It is valid for the complete range of int values except its min value i.e. -2147483648 where compilation fails with the error\n\ncall of overloaded display(long int) is ambiguous\n\nBut taking the same value to an int and printing the value gives 2147483648. I'm literally confused with this behavior.\nWhy is this behavior observed only when the most negative number is passed? (The behavior is the same if a short is used with -32768 - in fact, in any case where the negative number and positive number have the same binary representation)\nCompiler used: g++ (GCC) 4.8.5\n",
        "all_answers": [
            "\nThe expression -2147483648 is actually applying the - operator to the constant 2147483648. On your platform, int can't store 2147483648, it must be represented by a larger type. Therefore, the expression -2147483648 is not deduced to be signed int but a larger signed type, signed long int.\nSince you do not provide an overload for long the compiler is forced to choose between two overloads that are both equally valid. Your compiler should issue a compiler error about ambiguous overloads.\n",
            "\nThis is a very subtle error.  What you are seeing is a consequence of there being no negative integer literals in C++.  If we look at [lex.icon] we get that a integer-literal,\n\ninteger-literal\n          decimal-literal integer-suffixopt\n          [...]\n\ncan be a decimal-literal,\n\ndecimal-literal:\n          nonzero-digit\n          decimal-literal ’ opt digit\n\nwhere digit is [0-9] and nonzero-digit is [1-9] and the suffix par can be one of u, U, l, L, ll, or LL.  Nowhere in here does it include - as being part of the decimal literal.\nIn §2.13.2, we also have:\n\nAn integer literal is a sequence of digits that has no period or exponent part, with optional separating single quotes that are ignored when determining its value. An integer literal may have a prefix that specifies its base and a suffix that specifies its type. The lexically first digit of the sequence of digits is the most significant. A decimal integer literal (base ten) begins with a digit other than 0 and consists of a sequence of decimal digits.\n\n(emphasis mine)\nWhich means the - in -2147483648 is the unary operator -.  That means -2147483648 is actually treated as -1 * (2147483648).  Since 2147483648 is one too many for your int it is promoted to a long int and the ambiguity comes from that not matching.\nIf you want to get the minimum or maximum value for a type in a portable manner you can use:\nstd::numeric_limits<type>::min();  // or max()\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c++",
            "integer",
            "overloading",
            "negative-number",
            "ambiguous-call"
        ]
    },
    {
        "question_id": "217424",
        "question": "\nI have data in a MySQL database. I am sending the user a URL to get their data out as a CSV file.\nI have the e-mailing of the link, MySQL query, etc. covered.\nHow can I, when they click the link, have a pop-up to download a CVS with the record from MySQL? \nI have all the information to get the record already. I just don't see how to have PHP create the CSV file and let them download a file with a .csv extension.\n",
        "all_answers": [
            "\nTo have it send it as a CSV and have it give the file name, use header():\nhttp://us2.php.net/header\nheader('Content-type: text/csv');\nheader('Content-disposition: attachment; filename=\"myfile.csv\"');\n\nAs far as making the CSV itself, you would just loop through the result set, formatting the output and sending it, just like you would any other content.\n",
            "\nYou can try this:\n    header(\"Expires: Tue, 03 Jul 2001 06:00:00 GMT\");\n    header(\"Last-Modified: \" . gmdate(\"D, d M Y H:i:s\") . \" GMT\");\n    header(\"Cache-Control: no-store, no-cache, must-revalidate, max-age=0\");\n    header(\"Cache-Control: post-check=0, pre-check=0\", false);\n    header(\"Pragma: no-cache\");\n    header(\"Connection: close\");\n\nHopefully it will help prevent Cache, if any!\n",
            "\ntry this \n<?php\n\nheader(\"Cache-Control: no-store, no-cache, must-revalidate, max-age=0\");\nheader(\"Cache-Control: post-check=0, pre-check=0\", false);\nheader(\"Pragma: no-cache\");\n?>\n\n",
            "\nTry:\nheader(\"Content-type: text/csv\");\nheader(\"Content-Disposition: attachment; filename=file.csv\");\nheader(\"Pragma: no-cache\");\nheader(\"Expires: 0\");\n\necho \"record1,record2,record3\\n\";\ndie;\n\netc\nEdit: Here's a snippet of code I use to optionally encode CSV fields:\nfunction maybeEncodeCSVField($string) {\n    if(strpos($string, ',') !== false || strpos($string, '\"') !== false || strpos($string, \"\\n\") !== false) {\n        $string = '\"' . str_replace('\"', '\"\"', $string) . '\"';\n    }\n    return $string;\n}\n\n",
            "\nHere, if  you want to control it through HTML: do like below Option 1:\n<meta http-equiv=\"expires\" content=\"Sun, 01 Jan 2014 00:00:00 GMT\"/>\n<meta http-equiv=\"pragma\" content=\"no-cache\" />\n\nAnd if you want to control it through PHP: do it like below Option 2:\nheader('Expires: Sun, 01 Jan 2014 00:00:00 GMT');\nheader('Cache-Control: no-store, no-cache, must-revalidate');\nheader('Cache-Control: post-check=0, pre-check=0', FALSE);\nheader('Pragma: no-cache');\n\nAND Option 2 IS ALWAYS BETTER in order to avoid proxy based caching issue.\n"
        ],
        "answer": "A4",
        "tags": [
            "php",
            "csv",
            "download",
            "http-headers"
        ]
    },
    {
        "question_id": "11657295",
        "question": "\nI found this answer already: Number of commits on branch in git\nbut that assumes that the branch was created from master.\nHow can I count the number of commits along a branch without relying on that assumption?\nIn SVN this is trivial, but for some reason is really difficult to figure out in git.\n",
        "all_answers": [
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nOne way to do it is list the log for your branch and count the lines.\ngit log <branch_name> --oneline | wc -l\n\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nTo count the commits for the branch you are on:\ngit rev-list --count HEAD\n\nfor a branch\ngit rev-list --count <branch-name>\n\nIf you want to count the commits on a branch that are made since you created the branch\ngit rev-list --count HEAD ^<branch-name>\n\nThis will count all commits ever made that are not on the branch-name as well.\nExamples\ngit checkout master\ngit checkout -b test\n<We do 3 commits>\ngit rev-list --count HEAD ^master\n\nResult: 3\nIf your branch comes of a branch called develop:\ngit checkout develop\ngit checkout -b test\n<We do 3 commits>\ngit rev-list --count HEAD ^develop\n\nResult: 3\nIgnoring Merges\nIf you merge another branch into the current branch without fast forward and you do the above, the merge is also counted. This is because for git a merge is a commit.\nIf you don't want to count these commits add --no-merges:\ngit rev-list --no-merges --count HEAD ^develop\n\n",
            "\nHow about git log --pretty=oneline | wc -l\nThat should count all the commits from the perspective of your current branch.\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n"
        ],
        "answer": "A4",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "761804",
        "question": "\nHow do I remove leading and trailing whitespace from a string in Python?\n\" Hello world \" --> \"Hello world\"\n\" Hello world\"  --> \"Hello world\"\n\"Hello world \"  --> \"Hello world\"\n\"Hello world\"   --> \"Hello world\"\n\n",
        "all_answers": [
            "\nYou want strip():\nmyphrases = [\" Hello \", \" Hello\", \"Hello \", \"Bob has a cat\"]\n\nfor phrase in myphrases:\n    print(phrase.strip())\n\n",
            "\nTo remove all whitespace surrounding a string, use .strip(). Examples:\n>>> ' Hello '.strip()\n'Hello'\n>>> ' Hello'.strip()\n'Hello'\n>>> 'Bob has a cat'.strip()\n'Bob has a cat'\n>>> '   Hello   '.strip()  # ALL consecutive spaces at both ends removed\n'Hello'\n\nNote that str.strip() removes all whitespace characters, including tabs and newlines. To remove only spaces, specify the specific character to remove as an argument to strip:\n>>> \"  Hello\\n  \".strip(\" \")\n'Hello\\n'\n\n\nTo remove only one space at most:\ndef strip_one_space(s):\n    if s.endswith(\" \"): s = s[:-1]\n    if s.startswith(\" \"): s = s[1:]\n    return s\n\n>>> strip_one_space(\"   Hello \")\n'  Hello'\n\n",
            "\nJust for a sake of completeness, if you need to find all positions of a character in a string, you can do the following:\ns = 'shak#spea#e'\nc = '#'\nprint([pos for pos, char in enumerate(s) if char == c])\n\nwhich will print: [4, 9]\n",
            "\n>>> s=\"mystring\"\n>>> s.index(\"r\")\n4\n>>> s.find(\"r\")\n4\n\n\"Long winded\" way\n>>> for i,c in enumerate(s):\n...   if \"r\"==c: print i\n...\n4\n\nto get substring, \n>>> s=\"mystring\"\n>>> s[4:10]\n'ring'\n\n",
            "\nThis will remove all leading and trailing whitespace in myString:\nmyString.strip()\n\n",
            "\nJust for completion, in the case I want to find the extension in a file name in order to check it, I need to find the last '.', in this case use rfind:\npath = 'toto.titi.tata..xls'\npath.find('.')\n4\npath.rfind('.')\n15\n\nin my case, I use the following, which works whatever the complete file name is:\nfilename_without_extension = complete_name[:complete_name.rfind('.')]\n\n",
            "\nThere are two string methods for this, find() and index().  The difference between the two is what happens when the search string isn't found.  find() returns -1  and index() raises a ValueError.\nUsing find()\n>>> myString = 'Position of a character'\n>>> myString.find('s')\n2\n>>> myString.find('x')\n-1\n\n\nUsing index()\n>>> myString = 'Position of a character'\n>>> myString.index('s')\n2\n>>> myString.index('x')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: substring not found\n\n\nFrom the Python manual\n\nstring.find(s, sub[, start[, end]])\nReturn the lowest index in s where the substring sub is found such that sub is wholly contained in s[start:end]. Return -1 on failure. Defaults for start and end and interpretation of negative values is the same as for slices.\n\nAnd:\n\nstring.index(s, sub[, start[, end]])\nLike find() but raise ValueError when the substring is not found.\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "string",
            "trim"
        ]
    },
    {
        "question_id": "5064563",
        "question": "\nI am using Git from the command line and am trying to add a line break to the commit message (using git commit -m \"\") without going into Vim.\nIs this possible?\n",
        "all_answers": [
            "\nIn Bash/Zsh you can simply use literal line breaks inside quotes:\ngit commit -m 'Multi-line\ncommit\nmessage'\n\nANSI-C quoting also works in Bash/Zsh:\ngit commit -m $'Multi-line\\ncommit\\nmessage'\nYou can also instruct Git to use an editor of your choice to edit the commit message. From the docs on git-commit:\n\nThe editor used to edit the commit log message will be chosen from the\nGIT_EDITOR environment variable, the core.editor configuration\nvariable, the VISUAL environment variable, or the EDITOR\nenvironment variable (in that order). See git-var for details.\n\nSo to edit your message using nano, for example, you can run:\nexport GIT_EDITOR=nano\ngit commit\n\n",
            "\nCertainly, how it's done depends on your shell. In Bash, you can use single quotes around the message and can just leave the quote open, which will make Bash prompt for another line, until you close the quote. Like this:\ngit commit -m 'Message\n\ngoes\nhere'\n\nAlternatively, you can use a \"here document\" (also known as heredoc):\ngit commit -F- <<EOF\nMessage\n\ngoes\nhere\nEOF\n\n"
        ],
        "answer": "A2",
        "tags": [
            "git",
            "bash",
            "shell"
        ]
    },
    {
        "question_id": "15385087",
        "question": "\nI'm wondering how I can add associations to my models. Suppose, I generate two models\nrails generate model User\nrails generate model Car\n\nNow I want to add an associations so that the models acquire the form\nclass User < ActiveRecord::Base\n  has_many :cars\nend\nclass Car < ActiveRecord::Base\n  belongs_to :user\nend\n\nThe question is: how to apply this modification by migrations in order to obtain cars_users table in the database? I'm planning to use that table in my code. \n",
        "all_answers": [
            "\nEven more shorter call\nActiveRecord::Base.connection.adapter_name == 'MySQL'\n\n",
            "\nGenerate a migration to create the association:\nrails g migration AddUserIdToCars user_id:integer\nrake db:migrate\n\n",
            "\nbelongs_to association expect an association_id column in its corresponding table.  Since cars belongs_to user, the cars table should have a user_id column.  This can be accomplished 2 ways.\nfirst, you can generate the column when you create the model\nrails g model car user_id:references\n\nor just add the user_id after you create the model like Richard Brown's answer.  Be careful that if you use integer instead of references, you'd have to create the index yourself.\nrails g migration add_user_id_to_cars user_id:integer\n\nthen in the generated migration, add\nadd_index :cars, :user_id\n\nUPDATE:\nAs Joseph has mentioned in the comments, the need to add the index manually has already been addressed in the current version of Rails.  I think it was introduced in Rails 4.  You can read more of it in the official Rails guide for migrations.  The gist of it is running the following generator\nbin/rails g migration add_user_to_cars user:references\n\nwill create a migration with a line similar to \nadd_reference :cars, :user, index: true\n\nThis will add a user_id column to the cars table and it will also mark that column to be indexed.\n",
            "\nIn Rails 3, (maybe earlier, but I'm using Rails 3 currently) using ActiveRecord::ConnectionAdapters::MysqlAdapter is a poor way to go about it, as it's only initialized if the database adapter in use is MySQL.  Even if you have the MySQL gem installed, if it's not your connection type, that call wil fail:\nLoading development environment (Rails 3.0.3)\n>> ActiveRecord::Base.connection.instance_of? ActiveRecord::ConnectionAdapters::MysqlAdapter\nNameError: uninitialized constant ActiveRecord::ConnectionAdapters::MysqlAdapter\nfrom (irb):1\n\nSo, I'd recommend stasl's answer and use the adapter_name property of the connection.\n",
            "\nActiveRecord::Base.connection will provide you with everything you ever wanted to know about the database connection established by boot.rb and environment.rb\nActiveRecord::Base.connection returns a lot of information. So you've got to know exactly what you're looking for.\nAs Marcel points out:\nActiveRecord::Base.connection.instance_of? \n  ActiveRecord::ConnectionAdapters::MysqlAdapter \n\nis probably the best method of determining if your database MySQL.\nDespite relying on internal information that could change between ActiveRecord release, I prefer doing it this way:\nActiveRecord::Base.connection.instance_values[\"config\"][:adapter] == \"mysql\"\n\n",
            "\nThere is an adapter_name in AbstractAdapter and that is there since Rails2.\nSo it's easier to use in the migration like this:\nadapter_type = connection.adapter_name.downcase.to_sym\ncase adapter_type\nwhen :mysql, :mysql2\n  # do the MySQL part\nwhen :sqlite\n  # do the SQLite3 part\nwhen :postgresql\n  # etc.\nelse\n  raise NotImplementedError, \"Unknown adapter type '#{adapter_type}'\"\nend\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "migration",
            "associations"
        ]
    },
    {
        "question_id": "11306669",
        "question": "\nDjango templating system provides a few options (filters) for escaping contents in the html, but they are kind of confusing to me as a beginner. Say I'm following a tutorial to make a simple blog, and the blog content needs to be escaped - I trust the content because I am the only one editing it. So the question is should I do it like {{ post.content|autoescape }}, {{ post.content|escape }}, or {{ post.content|safe }} in the html?\nThanks\nEDIT: Which filter should I use to have special characters converted to html entities automatically?\nEDIT 2: I just realized that autoescape is not a valid filter.\n",
        "all_answers": [
            "\nHTML escaping is on by default in Django templates.\nAutoescape is a tag. not a filter:\n{% autoescape on %}\n    {{ post.content }}\n{% endautoescape %}\n\nThe 'escape' filter escapes a string's HTML. Specifically, it makes these replacements:\n\n< is converted to &lt;\n> is converted to &gt;\n' (single quote) is converted to &#39;\n\" (double quote) is converted to &quot;\n& is converted to &amp;\n\nThe 'force_escape' is almost identical to 'escape' except for a few corner cases.\nThe 'safe' filter will mark your content as safe, so it won't be escaped (will be sent to browser as is).\n\nWhich filter should I use to have special characters converted to html entities automatically?\n\nWell, you mean, like converting Ã to &Atilde;? Stick with utf-8 encoding all the way and forget about those.\n",
            "\nYour question shows you are a little confused about what escaping is.\nEscaping is turning non-safe characters - like HTML tags - into escaped versions so that malicious content such as script tags don't ruin your site. Django does this by default on all content rendered in a template from a variable.\nIt seems by your comment that you're the only one editing your content that what you want is to render your variables without the automatic escaping. So, for that, you need to mark it as safe. You can either do this in the template, by either wrapping the whole lot in {% autoescape off %}...{% endautoescape %} tags or via the {{ myvar|safe }} filter on individual variables. Or, you can do it in the view, by calling mark_safe(myvar) on individual variables before passing them to the template.\n",
            "\nTo avoid escaping use \"safe\" (https://docs.djangoproject.com/en/dev/ref/templates/builtins/?from=olddocs#safe):\n\nMarks a string as not requiring further HTML escaping prior to output. When autoescaping is off, this filter has no effect.\n\nTo escape use \"escape\" (https://docs.djangoproject.com/en/dev/ref/templates/builtins/?from=olddocs#escape):\n\nEscapes a string's HTML.\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n"
        ],
        "answer": "A1",
        "tags": [
            "django",
            "django-templates",
            "django-template-filters"
        ]
    },
    {
        "question_id": "11880430",
        "question": "\nI need to print some stuff only when a boolean variable is set to True. So, after looking at this, I tried with a simple example:\n>>> a = 100\n>>> b = True\n>>> print a if b\n  File \"<stdin>\", line 1\n    print a if b\n             ^\nSyntaxError: invalid syntax  \n\nSame thing if I write print a if b==True.\nWhat am I missing here?\n",
        "all_answers": [
            "\nFor your case this works:\na = b or 0\n\nEdit: How does this work?\nIn the question\nb = True\n\nSo evaluating\nb or 0\n\nresults in\nTrue\n\nwhich is assigned to a.\nIf b == False?, b or 0 would evaluate to the second operand 0 which would be assigned to a.\n",
            "\nPython does not have a trailing if statement.\nThere are two kinds of if in Python:\n\nif statement:\nif condition: statement\nif condition:\n    block\n\nif expression (introduced in Python 2.5)\nexpression_if_true if condition else expression_if_false\n\n\nAnd note, that both print a and b = a are statements. Only the a part is an expression. So if you write\nprint a if b else 0\n\nit means\nprint (a if b else 0)\n\nand similarly when you write\nx = a if b else 0\n\nit means\nx = (a if b else 0)\n\nNow what would it print/assign if there was no else clause? The print/assignment is still there.\nAnd note, that if you don't want it to be there, you can always write the regular if statement on a single line, though it's less readable and there is really no reason to avoid the two-line variant.\n",
            "\nThe 'else' statement is mandatory. You can do stuff like this :\n>>> b = True\n>>> a = 1 if b else None\n>>> a\n1\n>>> b = False\n>>> a = 1 if b else None\n>>> a\n>>> \n\nEDIT:\nOr, depending of your needs, you may try:\n>>> if b: print(a)\n\n",
            "\nInline if-else EXPRESSION must always contain else clause, e.g:\na = 1 if b else 0\n\nIf you want to leave your 'a' variable value unchanged - assing old 'a' value (else is still required by syntax demands):\na = 1 if b else a\n\nThis piece of code leaves a unchanged when b turns to be False.\n",
            "\nI think both the fastest and most concise way to do this is to use NumPy's built-in Fancy indexing. If you have an ndarray named arr, you can replace all elements >255 with a value x as follows:\narr[arr > 255] = x\n\nI ran this on my machine with a 500 x 500 random matrix, replacing all values >0.5 with 5, and it took an average of 7.59ms.\nIn [1]: import numpy as np\nIn [2]: A = np.random.rand(500, 500)\nIn [3]: timeit A[A > 0.5] = 5\n100 loops, best of 3: 7.59 ms per loop\n\n",
            "\nYou always need an else in an inline if:\na = 1 if b else 0\n\nBut an easier way to do it would be a = int(b).\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "if-statement",
            "conditional-statements",
            "inline"
        ]
    },
    {
        "question_id": "5893163",
        "question": "\nWhat is the meaning of _ after for in this code?\nif tbh.bag:\n    n = 0\n    for _ in tbh.bag.atom_set():\n        n += 1\n\n",
        "all_answers": [
            "\n_ has 3 main conventional uses in Python:\n\nTo hold the result of the last executed expression in an interactive\ninterpreter session (see docs). This precedent was set by the standard CPython\ninterpreter, and other interpreters have followed suit\n\nFor translation lookup in i18n (see the\ngettext\ndocumentation for example), as in code like\nraise forms.ValidationError(_(\"Please enter a correct username\"))\n\n\nAs a general purpose \"throwaway\" variable name:\n\nTo indicate that part\nof a function result is being deliberately ignored (Conceptually, it is being discarded.), as in code like:\nlabel, has_label, _ = text.partition(':')\n\n\nAs part of a function definition (using either def or lambda), where\nthe signature is fixed (e.g. by a callback or parent class API), but\nthis particular function implementation doesn't need all of the\nparameters, as in code like:\ndef callback(_):\n    return True\n\n[For a long time this answer didn't list this use case, but it came up often enough, as noted here, to be worth listing explicitly.]\n\n\nThis use case can conflict with the translation lookup use case, so it is necessary to avoid using _ as a throwaway variable in any code block that also uses it for i18n translation (many folks prefer a double-underscore, __, as their throwaway variable for exactly this reason).\nLinters often recognize this use case. For example year, month, day = date() will raise a lint warning if day is not used later in the code. The fix, if day is truly not needed, is to write year, month, _ = date(). Same with lambda functions, lambda arg: 1.0 creates a function requiring one argument but not using it, which will be caught by lint. The fix is to write lambda _: 1.0. An unused variable is often hiding a bug/typo (e.g. set day but use dya in the next line).\nThe pattern matching feature added in Python 3.10 elevated this usage from \"convention\" to \"language syntax\" where match statements are concerned: in match cases, _ is a wildcard pattern, and the runtime doesn't even bind a value to the symbol in that case.\nFor other use cases, remember that _ is still a valid variable name, and hence will still keep objects alive. In cases where this is undesirable (e.g. to release memory or external resources) an explicit del name call will both satisfy linters that the name is being used, and promptly clear the reference to the object.\n\n\n",
            "\nIt's just a variable name, and it's conventional in python to use _ for throwaway variables.  It just indicates that the loop variable isn't actually used.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "variables",
            "naming-conventions",
            "metasyntactic-variable"
        ]
    },
    {
        "question_id": "1966591",
        "question": "\nDo Python iterators have a hasnext method?\n",
        "all_answers": [
            "\nThere are several things to keep in mind when using poetry together with docker.\nInstallation\nOfficial way to install poetry is via:\ncurl -sSL https://install.python-poetry.org | python3 -\n\nThis way allows poetry and its dependencies to be isolated from your dependencies. But, in my point of view, it is not a very good thing for two reasons:\n\npoetry version might get an update and it will break your build. In this case you can specify POETRY_VERSION environment variable. Installer will respect it\nI do not like the idea to pipe things from the internet into my containers without any protection from possible file modifications\n\nSo, I use pip install 'poetry==$POETRY_VERSION'. As you can see, I still recommend to pin your version.\nAlso, pin this version in your pyproject.toml as well:\n[build-system]\n# Should be the same as `$POETRY_VERSION`:\nrequires = [\"poetry-core>=1.0.0\"]\nbuild-backend = \"poetry.core.masonry.api\"\n\nIt will protect you from version mismatch between your local and docker environments.\nCaching dependencies\nWe want to cache our requirements and only reinstall them when pyproject.toml or poetry.lock files change. Otherwise builds will be slow. To achieve working cache layer we should put:\nCOPY poetry.lock pyproject.toml /code/\n\nAfter the poetry is installed, but before any other files are added.\nVirtualenv\nThe next thing to keep in mind is virtualenv creation. We do not need it in docker. It is already isolated. So, we use poetry config virtualenvs.create false setting to turn it off.\nDevelopment vs Production\nIf you use the same Dockerfile for both development and production as I do, you will need to install different sets of dependencies based on some environment variable:\npoetry install $(test \"$YOUR_ENV\" == production && echo \"--no-dev\")\n\nThis way $YOUR_ENV will control which dependencies set will be installed: all (default) or production only with --no-dev flag.\nYou may also want to add some more options for better experience:\n\n--no-interaction not to ask any interactive questions\n--no-ansi flag to make your output more log friendly\n\nResult\nYou will end up with something similar to:\nFROM python:3.6.6-alpine3.7\n\nARG YOUR_ENV\n\nENV YOUR_ENV=${YOUR_ENV} \\\n  PYTHONFAULTHANDLER=1 \\\n  PYTHONUNBUFFERED=1 \\\n  PYTHONHASHSEED=random \\\n  PIP_NO_CACHE_DIR=off \\\n  PIP_DISABLE_PIP_VERSION_CHECK=on \\\n  PIP_DEFAULT_TIMEOUT=100 \\\n  POETRY_VERSION=1.0.0\n\n# System deps:\nRUN pip install \"poetry==$POETRY_VERSION\"\n\n# Copy only requirements to cache them in docker layer\nWORKDIR /code\nCOPY poetry.lock pyproject.toml /code/\n\n# Project initialization:\nRUN poetry config virtualenvs.create false \\\n  && poetry install $(test \"$YOUR_ENV\" == production && echo \"--no-dev\") --no-interaction --no-ansi\n\n# Creating folders, and files for a project:\nCOPY . /code\n\nYou can find a fully working real-life example here: wemake-django-template\nUpdate on 2019-12-17\n\nUpdate poetry to 1.0\n\nUpdate on 2022-11-24\n\nUpdate curl command to use modern poetry installation script\n\n",
            "\nI believe python just has next() and according to the doc, it throws an exception is there are no more elements.\nhttp://docs.python.org/library/stdtypes.html#iterator-types\n",
            "\nNo. The most similar concept is most likely a StopIteration exception. \n",
            "\nNo, there is no such method. The end of iteration is indicated by an exception. See the documentation.\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "iterator"
        ]
    },
    {
        "question_id": "1115854",
        "question": "\nAfter git init, I added and committed a few files, made some changes, added and committed.  Set up the git daemon (running under Cygwin on WinXP) and cloned the repository once.\nNow, I get this error with the cloned repository:\n$ git status\nerror: bad index file sha1 signature\nfatal: index file corrupt\n\nIs there any way to fix this, other than getting a new copy of the repository?\n",
        "all_answers": [
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nIf the problem is with the index as the staging area for commits (i.e. .git/index), you can simply remove the index (make a backup copy if you want), and then restore index to version in the last commit:\nOn OSX/Linux/Windows(With Git bash):\nrm -f .git/index\ngit reset\n\nOn Windows (with CMD and not git bash):\ndel .git\\index\ngit reset\n\n(The reset command above is the same as  git reset --mixed HEAD)\nYou can alternatively use lower level plumbing git read-tree instead of git reset.\n\nIf the problem is with index for packfile, you can recover it using git index-pack.\n",
            "\nRemove the last commit before push\ngit reset --soft HEAD~1\n1 means the last commit, if you want to remove two last use 2, and so forth*\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nThis sounds like a bad clone. You could try the following to get (possibly?) more information:\ngit fsck --full\n\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n"
        ],
        "answer": "A4",
        "tags": [
            "git",
            "corruption"
        ]
    },
    {
        "question_id": "11296361",
        "question": "\nIt appears that there is no concept of AUTO_INCREMENT in Oracle, up until and including version 11g.\nHow can I create a column that behaves like auto increment in Oracle 11g?\n",
        "all_answers": [
            "\nHere are three flavors:\n\nnumeric.  Simple increasing numeric value, e.g. 1,2,3,....\nGUID. globally univeral identifier, as a RAW datatype.\nGUID (string).  Same as above, but as a string which might be easier to handle in some languages.\n\nx is the identity column.  Substitute FOO with your table name in each of the examples.\n-- numerical identity, e.g. 1,2,3...\ncreate table FOO (\n    x number primary key\n);\ncreate sequence  FOO_seq;\n\ncreate or replace trigger FOO_trg\nbefore insert on FOO\nfor each row\nbegin\n  select FOO_seq.nextval into :new.x from dual;\nend;\n/\n\n-- GUID identity, e.g. 7CFF0C304187716EE040488AA1F9749A\n-- use the commented out lines if you prefer RAW over VARCHAR2.\ncreate table FOO (\n    x varchar(32) primary key        -- string version\n    -- x raw(32) primary key         -- raw version\n);\n\ncreate or replace trigger FOO_trg\nbefore insert on FOO\nfor each row\nbegin\n  select cast(sys_guid() as varchar2(32)) into :new.x from dual;  -- string version\n  -- select sys_guid() into :new.x from dual;                     -- raw version\nend;\n/\n\nupdate:\nOracle 12c introduces these two variants that don't depend on triggers:\ncreate table mytable(id number default mysequence.nextval);\ncreate table mytable(id number generated as identity);\n\nThe first one uses a sequence in the traditional way; the second manages the value internally.\n",
            "\nThere is no such thing as \"auto_increment\" or \"identity\" columns in Oracle as of Oracle 11g. However, you can model it easily with a sequence and a trigger:\nTable definition:\nCREATE TABLE departments (\n  ID           NUMBER(10)    NOT NULL,\n  DESCRIPTION  VARCHAR2(50)  NOT NULL);\n\nALTER TABLE departments ADD (\n  CONSTRAINT dept_pk PRIMARY KEY (ID));\n\nCREATE SEQUENCE dept_seq START WITH 1;\n\nTrigger definition:\nCREATE OR REPLACE TRIGGER dept_bir \nBEFORE INSERT ON departments \nFOR EACH ROW\n\nBEGIN\n  SELECT dept_seq.NEXTVAL\n  INTO   :new.id\n  FROM   dual;\nEND;\n/\n\nUPDATE:\nIDENTITY column is now available on Oracle 12c:\ncreate table t1 (\n    c1 NUMBER GENERATED by default on null as IDENTITY,\n    c2 VARCHAR2(10)\n    );\n\nor specify starting and increment values, also preventing any insert into the identity column (GENERATED ALWAYS) (again, Oracle 12c+ only)\ncreate table t1 (\n    c1 NUMBER GENERATED ALWAYS as IDENTITY(START with 1 INCREMENT by 1),\n    c2 VARCHAR2(10)\n    );\n\nAlternatively, Oracle 12 also allows to use a sequence as a default value:\nCREATE SEQUENCE dept_seq START WITH 1;\n\nCREATE TABLE departments (\n  ID           NUMBER(10)    DEFAULT dept_seq.nextval NOT NULL,\n  DESCRIPTION  VARCHAR2(50)  NOT NULL);\n\nALTER TABLE departments ADD (\n  CONSTRAINT dept_pk PRIMARY KEY (ID));\n\n",
            "\nAssuming you mean a column like the SQL Server identity column?\nIn Oracle, you use a SEQUENCE to achieve the same functionality.  I'll see if I can find a good link and post it here.\nUpdate: looks like you found it yourself.  Here is the link anyway:\nhttp://www.techonthenet.com/oracle/sequences.php\n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "oracle",
            "auto-increment"
        ]
    },
    {
        "question_id": "6277456",
        "question": "\nI always worked my way around Nokogiri installation issues by following the documentation in the \"Installing Nokogiri\" tutorial.\nBut this time, even after installing all the dependencies, Nokogiri hasn't been installed.  I get the following error: \nlibxml2 is missing.  please visit <http://nokogiri.org/tutorials/installing_nokogiri.html>\n\nI tried installing it by specifying the libxml2 and libxslt directories:\nsudo gem install nokogiri -- --with-xml2-include=/usr/include/libxml2 --with-xml2-lib=/usr/lib --with-xslt-dir=/usr/\n\nbut it returned the same error.\nI followed all the other related Stack Overflow articles and none helped.  Does anyone have a solution?\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nFirst, install the dependencies:\nsudo apt-get install libxslt-dev libxml2-dev\n\nIf you still receive the error, you may be missing a compiler toolchain:\nsudo apt-get install build-essential\n\nYou'll get the \"libxml2 is missing\" error if you're missing a build toolchain (at least I ran into this issue on Debian Lenny).\nThe Nokogiri build test-compiles a libxml2 header file to verify that it is present, however, it doesn't differentiate between \"libxml2 is missing\" and \"a compiler to test libxml2 is missing\".\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nHave you tried installing libxml2? Not from rubygems, but via the standard install process for your operating system.  On Ubuntu/Debian for example:\nsudo apt-get install libxml2\n\nOn any recent version of OS X it should already be installed.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "rubygems"
        ]
    },
    {
        "question_id": "46141705",
        "question": "\nMy register page is showing the form properly with CsrfToken ({{ csrf_field() }}) present in the form).\nForm HTML\n<form class=\"form-horizontal registration-form\" novalidate method=\"POST\" action=\"{{ route('register') }}\">\n        {{ csrf_field() }}\n        ....\n</form>\n\nI am using inbuilt authentication for the users. Have not changed anything except the routes and redirects.\nWhen I submit the form (just after reloading also), it gives that The page has expired due to inactivity. Please refresh and try again. error.\nMy be I am missing a very small thing. But not sure what it is. Any help?\nUpdate\nFound the issue. The session driver was set to array. Changed it to file and the error is gone now.\nBut what is wrong if I use array?\n",
        "all_answers": [
            "\nTry all of them.\ncomposer dump-autoload\nphp artisan optimize\nphp artisan cache:clear\nphp artisan config:clear\nphp artisan route:clear\nphp artisan view:clear\n\n",
            "\nIf you're coming to this answer directly from a search, make sure you have already added the csrf token to your form with {{ csrf_field() }} like the OP.\n\nIf you have your session driver set to file:\nMay have something to do with the storage_path not being writable. This is where it stores session data regarding tokens if you're using file based sessions.  The can be verified with is_writable(config('session.files'))\n\nFor the OP, the session driver was set to array.  Array is for testing only.  Since data is not persisted, it will not be able to compare the token on the next request.\n\nThe array driver is used during testing and prevents the data stored\n  in the session from being persisted.\n\nhttps://laravel.com/docs/5.5/session#configuration\n\nCheck config/session.php\nLastly, an issue I just had, we had a project which has the session domain and secure settings in config/session.php but the development site was not using HTTPS (SSL/TLS).  This caused this generic error since sessions.secure was set to true by default.\n",
            "\nSome information is stored in the cookie which is related to previous versions of laravel in development. So it's conflicting with csrf generated tokens which are generated by another's versions. Just  Clear the cookie and give a try. \n",
            "\nAs mentioned above  if you wish to add as a new element your queried collection you can use:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n        $product = DB::select(DB::raw(' select * from product\n               where product_id = '. $id.';' ));\n\n        $items->push($product);\n        // or \n        // $items->put('products', $product);\n    }\n\nbut if you wish to add new element to each queried element you need to do like:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n           $product = DB::select(DB::raw(' select * from product\n                 where product_id = '. $id.';' ));\n    \n          $item->add_whatever_element_you_want = $product;\n    }\n\nadd_whatever_element_you_want can be whatever you wish that your element is named (like product for example).\n",
            "\nIt looks like you have everything correct according to Laravel docs, but you have a typo\n$item->push($product);\n\nShould be\n$items->push($product);\n\npush method appends an item to the end of the collection:\nI also want to think the actual method you're looking for is put\n$items->put('products', $product);\n\nput method sets the given key and value in the collection\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "laravel",
            "csrf",
            "laravel-5.5"
        ]
    },
    {
        "question_id": "9784118",
        "question": "\nBasically, what I'm trying to do is click on a button that becomes visible when hovering another element (its parent).\nI have tried to use trigger.('mouseover') on the parent of the hidden button, but that doesn't seem to work.\nHere's a code snippet from the spec:\n # label[for ... ] -> the parent element\n page.execute_script(\"$('label[for=\\\"department_#{department.id}\\\"]').trigger(\\\"mouseover\\\")\")     \n # le hidden button\n find(\".actions\").click     \n # some <li> on a list that drops down when clicking the hidden button    \n click_on(\"Edit department\")\n\nAnd the error ... \n Failure/Error: click_on(\"Edit department\")\n Selenium::WebDriver::Error::ElementNotVisibleError:\n Element is not currently visible and so may not be interacted with\n\nI would like to know how can I make the .actions button visible on the page, in order to click it afterwards.\nAny help would be much appreciated.\n",
        "all_answers": [
            "\nAlex described the solution of such problems in his blog: check it out http://aokolish.me/blog/2012/01/22/testing-hover-events-with-capybara\nRSpec.configure do |config|\n  # ...\n  Capybara.javascript_driver = :webkit\nend\n\npage.find('#element').trigger(:mouseover)\n\n",
            "\nUpdate (2013): Matt Connolly has provided a GIST which also works for request and controller specs: http://gist.github.com/4158961\n\nAnother way of doing this if you have many tests to run and don't want to include it everytime (DRYer code):\nCreate a /spec/support/auth_helper.rb file:\nmodule AuthHelper\n  def http_login\n    user = 'username'\n    pw = 'password'\n    request.env['HTTP_AUTHORIZATION'] = ActionController::HttpAuthentication::Basic.encode_credentials(user,pw)\n  end  \nend\n\nIn your test spec file:\ndescribe HomeController do\n  render_views\n\n  # login to http basic auth\n  include AuthHelper\n  before(:each) do\n    http_login\n  end\n\n  describe \"GET 'index'\" do\n    it \"should be successful\" do\n      get 'index'\n      response.should be_success\n    end\n  end\n\nend\n\nCredit here - Archived site\n",
            "\nCapybara provides Element#hover method from version 2.1:\nfind('.some_class').hover\n\nThis method is implemented in Capybara::Selenium::Driver in almost the same way as in @AlexD's answer.\nNote that to use #hover in Selenium it's usually better to turn native events on:\nCapybara.register_driver :selenium do |app|\n  profile = Selenium::WebDriver::Firefox::Profile.new\n  profile.native_events = true\n  Capybara::Selenium::Driver.new(app, :browser => :firefox, profile: profile)\nend\n\n",
            "\nI found a way to simulate \"mouse hover\" using Capybara + the Selenium driver:\nmodule Capybara\n  module Node\n    class Element\n      def hover\n        @session.driver.browser.action.move_to(self.native).perform\n      end\n    end\n  end\nend\n\n",
            "\nSorry I didn't search enough, the solution seems to be the following:\ndescribe \"GET 'index'\" do\n  it \"should be successful\" do\n    @request.env[\"HTTP_AUTHORIZATION\"] = \"Basic \" + Base64::encode64(\"username:password\")\n    get 'index'\n    response.should be_success\n  end\nend\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "rspec",
            "capybara"
        ]
    },
    {
        "question_id": "30795117",
        "question": "\nIn Swift, I see some methods like:\n@objc private func doubleTapGestureRecognized(recognizer: UITapGestureRecognizer)\n\nI was wondering, when to use @objc? I read some documents, but they are saying when you want it to be callable in Objective-C, you should add @objc flag\nHowever, this is a private function in Swift, what does the @obj do?\n",
        "all_answers": [
            "\nprivate mean it visible only in Swift.\nso use @objc to visible in Objective-C.\nIf you have a func to selector a private func in swift, it is required.\n\nThe @objc attribute makes your Swift API available in Objective-C and the Objective-C runtime.\n\nSee:\nhttps://developer.apple.com/library/ios/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html\nhttps://developer.apple.com/library/ios/documentation/Swift/Conceptual/BuildingCocoaApps/InteractingWithObjective-CAPIs.html\n",
            "\n@objc is a class attribute, so you use\n@objc public class MyClass\n\nIt exposes the class' methods to Objective C classes, so you'll only use it if your class contains public functions\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "objective-c",
            "swift",
            "selector",
            "private"
        ]
    },
    {
        "question_id": "31501142",
        "question": "\nThere is question about using exit in C++. The answer discusses that it is not good idea mainly because of RAII, e.g., if exit is called somewhere in code, destructors of objects will not be called, hence, if for example a destructor was meant to write data to file, this will not happen, because the destructor was not called.\nI was interested how is this situation in C. Are similar issues applicable also in C? I thought since in C we don't use constructors/destructors, situation might be different in C. So is it ok to use exit in C? For example I have seen following functions sometimes used in C:\nvoid die(const char *message)\n{\n    if(errno) {\n        perror(message);\n    } else {\n        printf(\"ERROR: %s\\n\", message);\n    }\n\n    exit(1);\n}\n\n",
        "all_answers": [
            "\nYes, it is ok to use exit in C.\nTo ensure all buffers and graceful orderly shutdown, it would be recommended to use this function atexit, more information on this here\nAn example code would be like this:\nvoid cleanup(void){\n   /* example of closing file pointer and free up memory */\n   if (fp) fclose(fp);\n   if (ptr) free(ptr);\n}\n\nint main(int argc, char **argv){\n   /* ... */\n   atexit(cleanup);\n   /* ... */\n   return 0;\n}\n\nNow, whenever exit is called, the function cleanup will get executed, which can house graceful shutdown, clean up of buffers, memory etc.\n",
            "\nYou don't have constructors and destructors but you could have resources (e.g. files, streams, sockets) and it is important to close them correctly. A buffer could not be written synchronously, so exiting from the program without correctly closing the resource first, could lead to corruption.\n",
            "\nRather than abort(), the exit() function in C is considered to be a \"graceful\" exit.\nFrom C11 (N1570) 7.22.4.4/p2 The exit function (emphasis mine):\n\nThe exit function causes normal program termination to occur.\n\nThe Standard also says in 7.22.4.4/p4 that:\n\nNext, all open streams with unwritten buffered data are flushed, all\n  open streams are closed, and all files created by the tmpfile function\n  are removed.\n\nIt is also worth looking at 7.21.3/p5 Files:\n\nIf the main function returns to its original caller, or if the exit\n  function is called, all open files are closed (hence all output\n  streams are flushed) before program termination. Other paths to\n  program termination, such as calling the abort function, need not\n  close all files properly.\n\nHowever, as mentioned in comments below you can't assume that it will cover every other resource, so you may need to resort to atexit() and define callbacks for their release individually. In fact it is exactly what atexit() is intended to do, as it says in 7.22.4.2/p2 The atexit function:\n\nThe atexit function registers the function pointed to by func, to be\n  called without arguments at normal program termination.\n\nNotably, the C standard does not say precisely what should happen to objects of allocated storage duration (i.e. malloc()), thus requiring you be aware of how it is done on particular implementation. For modern, host-oriented OS it is likely that the system will take care of it, but still you might want to handle this by yourself in order to silence memory debuggers such as Valgrind.\n"
        ],
        "answer": "A3",
        "tags": [
            "c"
        ]
    },
    {
        "question_id": "11134144",
        "question": "\nI know a little bit about TextWatcher but that fires on every character you enter. I want a listener that fires whenever the user finishes editing. Is it possible? Also in TextWatcher I get an instance of Editable but I need an instance of EditText. How do I get that?\nEDIT: the second question is more important. Please answer that.\n",
        "all_answers": [
            "\nFirst, you can see if the user finished editing the text if the EditText loses focus or if the user presses the done button (this depends on your implementation and on what fits the best for you). \nSecond, you can't get an EditText instance within the TextWatcher only if you have declared the EditText as an instance object. Even though you shouldn't edit the EditText within the TextWatcher because it is not safe.\nEDIT:\nTo be able to get the EditText instance into your TextWatcher implementation, you should try something like this:\npublic class YourClass extends Activity {\n\n    private EditText yourEditText;\n\n    @Override\n    public void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n\n        setContentView(R.layout.main);\n        yourEditText = (EditText) findViewById(R.id.yourEditTextId);\n\n        yourEditText.addTextChangedListener(new TextWatcher() {\n\n            public void afterTextChanged(Editable s) {\n\n                // you can call or do what you want with your EditText here\n\n                // yourEditText... \n            }\n\n            public void beforeTextChanged(CharSequence s, int start, int count, int after) {}\n\n            public void onTextChanged(CharSequence s, int start, int before, int count) {}\n        });\n    }\n}\n\nNote that the above sample might have some errors but I just wanted to show you an example.\n",
            "\nUse the following layout:\n<FrameLayout\n    android:layout_width=\"fill_parent\"\n    android:layout_height=\"wrap_content\"\n    android:layout_marginTop=\"9dp\"\n    android:padding=\"5dp\">\n\n    <EditText\n        android:id=\"@+id/calc_txt_Prise\"\n        android:layout_width=\"fill_parent\"\n        android:layout_height=\"wrap_content\"\n        android:inputType=\"numberDecimal\"  \n        android:layout_marginTop=\"20dp\"\n        android:textSize=\"25dp\"\n        android:textColor=\"@color/gray\"\n        android:textStyle=\"bold\"\n        android:hint=\"@string/calc_txt_Prise\"\n        android:singleLine=\"true\" />\n\n    <Button\n        android:id=\"@+id/calc_clear_txt_Prise\"      \n        android:layout_width=\"wrap_content\"\n        android:layout_height=\"wrap_content\"\n        android:layout_marginRight=\"10dp\"\n        android:layout_gravity=\"right|center_vertical\"\n        android:background=\"@drawable/delete\" />\n\n</FrameLayout>\n\nYou can also use the button's id and perform whatever action you want on its onClickListener method.\n",
            "\nAs far as I can think bout it, there's only two ways you can do it. How can you know the user has finished writing a word? Either on focus lost, or clicking on an \"ok\" button. There's no way on my mind you can know the user pressed the last character...\nSo call onFocusChange(View v, boolean hasFocus) or add a button and a click listener to it.\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "android-edittext",
            "textwatcher"
        ]
    },
    {
        "question_id": "27484001",
        "question": "\nIs it safe to create new thread inside while loop? I have tried this way:\nstd::thread thread(ClientLoop,clientSocket)\n\nBut as soon as the function return it throws the error.\nwhile (true){\n    cout << \"Waiting for new connections\" << endl;\n    clientSocket = accept(listenSocket, nullptr, nullptr);\n    cout << \"Client connected\" << endl;\n    new thread(ClientLoop,clientSocket);                \n}   \n\nThis way it works, but I wonder if there are no memory leaks. Thanks.\n",
        "all_answers": [
            "\n\nas soon as the function return it throws the error\n\nIndeed, you mustn't destroy a joinable thread object. If you have no need to wait for the thread's completion later, then detach it:\nstd::thread thread(ClientLoop,clientSocket);\nthread.detach();\n// OK to destroy now\n\nIf you will need to join it later, then you'll have to store it somewhere that persists beyond the loop, for example\nstd::vector<std::thread> threads;\nwhile (whatever){\n    clientSocket = accept(listenSocket, nullptr, nullptr);\n    threads.emplace_back(ClientLoop,clientSocket);\n}\n\n// later\nfor (std::thread & t : threads) {\n    t.join();\n}\n\n// OK to destroy now\nthreads.clear();\n\n\nThis way it works, but I wonder if there are no memory leaks.\n\nYes, that's leaky. Each new creates a thread object, and you discard the pointer without deleting it or assigning it to a smart pointer to take care of. As mentioned in the comments, it not only leaks memory, but also thread handles, which on some systems are a more scarce resource; so after a while you might find that you can't launch any more threads.\nDetaching a thread is the way to leave it running in the background without leaking. This causes the thread to release its resources when it finishes.\n",
            "\nThere's no problem creating the thread in a loop, but there may\nbe a problem destructing it at the end of the loop if it is\na local variable.  To be legally destructed, a thread object\nmust be detached, joined or moved.  If your threads are\nsimply “fire and forget”, and you never have to\nsynchronize with them later (even for a clean shutdown), then\njust call std::thread::detach on the thread after creating it.\nOtherwise, you can put it into an std::vector<std::thread>, so\nthat you can find it and join it sometimes later.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n"
        ],
        "answer": "A1",
        "tags": [
            "c++",
            "multithreading"
        ]
    },
    {
        "question_id": "8668776",
        "question": "\nI have this folder structure in my PHP project.\n(this is as shown in eclips) \n-MySystem\n    +Code\n    +Data_Access\n    -Public_HTML\n        +css\n        +js\n        +Templates\n    -resources\n\nWhen I try this code\necho $_SERVER['DOCUMENT_ROOT']\n\noutput is\n\nD:/workspace\n\nHow can I get the path to RootDirectory of the system (MySystem), without hardcoding the Folder Name?\n",
        "all_answers": [
            "\nyou can try:\n$_SERVER['PATH_TRANSLATED']\nquote:\n\nFilesystem- (not document root-) based path to the current script, after the server has done any virtual-to-real mapping. Note: As of PHP 4.3.2, PATH_TRANSLATED is no longer set implicitly under the Apache 2 SAPI in contrast to the situation in Apache 1, where it's set to the same value as the SCRIPT_FILENAME server variable when it's not populated by Apache.\n  This change was made to comply with the CGI specification that PATH_TRANSLATED should only exist if PATH_INFO is defined. Apache 2 users may use AcceptPathInfo = On inside httpd.conf to define PATH_INFO\n\nsource:\nphp.net/manual\n",
            "\nFor PHP >= 5.3.0 try\nPHP magic constants.\n__DIR__\n\nAnd make your path relative.\nFor PHP < 5.3.0 try\ndirname(__FILE__)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "1873191",
        "question": "\nI'm using Visual Studio 2010 Beta 2. I've got a single [TestClass], which has a [TestInitialize], [TestCleanup] and a few [TestMethods].\nEvery time a test method is run, the initialize and cleanup methods are ALSO run!\nI was under the impression that the [TestInitialize] & [TestCleanup] should only be run once, per local test run.\nIs that correct? If not, what is the proper way to do this?\n",
        "all_answers": [
            "\nThe error shown in visual studio for the project (Let's say A) does not have issues. When I looked at the output window for the build line by line for each project, I saw that it was complaining about another project (B) that had been referred as assembly in project A. Project B added into the solution. But it had not been referred in the project A  as project reference instead as assembly reference from different location. That location contains the assembly which compiled for Platform AnyCpu. Then I removed the assembly reference from the project A and added project B as a reference. It started compiling. \nNot sure though how this fix worked.\n",
            "\nIf you are using WiX look at this (there is a bug)\nhttp://www.cnblogs.com/xixifusigao/archive/2012/03/20/2407651.html\nSometimes new build configurations get added to the .wixproj file further down the file, that is, separated from their sibling config definitions by other unrelated XML elements.\nSimply edit the .wixproj file so that all the <PropertyGroup> sections that define your build configs are adjacent to one another. (To edit the .wixproj in VS2013 right click on project in Solution Explorer, Unload project, right-click again->Edit YourProject.wixproj. Reload after editing the file.)\n",
            "\nTestInitialize and TestCleanup are ran before and after every test in the same class they are defined, this to ensure that no test is coupled to any other test in the same one class and to always start each test in a clean state.\n\nIf you want to run methods before and after all tests in a particular class, decorate relevant methods with the ClassInitialize and ClassCleanup attributes.\nIf you want to run methods before and after all tests in a particular test project (assembly), decorate relevant methods with the AssemblyInitialize and AssemblyCleanup attributes.\nRelevant information from the auto generated test-file in Visual Studio:\nYou can use the following additional attributes as you write your tests:\n// Use ClassInitialize to run code before running the first test in the class\n[ClassInitialize()]\npublic static void MyClassInitialize(TestContext testContext) { }\n\n// Use ClassCleanup to run code after all tests in a class have run\n[ClassCleanup()]\npublic static void MyClassCleanup() { }\n\n// Use TestInitialize to run code before running each test \n[TestInitialize()]\npublic void MyTestInitialize() { }\n\n// Use TestCleanup to run code after each test has run\n[TestCleanup()]\npublic void MyTestCleanup() { }\n\n",
            "\nthis is rather standard behaviour for test suites: setup and teardown before and after each test. The philosophy is that tests should not depend on each other. If you want another behaviour, you should probably use static objects that persist between each test.\n",
            "\nI had exact same error after adding a new configuration via ConfigurationManager in Visual Studio.\nIt turned out when the 'Production' configuration was added for the whole solution (and each project) the OutputPath element was not added to the .csproj files.\nTo fix, I went to the Build tab in project properties, changed OutputPath from \\bin\\Production\\ to \\bin\\Production (deleted trailing \\) and saved changes. This forced creation of the OutputPath element in the .csproj file and the project has built successfully.\nSounds like a glitch to me.\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "visual-studio",
            "visual-studio-2010",
            "mstest",
            "vs-unit-testing-framework"
        ]
    },
    {
        "question_id": "7049875",
        "question": "\nI want the carousel DIV (s7) to expand to the height of the entire screen. I haven't an idea as to why it's not succeeding. To see the page you can go here.\n\n\nbody {\r\n  height: 100%;\r\n  color: #FFF;\r\n  font: normal 28px/28px'HelveticaWorldRegular', Helvetica, Arial, Sans-Serif;\r\n  background: #222 url('') no-repeat center center fixed;\r\n  overflow: hidden;\r\n  background-size: cover;\r\n  margin: 0;\r\n  padding: 0;\r\n}\r\n.holder {\r\n  height: 100%;\r\n  margin: auto;\r\n}\r\n#s7 {\r\n  width: 100%;\r\n  height: 100%: margin: auto;\r\n  overflow: hidden;\r\n  z-index: 1;\r\n}\r\n#s7 #posts {\r\n  width: 100%;\r\n  min-height: 100%;\r\n  color: #FFF;\r\n  font-size: 13px;\r\n  text-align: left;\r\n  line-height: 16px;\r\n  margin: auto;\r\n  background: #AAA;\r\n}\n<div class=\"nav\">\r\n  <a class=\"prev2\" id=\"prev2\" href=\"#\">\r\n    <img src=\"http://static.tumblr.com/ux4v5bf/ASslogxz4/left.png\">\r\n  </a>\r\n  <a class=\"next2\" id=\"next2\" href=\"#\">\r\n    <img src=\"http://static.tumblr.com/ux4v5bf/swslogxmg/right.png\">\r\n  </a>\r\n</div>\r\n\r\n<div class=\"holder\">\r\n  <tr>\r\n    <td>\r\n      <div id=\"s7\">\r\n        {block:Posts}\r\n        <div id=\"posts\">\n\n\n\n",
        "all_answers": [
            "\nAdd only the class center-block to an image, this works with Bootstrap 4 as well:\n<img src=\"...\" alt=\"...\" class=\"center-block\" />\n\nNote: center-block works even when img-responsive is used\n",
            "\nThere is .center-block class in Twitter Bootstrap 3 (Since v3.0.1), so use:\n<img src=\"...\" alt=\"...\" class=\"img-responsive center-block\" />\n\n",
            "\nIf you're using Bootstrap v3.0.1 or greater, you should use this solution instead. It doesn't override Bootstrap's styles with custom CSS, but instead uses a Bootstrap feature.\nMy original answer is shown below for posterity\n\nThis is a pleasantly easy fix. Because .img-responsive from Bootstrap already sets display: block, you can use margin: 0 auto to center the image:\n.product .img-responsive {\n    margin: 0 auto;\n}\n\n",
            "\nIn order for a percentage value to work for height, the parent's height must be determined. The only exception is the root element <html>, which can be a percentage height. .\nSo, you've given all of your elements height, except for the <html>, so what you should do is add this:\nhtml {\n    height: 100%;\n}\n\nAnd your code should work fine.\n\n* { padding: 0; margin: 0; }\r\nhtml, body, #fullheight {\r\n    min-height: 100% !important;\r\n    height: 100%;\r\n}\r\n#fullheight {\r\n    width: 250px;\r\n    background: blue;\r\n}\n<div id=fullheight>\r\n  Lorem Ipsum        \r\n</div>\n\n\n\nJsFiddle example.\n",
            "\nYou will also need to set 100% height on the html element:\nhtml { height:100%; }\n\n",
            "\nIn the page source I see the following:\n<div class=\"holder\"> \n    <div id=\"s7\" style=\"position: relative; width: 1366px; height: 474px; overflow: hidden;\">\n\nIf you put the height value in the tag, it will use this instead of the height defined in the css file.\n"
        ],
        "answer": "A4",
        "tags": [
            "html",
            "css",
            "height"
        ]
    },
    {
        "question_id": "11498575",
        "question": "\nI have to write tests for a web site. I am trying to get the selected value of a dropdown box.  So far i can get the contents of the dropdown by doing\nfind_field('restrictions__rating_movies').text\n\nreturns - \nDon't Allow Movies\nG\nPG\nM\nR13\nR15\nR16\nR18\nR\nRP16\nAllow All Movies\nI can get the value of the selected object.\nfind_field('restrictions__rating_movies').value\n\nreturns -\n1000\nThis does not help me much though because i am trying to get the text of the selected item from a drop down box.\n<select class=\"\" id=\"restrictions__rating_movies\" name=\"restrictions[][rating_movies]\">            \n<option value=\"0\">Don't Allow Movies</option>\n<option value=\"100\">G</option>\n<option value=\"200\">PG</option>\n<option value=\"300\">M</option>\n<option value=\"325\">R13</option>\n<option value=\"350\">R15</option>\n<option value=\"375\">R16</option>\n<option value=\"400\">R18</option>\n<option value=\"500\">R</option>\n<option value=\"600\">RP16</option>\n<option value=\"1000\" selected=\"selected\">Allow All Movies</option></select>\n\nin this case shown i need to get the value 'Allow All Movies' I have tried many different combinations of the above two examples.\n",
        "all_answers": [
            "\nSorry I didn't search enough, the solution seems to be the following:\ndescribe \"GET 'index'\" do\n  it \"should be successful\" do\n    @request.env[\"HTTP_AUTHORIZATION\"] = \"Basic \" + Base64::encode64(\"username:password\")\n    get 'index'\n    response.should be_success\n  end\nend\n\n",
            "\nUpdate (2013): Matt Connolly has provided a GIST which also works for request and controller specs: http://gist.github.com/4158961\n\nAnother way of doing this if you have many tests to run and don't want to include it everytime (DRYer code):\nCreate a /spec/support/auth_helper.rb file:\nmodule AuthHelper\n  def http_login\n    user = 'username'\n    pw = 'password'\n    request.env['HTTP_AUTHORIZATION'] = ActionController::HttpAuthentication::Basic.encode_credentials(user,pw)\n  end  \nend\n\nIn your test spec file:\ndescribe HomeController do\n  render_views\n\n  # login to http basic auth\n  include AuthHelper\n  before(:each) do\n    http_login\n  end\n\n  describe \"GET 'index'\" do\n    it \"should be successful\" do\n      get 'index'\n      response.should be_success\n    end\n  end\n\nend\n\nCredit here - Archived site\n",
            "\nWould something like this work?\nwithin(\"//select[@id='restrictions__rating_movies']\") do\n  find_field(\"//option[@selected='selected']\").text\nend\n\n",
            "\nfind_field('restrictions__rating_movies').find('option[selected]').text\n\n",
            "\nSome answers suggest to set request.env which is unsafe, because request can be nil and you will end up with private method env' called for nil:NilClass, especially when run single tests with rspec -e\nCorrect approach will be:\ndef http_login\n  user = 'user'\n  password = 'passw'\n  {\n    HTTP_AUTHORIZATION: ActionController::HttpAuthentication::Basic.encode_credentials(user,password)\n  }\nend\n\nget 'index', nil, http_login\n\npost 'index', {data: 'post-data'}, http_login\n\n"
        ],
        "answer": "A4",
        "tags": [
            "ruby-on-rails",
            "rspec",
            "capybara"
        ]
    },
    {
        "question_id": "2189376",
        "question": "\nI would like to change the color of a particular row in my datagridview. The row should be changed to red when the value of columncell 7 is less than the value in columncell 10. Any suggestions on how to accomplish this?\n",
        "all_answers": [
            "\nActually, \nCursor.Current = Cursors.WaitCursor;\n\ntemporarily sets the Wait cursor, but doesn’t ensure that the Wait cursor shows until the end of your operation. Other programs or controls within your program can easily reset the cursor back to the default arrow as in fact happens when you move mouse while operation is still running. \nA much better way to show the Wait cursor is to set the UseWaitCursor property in a form to true:\nform.UseWaitCursor = true;\n\nThis will display wait cursor for all controls on the form until you set this property to false.\nIf you want wait cursor to be shown on Application level you should use:\nApplication.UseWaitCursor = true;\n\n",
            "\nBuilding on the previous, my preferred approach (since this is a frequently performed action) is to wrap the wait cursor code in an IDisposable helper class so it can be used with using() (one line of code), take optional parameters, run the code within, then clean up (restore cursor) afterwards.\npublic class CursorWait : IDisposable\n{\n    public CursorWait(bool appStarting = false, bool applicationCursor = false)\n    {\n        // Wait\n        Cursor.Current = appStarting ? Cursors.AppStarting : Cursors.WaitCursor;\n        if (applicationCursor) Application.UseWaitCursor = true;\n    }\n\n    public void Dispose()\n    {\n        // Reset\n        Cursor.Current = Cursors.Default;\n        Application.UseWaitCursor = false;\n    }\n}\n\nUsage:\nusing (new CursorWait())\n{\n    // Perform some code that shows cursor\n}\n\n",
            "\nYou can use Cursor.Current.\n// Set cursor as hourglass\nCursor.Current = Cursors.WaitCursor;\n\n// Execute your time-intensive hashing code here...\n\n// Set cursor as default arrow\nCursor.Current = Cursors.Default;\n\nHowever, if the hashing operation is really lengthy (MSDN defines this as more than 2-7 seconds), you should probably use a visual feedback indicator other than the cursor to notify the user of the progress. For a more in-depth set of guidelines, see this article.\nEdit:\nAs @Am pointed out, you may need to call Application.DoEvents(); after Cursor.Current = Cursors.WaitCursor; to ensure that the hourglass is actually displayed. \n",
            "\nYou're looking for the CellFormatting event.\nHere is an example.\n",
            "\nSomething like the following... assuming the values in the cells are Integers. \nforeach (DataGridViewRow dgvr in myDGV.Rows)\n{\n  if (dgvr.Cells[7].Value < dgvr.Cells[10].Value)\n  {\n    dgvr.DefaultCellStyle.ForeColor = Color.Red;\n  }\n}\n\nuntested, so apologies for any error.\nIf you know the particular row, you can skip the iteration:\nif (myDGV.Rows[theRowIndex].Cells[7].Value < myDGV.Rows[theRowIndex].Cells[10].Value)\n{\n  dgvr.DefaultCellStyle.ForeColor = Color.Red;\n}\n\n",
            "\nYou need to loop through the rows in the datagridview and then compare values of columns 7 and 10 on each row.\nTry this:\nforeach (DataGridViewRow row in vendorsDataGridView.Rows) \n     if (Convert.ToInt32(row.Cells[7].Value) < Convert.ToInt32(row.Cells[10].Value)) \n     {\n         row.DefaultCellStyle.BackColor = Color.Red; \n     }\n\n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            "winforms",
            "datagridview",
            "background-color"
        ]
    },
    {
        "question_id": "5870537",
        "question": "\nWhat's the difference between Django OneToOneField and ForeignKey?\n",
        "all_answers": [
            "\nI usually use a dictionary, not a list to return JSON content. \nimport json\n\nfrom django.http import HttpResponse\n\nresponse_data = {}\nresponse_data['result'] = 'error'\nresponse_data['message'] = 'Some error message'\n\nPre-Django 1.7 you'd return it like this:\nreturn HttpResponse(json.dumps(response_data), content_type=\"application/json\")\n\nFor Django 1.7+, use JsonResponse as shown in this SO answer like so : \nfrom django.http import JsonResponse\nreturn JsonResponse({'foo':'bar'})\n\n",
            "\nNew in django 1.7\nyou could use JsonResponse objects. \nfrom the docs:\nfrom django.http import JsonResponse\nreturn JsonResponse({'foo':'bar'})\n\n",
            "\nDifferences between OneToOneField(SomeModel) and ForeignKey(SomeModel, unique=True) as stated in The Definitive Guide to Django:\n\nOneToOneField\nA one-to-one relationship. Conceptually, this is similar to a ForeignKey with unique=True, but the \"reverse\" side of the relation will directly return a single object.\n\nIn contrast to the OneToOneField \"reverse\" relation, a ForeignKey \"reverse\" relation returns a QuerySet.\nExample\nFor example, if we have the following two models (full model code below):\n\nCar model uses OneToOneField(Engine)\nCar2 model uses ForeignKey(Engine2, unique=True)\n\nFrom within python manage.py shell execute the following:\nOneToOneField Example\n>>> from testapp.models import Car, Engine\n>>> c = Car.objects.get(name='Audi')\n>>> e = Engine.objects.get(name='Diesel')\n>>> e.car\n<Car: Audi>\n\nForeignKey with unique=True Example\n>>> from testapp.models import Car2, Engine2\n>>> c2 = Car2.objects.get(name='Mazda')\n>>> e2 = Engine2.objects.get(name='Wankel')\n>>> e2.car2_set.all()\n[<Car2: Mazda>]\n\nModel Code\nfrom django.db import models\n\nclass Engine(models.Model):\n    name = models.CharField(max_length=25)\n\n    def __unicode__(self):\n        return self.name\n\nclass Car(models.Model):\n    name = models.CharField(max_length=25)\n    engine = models.OneToOneField(Engine)\n\n    def __unicode__(self):\n        return self.name\n\nclass Engine2(models.Model):\n    name = models.CharField(max_length=25)\n\n    def __unicode__(self):\n        return self.name\n\nclass Car2(models.Model):\n    name = models.CharField(max_length=25)\n    engine = models.ForeignKey(Engine2, unique=True, on_delete=models.CASCADE)\n\n    def __unicode__(self):\n        return self.name\n\n",
            "\nI use this, it works fine.\nfrom django.utils import simplejson\nfrom django.http import HttpResponse\n\ndef some_view(request):\n    to_json = {\n        \"key1\": \"value1\",\n        \"key2\": \"value2\"\n    }\n    return HttpResponse(simplejson.dumps(to_json), mimetype='application/json')\n\nAlternative:\nfrom django.utils import simplejson\n\nclass JsonResponse(HttpResponse):\n    \"\"\"\n        JSON response\n    \"\"\"\n    def __init__(self, content, mimetype='application/json', status=None, content_type=None):\n        super(JsonResponse, self).__init__(\n            content=simplejson.dumps(content),\n            mimetype=mimetype,\n            status=status,\n            content_type=content_type,\n        )\n\nIn Django 1.7 JsonResponse objects have been added to the Django framework itself which makes this task even easier:\nfrom django.http import JsonResponse\ndef some_view(request):\n    return JsonResponse({\"key\": \"value\"})\n\n",
            "\nA ForeignKey is a many-to-one relationship. So, a Car object might have many instances of Wheel. Each Wheel would consequently have a ForeignKey to the Car it belongs to. A OneToOneField would be like an instance of Engine, where a Car object has at most one and only one.\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "django",
            "django-models",
            "foreign-keys"
        ]
    },
    {
        "question_id": "1244921",
        "question": "\nI have a Rails question.\nHow do I get a controller action's name inside the controller action?\nFor example, instead of\ndef create\n  logger.info(\"create\")\nend\n\nI want to write something like\ndef create\n  logger.info(this_def_name)\nend\n\nWhat is a way to get this_def_name?\n",
        "all_answers": [
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nRails 2.X: @controller.action_name\nRails 3.1.X: controller.action_name, action_name\nRails 4+: action_name\n",
            "\nmikej's answer was very precise and helpful, but the the thing i also wanted to know was how to get current method name in rails.\nfound out it's possible with self.current_method\neasily found at http://www.ruby-forum.com/topic/75258\n",
            "\nIn the specific case of a Rails action (as opposed to the general case of getting the current method name) you can use params[:action]\nAlternatively you might want to look into customising the Rails log format so that the action/method name is included by the format rather than it being in your log message.\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "function"
        ]
    },
    {
        "question_id": "41154784",
        "question": "\nI have a UIImageView and the user is able to download UIImages in various formats. The issue is that I need the UIImageView to resize based on the given Image's ratio.\nCurrently, I'm using Aspect fit, but the UIImageView remains empty on big parts of itself. I would like to have the UIImageView resize itself based on its content. E.g if the pic is 1:1, 4:3, 6:2, 16:9...\n\nHelp is very appreciated.\nAs requested, that is what I want:\n\nI have had an UIImageView that was square, loaded with an Image in 16:7 or whatever, and the UIImageView resized to fit the size of the Image...\n",
        "all_answers": [
            "\nSet your imageView to aspectFit, that will resize the image to  not exceed your imageView's frame. \nYou can get the size of your UIImage of your imageView with logic from this question - basically just get the height and width of the UIImage. \nCalculate the ratio and set the width/height of the imageView to fit you screen.\nThere is also a similar question to your that you might get you answer from.\n",
            "\nIt looks like you want to resize an ImageView according to the image ratio and the container view's size, here is the example in Swift (Sorry,the former answer with a bug, I fixed it):  \n   let containerView = UIView(frame: CGRect(x:0,y:0,width:320,height:500))\n   let imageView = UIImageView()\n\n    if let image = UIImage(named: \"a_image\") {\n        let ratio = image.size.width / image.size.height\n        if containerView.frame.width > containerView.frame.height {\n            let newHeight = containerView.frame.width / ratio\n            imageView.frame.size = CGSize(width: containerView.frame.width, height: newHeight)\n        }\n        else{\n            let newWidth = containerView.frame.height * ratio\n            imageView.frame.size = CGSize(width: newWidth, height: containerView.frame.height)\n        }\n    }\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "swift"
        ]
    },
    {
        "question_id": "59391984",
        "question": "\nEverthing below is made in VS2019, using .NET Framework 4.7 and NUnit + NUnit3TestAdapter\nI created an assembly called Exitus.Tests, and added a few unit tests. However, do to some issues with Nuget, that I could not solve, I made another project called Exitus.UnitTests and removed the once file I had in the old project (including changing the namespace). \nNow the new test project showed op correctly in the explorer, but a \"ghost\" of the old project remained:\n\nIf I try to run the test, the output window shows the following error:\n\nSystem.InvalidOperationException: The following TestContainer was not found 'C:\\Users\\xxx\\Source\\Repositories\\Expire\\Exitus.Tests\\bin\\Debug\\Exitus.Tests.dll'\n     at Microsoft.VisualStudio.TestWindow.Client.TestContainer.TestContainerProvider.d__46.MoveNext()\n  --- End of stack trace from previous location where exception was thrown ---\n     at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n     at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n     at Microsoft.VisualStudio.TestWindow.Controller.TestContainerConfigurationQueryByTestsBase.d__6.MoveNext()\n     (...)\n\nThe stack trace is a lot longer, but the curious thing is the second line, stating that it could not find the test container at \\Exitus.Tests\\bin\\Debug\\Exitus.Tests.dll. This is the name of the old test project, which I removed and deleted. I have searched my entire project for the term Exitus.Tests and it returns no results. \nIs there anyway to forcefully remove this 'ghost' project? \n",
        "all_answers": [
            "\nI had exact same error after adding a new configuration via ConfigurationManager in Visual Studio.\nIt turned out when the 'Production' configuration was added for the whole solution (and each project) the OutputPath element was not added to the .csproj files.\nTo fix, I went to the Build tab in project properties, changed OutputPath from \\bin\\Production\\ to \\bin\\Production (deleted trailing \\) and saved changes. This forced creation of the OutputPath element in the .csproj file and the project has built successfully.\nSounds like a glitch to me.\n",
            "\nI faced the same issue right now. A cleanup helped. As I had cleanup issues with VS in the last time (some DB-lock prevents a real cleanup to happen), my working cleanup was this way:\n\nClose VS. \nGit Bash in solution folder: git clean -xfd\n\nProbably it helps.\n",
            "\n\nClose Visual Studio.\nDelete the *.testlog files in:\nsolutionfolder\\.vs\\solution name\\v16\\TestStore\\number.\n\n",
            "\nThe error shown in visual studio for the project (Let's say A) does not have issues. When I looked at the output window for the build line by line for each project, I saw that it was complaining about another project (B) that had been referred as assembly in project A. Project B added into the solution. But it had not been referred in the project A  as project reference instead as assembly reference from different location. That location contains the assembly which compiled for Platform AnyCpu. Then I removed the assembly reference from the project A and added project B as a reference. It started compiling. \nNot sure though how this fix worked.\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "visual-studio",
            "nunit"
        ]
    },
    {
        "question_id": "8889025",
        "question": "\nI want to unzip a file and this works fine\nsystem('unzip File.zip');\n\nBut I need to pass in the file name through the URL and can not get it to work, this is what I have. \n$master = $_GET[\"master\"];\nsystem('unzip $master.zip'); \n\nWhat am I missing? I know it has to be something small and stupid I am overlooking.\nThank you, \n",
        "all_answers": [
            "\nPlease, don't do it like that (passing GET var to be a part of a system call). Use ZipArchive instead.\nSo, your code should look like:\n$zipArchive = new ZipArchive();\n$result = $zipArchive->open($_GET[\"master\"]);\nif ($result === TRUE) {\n    $zipArchive ->extractTo(\"my_dir\");\n    $zipArchive ->close();\n    // Do something else on success\n} else {\n    // Do something on error\n}\n\nAnd to answer your question, your error is 'something $var something else' should be \"something $var something else\" (in double quotes).\n",
            "\nI can only assume your code came from a tutorial somewhere online? In that case, good job trying to figure it out by yourself. On the other hand, the fact that this code could actually be published online somewhere as the correct way to unzip a file is a bit frightening.\nPHP has built-in extensions for dealing with compressed files. There should be no need to use system calls for this. ZipArchivedocs is one option.\n$zip = new ZipArchive;\n$res = $zip->open('file.zip');\nif ($res === TRUE) {\n  $zip->extractTo('/myzips/extract_path/');\n  $zip->close();\n  echo 'woot!';\n} else {\n  echo 'doh!';\n}\n\nAlso, as others have commented, $HTTP_GET_VARS has been deprecated since version 4.1 ... which was a reeeeeally long time ago. Don't use it. Use the $_GET superglobal instead.\nFinally, be very careful about accepting whatever input is passed to a script via a $_GET variable.\nALWAYS SANITIZE USER INPUT.\n\nUPDATE\nAs per your comment, the best way to extract the zip file into the same directory in which it resides is to determine the hard path to the file and extract it specifically to that location. So, you could do:\n// assuming file.zip is in the same directory as the executing script.\n$file = 'file.zip';\n\n// get the absolute path to $file\n$path = pathinfo(realpath($file), PATHINFO_DIRNAME);\n\n$zip = new ZipArchive;\n$res = $zip->open($file);\nif ($res === TRUE) {\n  // extract it to the path we determined above\n  $zip->extractTo($path);\n  $zip->close();\n  echo \"WOOT! $file extracted to $path\";\n} else {\n  echo \"Doh! I couldn't open $file\";\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "unzip"
        ]
    },
    {
        "question_id": "300705",
        "question": "\nI have the following code:\nfor attribute in site.device_attributes\n  device.attribute\nend\n\nwhere I would like the code to substitute the value of \"attribute\" for the method name.\nI have tried device.\"#{attribute}\" and various permutations.\nIs this completely impossible? Am I missing something?\nI have considered overriding method_missing, but I can't figure out how that would actually help me when my problem is that I need to call an \"unknown\" method.\n",
        "all_answers": [
            "\nThe \"send\" method should do what you're looking for:\nobject = \"upcase me!\"\nmethod = \"upcase\"\nobject.send(method.to_sym) # => \"UPCASE ME!\"\n\n",
            "\nyou can also do\ndevice.instance_eval(attribute)\n\n",
            "\nYou can use #send method to call object's method by method's name:\nobject.send(:foo) # same as object.foo\n\nYou can pass arguments with to invoked method:\nobject.send(:foo, 1, \"bar\", 1.23) # same as object.foo(1, \"bar\", 1.23)\n\nSo, if you have attribute name in variable \"attribute\" you can read object's attribute with\nobject.send(attribute.to_sym)\n\nand write attribute's value with \nobject.send(\"#{attribute}=\".to_sym, value)\n\nIn Ruby 1.8.6 #send method can execute any object's method regardless of its visibility (you can e.g. call private methods). This is subject to change in future versions of Ruby and you shouldn't rely on it. To execute private methods, use #instance_eval:\nobject.instance_eval {\n  # code as block, can reference variables in current scope\n}\n\n# or\n\nobject.instance_eval <<-CODE\n  # code as string, can generate any code text\nCODE\n\nUpdate\nYou can use public_send to call methods with regard to visibility rules.\nobject.public_send :public_foo # ok\nobject.public_send :private_bar # exception\n\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "ruby"
        ]
    },
    {
        "question_id": "19791482",
        "question": "\nI am currently in the process of retrofitting our long-running methods to be cancelable. I am planning on using System.Threading.Tasks.CancellationToken to implement that.\nOur methods generally perform a few long-running steps (sending commands to and then waiting for hardware mostly), e.g.\nvoid Run()\n{\n    Step1();\n    Step2();    \n    Step3();\n}\n\nMy first (maybe stupid) thought on cancellation would transform this into\nbool Run(CancellationToken cancellationToken)\n{\n    Step1(cancellationToken);\n\n    if (cancellationToken.IsCancellationRequested)\n        return false;\n\n    Step2(cancellationToken);\n\n    if (cancellationToken.IsCancellationRequested)\n        return false;    \n\n    Step3(cancellationToken);\n\n    if (cancellationToken.IsCancellationRequested)\n        return false;\n\n    return true;\n}\n\nwhich frankly looks horrible. This \"pattern\" would continue inside the single steps, too (and they are necessarily rather longish already). This would make Thread.Abort() look rather sexy, although I know its not recommended. \nIs there a cleaner pattern to achieve this that does not hide away the application logic beneath lots of boilerplate code?\nEdit\nAs an example for the nature of the steps, the Run method could read\nvoid Run()\n{\n    GiantRobotor.MoveToBase();\n    Oven.ThrowBaguetteTowardsBase();    \n    GiantRobotor.CatchBaguette();\n    // ...\n}\n\nWe are controlling different hardware units that need to be synchronized to work together.\n",
        "all_answers": [
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nI admit it isn't pretty, but the guidance is to either do what you have done:\nif (cancellationToken.IsCancellationRequested) { /* Stop */ }\n\n...or the slightly shorter:\ncancellationToken.ThrowIfCancellationRequested()\n\nGenerally, if you can pass the cancellation token to the individual steps, you can spread the checks out such that they don't saturate the code.  You may also choose not to check for cancellation constantly; if the operations you are performing are idempotent and aren't resource intensive, you don't necessarily have to check for cancellation at every stage.  The most important time to check is before returning a result.\nIf you're passing the token to all of your steps, you could do something like this:\npublic static CancellationToken VerifyNotCancelled(this CancellationToken t) {\n    t.ThrowIfCancellationRequested();\n    return t;\n}\n\n...\n\nStep1(token.VerifyNotCancelled());\nStep2(token.VerifyNotCancelled());\nStep3(token.VerifyNotCancelled());\n\n",
            "\nIf the steps are somehow independend regarding the dataflow within the method, but can't be executed in a parallel matter, the following approach may be better readable:\nvoid Run()\n{\n    // list of actions, defines the order of execution\n    var actions = new List<Action<CancellationToken>>() {\n       ct => Step1(ct),\n       ct => Step2(ct),\n       ct => Step3(ct) \n    };\n\n    // execute actions and check for cancellation token\n    foreach(var action in actions)\n    {\n        action(cancellationToken);\n\n        if (cancellationToken.IsCancellationRequested)\n            return false;\n    }\n\n    return true;\n}\n\nIf the steps don't need the cancellation token because you can split them up in tiny units, you can even write a smaller list definition:\nvar actions = new List<Action>() {\n    Step1, Step2, Step3\n};\n\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "multithreading",
            "cancellation-token"
        ]
    },
    {
        "question_id": "1344232",
        "question": "\nI would like to see the SQL statement that a given ActiveRecord Query will generate.  I recognize I can get this information from the log after the query has been issued, but I'm wondering if there is a method that can be called on and ActiveRecord Query.\nFor example:\nSampleModel.find(:all, :select => \"DISTINCT(*)\", :conditions => [\"`date` > #{self.date}\"], :limit => 1, :order => '`date`', :group => \"`date`\")\n\nI would like to open the irb console and tack a method on the end that would show the SQL that this query will generate, but not necessarily execute the query.\n",
        "all_answers": [
            "\nMySQL's GROUP BY can be used without an aggregate function (which is contrary to the SQL standard), and returns the first row in the group (I don't know based on what criteria), while PostgreSQL must have an aggregate function (MAX, SUM, etc) on the column, on which the GROUP BY clause is issued.\n",
            "\nCorrect, the solution to fixing this is to use :select and to select each field that you wish to decorate the resulting object with and group by them.\nNasty - but it is how group by should work as opposed to how MySQL works with it by guessing what you mean if you don't stick fields in your group by.\n",
            "\nMySQL's totally non standards compliant GROUP BY can be emulated by Postgres' DISTINCT ON. Consider this:\nMySQL:\nSELECT a,b,c,d,e FROM table GROUP BY a\n\nThis delivers 1 row per value of a (which one, you don't really know). Well actually you can guess, because MySQL doesn't know about hash aggregates, so it will probably use a sort... but it will only sort on a, so the order of the rows could be random. Unless it uses a multicolumn index instead of sorting. Well, anyway, it's not specified by the query.\nPostgres:\nSELECT DISTINCT ON (a) a,b,c,d,e FROM table ORDER BY a,b,c\n\nThis delivers 1 row per value of a, this row will be the first one in the sort according to the ORDER BY specified by the query. Simple.\nNote that here, it's not an aggregate I'm computing. So GROUP BY actually makes no sense. DISTINCT ON makes a lot more sense.\nRails is married to MySQL, so I'm not surprised that it generates SQL that doesn't work in Postgres.\n",
            "\nCreate a .irbrc file in your home directory and paste this in:\nif ENV.include?('RAILS_ENV') && !Object.const_defined?('RAILS_DEFAULT_LOGGER')\n  require 'logger'\n  RAILS_DEFAULT_LOGGER = Logger.new(STDOUT)\nend\n\nThat will output SQL statements into your irb session as you go.\nEDIT: Sorry that will execute the query still, but it's closest I know of.\nEDIT: Now with arel, you can build up scopes/methods as long as the object returns ActiveRecord::Relation and call .to_sql on it and it will out put the sql that is going to be executed.\n",
            "\nPostgreSQL is more SQL compliant than MySQL. All fields - except computed field with aggregation function - in the output must be present in the GROUP BY clause.\n",
            "\nWhen last I tried to do this there was no official way to do it. I resorted to using the function that find and its friends use to generate their queries directly. It is private API so there is a huge risk that Rails 3 will totally break it, but for debugging, it is an ok solution.\nThe method is construct_finder_sql(options) (lib/active_record/base.rb:1681) you will have to use send because it is private. \nEdit: construct_finder_sql was removed in Rails 5.1.0.beta1.\n"
        ],
        "answer": "A6",
        "tags": [
            "sql",
            "ruby-on-rails",
            "activerecord"
        ]
    },
    {
        "question_id": "498970",
        "question": "\nHow do I remove all whitespace from the start and end of the string?\n",
        "all_answers": [
            "\nThere are a lot of implementations that can be used. The most obvious seems to be something like this:\nString.prototype.trim = function() {\n    return this.replace(/^\\s+|\\s+$/g, \"\");\n};\n\n\" foo bar \".trim();  // \"foo bar\"\n\n",
            "\n\nNote: This is not unicode compliant. \"I💖U\".split('') results in the\n  4 character array [\"I\", \"�\", \"�\", \"u\"] which can lead to dangerous\n  bugs. See answers below for safe alternatives.\n\nJust split it by an empty string. \n\n\nvar output = \"Hello world!\".split('');\r\nconsole.log(output);\n\n\n\nSee the String.prototype.split() MDN docs.\n",
            "\nAll browsers since IE9+ have trim() method for strings:\n\" \\n test \\n \".trim(); // returns \"test\" here\n\nFor those browsers who does not support trim(), you can use this polyfill from MDN:\nif (!String.prototype.trim) {\n    (function() {\n        // Make sure we trim BOM and NBSP\n        var rtrim = /^[\\s\\uFEFF\\xA0]+|[\\s\\uFEFF\\xA0]+$/g;\n        String.prototype.trim = function() {\n            return this.replace(rtrim, '');\n        };\n    })();\n}\n\n\nThat said, if using jQuery, $.trim(str) is also available and handles undefined/null.\n\nSee this:\nString.prototype.trim=function(){return this.replace(/^\\s+|\\s+$/g, '');};\n\nString.prototype.ltrim=function(){return this.replace(/^\\s+/,'');};\n\nString.prototype.rtrim=function(){return this.replace(/\\s+$/,'');};\n\nString.prototype.fulltrim=function(){return this.replace(/(?:(?:^|\\n)\\s+|\\s+(?:$|\\n))/g,'').replace(/\\s+/g,' ');};\n\n",
            "\nThe trim from jQuery is convenient if you are already using that framework. \n$.trim('  your string   ');\n\nI tend to use jQuery often, so trimming strings with it is natural for me.  But it's possible that there is backlash against jQuery out there? :) \n",
            "\nSimple version here What is a general function for JavaScript trim?\nfunction trim(str) {\n        return str.replace(/^\\s+|\\s+$/g,\"\");\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "string",
            "trim"
        ]
    },
    {
        "question_id": "856845",
        "question": "\nI have an interesting question.\nImagine I have a lot of data changing in very fast intervals.\nI want to display that data as a table in console app. f.ex:\n-------------------------------------------------------------------------\n|    Column 1     |    Column 2     |    Column 3     |    Column 4     |\n-------------------------------------------------------------------------\n|                 |                 |                 |                 |\n|                 |                 |                 |                 |\n|                 |                 |                 |                 |\n-------------------------------------------------------------------------\n\nHow to keep things fast and how to fix column widths ? I know how to do that in java, but I don't how it's done in C#.\n",
        "all_answers": [
            "\nSee MSDN:\nConsole.CancelKeyPress Event\nArticle with code samples:\nCtrl-C and the .NET console application\n",
            "\nYou could do something like the following:\nstatic int tableWidth = 73;\n\nstatic void Main(string[] args)\n{\n    Console.Clear();\n    PrintLine();\n    PrintRow(\"Column 1\", \"Column 2\", \"Column 3\", \"Column 4\");\n    PrintLine();\n    PrintRow(\"\", \"\", \"\", \"\");\n    PrintRow(\"\", \"\", \"\", \"\");\n    PrintLine();\n    Console.ReadLine();\n}\n\nstatic void PrintLine()\n{\n    Console.WriteLine(new string('-', tableWidth));\n}\n\nstatic void PrintRow(params string[] columns)\n{\n    int width = (tableWidth - columns.Length) / columns.Length;\n    string row = \"|\";\n\n    foreach (string column in columns)\n    {\n        row += AlignCentre(column, width) + \"|\";\n    }\n\n    Console.WriteLine(row);\n}\n\nstatic string AlignCentre(string text, int width)\n{\n    text = text.Length > width ? text.Substring(0, width - 3) + \"...\" : text;\n\n    if (string.IsNullOrEmpty(text))\n    {\n        return new string(' ', width);\n    }\n    else\n    {\n        return text.PadRight(width - (width - text.Length) / 2).PadLeft(width);\n    }\n}\n\n",
            "\nThe Console.CancelKeyPress event is used for this. This is how it's used:\npublic static void Main(string[] args)\n{\n    Console.CancelKeyPress += delegate {\n        // call methods to clean up\n    };\n\n    while (true) {}\n}\n\nWhen the user presses Ctrl+C the code in the delegate is run and the program exits. This allows you to perform cleanup by calling necessary methods. Note that no code after the delegate is executed.\nThere are other situations where this won't cut it. For example, if the program is currently performing important calculations that can't be immediately stopped. In that case, the correct strategy might be to tell the program to exit after the calculation is complete. The following code gives an example of how this can be implemented:\nclass MainClass\n{\n    private static bool keepRunning = true;\n\n    public static void Main(string[] args)\n    {\n        Console.CancelKeyPress += delegate(object? sender, ConsoleCancelEventArgs e) {\n            e.Cancel = true;\n            MainClass.keepRunning = false;\n        };\n        \n        while (MainClass.keepRunning) {\n            // Do your work in here, in small chunks.\n            // If you literally just want to wait until Ctrl+C,\n            // not doing anything, see the answer using set-reset events.\n        }\n        Console.WriteLine(\"exited gracefully\");\n    }\n}\n\nThe difference between this code and the first example is that e.Cancel is set to true, which means the execution continues after the delegate. If run, the program waits for the user to press Ctrl+C. When that happens the keepRunning variable changes value which causes the while loop to exit. This is a way to make the program exit gracefully.\n",
            "\nUse String.Format with alignment values.\nFor example:\nString.Format(\"|{0,5}|{1,5}|{2,5}|{3,5}|\", arg0, arg1, arg2, arg3);\n\nTo create one formatted row.\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "console",
            "drawing"
        ]
    },
    {
        "question_id": "19411135",
        "question": "\nI have recently have gotten into AngularJS and I love it. For an upcoming project I am looking to use the MEAN stack (MongoDB, Express, Angular, Node). I'm pretty familiar with Angular and I have a modest understanding of the purposes of MongoDB and Node in the stack. However, I don't really understand what the purpose of Express.js is. Is it essential to the MEAN stack? What would you compare it to in a traditional MySQL, PHP, javascript app? What does it do that the other three components can't do?\nAlso, if someone wants to give their own take on how the four parts of the stack work together, that'd be great.\n",
        "all_answers": [
            "\nYou can close the connection with\nmongoose.connection.close()\n\n",
            "\n\nMongoDB = database \nExpress.js = back-end web framework\nAngular = front-end framework\nNode = back-end platform / web framework\n\nBasically, what Express does is that it enables you to easily create web applications by providing a slightly simpler interface for creating your request endpoints, handling cookies, etc. than vanilla Node. You could drop it out of the equation, but then you'd have to do a lot more work in whipping up your web-application. Node itself could do everything express is doing (express is implemented with node), but express just wraps it up in a nicer package.\nI would compare Express to some PHP web framework in the stack you describe, something like slim.\n",
            "\nI'm using version 4.4.2 and none of the other answers worked for me. But adding useMongoClient to the options and putting it into a variable that you call close on seemed to work. \nvar db = mongoose.connect('mongodb://localhost:27017/somedb', { useMongoClient: true })\n\n//do stuff\n\ndb.close()\n\n",
            "\nYou will get an error if you try to close/disconnect outside of the method. The best solution is to close the connection in both callbacks in the method. The dummy code is here.\nconst newTodo = new Todo({text:'cook dinner'});\n\nnewTodo.save().then((docs) => {\n  console.log('todo saved',docs);\n  mongoose.connection.close();\n},(e) => {\n  console.log('unable to save');\n});\n\n",
            "\nThe other answer didn't work for me. I had to use mongoose.disconnect(); as stated in this answer. \n",
            "\nYou can set the connection to a variable then disconnect it when you are done:\nvar db = mongoose.connect('mongodb://localhost:27017/somedb');\n\n// Do some stuff\n\ndb.disconnect();\n\n",
            "\nExpress handles things like cookies, parsing the request body, forming the response and handling routes.  \nIt also is the part of the application that listens to a socket to handle incoming requests.\nA simple example from express github\n\nvar express = require('express');\nvar app = express();\n\napp.get('/', function(req, res){\n  res.send('Hello World');\n});\napp.listen(3000);\n\nShows the creation of the express server, creating a route app.get('/'... and opening the port to listen for incoming http requests on.\n",
            "\nmongoose.connection.close(function(){\nconsole.log('Mongoose default connection disconnected through app termination');\nprocess.exit(0);\n});\n\nThis will close the mongoose connection and will also notify you by message in your console.\n",
            "\nJust as Jake Wilson said: You can set the connection to a variable then disconnect it when you are done:\nlet db;\nmongoose.connect('mongodb://localhost:27017/somedb').then((dbConnection)=>{\n    db = dbConnection;\n    afterwards();\n});\n\n\nfunction afterwards(){\n\n    //do stuff\n\n    db.disconnect();\n}\n\nor if inside Async function:\n(async ()=>{\n    const db = await mongoose.connect('mongodb://localhost:27017/somedb', { useMongoClient: \n                  true })\n\n    //do stuff\n\n    db.disconnect()\n})\n\notherwise when i was checking it in my environment it has an error.\n"
        ],
        "answer": "A2",
        "tags": [
            "node.js",
            "mongodb",
            "angularjs",
            "express"
        ]
    },
    {
        "question_id": "7357818",
        "question": "\nI have a header element and a content element:\n#header\n#content\n\nI want the header to be of fixed height and the content to fill up all the remaining height available on the screen, with overflow-y: scroll;. \nIt this possible without Javascript? \n",
        "all_answers": [
            "\nCSS PLaY | cross browser fixed header/footer/centered single column layout\nCSS Frames, version 2: Example 2, specified width | 456 Berea Street\nOne important thing is that although this sounds easy, there's going to be quite a bit of ugly code going into your CSS file to get an effect like this. Unfortunately, it really is the only option.\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nThe trick to this is specifying 100% height on the html and body elements.\nSome browsers look to the parent elements (html, body) to calculate the height. \n<html>\n    <body>\n        <div id=\"Header\">\n        </div>\n        <div id=\"Content\">\n        </div>\n    </body>\n</html>\n\nhtml, body\n{\n    height: 100%;\n}\n#Header\n{\n    width: 960px;\n    height: 150px;\n}\n#Content\n{\n    height: 100%;\n    width: 960px;\n}\n\n"
        ],
        "answer": "A5",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "7366363",
        "question": "\nI have a Django model with a start and end date range. I want to enforce validation so that no two records have overlapping date ranges. What's the simplest way to implement this so that I don't have to repeat myself writing this logic?\ne.g. I don't want to re-implement this logic in a Form and a ModelForm and an admin form and the model's overridden save().\nAs far as I know, Django doesn't make it easy to globally enforce these types of criteria. \nGoogling hasn't been very helpful, since \"model validation\" typically refers to validating specific model fields, and not the entire model contents, or relations between fields.\n",
        "all_answers": [
            "\nI would override the validate_unique method on the model. To make sure you ignore the current object when validating, you can use the following:\nfrom django.db.models import Model, DateTimeField\nfrom django.core.validators import NON_FIELD_ERRORS, ValidationError\n\nclass MyModel(Model):\n    start_date = DateTimeField()\n    end_date = DateTimeField()\n\n    def validate_unique(self, *args, **kwargs):\n        super(MyModel, self).validate_unique(*args, **kwargs)\n\n        qs = self.__class__._default_manager.filter(\n            start_date__lt=self.end_date,\n            end_date__gt=self.start_date\n        )\n\n        if not self._state.adding and self.pk is not None:\n            qs = qs.exclude(pk=self.pk)\n\n        if qs.exists():\n            raise ValidationError({\n                NON_FIELD_ERRORS: ['overlapping date range',],\n            })\n\nModelForm will automatically call this for you through a full_clean(), which you can use manually too.\nPPR has a nice discussion of a simple, correct range overlap condition.\n",
            "\nI think you should use this:\nhttps://docs.djangoproject.com/en/dev/ref/models/instances/#validating-objects\nJust define clean() method in your model like this: (example from the docs link)\ndef clean(self):\n    from django.core.exceptions import ValidationError\n    # Don't allow draft entries to have a pub_date.\n    if self.status == 'draft' and self.pub_date is not None:\n        raise ValidationError('Draft entries may not have a publication date.')\n    # Set the pub_date for published items if it hasn't been set already.\n    if self.status == 'published' and self.pub_date is None:\n        self.pub_date = datetime.datetime.now()\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nThe basic pattern I've found useful is to put all my custom validation in clean() and then simply call full_clean() (which calls clean() and a few other methods) from inside save(), e.g.:\nclass BaseModel(models.Model):\n    \n    def clean(self, *args, **kwargs):\n        # add custom validation here\n        super().clean(*args, **kwargs)\n\n    def save(self, *args, **kwargs):\n        self.full_clean()\n        super().save(*args, **kwargs)\n\nThis isn't done by default, as explained here, because it interferes with certain features, but those aren't a problem for my application.\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "django",
            "django-models"
        ]
    },
    {
        "question_id": "2213977",
        "question": "\nIs there a template tag (or any other trick) I can use to display all the variables available in a page?\n",
        "all_answers": [
            "\nYou try this. \nI have already tried it in my django template.\nIt will work fine. Just remove the curly braces pair {{ and }} from {{source}}.\nI have also added <table> tag and that's it.\nAfter modification your code will look something like below. \n{% for source in sources %}\n   <table>\n      <tr>\n          <td>{{ source }}</td>\n          <td>\n              {% if title == source %}\n                Just now! \n              {% endif %}\n          </td>\n      </tr>\n   </table>\n{% endfor %}\n\nMy dictionary looks like below,\n{'title':\"Rishikesh\", 'sources':[\"Hemkesh\", \"Malinikesh\", \"Rishikesh\", \"Sandeep\", \"Darshan\", \"Veeru\", \"Shwetabh\"]}\n\nand OUTPUT looked like below once my template got rendered.\nHemkesh \nMalinikesh  \nRishikesh   Just now!\nSandeep \nDarshan \nVeeru   \nShwetabh    \n\n",
            "\nYou shouldn't use the double-bracket {{ }} syntax within if or ifequal statements, you can simply access the variable there like you would in normal python:\n{% if title == source %}\n   ...\n{% endif %}\n\n",
            "\nThere are a bunch of ways to do it, but the most straightforward is to simply \nuse the Python debugger. Just add following line in to a Django view function:\nimport pdb; pdb.set_trace()\n\nor \nbreakpoint()  #from Python3.7\n\nIf you try to load that page in your browser, the browser will hang and you get a prompt to carry on debugging on actual executing code.\nHowever there are other options (I am not recommending them):\n* return HttpResponse({variable to inspect})\n\n* print {variable to inspect}\n\n* raise Exception({variable to inspect})\n\nBut the Python Debugger (pdb) is highly recommended for all types of Python code. If you are already into pdb, you'd also want to have a look at IPDB that uses ipython for debugging.\nSome more useful extension to pdb are\npdb++, suggested by Antash.\npudb, suggested by PatDuJour.\nUsing the Python debugger in Django, suggested by Seafangs.\n",
            "\nIf DEBUG is enabled, there's a template tag called {% debug %}\n",
            "\nSorry for comment in an old post but if you want to use an else if statement this will help you\n{% if title == source %}\n    Do This\n{% elif title == value %}\n    Do This\n{% else %}\n    Do This\n{% endif %}\n\nFor more info see https://docs.djangoproject.com/en/3.2/ref/templates/builtins/#if\n",
            "\n{% for source in sources %}\n  <tr>\n    <td>{{ source }}</td>\n    <td>\n      {% ifequal title source %}\n        Just now!\n      {% endifequal %}\n    </td>\n  </tr>\n{% endfor %}\n\n                or\n\n\n{% for source in sources %}\n      <tr>\n        <td>{{ source }}</td>\n        <td>\n          {% if title == source %}\n            Just now!\n          {% endif %}\n        </td>\n      </tr>\n    {% endfor %}\n\nSee Django Doc\n",
            "\nThe debug toolbar does all this and much, much more. See the screencast for more. If you literally just want the variables, you could try\nassert False, locals()\n\nin your view\n"
        ],
        "answer": "A4",
        "tags": [
            "django",
            "variables",
            "templates",
            "debugging"
        ]
    },
    {
        "question_id": "18440130",
        "question": "\nI have a little problem and hoping someone can give me some advice. I am running a SQL command, but it appears it takes this command about 2 mins to return the data as there is a lot of data. But the default connection time is 30 secs, how do I increase this, and apply it to this command? \npublic static DataTable runtotals(string AssetNumberV, string AssetNumber1V)\n{\n    DataTable dtGetruntotals;\n\n    try\n    {\n        dtGetruntotals = new DataTable(\"Getruntotals\");\n\n        //SqlParameter AssetNumber = new SqlParameter(\"@AssetNumber\", SqlDbType.VarChar, 6);\n        //AssetNumber.Value = AssetNumberV; \n\n        SqlParameter AssetNumber = new SqlParameter(\"@AssetNumber\", SqlDbType.VarChar, 10);\n        AssetNumber.Value = AssetNumberV;\n\n        SqlParameter AssetNumber1 = new SqlParameter(\"@AssetNumber1\", SqlDbType.VarChar, 10);\n        AssetNumber1.Value = AssetNumber1V;\n\n        SqlCommand scGetruntotals = new SqlCommand(\"EXEC spRunTotals @AssetNumber,@AssetNumber1 \", DataAccess.AssetConnection); \n        // scGetruntotals.Parameters.Add(AssetNumber);\n        scGetruntotals.Parameters.Add(AssetNumber);\n        scGetruntotals.Parameters.Add(AssetNumber1);\n\n        SqlDataAdapter sdaGetruntotals = new SqlDataAdapter();\n        sdaGetruntotals.SelectCommand = scGetruntotals;\n        sdaGetruntotals.Fill(dtGetruntotals);\n\n        return dtGetruntotals;\n    }\n    catch (Exception ex)\n    {\n        MessageBox.Show(\"Error Retriving totals Details: Processed with this error:\" + ex.Message);\n        return null;\n    }\n}\n\n",
        "all_answers": [
            "\nYou must remove the constraints from the column before removing the column. The name you are referencing is a default constraint. \ne.g. \nalter table CompanyTransactions drop constraint [df__CompanyTr__Creat__0cdae408];\nalter table CompanyTransactions drop column [Created];\n\n",
            "\nAdd timeout of your SqlCommand. Please note time is in second.\n// Setting command timeout to 1 second\nscGetruntotals.CommandTimeout = 1;\n\n",
            "\n\nit takes this command about 2 mins to return the data as there is a lot of data\n\nProbably, Bad Design. Consider using paging here. \n\ndefault connection time is 30 secs, how do I increase this\n\nAs you are facing a timeout on your command, therefore you need to increase the timeout of your sql command. You can specify it in your command like this\n// Setting command timeout to 2 minutes\nscGetruntotals.CommandTimeout = 120;\n\n",
            "\nThe @SqlZim's answer is correct but just to explain why this possibly have happened. I've had similar issue and this was caused by very innocent thing: adding default value to a column\nALTER TABLE MySchema.MyTable ADD \n  MyColumn int DEFAULT NULL;\n\nBut in the realm of MS SQL Server a default value on a colum is a CONSTRAINT. And like every constraint it has an identifier. And you cannot drop a column if it is used in a CONSTRAINT.\nSo what you can actually do avoid this kind of problems is always give your default constraints a explicit name, for example:\nALTER TABLE MySchema.MyTable ADD \n  MyColumn int NULL,\n  CONSTRAINT DF_MyTable_MyColumn DEFAULT NULL FOR MyColumn;\n\nYou'll still have to drop the constraint before dropping the column, but you will at least know its name up front.\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "sql",
            "ado.net",
            "connection-timeout"
        ]
    },
    {
        "question_id": "2588241",
        "question": "\nAnyone have any \"best practices\" tips for Rails and sessions? The default session type for Rails 3 is still CookieStore, right? I used SqlSessionStore for a while and it worked well, but I may move away from that in favor of CookieStore. \nIs it still not a good idea to use CookieStore for sensitive info, even with salted info or is that better stored in the DB?\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nUse the database for sessions instead of the cookie-based default, which shouldn't be used to store highly confidential information\nCreate the session table with\nrake db:sessions:create\n\nRun the migration\nrake db:migrate\n\nMake sure you also tell rails to use ActiveRecord to manage your sessions too.\nRails 3\nconfig/initializers/session_store.rb:\nRails.application.config.session_store :active_record_store\n\nRails 2\nconfig/environment.rb:\nconfig.action_controller.session_store = :active_record_store\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nI don't believe anything has changed in how anyone on any platform should handle cookie based sessions.  Be skeptical of anything that passes beyond the server's control (cookies, form posts, etc.)  Thats a general principle of web development.\nAs far the encryption, I don't know if anything has changed on that front.\nSomething to be mindful of with a cookie store is the limit to the amount of data, and the gotcha that this data will be sent on the wire in every request, where as a database store only transfers the id and the data lives on the server.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "session",
            "cookies"
        ]
    },
    {
        "question_id": "7795809",
        "question": "\nI am developing a new Rails app based on a similar existing one. In my old app, I have Coupon class, which is very similar to Ticket in my new app. I want to reuse all code in Coupon, but with a new class name.\nSince refactoring is cumbersome in Rails, I wonder if there is a way to create alias for a class in Ruby (similar to alias for attributes and methods).\n",
        "all_answers": [
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nClasses don't have names in Ruby. They are just objects assigned to variables, just like any other object. If you want to refer to a class via a different variable, assign it to a different variable:\nFoo = String\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nI agree with warhog, more or less - but I would subclass ticket from your coupon class - that way if you need to do any data munging, you can put the code in your ticket class\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "class",
            "alias"
        ]
    },
    {
        "question_id": "3823211",
        "question": "\nI have a matrix (32X48).\nHow can I convert the matrix into a single dimensional array?\n",
        "all_answers": [
            "\nYou can use Joshua's solution but I think you need Elts_int <- as.matrix(tmp_int)\nOr for loops: \nz <- 1 ## Initialize\ncounter <- 1 ## Initialize\nfor(y in 1:48) { ## Assuming 48 columns otherwise, swap 48 and 32\nfor (x in 1:32) {  \nz[counter] <- tmp_int[x,y]\ncounter <- 1 + counter\n}\n}\n\nz is a 1d vector. \n",
            "\nFrom ?matrix: \"A matrix is the special case of a two-dimensional 'array'.\"  You can simply change the dimensions of the matrix/array.\nElts_int <- as.matrix(tmp_int)  # read.table returns a data.frame as Brandon noted\ndim(Elts_int) <- (maxrow_int*maxcol_int,1)\n\n",
            "\nEither read it in with 'scan', or just do as.vector() on the matrix. You might want to transpose the matrix first if you want it by rows or columns. \n> m=matrix(1:12,3,4)\n> m\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n> as.vector(m)\n [1]  1  2  3  4  5  6  7  8  9 10 11 12\n> as.vector(t(m))\n [1]  1  4  7 10  2  5  8 11  3  6  9 12\n\n",
            "\ncbindX from the package gdata combines multiple columns of differing column and row lengths. Check out the page here:\nhttp://hosho.ees.hokudai.ac.jp/~kubo/Rdoc/library/gdata/html/cbindX.html\nIt takes multiple comma separated matrices and data.frames as input :) You just need to \ninstall.packages(\"gdata\", dependencies=TRUE)\nand then\nlibrary(gdata)\nconcat_data <- cbindX(df1, df2, df3) # or cbindX(matrix1, matrix2, matrix3, matrix4)\n\n",
            "\nSounds like you're looking for rbind:\n> a<-matrix(nrow=10,ncol=5)\n> b<-matrix(nrow=20,ncol=5)\n> dim(rbind(a,b))\n[1] 30  5\n\nSimilarly, cbind stacks the matrices horizontally.\nI am not entirely sure what you mean by the last question (\"Can I do this for matrices of different rows and columns.?\")\n"
        ],
        "answer": "A3",
        "tags": [
            "arrays",
            "r",
            "matrix"
        ]
    },
    {
        "question_id": "122316",
        "question": "\nIn C# we can define a generic type that imposes constraints on the types that can be used as the generic parameter. The following example illustrates the usage of generic constraints:\ninterface IFoo\n{\n}\n\n\nclass Foo<T> where T : IFoo\n{\n}\n\nclass Bar : IFoo\n{\n}\n\nclass Simpson\n{\n}\n\nclass Program\n{\n    static void Main(string[] args)\n    {\n        Foo<Bar> a = new Foo<Bar>();\n        Foo<Simpson> b = new Foo<Simpson>(); // error CS0309\n    }\n}\n\nIs there a way we can impose constraints for template parameters in C++.\n\nC++0x has native support for this but I am talking about current standard C++.\n",
        "all_answers": [
            "\nSort of.  If you static_cast to an IFoo*, then it will be impossible to instantiate the template unless the caller passes a class that can be assigned to an IFoo *.\n",
            "\ntypeid(T).name() is implementation defined and doesn't guarantee human readable string.\nReading cppreference.com :\n\nReturns an implementation defined null-terminated character string\n  containing the name of the type. No guarantees are given, in\n  particular, the returned string can be identical for several types and\n  change between invocations of the same program.\n...\nWith compilers such as gcc and clang, the returned string can be piped through c++filt -t to be converted to human-readable form. \n\nBut in some cases gcc doesn't return right string. For example on my machine I have gcc whith -std=c++11 and inside template function typeid(T).name() returns \"j\" for \"unsigned int\". It's so called mangled name. To get real type name, use \n abi::__cxa_demangle() function (gcc only):\n#include <string>\n#include <cstdlib>\n#include <cxxabi.h>\n\ntemplate<typename T>\nstd::string type_name()\n{\n    int status;\n    std::string tname = typeid(T).name();\n    char *demangled_name = abi::__cxa_demangle(tname.c_str(), NULL, NULL, &status);\n    if(status == 0) {\n        tname = demangled_name;\n        std::free(demangled_name);\n    }   \n    return tname;\n}\n\n",
            "\nOnly implicitly.\nAny method you use in a method that is actually called is imposed on the template parameter.  \n",
            "\nThe solution is:\ntypeid(T).name()\n\nwhere typeid(T) returns std::type_info.\n",
            "\nAs someone else has mentioned, C++0x is getting this built into the language.  Until then, I'd recommend Bjarne Stroustrup's suggestions for template constraints.\nEdit: Boost also has an alternative of its own.\nEdit2: Looks like concepts have been removed from C++0x.\n",
            "\nCheck out Boost\n\nThe Boost Concept Check Library (BCCL)\nThe Concept Check library allows one to add explicit statement and checking of concepts in the style of the proposed C++ language extension.\n\n",
            "\nJesse Beder's solution is likely the best, but if you don't like the names typeid gives you (I think gcc gives you mangled names for instance), you can do something like:\ntemplate<typename T>\nstruct TypeParseTraits;\n\n#define REGISTER_PARSE_TYPE(X) template <> struct TypeParseTraits<X> \\\n    { static const char* name; } ; const char* TypeParseTraits<X>::name = #X\n\n\nREGISTER_PARSE_TYPE(int);\nREGISTER_PARSE_TYPE(double);\nREGISTER_PARSE_TYPE(FooClass);\n// etc...\n\nAnd then use it like\nthrow ParseError(TypeParseTraits<T>::name);\n\nEDIT:\nYou could also combine the two, change name to be a function that by default calls typeid(T).name() and then only specialize for those cases where that's not acceptable.\n"
        ],
        "answer": "A5",
        "tags": [
            "c++",
            "templates",
            "constraints"
        ]
    },
    {
        "question_id": "22752777",
        "question": "\nI'm trying to manually execute SQL commands so I can access procedures in NuoDB.\nI'm using Ruby on Rails and I'm using the following command:\nActiveRecord::Base.connection.execute(\"SQL query\")\n\nThe \"SQL query\" could be any SQL command.\nFor example, I have a table called \"Feedback\" and when I execute the command:\nActiveRecord::Base.connection.execute(\"SELECT `feedbacks`.* FROM `feedbacks`\")\n\nThis would only return a \"true\" response instead of sending me all the data requested.\nThis is the output on the Rails Console is:\nSQL (0.4ms)  SELECT `feedbacks`.* FROM `feedbacks`\n => true\n\nI would like to use this to call stored procedures in NuoDB but upon calling the procedures, this would also return a \"true\" response.\nIs there any way I can execute SQL commands and get the data requested instead of getting a \"true\" response?\n",
        "all_answers": [
            "\nThe working command I'm using to execute custom SQL statements is:\nresults = ActiveRecord::Base.connection.execute(\"foo\")\n\nwith \"foo\" being the sql statement( i.e. \"SELECT * FROM table\").\nThis command will return a set of values as a hash and put them into the results variable.\nSo on my rails application_controller.rb I added this:\ndef execute_statement(sql)\n  results = ActiveRecord::Base.connection.execute(sql)\n\n  if results.present?\n    return results\n  else\n    return nil\n  end\nend\n\nUsing execute_statement will return the records found and if there is none, it will return nil.\nThis way I can just call it anywhere on the rails application like for example:\nrecords = execute_statement(\"select * from table\")\n\n\"execute_statement\" can also call NuoDB procedures, functions, and also Database Views.\n",
            "\nPostgreSQL is more SQL compliant than MySQL. All fields - except computed field with aggregation function - in the output must be present in the GROUP BY clause.\n",
            "\nres = ActiveRecord::Base.connection_pool.with_connection { |con| con.exec_query( \"SELECT 1;\" ) }\n\nThe above code is an example for\n\nexecuting arbitrary SQL on your database-connection\nreturning the connection back to the connection pool afterwards\n\n",
            "\nReposting the answer from our forum to help others with a similar issue:\n@connection = ActiveRecord::Base.connection\nresult = @connection.exec_query('select tablename from system.tables')\nresult.each do |row|\nputs row\nend\n\n",
            "\nMySQL's GROUP BY can be used without an aggregate function (which is contrary to the SQL standard), and returns the first row in the group (I don't know based on what criteria), while PostgreSQL must have an aggregate function (MAX, SUM, etc) on the column, on which the GROUP BY clause is issued.\n",
            "\nMySQL's totally non standards compliant GROUP BY can be emulated by Postgres' DISTINCT ON. Consider this:\nMySQL:\nSELECT a,b,c,d,e FROM table GROUP BY a\n\nThis delivers 1 row per value of a (which one, you don't really know). Well actually you can guess, because MySQL doesn't know about hash aggregates, so it will probably use a sort... but it will only sort on a, so the order of the rows could be random. Unless it uses a multicolumn index instead of sorting. Well, anyway, it's not specified by the query.\nPostgres:\nSELECT DISTINCT ON (a) a,b,c,d,e FROM table ORDER BY a,b,c\n\nThis delivers 1 row per value of a, this row will be the first one in the sort according to the ORDER BY specified by the query. Simple.\nNote that here, it's not an aggregate I'm computing. So GROUP BY actually makes no sense. DISTINCT ON makes a lot more sense.\nRails is married to MySQL, so I'm not surprised that it generates SQL that doesn't work in Postgres.\n"
        ],
        "answer": "A1",
        "tags": [
            "sql",
            "ruby-on-rails",
            "activerecord",
            "nuodb"
        ]
    },
    {
        "question_id": "4597050",
        "question": "\nHow could I do something like this:\n<script type=\"text/javascript\">\n$(document).ready(function () {\n    if(window.location.contains(\"franky\")) // This doesn't work, any suggestions?\n    {\n         alert(\"your url contains the name franky\");\n    }\n});\n</script>\n\n",
        "all_answers": [
            "\nYou need add href property and check indexOf instead of contains\n\n\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n<script type=\"text/javascript\">\r\n  $(document).ready(function() {\r\n    if (window.location.href.indexOf(\"franky\") > -1) {\r\n      alert(\"your url contains the name franky\");\r\n    }\r\n  });\r\n</script>\n\n\n\n",
            "\nYou would use indexOf like this:\nif(window.location.href.indexOf(\"franky\") != -1){....}\n\nAlso notice the addition of href for the string otherwise you would do:\nif(window.location.toString().indexOf(\"franky\") != -1){....}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "jquery",
            "url"
        ]
    },
    {
        "question_id": "1947933",
        "question": "\nIn Android, I am trying to get the selected Spinner value with a listener.\nWhat is the best way to get the spinner's value?\n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nThe Spinner should fire an \"OnItemSelected\" event when something is selected:\nspinner.setOnItemSelectedListener(new AdapterView.OnItemSelectedListener() {\n    public void onItemSelected(AdapterView<?> parent, View view, int pos, long id) {\n        Object item = parent.getItemAtPosition(pos);\n    }\n    public void onNothingSelected(AdapterView<?> parent) {\n    }\n});\n\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nYes, you can register a listener via setOnItemSelectedListener(), as is demonstrated here.\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nSpinner mySpinner = (Spinner) findViewById(R.id.your_spinner);\nString text = mySpinner.getSelectedItem().toString();\n\n"
        ],
        "answer": "A8",
        "tags": [
            "android",
            "spinner"
        ]
    },
    {
        "question_id": "32561435",
        "question": "\nI want to make sure the button text fits into a UIButton, while the UIButton has a fixed size. \nOf course I can access the titleLabel of the UIButton.\nIn a label I would set autoshrink to minimum font scale which seems to correspond to \nself.myButton.titleLabel.adjustsFontSizeToFitWidth = YES;\n\n, but doesn't really behave the same, since it only makes the text fits horizontally into the bounds, not vertically, thereby not changing the font size.\nHow can i actually adjust the font size of a label programmatically to make the text fit into the label bounds (as shown in  Goal  in the picture below) ?\n\nI already tried \nself.myButton.titleLabel.numberOfLines = 0;\nself.myButton.titleLabel.minimumScaleFactor = 0.5f;\n\nwithout success, always ended up as in adjustsFontSizeToFitWidth on the left side of the pic above.\nEdit: The solution also has to be ios7 compliant\n",
        "all_answers": [
            "\nself.mybutton.titleLabel.minimumScaleFactor = 0.5f;\nself.mybutton.titleLabel.numberOfLines = 0;   <-- Or to desired number of lines\nself.mybutton.titleLabel.adjustsFontSizeToFitWidth = YES;\n\n... did the trick, after layoutIfNeeded in viewDidLoad\nAs it turns out, all those must be set to actually adjust the font-size, not just making it fit into the frame.\nUpdate for Swift 3:\nmybutton.titleLabel?.minimumScaleFactor = 0.5\nmybutton.titleLabel?.numberOfLines = 0   <-- Or to desired number of lines\nmybutton.titleLabel?.adjustsFontSizeToFitWidth = true\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nTry to call the following method.\nbutton.titleLabel?.baselineAdjustment = UIBaselineAdjustment.AlignCenters\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "objective-c",
            "swift",
            "uibutton",
            "uilabel"
        ]
    },
    {
        "question_id": "1259219",
        "question": "\nIn a model I have a such field:\nmydate = models.DateField()\nnow a javascript graph function requires unix timestamp such as \"1196550000000\", how can I return the unix timestamp of my mydate input.\nThanks\n",
        "all_answers": [
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nIn your views.py, you can convert the value of mydate to seconds since the Unix epoch as follows:\nseconds = time.mktime(mydate.timetuple())\n\nThen pass it in the dictionary you use as an argument to render_to_response() (or whatever you're using to render your view), and in your template, stick {{seconds}} into a hidden field, which you can then pull out of the DOM to pass to your javascript graph function.\nNote that a DateField maps to the Python object datetime.date, and as such, its timetuple will have its hours, minutes and seconds fields set to 0. If that's not fine-grained enough for you, you'll need to change mydate to a DateTimeField and it'll be a datetime.datetime. You can still use mydate.timetuple() if you do this.\nAlso, I'm assuming you're using local time. If you're using UTC time, you want calendar.gmtime() rather than time.mktime() and mydate.utctimetuple() rather than mydate.timetuple(), but utctimetuple() is only a valid method for datetime.datetime objects. See the datetime docs (also time and calendar) for more fiddly details.\nEDIT: fiddly details such as the fact that mktime() returns a float, which piquadrat remembered and I didn't. The custom-filter approach is also a good one. Voting that one up.\n",
            "\nedit: please check the second answer, it has a much better solution\nIn python code, you can do this to convert a date or datetime to the Unix Epoch\nimport time\nepoch = int(time.mktime(mydate.timetuple())*1000)\n\nThis doesn't work in a Django template though, so you need a custom filter, e.g:\nimport time\n\nfrom django import template\n\nregister = template.Library()\n\n@register.filter\ndef epoch(value):\n    try:\n        return int(time.mktime(value.timetuple())*1000)\n    except AttributeError:\n        return ''\n\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "django",
            "unix-timestamp"
        ]
    },
    {
        "question_id": "4785107",
        "question": "\nI'm trying to pull code from my GitHub repo onto my server, but the pull keeps failing because of merge conflicts. I don't want to keep any of the changes that may have occurred on my local server since the last pull.\nSo is there a way I can force Git to overwrite with whatever version is in GitHub, rather than bother me about conflicts?\n",
        "all_answers": [
            "\nIf you truly want to discard the commits you've made locally, i.e. never have them in the history again, you're not asking how to pull - pull means merge, and you don't need to merge. All you need do is this:\n# fetch from the default remote, origin\ngit fetch\n# reset your current branch (master) to origin's master\ngit reset --hard origin/master\n\nI'd personally recommend creating a backup branch at your current HEAD first, so that if you realize this was a bad idea, you haven't lost track of it.\nIf on the other hand, you want to keep those commits and make it look as though you merged with origin, and cause the merge to keep the versions from origin only, you can use the ours merge strategy:\n# fetch from the default remote, origin\ngit fetch\n# create a branch at your current master\ngit branch old-master\n# reset to origin's master\ngit reset --hard origin/master\n# merge your old master, keeping \"our\" (origin/master's) content\ngit merge -s ours old-master\n\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nYou can either use the answer from the duplicate link pointed by nvm.\nOr you can resolve conflicts by using their changes (but some of your changes might be kept if they don't conflict with remote version):\ngit pull -s recursive -X theirs\n\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n"
        ],
        "answer": "A1",
        "tags": [
            "git",
            "git-pull"
        ]
    },
    {
        "question_id": "20939648",
        "question": "\nI created a new repository on Github which has only Readme.md file now.\nI have a newly created RoR project which I wanted to push to this repository.\nFollowing are the commands I gave in my Terminal to execute this along with the error I am getting.\ngit remote add origin https://github.com/aniruddhabarapatre/learn-rails.git\n\nAfter which I entered my username and password\ngit push -u origin master\n\nError ---\nTo https://github.com/aniruddhabarapatre/learn-rails.git\n ! [rejected]        master -> master (fetch first)\nerror: failed to push some refs to 'https://github.com/aniruddhabarapatre/learn-rails.git'\nhint: Updates were rejected because the remote contains work that you do\nhint: not have locally. This is usually caused by another repository pushing\nhint: to the same ref. You may want to first merge the remote changes (e.g.,\nhint: 'git pull') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\n\nThis is my first time pushing my code to a Github repository and I'm lost with the errors. I searched few other questions that are asked here, but none of them had issues first time.\n",
        "all_answers": [
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nWhen you created your repository on GitHub, you created a README.md, which is a new commit.\nYour local repository doesn't know about this commit yet. Hence:\n\nUpdates were rejected because the remote contains work that you do\n  not have locally.\n\nYou may want to find to follow this advice:\n\nYou may want to first merge the remote changes (e.g.,\n  'git pull') before pushing again.\n\nThat is:\ngit pull\n# Fix any merge conflicts, if you have a `README.md` locally\ngit push -u origin master\n\n",
            "\nAssuming that you added the Readme.md file through the interface provided by github, the readme is not yet in your local folder.  Hence, when you try to push to the remote repo, you get an error, because your local repo is lacking the readme file - it's \"behind the times\", so to speak.  Hence, as is suggested in the error message, try \"git pull\" first.  This will pull the readme from the remote repository and merge it with your local directory.  After that, you should have no problem pushing to the remote repo  (the commands you posted look valid to me).\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n"
        ],
        "answer": "A4",
        "tags": [
            "git",
            "github",
            "git-push"
        ]
    },
    {
        "question_id": "25101009",
        "question": "\nAssume I have this model:  \nclass Conversation < ActiveRecord::Base\n  enum status: [ :active, :archived ]\nend\n\nHow can I find all active conversations without using the numeric value of the enum or without having to iterate over each conversation?  \nI tried doing Conversation.where(status: :active), but it didn't yield any results.  \nThe only solution comes to mind is to iterate over all conversations and select the active ones, but it doesn't look like a good solution.\nConversation.all.select {|conversation| conversation.active? }  \n\nIs there anything I can do about this?\n",
        "all_answers": [
            "\nActiveRecord::Enum provides built-in scopes based on the values so you can simply do:\nConversation.active\nConversation.archived\n\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nActiveRecord::Enum provides scopes based on its values.  \nJust try:\nConversation.active\n\nor\nConversation.archived\n\nOf course, you can create your own scopes as Kyle Decot mentioned. \n",
            "\nConversation.where(status: Conversation.statuses[:active])\n\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "ruby-on-rails-4",
            "rails-activerecord",
            "ruby-on-rails-4.1"
        ]
    },
    {
        "question_id": "2443752",
        "question": "\nI'm trying to display uploaded images in \"Change List\" page in Django Admin:\n\nThis is my code below:\n# \"models.py\"\n\nfrom django.db import models\n\nclass Product(models.Model):\n    name = models.CharField(max_length=50)\n    price = models.DecimalField(decimal_places=2, max_digits=5)\n    image = models.ImageField()\n        \n    def __str__(self):\n        return self.name\n\n# \"admin.py\"\n\nfrom django.contrib import admin\nfrom .models import Product\n\n@admin.register(Product)\nclass ProductAdmin(admin.ModelAdmin):\n    list_display = ('name', 'price', 'image',)\n\nSo, how can I display uploaded images in \"Change List\" page in Django Admin?\n",
        "all_answers": [
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nYou can create a model instance method with another name, allow HTML tags for its output and add this method as a list field. Here is an example:\nFirst add a new method returning the HTML for the image inclusion:\nclass Article(models.Model):\n    ...\n    def admin_image(self):\n        return '<img src=\"%s\"/>' % self.img\n    admin_image.allow_tags = True\n\nThen add this method to the list:\nclass ArticleAdmin(admin.ModelAdmin):    \n    ...\n    list_display = ('url', 'title', 'admin_image')\n\n",
            "\nYou can overwrite django admin view for your model. See http://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-admin-templates for more details.\nIn a brief you need to create a template: templates/admin/your_app/article/change_form.html\nAnd there add html to display the image.\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django",
            "django-models",
            "django-admin",
            "changelist"
        ]
    },
    {
        "question_id": "10586003",
        "question": "\nI was thinking today about the try/catch blocks existent in another languages. Googled for a while this but with no result. From what I know, there is not such a thing as try/catch in C. However, is there a way to \"simulate\" them?\nSure, there is assert and other tricks but nothing like try/catch, that also catch the raised exception. Thank you\n",
        "all_answers": [
            "\nA quick google search yields kludgey solutions such as this that use setjmp/longjmp as others have mentioned.  Nothing as straightforward and elegant as C++/Java's try/catch.  I'm rather partial to Ada's exception handling myself.\nCheck everything with if statements :)\n",
            "\nYou can use GCC's nested functions to simulate lambda expressions, in fact, I have a macro to do it for me:\n#define lambda(return_type, function_body) \\\n  ({ \\\n    return_type anon_func_name_ function_body \\\n    anon_func_name_; \\\n  })\n\nUse like this:\nint (*max)(int, int) = lambda (int, (int x, int y) { return x > y ? x : y; });\n\n",
            "\nFunctional programming is not about lambdas, it is all about pure functions.  So the following broadly promote functional style:\n\nOnly use function arguments, do not use global state.\nMinimise side effects i.e. printf, or any IO.  Return data describing IO which can be executed instead of causing the side effects directly in all functions.  \n\nThis can be achieved in plain c, no need for magic.\n",
            "\nFFCALL lets you build closures in C -- callback = alloc_callback(&function, data) returns a function pointer such that callback(arg1, ...) is equivalent to calling function(data, arg1, ...).  You will have to handle garbage collection manually, though.\nRelatedly, blocks have been added to Apple's fork of GCC; they're not function pointers, but they let you pass around lambdas while avoiding the need to build and free storage for captured variables by hand (effectively, some copying and reference counting happens, hidden behind some syntactic sugar and runtime libraries).\n",
            "\nYou use goto in C for similar error handling situations.\nThat is the closest equivalent of exceptions you can get in C.\n",
            "\nThis can be done with setjmp/longjmp in C. P99 has a quite comfortable toolset for this that also is consistent with the new thread model of C11.\n",
            "\nIn C99, you can use setjmp/longjmp for non-local control flow.\nWithin a single scope, the generic, structured coding pattern for C in the presence of multiple resource allocations and multiple exits uses goto, like in this example. This is similar to how C++ implements destructor calls of automatic objects under the hood, and if you stick to this diligently, it should allow you for a certain degree of cleanness even in complex functions.\n",
            "\nHartel & Muller's book, Functional C, can nowadays (2012-01-02) be found at: http://eprints.eemcs.utwente.nl/1077/ (there is a link to PDF version).\n",
            "\nC itself doesn't support exceptions but you can simulate them to a degree with setjmp and longjmp calls.\nstatic jmp_buf s_jumpBuffer;\n\nvoid Example() { \n  if (setjmp(s_jumpBuffer)) {\n    // The longjmp was executed and returned control here\n    printf(\"Exception happened here\\n\");\n  } else {\n    // Normal code execution starts here\n    Test();\n  }\n}\n\nvoid Test() {\n  // Rough equivalent of `throw`\n  longjmp(s_jumpBuffer, 42);\n}\n\nThis website has a nice tutorial on how to simulate exceptions with setjmp and longjmp \n\nhttp://www.di.unipi.it/~nids/docs/longjump_try_trow_catch.html\n\n"
        ],
        "answer": "A9",
        "tags": [
            "c"
        ]
    },
    {
        "question_id": "7759200",
        "question": "\nTake this object:\nx = {\n \"key1\": \"xxx\",\n \"key2\": function(){return this.key1}\n}\n\nIf I do this:\ny = JSON.parse( JSON.stringify(x) );\n\nThen y will return { \"key1\": \"xxx\" }. Is there anything one could do to transfer functions via stringify? Creating an object with attached functions is possible with the \"ye goode olde eval()\", but whats with packing it?\n",
        "all_answers": [
            "\nvar array = new Array(); // or the shortcut: = []\narray.push ( {\"cool\":\"34.33\",\"also cool\":\"45454\"} );\narray.push (  {\"cool\":\"34.39\",\"also cool\":\"45459\"} );\n\nYour variable is a javascript object {} not an array [].\nYou could do:\nvar o = {}; // or the longer form: = new Object()\no.SomeNewProperty = \"something\";\no[\"SomeNewProperty\"] = \"something\";\n\nand\nvar o = { SomeNewProperty: \"something\" };\nvar o2 = { \"SomeNewProperty\": \"something\" };\n\nLater, you add those objects to your array: array.push (o, o2);\nAlso JSON is simply a string representation of a javascript object, thus:\nvar json = '{\"cool\":\"34.33\",\"alsocool\":\"45454\"}'; // is JSON\nvar o = JSON.parse(json); // is a javascript object\njson = JSON.stringify(o); // is JSON again\n\n",
            "\nTechnically this is not JSON, I can also hardly imagine why would you want to do this, but try the following hack:\nx.key2 = x.key2.toString();\nJSON.stringify(x)  //\"{\"key1\":\"xxx\",\"key2\":\"function (){return this.key1}\"}\"\n\nOf course the first line can be automated by iterating recursively over the object. Reverse operation is harder - function is only a string, eval will work, but you have to guess whether a given key contains a stringified function code or not.\n",
            "\nThat is an object, not an array. So you would do:\nvar json = { cool: 34.33, alsocool: 45454 };\njson.supercool = 3.14159;\nconsole.dir(json);\n\n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n",
            "\nYou can't pack functions since the data they close over is not visible to any serializer.\nEven Mozilla's uneval cannot pack closures properly.\nYour best bet, is to use a reviver and a replacer.\nhttps://yuilibrary.com/yui/docs/json/json-freeze-thaw.html\n\nThe reviver function passed to JSON.parse is applied to all key:value pairs in the raw parsed object from the deepest keys to the highest level. In our case, this means that the name and discovered properties will be passed through the reviver, and then the object containing those keys will be passed through.\n\n",
            "\nobject[\"property\"] = value;\n\nor\nobject.property = value;\n\nObject and Array in JavaScript are different in terms of usage.  Its best if you understand them:  \nObject vs Array: JavaScript\n",
            "\nTo my knowledge, there are no serialization libraries that persist functions - in any language.  Serialization is what one does to preserve data.  Compilation is what one does to preserve functions.\n"
        ],
        "answer": "A5",
        "tags": [
            "javascript",
            "json",
            "object"
        ]
    },
    {
        "question_id": "1672156",
        "question": "\n\n\n\n\nPossible Duplicate:\nHow to delete an element from an array in php? \n\nFor instance,\nArray(      \n    [0] => Array\n        (\n            [0] => hello\n            [1] => open\n        )\n\n    [1] => Array\n        (\n            [0] => good\n            [1] => center\n        )\n\n    [2] => Array\n        (\n            [0] => hello\n            [1] => close\n        )\n)\n\nI want to delete the element which key is 1, after the operation:\nArray(\n    [0] => Array\n        (\n            [0] => hello\n            [1] => open\n        )\n\n    [2] => Array\n        (\n            [0] => hello\n            [1] => close\n        )\n)\n\n",
        "all_answers": [
            "\nthis looks like PHP to me. I'll delete if it's some other language.\nSimply unset($arr[1]);\n",
            "\nYou don't say what language you're using, but looking at that output, it looks like PHP output (from print_r()).\nIf so, just use unset():\nunset($arr[1]);\n\n",
            "\nPHP\nunset($array[1]);\n\n"
        ],
        "answer": "A3",
        "tags": [
            "php",
            "arrays"
        ]
    },
    {
        "question_id": "390164",
        "question": "\nSay I need to call a javascript file in the <head> of an ERb template.\nMy instinct is to do the usual:\n<head>\n<%= javascript_include_tag :defaults %> <!-- For example -->\n</head>\n\nin my application's layout. The problem of course becoming that these javascript files are loaded into every page in my application, regardless of whether or not they are needed for the page being viewed.\nSo what I'm wondering is if there's a good way of loading a javascript into the the headers of, for example, all ERb templates found only in a specific directory.\n",
        "all_answers": [
            "\nI usually have the following in the layout file:\n<head>\n  <%= javascript_include_tag :defaults %> <!-- For example -->\n  <%= @extra_head_content %>\n</head>\n\nAnd then in the views:\n<% (@extra_head_content ||= \"\") += capture do %>\n  <%= other_content %>\n<% end %>\n\nSee the API documentation for #capture\n",
            "\nI would use content_for.\nFor instance, specify the place to insert it in the application layout:\n<head>\n<title>Merry Christmas!</title>\n<%= yield(:head) -%>\n</head>\n\nAnd send it there from a view:\n<%- content_for(:head) do -%>\n<%= javascript_include_tag :defaults -%>\n<%- end -%>\n\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "ruby-on-rails",
            "header",
            "rjs"
        ]
    },
    {
        "question_id": "24351102",
        "question": "\nIn Objective-C we use to do it like this\n+ (Class)layerClass\n{\n    return [CAEAGLLayer class];\n}\n\nObviously this won't work:\nCAEAGLLayer.class()\n\nBecause class is a keyword in Swift. How do you do it in Swift?\n",
        "all_answers": [
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nSwift does introspection much differently than Objective-C. You may want to take a look at the docs about Metatypes.\nFor your case I'd try: CAEAGLLayer.self\n",
            "\nYou actually don't need to use a web and app URL anymore. The web URL will automatically open in the app if the user has it. Instagram or other apps implement this on their end as a Universal Link\nSwift 4\nfunc openInstagram(instagramHandle: String) {\n    guard let url = URL(string: \"https://instagram.com/\\(instagramHandle)\")  else { return }\n    if UIApplication.shared.canOpenURL(url) {\n        if #available(iOS 10.0, *) {\n            UIApplication.shared.open(url, options: [:], completionHandler: nil)\n        } else {\n            UIApplication.shared.openURL(url)\n        }\n    }\n}\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nAdapted from Apple's ListerKit sample code:\noverride class func layerClass() -> AnyClass {\n    return CAEAGLLayer.self\n}\n\nUpdate for Swift 3:\noverride class var layerClass: AnyClass {\n    get {\n        return CAGradientLayer.self\n    }\n}\n\n"
        ],
        "answer": "A6",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "1065774",
        "question": "\nC++ Notes: Array Initialization has a nice list over initialization of arrays. I have a\nint array[100] = {-1};\n\nexpecting it to be full with -1's but its not, only first value is and the rest are 0's mixed with random values.\nThe code\nint array[100] = {0};\n\nworks just fine and sets each element to 0.\nWhat am I missing here.. Can't one initialize it if the value isn't zero ?\nAnd 2: Is the default initialization (as above) faster than the usual loop through the whole array and assign a value or does it do the same thing?\n",
        "all_answers": [
            "\nWith {} you assign the elements as they are declared; the rest is initialized with 0.\nIf there is no = {} to initalize, the content is undefined.\n",
            "\nUsing the syntax that you used,\nint array[100] = {-1};\n\nsays \"set the first element to -1 and the rest to 0\" since all omitted elements are set to 0.\nIn C++, to set them all to -1, you can use something like std::fill_n (from <algorithm>):\nstd::fill_n(array, 100, -1);\n\nIn portable C, you have to roll your own loop. There are compiler-extensions or you can depend on implementation-defined behavior as a shortcut if that's acceptable.\n",
            "\nstd::array is just a class version of the classic C array.  That means its size is fixed at compile time and it will be allocated as a single chunk (e.g. taking space on the stack).  The advantage it has is slightly better performance because there is no indirection between the object and the arrayed data.\nstd::vector is a small class containing pointers into the heap.  (So when you allocate a std::vector, it always calls new.)  They are slightly slower to access because those pointers have to be chased to get to the arrayed data...  But in exchange for that, they can be resized and they only take a trivial amount of stack space no matter how large they are.\n[edit]\nAs for when to use one over the other, honestly std::vector is almost always what you want.  Creating large objects on the stack is generally frowned upon, and the extra level of indirection is usually irrelevant.  (For example, if you iterate through all of the elements, the extra memory access only happens once at the start of the loop.)\nThe vector's elements are guaranteed to be contiguous, so you can pass &vec[0] to any function expecting a pointer to an array; e.g., C library routines.  (As an aside, std::vector<char> buf(8192); is a great way to allocate a local buffer for calls to read/write or similar without directly invoking new.)\nThat said, the lack of that extra level of indirection, plus the compile-time constant size, can make std::array significantly faster for a very small array that gets created/destroyed/accessed a lot.\nSo my advice would be:  Use std::vector unless (a) your profiler tells you that you have a problem and (b) the array is tiny.\n"
        ],
        "answer": "A2",
        "tags": [
            "c++",
            "arrays",
            "initialization",
            "variable-assignment",
            "default-value"
        ]
    },
    {
        "question_id": "36358265",
        "question": "\nUsing git branch --all shows all remote and local branches. When does Git refresh this list?\nOn pull/push? And how do I refresh it using Git Bash?\n",
        "all_answers": [
            "\nAs the message says:\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nGit has a \"staging area\" where files need to be added before being committed, you can read an explanation of it here.\n\nFor your specific example, you can use:\ngit commit -am \"save arezzo files\"\n\n(note the extra a in the flags, can also be written as git commit -a -m \"message\" - both do the same thing)\nAlternatively, if you want to be more selective about what you add to the commit, you use the git add command to add the appropriate files to the staging area, and git status to preview what is about to be added (remembering to pay attention to the wording used).\nYou can also find general documentation and tutorials for how to use git on the git documentation page which will give more detail about the concept of staging/adding files.\n\nOne other thing worth knowing about is interactive staging - this allows you to add parts of a file to the staging area, so if you've made three distinct code changes (for related but different functionality), you can use interactive mode to split the changes and add/commit each part in turn. Having smaller specific commits like this can be helpful.\n",
            "\nI believe that if you run git branch --all from Bash that the list of remote and local branches you see will reflect what your local Git \"knows\" about at the time you run the command.  Because your Git is always up to date with regard to the local branches in your system, the list of local branches will always be accurate.\nHowever, for remote branches this need not be the case.  Your local Git only knows about remote branches which it has seen in the last fetch (or pull).  So it is possible that you might run git branch --all and not see a new remote branch which appeared after the last time you fetched or pulled.\nTo ensure that your local and remote branch list be up to date you can do a git fetch before running git branch --all.\nFor further information, the \"remote\" branches which appear when you run git branch --all are not really remote at all; they are actually local.  For example, suppose there be a branch on the remote called feature which you have pulled at least once into your local Git.  You will see origin/feature listed as a branch when you run git branch --all.  But this branch is actually a local Git branch.  When you do git fetch origin, this tracking branch gets updated with any new changes from the remote.  This is why your local state can get stale, because there may be new remote branches, or your tracking branches can become stale.\n",
            "\nI copied a small sub project I had that was under Git source control into another project and forgot to delete the .git folder. When I went to commit I got the same message as above and couldn't clear it until I deleted the .git folder.\nIt is a bit silly, but it is worth checking you don't have a .git folder under the folder that doesn't commit.\n",
            "\nYou didn't add the changes. Either specifically add them via\ngit add filename1 filename2\n\nor add all changes (from root path of the project)\ngit add .\n\nor use the shorthand -a while commiting:\ngit commit -a -m \"message\".\n\n",
            "\nYou should do:\ngit commit . -m \"save arezzo files\"\n\n",
            "\nTo update the local list of remote branches:\ngit remote update origin --prune\n\nTo show all local and remote branches that (local) Git knows about:\ngit branch -a\n\n"
        ],
        "answer": "A6",
        "tags": [
            "git",
            "github",
            "branch",
            "remote-branch"
        ]
    },
    {
        "question_id": "26298821",
        "question": "\nI need to test the Photo model of my Django application. How can I mock the ImageField with a test image file?\ntests.py\nclass PhotoTestCase(TestCase):\n\n    def test_add_photo(self):\n        newPhoto = Photo()\n        newPhoto.image = # ??????\n        newPhoto.save()\n        self.assertEqual(Photo.objects.count(), 1)\n\n",
        "all_answers": [
            "\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['62.63.141.41', 'namjoosadr.com']\n\nand then restart your apache. in ubuntu:\n/etc/init.d/apache2 restart\n\n",
            "\nFor future users, I've solved the problem.\nYou can mock an ImageField with a SimpleUploadedFile instance.\ntest.py\nfrom django.core.files.uploadedfile import SimpleUploadedFile\n\nnewPhoto.image = SimpleUploadedFile(name='test_image.jpg', content=open(image_path, 'rb').read(), content_type='image/jpeg')\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nsettings.py\nALLOWED_HOSTS = ['*'] // if you are in dev or docker\n\nEdited\nOk guys, dont do this in production if you are not using docker, just put the IP addr.\nGrettings\n",
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n",
            "\nTell the mock library to create a mock object based on Django's File class\nimport mock\nfrom django.core.files import File\n\nfile_mock = mock.MagicMock(spec=File, name='FileMock')\n\nand then use in your tests \nnewPhoto.image = file_mock\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "django",
            "testing",
            "mocking"
        ]
    },
    {
        "question_id": "3517989",
        "question": "\nFor example, I'm using \"Bonus\" as my model, so I'd expect \"bonuses\" to be the plural form and \"bonus\" to be the singular form.\nHowever, in Ruby, this results in:\n\"bonus\".pluralize # bonus\n\"bonuses\".singularize # bonuse\n\nSo, when I do a \"has_many :bonuses\", for example, it doesn't use the Bonus.rb model (since Ruby expects a Bonuse.rb model instead). Is there a way to correct that in Ruby on Rails somehow such that \"bonuses\" acts as the plural form for the model bonus.rb?\n",
        "all_answers": [
            "\nJust to back up bcarlso, more on Inflector can be found here: \nhttp://4loc.wordpress.com/2009/04/09/inflector-rails-pluralization/\nNote that the position of the Inflector.inflections block is important and, as noted in the link reference, must be after the Initializer.run block.\n",
            "\nIn config/initializers, you will find a file called inflections.rb. There are some instructions in here, but you will want something along the lines of:\nActiveSupport::Inflector.inflections do |inflect|\n  inflect.irregular 'bonus', 'bonuses'\nend\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nI believe you use the Inflector in your environment.rb (memory's a bit sketchy though)\nIf I remember correctly you put it in a block\nInflector.inflections { | i | i.irregular 'bonus', 'bonuses' }\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby"
        ]
    },
    {
        "question_id": "496052",
        "question": "\nI have a select control, and in a javascript variable I have a text string.\nUsing jQuery I want to set the selected element of the select control to be the item with the text description I have (as opposed to the value, which I don't have).\nI know setting it by value is pretty trivial. e.g.\n$(\"#my-select\").val(myVal);\n\nBut I'm a bit stumped on doing it via the text description. I guess there must be a way of getting the value out from the text description, but my brain is too Friday afternoon-ed to be able to work it out.\n",
        "all_answers": [
            "\nGet the children of the select box; loop through them; when you have found the one you want, set it as the selected option; return false to stop looping.\n",
            "\nI haven't tested this, but this might work for you.\n$(\"select#my-select option\")\n   .each(function() { this.selected = (this.text == myVal); });\n\n",
            "\nSelect by description for jQuery v1.6+\n\n\nvar text1 = 'Two';\r\n$(\"select option\").filter(function() {\r\n  //may want to use $.trim in here\r\n  return $(this).text() == text1;\r\n}).prop('selected', true);\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n\r\n<select>\r\n  <option value=\"0\">One</option>\r\n  <option value=\"1\">Two</option>\r\n</select>\n\n\n\njQuery versions below 1.6 and greater than or equal to 1.4\n\n\nvar text1 = 'Two';\r\n$(\"select option\").filter(function() {\r\n  //may want to use $.trim in here\r\n  return $(this).text() == text1;\r\n}).attr('selected', true);\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/1.4.0/jquery.min.js\"></script>\r\n\r\n<select>\r\n  <option value=\"0\">One</option>\r\n  <option value=\"1\">Two</option>\r\n</select>\n\n\n\nNote that while this approach will work in versions that are above 1.6 but less than 1.9, it has been deprecated since 1.6. It will not work in jQuery 1.9+.\n\nPrevious versions\nval() should handle both cases.\n\n\n$('select').val('1'); // selects \"Two\"\r\n$('select').val('Two'); // also selects \"Two\"\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/1.2.3/jquery.min.js\"></script>\r\n\r\n<select>\r\n  <option value=\"0\">One</option>\r\n  <option value=\"1\">Two</option>\r\n</select>\n\n\n\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "jquery"
        ]
    },
    {
        "question_id": "50577437",
        "question": "\nI updated to gradle 4.0.1 and started receiving following error\n\nThe library com.google.android.gms:play-services-measurement-base is\n  being requested by various other libraries at [[15.0.4,15.0.4]], but\n  resolves to 15.0.2. Disable the plugin and check your dependencies\n  tree using ./gradlew :app:dependencies.\n\nMy project doesn't use that dependency so I searched globally for it, and it it only comes up inside\n\nbuild/intermediates/lint-cache/maven.google/com/google/android/gms/group-index.xml\n\nas this line\n<play-services-measurement-base versions=\"15.0.0,15.0.2\"/>\n\nSo I tried deleting my build folder and cleaning the project, but it regenerates it with same values :/ hence error still remains\n",
        "all_answers": [
            "\nYou can find the library pulling this dependancy using:\n$ ./gradlew app:dependencies\n\n",
            "\nEdit: August 15rd, 2023\nThe same issue seems to appear with the latest Android Studio Electric Giraffe where you need to specify the Gradle version to be 8.1.0 and Google Services 4.3.15. I have not tested if it's working with 5.0.0.\nplugins {\n    id 'com.android.application' version '8.1.0' apply false\n    id 'com.android.library' version '8.1.0' apply false\n}\n\ndependencies {\n    classpath 'com.google.gms:google-services:4.3.15'\n}\n\n\nEdit: March 24rd, 2023\nThe same issue seems to appear with the latest Android Studio Electric Eel where you need to specify the Gradle version to be 7.4.0 and Google Services 4.3.15.\nplugins {\n    id 'com.android.application' version '7.4.0' apply false\n    id 'com.android.library' version '7.4.0' apply false\n}\n\ndependencies {\n    classpath 'com.google.gms:google-services:4.3.15'\n}\n\n\nEdit: January 4th, 2023\nI have seen the same issue with the latest Android Studio Dolphin release, where you need to specify the Gradle version to be 7.3.1 and Google Services 4.3.14.\nplugins {\n    id 'com.android.application' version '7.3.1' apply false\n    id 'com.android.library' version '7.3.1' apply false\n}\n\ndependencies {\n    classpath 'classpath \"com.google.gms:google-services:4.3.14'\n}\n\n\nAccording to the new Chipmunk update of Android Studio, if you need to use Google Services, you have to add the following lines of code inside your build.gradle (Project) file:\nplugins {\n    id 'com.android.application' version '7.3.1' apply false\n    id 'com.android.library' version '7.3.1' apply false\n    id 'com.google.gms.google-services' version '4.3.14' apply false 👈\n}\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n\nAnd inside your build.gradle (Module) file, the following plugin IDs:\nplugins {\n    id 'com.android.application'\n    id 'com.google.gms.google-services' 👈\n}\n\n",
            "\nThe actual problem is discussed in the May, 23rd release note of https://developers.google.com/android/guides/releases#may_23_2018\nBasically, you need to bump all Play Services and Firebase libraries to their latest version (which may be different for each since version 15).\nYou may use https://mvnrepository.com/ to find the latest version for each library.\nSee also: https://firebase.google.com/support/release-notes/android#20180523\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "gradle",
            "android-gradle-plugin",
            "google-play-services"
        ]
    },
    {
        "question_id": "30342744",
        "question": "\nI need to extract numbers from string and put them into a new array in Swift.\nvar str = \"I have to buy 3 apples, 7 bananas, 10eggs\"\n\nI tried to loop each characters and I have no idea to compare between Characters and Int.\n",
        "all_answers": [
            "\nYou will want to use attributedString which allows you to style parts of a string etc. This can be done like this by having two styles, one normal, one bold, and then attaching them together:\nlet boldText = \"Filter:\"\nlet attrs = [NSAttributedString.Key.font : UIFont.boldSystemFont(ofSize: 15)]\nlet attributedString = NSMutableAttributedString(string:boldText, attributes:attrs)\n\nlet normalText = \"Hi am normal\"\nlet normalString = NSMutableAttributedString(string:normalText)\n\nattributedString.append(normalString)\n\nWhen you want to assign it to a label:\nlabel.attributedText = attributedString\n\n",
            "\n// This will only work with single digit numbers. Works with “10eggs” (no space between number and word\nvar str = \"I have to buy 3 apples, 7 bananas, 10eggs\"\nvar ints: [Int] = []\nfor char:Character in str {\n  if let int = \"\\(char)\".toInt(){\n    ints.append(int)\n  }\n}\n\nThe trick here is that you can check if a string is an integer (but you can’t check if a character is).\nBy looping though every character of the string, use string interpolation to create a string from the character and check if that string cas be casted as a integer.\nIf it can be, add it to the array.\n// This will work with multi digit numbers. Does NOT work with “10 eggs” (has to have a space between number and word)\nvar str = \"I have to buy 3 apples, 7 bananas, 10 eggs\"\nvar ints: [Int] = []\nvar strArray = split(str) {$0 == \" \"}\nfor subString in strArray{\n  if let int = subString.toInt(){\n    ints.append(int)\n  }\n}\n\nHere we split the string at any space and create an array of every substring that is in the long string.\nWe again check every string to see if it is (or can be casted as) an integer.\n",
            "\nFirst, we split the string so we can process the single items. Then we use NSCharacterSet to select the numbers only.     \nimport Foundation\n\nlet str = \"I have to buy 3 apples, 7 bananas, 10eggs\"\nlet strArr = str.split(separator: \" \")\n\nfor item in strArr {\n    let part = item.components(separatedBy: CharacterSet.decimalDigits.inverted).joined()\n\n    if let intVal = Int(part) {\n        print(\"this is a number -> \\(intVal)\")\n    }\n}\n\nSwift 4:\nlet string = \"I have to buy 3 apples, 7 bananas, 10eggs\"\nlet stringArray = string.components(separatedBy: CharacterSet.decimalDigits.inverted)\nfor item in stringArray {\n    if let number = Int(item) {\n        print(\"number: \\(number)\")\n    }\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "string",
            "swift",
            "integer",
            "character"
        ]
    },
    {
        "question_id": "39332010",
        "question": "\nI'm using Django's command to perform some tasks involving database manipulation:\nclass SomeCommand(BaseCommand):\n    @transaction.atomic\n    def handle(self, *args, **options):\n        # Some stuff on the database\n\nIf an exception is thrown during execution of my program, @transaction.atomic guarantees rollback. Can I force this behavior without throwing exception? Something like:\n# Doing some stuff, changing objects\n\nif some_condition:\n    # ABANDON ALL CHANGES AND RETURN\n\n",
        "all_answers": [
            "\nOne way to do this is to create a method on the Model itself and reference it in the serializer:\n#Models.py\nclass MyModel(models.Model):\n    #...\n    def my_filtered_field (self):\n            return self.othermodel_set.filter(field_a = 'value_a').order_by('field_b')[:10]\n#Serialziers.py\nclass MyModelSerialzer(serializers.ModelSerializer):\n    my_filtered_field = OtherModelSerializer (many=True, read_only=True)\n    class Meta:\n        model   = MyModel\n        fields  = [\n            'my_filtered_field'             ,\n            #Other fields ...\n        ]\n\n",
            "\nJust call transaction.rollback().\n\nCalling transaction.rollback() rolls back the entire transaction. Any uncommitted database operations will be lost.\n\nYou can see example in the docs.\n",
            "\ntransaction.set_rollback can do this.\nclass SomeCommand(BaseCommand):\n    @transaction.atomic\n    def handle(self, *args, **options):\n        # Doing some stuff, changing objects\n        if some_condition:\n            # Return, rolling back transaction when atomic block exits\n            transaction.set_rollback(True)\n            return\n\nQuoting from the docs:\n\nSetting the rollback flag to True forces a rollback when exiting the innermost atomic block. This may be useful to trigger a rollback without raising an exception.\n\n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n"
        ],
        "answer": "A3",
        "tags": [
            "django"
        ]
    },
    {
        "question_id": "18946662",
        "question": "\nI've been hearing a lot about the PyPy project. They claim it is 6.3 times faster than the CPython interpreter on their site.\nWhenever we talk about dynamic languages like Python, speed is one of the top issues. To solve this, they say PyPy is 6.3 times faster.\nThe second issue is parallelism, the infamous Global Interpreter Lock (GIL). For this, PyPy says it can give GIL-less Python.\nIf PyPy can solve these great challenges, what are its weaknesses that are preventing wider adoption? That is to say, what's preventing someone like me, a typical Python developer, from switching to PyPy right now? \n",
        "all_answers": [
            "\n\nNOTE: PyPy is more mature and better supported now than it was in 2013, when this question was asked. Avoid drawing conclusions from out-of-date information.\n\n\n\nPyPy, as others have been quick to mention, has tenuous support for C extensions. It has support, but typically at slower-than-Python speeds and it's iffy at best. Hence a lot of modules simply require CPython. Check the list of supported packages, but look at the date that list was updated, because it's not not kept in lockstep with actual support, so it's still possible that packages that marked unsupported on that list are actually supported.\nPython support typically lags a few versions behind, so if you absolutely need the latest features, you may need to wait a while before PyPy supports them.\nPyPy sometimes isn't actually faster for \"scripts\", which a lot of people use Python for. These are the short-running programs that do something simple and small. Because PyPy is a JIT compiler its main advantages come from long run times and simple types (such as numbers). PyPy's pre-JIT speeds can be bad compared to CPython.\nInertia. Moving to PyPy often requires retooling, which for some people and organizations is simply too much work.\n\nThose are the main reasons that affect me, I'd say.\n",
            "\nBecause pypy is not 100% compatible, takes 8 gigs of ram to compile, is a moving target, and highly experimental, where cpython is stable, the default target for module builders for 2 decades (including c extensions that don't work on pypy), and already widely deployed.\nPypy will likely never be the reference implementation, but it is a good tool to have.\n",
            "\nThe second question is easier to answer: you basically can use PyPy as a drop-in replacement if all your code is pure Python.  However, many widely used libraries (including some of the standard library) are written in C and compiled as Python extensions.  Some of these can be made to work with PyPy, some can't.  PyPy provides the same \"forward-facing\" tool as Python --- that is, it is Python --- but its innards are different, so tools that interface with those innards won't work.\nAs for the first question, I imagine it is sort of a Catch-22 with the first: PyPy has been evolving rapidly in an effort to improve speed and enhance interoperability with other code.  This has made it more experimental than official.\nI think it's possible that if PyPy gets into a stable state, it may start getting more widely used.  I also think it would be great for Python to move away from its C underpinnings.  But it won't happen for a while.  PyPy hasn't yet reached the critical mass where it is almost useful enough on its own to do everything you'd want, which would motivate people to fill in the gaps.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "performance",
            "jit",
            "pypy",
            "cpython"
        ]
    },
    {
        "question_id": "804961",
        "question": "\nHow do I use CSS with RoR? When I link externally, I'm never able to see the files. I cp'd the .css file to every folder I could think of...views, controller, template, and nothing seems to work.\nWhat do I need to do to enable external CSS files with a rails application? I'm new to rails, so forgive me if this is basic.\n",
        "all_answers": [
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nHave you tried putting it in your public folder? Whenever I have images or the like that I need to reference externally, I put it all there.\n",
            "\nPut the CSS files in public/stylesheets and then use:\n<%= stylesheet_link_tag \"filename\" %>\n\nto link to the stylesheet in your layouts or erb files in your views.\nSimilarly you put images in public/images and javascript files in public/javascripts. \n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n"
        ],
        "answer": "A4",
        "tags": [
            "ruby-on-rails",
            "css",
            "ruby"
        ]
    },
    {
        "question_id": "2504123",
        "question": "\nI am trying to generate a controller with all the RESTful actions stubbed.  I had read at Wikibooks - Ruby on Rails that all I needed to do was to call the generator with the controller name and I would get just that. So, I ran script/generate rspec_controller Properties but got an empty controller.\nAny other suggestions would be greatly appreciated.\n",
        "all_answers": [
            "\nUpdate (2013): Matt Connolly has provided a GIST which also works for request and controller specs: http://gist.github.com/4158961\n\nAnother way of doing this if you have many tests to run and don't want to include it everytime (DRYer code):\nCreate a /spec/support/auth_helper.rb file:\nmodule AuthHelper\n  def http_login\n    user = 'username'\n    pw = 'password'\n    request.env['HTTP_AUTHORIZATION'] = ActionController::HttpAuthentication::Basic.encode_credentials(user,pw)\n  end  \nend\n\nIn your test spec file:\ndescribe HomeController do\n  render_views\n\n  # login to http basic auth\n  include AuthHelper\n  before(:each) do\n    http_login\n  end\n\n  describe \"GET 'index'\" do\n    it \"should be successful\" do\n      get 'index'\n      response.should be_success\n    end\n  end\n\nend\n\nCredit here - Archived site\n",
            "\nSome answers suggest to set request.env which is unsafe, because request can be nil and you will end up with private method env' called for nil:NilClass, especially when run single tests with rspec -e\nCorrect approach will be:\ndef http_login\n  user = 'user'\n  password = 'passw'\n  {\n    HTTP_AUTHORIZATION: ActionController::HttpAuthentication::Basic.encode_credentials(user,password)\n  }\nend\n\nget 'index', nil, http_login\n\npost 'index', {data: 'post-data'}, http_login\n\n",
            "\nThere's no way (that I know of? that is documented?) to stub out a controller except through scaffolding. But you could do:\nscript/generate controller WhateverController new create edit update destroy show\n\n",
            "\nYou're looking for scaffolding.\nTry:\nscript/generate scaffold Property\n\nThis will give you a controller, a model, a migration and related tests. You can skip the migration with the option --skip-migration. If you don't want the others, you'll have to delete them yourself. Don't worry about overwriting existing files, that won't happen unless you use --force.\nAs klew points out in the comments, this also defines the method bodies for you, not just the names. It is very helpful to use as a starting point for your REST controller.\n",
            "\nEDIT(due to some comments) : Original question was in 2010 - hence the answer is NOT for RAILS 4 , but for rails 2!!\ntry using scaffolding.\nscript/generate scaffold controller Properties\n\nSection of Official docs on Ruby On Rails\nI'm sure you can find more info if you do a google search on rails scaffolding. Hope that helps.\nEDIT:\nFor RAILS 4\nrails g scaffold_controller Property\n",
            "\nI don't know about an automated way of doing it, but if you do:\nscript/generate controller your_model_name_in_plural new create update edit destroy index show\n\nAll of them will be created for you\nUpdate for Rails 4\nrails g scaffold_controller Property\n\n",
            "\nSorry I didn't search enough, the solution seems to be the following:\ndescribe \"GET 'index'\" do\n  it \"should be successful\" do\n    @request.env[\"HTTP_AUTHORIZATION\"] = \"Basic \" + Base64::encode64(\"username:password\")\n    get 'index'\n    response.should be_success\n  end\nend\n\n"
        ],
        "answer": "A6",
        "tags": [
            "ruby-on-rails",
            "controller",
            "rest",
            "rspec"
        ]
    },
    {
        "question_id": "3847736",
        "question": "\nHow can I compare two dates in PHP?\nThe date is stored in the database in the following format \n\n2011-10-2\n\nIf I wanted to compare today's date against the date in the database to see which one is greater, how would I do it?\nI tried this,\n$today = date(\"Y-m-d\");\n$expire = $row->expireDate //from db\n\nif($today < $expireDate) { //do something; }\n\nbut it doesn't really work that way. What's another way of doing it?\n",
        "all_answers": [
            "\nThere is also strptime() which expects exactly one format:\n$a = strptime('22-09-2008', '%d-%m-%Y');\n$timestamp = mktime(0, 0, 0, $a['tm_mon']+1, $a['tm_mday'], $a['tm_year']+1900);\n\nWarnings:\n\nThis function is not implemented on Windows\nThis function has been DEPRECATED as of PHP 8.1.0. Relying on this function is highly discouraged.\n\n",
            "\n\nin the database the date looks like this 2011-10-2\n\nStore it in YYYY-MM-DD and then string comparison will work because '1' > '0', etc.\n",
            "\n\nThis method works on both Windows and Unix and is time-zone aware, which is probably what you want if you work with dates.\nIf you don't care about timezone, or want to use the time zone your server uses:\n$d = DateTime::createFromFormat('d-m-Y H:i:s', '22-09-2008 00:00:00');\nif ($d === false) {\n    die(\"Incorrect date string\");\n} else {\n    echo $d->getTimestamp();\n}\n\n1222093324 (This will differ depending on your server time zone...)\n\nIf you want to specify in which time zone, here EST. (Same as New York.)\n$d = DateTime::createFromFormat(\n    'd-m-Y H:i:s',\n    '22-09-2008 00:00:00',\n    new DateTimeZone('EST')\n);\n\nif ($d === false) {\n    die(\"Incorrect date string\");\n} else {\n    echo $d->getTimestamp();\n}\n\n1222093305\n\nOr if you want to use UTC. (Same as \"GMT\".)\n$d = DateTime::createFromFormat(\n    'd-m-Y H:i:s',\n    '22-09-2008 00:00:00',\n    new DateTimeZone('UTC')\n);\n\nif ($d === false) {\n    die(\"Incorrect date string\");\n} else {\n    echo $d->getTimestamp();\n}\n\n1222093289\n\nRegardless, it's always a good starting point to be strict when parsing strings into structured data. It can save awkward debugging in the future. Therefore I recommend to always specify date format.\n",
            "\nIf all your dates are posterior to the 1st of January of 1970, you could use something like:\n$today = date(\"Y-m-d\");\n$expire = $row->expireDate; //from database\n\n$today_time = strtotime($today);\n$expire_time = strtotime($expire);\n\nif ($expire_time < $today_time) { /* do Something */ }\n\nIf you are using PHP 5 >= 5.2.0, you could use the DateTime class:\n$today_dt = new DateTime($today);\n$expire_dt = new DateTime($expire);\n\nif ($expire_dt < $today_dt) { /* Do something */ }\n\nOr something along these lines.\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "date",
            "compare"
        ]
    },
    {
        "question_id": "6903557",
        "question": "\nWhat would be the best way to split a string on the first occurrence of a delimiter?\nFor example:\n\"123mango abcd mango kiwi peach\"\n\nsplitting on the first mango to get:\n\"abcd mango kiwi peach\"\n\n\nTo split on the last occurrence instead, see partition string in python and get value of last segment after colon.\n",
        "all_answers": [
            "\n>>> s = \"123mango abcd mango kiwi peach\"\n>>> s.split(\"mango\", 1)\n['123', ' abcd mango kiwi peach']\n>>> s.split(\"mango\", 1)[1]\n' abcd mango kiwi peach'\n\n",
            "\nFrom the docs:\n\nstr.split([sep[, maxsplit]])\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements).\n\ns.split('mango', 1)[1]\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "split"
        ]
    },
    {
        "question_id": "3752769",
        "question": "\nI am trying to use a string that contains double quotes in the title attribute of an anchor. So far I tried these:\n<a href=\"..\" title=\"Some \\\"text\\\"\">Some text</a>\n<!-- The title looks like `Some \\` --!>\n\nand\n<a href=\"..\" title=\"Some &quot;text&quot;\">Some text</a>\n<!-- The title looks like `Some ` --!>\n\nPlease note that using single quotes is not an option.\n",
        "all_answers": [
            "\nStringEscapeUtils from Apache Commons Lang:\nimport static org.apache.commons.lang.StringEscapeUtils.escapeHtml;\n// ...\nString source = \"The less than sign (<) and ampersand (&) must be escaped before using them in HTML\";\nString escaped = escapeHtml(source);\n\nFor version 3:\nimport static org.apache.commons.lang3.StringEscapeUtils.escapeHtml4;\n// ...\nString escaped = escapeHtml4(source);\n\n",
            "\nAn alternative to Apache Commons: Use Spring's HtmlUtils.htmlEscape(String input) method.\n",
            "\nHere's a snippet of the HTML escape characters taken from a cached page on archive.org:\n&#060   |   <   less than sign\n&#064   |   @   at sign\n&#093   |   ]   right bracket\n&#123   |   {   left curly brace\n&#125   |   }   right curly brace\n&#133   |   …   ellipsis\n&#135   |   ‡   double dagger\n&#146   |   ’   right single quote\n&#148   |   ”   right double quote\n&#150   |   –   short dash\n&#153   |   ™   trademark\n&#162   |   ¢   cent sign\n&#165   |   ¥   yen sign\n&#169   |   ©   copyright sign\n&#172   |   ¬   logical not sign\n&#176   |   °   degree sign\n&#178   |   ²   superscript 2\n&#185   |   ¹   superscript 1\n&#188   |   ¼   fraction 1/4\n&#190   |   ¾   fraction 3/4\n&#247   |   ÷   division sign\n&#8221  |   ”   right double quote\n&#062   |   >   greater than sign\n&#091   |   [   left bracket\n&#096   |   `   back apostrophe\n&#124   |   |   vertical bar\n&#126   |   ~   tilde\n&#134   |   †   dagger\n&#145   |   ‘   left single quote\n&#147   |   “   left double quote\n&#149   |   •   bullet\n&#151   |   —   longer dash\n&#161   |   ¡   inverted exclamation point\n&#163   |   £   pound sign\n&#166   |   ¦   broken vertical bar\n&#171   |   «   double left than sign\n&#174   |   ®   registered trademark sign\n&#177   |   ±   plus or minus sign\n&#179   |   ³   superscript 3\n&#187   |   »   double greater-than sign\n&#189   |   ½   fraction 1/2\n&#191   |   ¿   inverted question mark\n&#8220  |   “   left double quote\n&#8212  |   —   dash\n\n",
            "\nThis variant - \n\n\n<a title=\"Some &quot;text&quot;\">Hover me</a>\n\n\n\nIs correct and it works as expected - you see normal quotes in rendered page.\n",
            "\nThe escape code &#34; can also be used instead of &quot;.\n"
        ],
        "answer": "A4",
        "tags": [
            "html",
            "escaping",
            "quotes"
        ]
    },
    {
        "question_id": "13474207",
        "question": "\nCan the following query be modified to return all records if the ? is null?\nSELECT NAME, SURNAME FROM MY_TABLE WHERE NAME = ?;\n\n",
        "all_answers": [
            "\nTry this one -\nWHERE DateDropped = 0\n    AND (\n        (ISNULL(@JobsOnHold, 0) = 1 AND DateAppr >= 0) \n        OR \n        (ISNULL(@JobsOnHold, 0) != 1 AND DateAppr != 0)\n    )\n\n",
            "\nTry this:\nSELECT * \nFROM MY_TABLE \nWHERE @parameter IS NULL OR NAME = @parameter;\n\n",
            "\nYou can also use functions IFNULL,COALESCE,NVL,ISNULL to check null value. It depends on your RDBMS.\nMySQL:\nSELECT NAME, SURNAME FROM MY_TABLE WHERE NAME = IFNULL(?,NAME);\n\nor\nSELECT NAME, SURNAME FROM MY_TABLE WHERE NAME = COALESCE(?,NAME);\n\nORACLE:\nSELECT NAME, SURNAME FROM MY_TABLE WHERE NAME = NVL(?,NAME);\n\nSQL Server / SYBASE:\nSELECT NAME, SURNAME FROM MY_TABLE WHERE NAME = ISNULL(?,NAME);\n\n",
            "\nTry this \nSELECT \n    DateAppr,\n    TimeAppr,\n    TAT,\n    LaserLTR,\n    Permit,\n    LtrPrinter,\n    JobName,\n    JobNumber,\n    JobDesc,\n    ActQty,\n    (ActQty-LtrPrinted) AS L,\n    (ActQty-QtyInserted) AS M,\n    ((ActQty-LtrPrinted)-(ActQty-QtyInserted)) AS N\nFROM \n    [test].[dbo].[MM]\nWHERE \n    DateDropped = 0\n    AND (\n    (ISNULL(@JobsOnHold, 0) = 1 AND DateAppr >= 0) \n    OR \n    (ISNULL(@JobsOnHold, 0) != 1 AND DateAppr != 0)\n    )\n\nYou can read more about conditional WHERE here.\n",
            "\nTo answer the underlying question of how to use a CASE expression in the WHERE clause: \nFirst remember that the value of a CASE expression has to have a normal data type value, not a boolean value.  It has to be a varchar, or an int, or something.  It's the same reason you can't say SELECT Name, 76 = Age FROM [...] and expect to get 'Frank', FALSE in the result set.\nAdditionally, all expressions in a WHERE clause need to have a boolean value.  They can't have a value of a varchar or an int.  You can't say WHERE Name; or WHERE 'Frank';.  You have to use a comparison operator to make it a boolean expression, so WHERE Name = 'Frank';\nThat means that the CASE expression must be on one side of a boolean expression.  You have to compare the CASE expression to something.  It can't stand by itself!\nHere:\nWHERE \n    DateDropped = 0\n    AND CASE\n            WHEN @JobsOnHold  = 1 AND DateAppr >= 0 THEN 'True'\n            WHEN DateAppr != 0 THEN 'True'\n            ELSE 'False'\n        END = 'True'\n\nNotice how in the end the CASE expression on the left will turn the boolean expression into either 'True' = 'True' or 'False' = 'True'.\nNote that there's nothing special about 'False' and 'True'.  You can use 0 and 1 if you'd rather, too.\nYou can typically rewrite the CASE expression into boolean expressions we're more familiar with, and that's generally better for performance.  However, sometimes is easier or more maintainable to use an existing expression than it is to convert the logic.\n"
        ],
        "answer": "A3",
        "tags": [
            "sql",
            "parameters",
            "where-clause"
        ]
    },
    {
        "question_id": "22316836",
        "question": "\nI'm currently looking at a UILabel with the property addMessageLabel.layer.cornerRadius = 5.0f; On a device with iOS 7.0 installed, it has rounded corners. On a device with iOS 7.1 installed, it does not have rounded corners.\nIs this just a bug with iOS 7.1?\n",
        "all_answers": [
            "\nIn the interface builder, you can use Ctrl + Enter to insert /n to the position you want.\nThis way could implement the following situation\n aaaaaaaaaa\n",
            "\nIf you read a string from an XML file, the line break \\n in this string will not work in UILabel text. The \\n is not parsed to a line break.\nHere is a little trick to solve this issue:\n// correct next line \\n in string from XML file\nNSString *myNewLineStr = @\"\\n\";\nmyLabelText = [myLabelText stringByReplacingOccurrencesOfString:@\"\\\\n\" withString:myNewLineStr];\n\nmyLabel.text = myLabelText;\n\nSo you have to replace the unparsed \\n part in your string by a parsed \\n in a hardcoded NSString.\nHere are my other label settings:\nmyLabel.numberOfLines = 0;\nmyLabel.backgroundColor = [UIColor lightGrayColor];\nmyLabel.textColor = [UIColor redColor]; \nmyLabel.font = [UIFont fontWithName:@\"Helvetica Neue\" size:14.0];   \nmyLabel.textAlignment = UITextAlignmentCenter;\n\nMost important is to set numberOfLines to 0 (= unlimited number of lines in label).\nNo idea why Apple has chosen to not parse \\n in strings read from XML?\n",
            "\nImportant to note it's \\n (backslash) rather than /n.\n",
            "\nFor those of you who want an easy solution, do the following in the text Label input box in Interface Builder:\nMake sure your number of lines is set to 0.\nAlt + Enter\n(Alt is your option key)\nCheers!\n",
            "\nTry the followings,\n[[addMessageLabel layer] setCornerRadius:5.0f];\n[[addMessageLabel layer] setMasksToBounds:YES];\n\n//or\n[addMessageLabel setClipsToBounds:YES];\n\nSwift\naddMessageLable.layer.cornerRadius = 5.0\naddMessageLable.layer.masksToBounds = true\n\n//or\naddMessageLable.layer.clipsToBounds = true\n\n",
            "\nUse \\n as you are using in your string.\nSet numberOfLines to 0 to allow for any number of lines.\nlabel.numberOfLines = 0;\nUpdate the label frame to match the size of the text using sizeWithFont:.  If you don't do this your text will be vertically centered or cut off.\nUILabel *label; // set frame to largest size you want\n...\nCGSize labelSize = [label.text sizeWithFont:label.font\n                          constrainedToSize:label.frame.size\n                              lineBreakMode:label.lineBreakMode];\nlabel.frame = CGRectMake(\n    label.frame.origin.x, label.frame.origin.y, \n    label.frame.size.width, labelSize.height);\n\nUpdate : Replacement for deprecatedsizeWithFont:constrainedToSize:lineBreakMode:\nReference, Replacement for deprecated sizeWithFont: in iOS 7?\nCGSize labelSize = [label.text sizeWithAttributes:@{NSFontAttributeName:label.font}];\n\nlabel.frame = CGRectMake(\n    label.frame.origin.x, label.frame.origin.y, \n    label.frame.size.width, labelSize.height);\n\n",
            "\n\nUse option-return when typing in the little box in Interface Builder to insert a line feed (\\n). In Interface Builder's Label attributes, set # Lines = 0.\nSelect the label and then change Lines property to 0 like in the above image, and then use \\n in your string for line break. \n",
            "\nSet the property clipsToBounds to true\naddMessageLabel.clipsToBounds = true\n\n",
            "\nYou have to set the numberOfLines property on the UILabel. The default is 1, if you set it to 0 it will remove all limits.\n"
        ],
        "answer": "A8",
        "tags": [
            "ios",
            "uiview",
            "ios7",
            "uilabel",
            "cornerradius"
        ]
    },
    {
        "question_id": "4308610",
        "question": "\nI have a repository with a file, Hello.java. When I compile it, an additional Hello.class file is generated.\nI created an entry for Hello.class in a .gitignore file. However, the file still appears to be tracked.\nHow can I make Git ignore Hello.class?\n",
        "all_answers": [
            "\nCreate a .gitignore file in the directory where directory .git is. You can list files in it separated by a newline. You also can use wildcards:\n*.o\n.*.swp\n\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nAdd the following line to file .gitignore:\n/Hello.class\n\nThis will exclude Hello.class from Git.  If you have already committed it, run the following command:\ngit rm Hello.class\n\nIf you want to exclude all class files from Git, add the following line to .gitignore:\n*.class\n\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nBy creating a .gitignore file. See here for details: Git Book - Ignoring files\nAlso check this one out: How do you make Git ignore files without using .gitignore?\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nYou should write something like\n*.class\n\ninto your .gitignore file.\n",
            "\nThe problem is that .gitignore ignores just files that weren't tracked before (by git add). Run git reset name_of_file to unstage the file and keep it. In case you want to also remove the given file from the repository (after pushing), use git rm --cached name_of_file.\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n"
        ],
        "answer": "A10",
        "tags": [
            "git",
            "gitignore"
        ]
    },
    {
        "question_id": "6368867",
        "question": "\nI have a dictionary I need to generate a JSON string by using dictionary. Is it possible to convert it? Can you guys please help on this?\n",
        "all_answers": [
            "\nNOTE: This answer was given before iOS 5 was released.\nGet the json-framework and do this:\n#import \"SBJsonWriter.h\"\n\n...\n\nSBJsonWriter *jsonWriter = [[SBJsonWriter alloc] init];\n\nNSString *jsonString = [jsonWriter stringWithObject:myDictionary];  \n\n[jsonWriter release];\n\nmyDictionary will be your dictionary.\n",
            "\nNSDate *methodStart = [NSDate date];\n\n/* ... Do whatever you need to do ... */\n\nNSDate *methodFinish = [NSDate date];\nNSTimeInterval executionTime = [methodFinish timeIntervalSinceDate:methodStart];\nNSLog(@\"executionTime = %f\", executionTime);\n\nSwift:\nlet methodStart = NSDate()\n\n/* ... Do whatever you need to do ... */\n\nlet methodFinish = NSDate()\nlet executionTime = methodFinish.timeIntervalSinceDate(methodStart)\nprint(\"Execution time: \\(executionTime)\")\n\nSwift3:\nlet methodStart = Date()\n\n/* ... Do whatever you need to do ... */\n\nlet methodFinish = Date()\nlet executionTime = methodFinish.timeIntervalSince(methodStart)\nprint(\"Execution time: \\(executionTime)\")\n\nEasy to use and has sub-millisecond precision.\n",
            "\nHere are categories for NSArray and NSDictionary to make this super-easy. I've added an option for pretty-print (newlines and tabs to make easier to read).\n@interface NSDictionary (BVJSONString)\n-(NSString*) bv_jsonStringWithPrettyPrint:(BOOL) prettyPrint;\n@end\n\n.\n@implementation NSDictionary (BVJSONString)\n\n  -(NSString*) bv_jsonStringWithPrettyPrint:(BOOL) prettyPrint {\n     NSError *error;\n     NSData *jsonData = [NSJSONSerialization dataWithJSONObject:self\n                                                   options:(NSJSONWritingOptions)    (prettyPrint ? NSJSONWritingPrettyPrinted : 0)\n                                                     error:&error];\n\n     if (! jsonData) {\n        NSLog(@\"%s: error: %@\", __func__, error.localizedDescription);\n        return @\"{}\";\n     } else {\n        return [[NSString alloc] initWithData:jsonData encoding:NSUTF8StringEncoding];\n     } \n }\n@end\n\n.\n@interface NSArray (BVJSONString)\n- (NSString *)bv_jsonStringWithPrettyPrint:(BOOL)prettyPrint;\n@end\n\n.\n@implementation NSArray (BVJSONString)\n-(NSString*) bv_jsonStringWithPrettyPrint:(BOOL) prettyPrint {\n    NSError *error;\n    NSData *jsonData = [NSJSONSerialization dataWithJSONObject:self\n                                                       options:(NSJSONWritingOptions) (prettyPrint ? NSJSONWritingPrettyPrinted : 0)\n                                                         error:&error];\n\n    if (! jsonData) {\n        NSLog(@\"%s: error: %@\", __func__, error.localizedDescription);\n        return @\"[]\";\n    } else {\n        return [[NSString alloc] initWithData:jsonData encoding:NSUTF8StringEncoding];\n    }\n}\n@end\n\n",
            "\nApple added a JSON parser and serializer in iOS 5.0 and Mac OS X 10.7. See NSJSONSerialization.\nTo generate a JSON string from a NSDictionary or NSArray, you do not need to import any third party framework anymore.\nHere is how to do it:\nNSError *error; \nNSData *jsonData = [NSJSONSerialization dataWithJSONObject:dictionaryOrArrayToOutput \n                                                   options:NSJSONWritingPrettyPrinted // Pass 0 if you don't care about the readability of the generated string\n                                                     error:&error];\n\nif (! jsonData) {\n    NSLog(@\"Got an error: %@\", error);\n} else {\n    NSString *jsonString = [[NSString alloc] initWithData:jsonData encoding:NSUTF8StringEncoding];\n}\n\n",
            "\nHere are two one-line macros that I use:\n#define TICK   NSDate *startTime = [NSDate date]\n#define TOCK   NSLog(@\"Time: %f\", -[startTime timeIntervalSinceNow])\n\nUse it like this:\nTICK;\n\n/* ... Do Some Work Here ... */\n\nTOCK;\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ios",
            "objective-c",
            "json",
            "string"
        ]
    },
    {
        "question_id": "46745014",
        "question": "\nI use the flag --experimental-modules when running my Node application in order to use ES6 modules.\nHowever when I use this flag the metavariable __dirname is not available. Is there an alternative way to get the same string that is stored in __dirname that is compatible with this mode?\n",
        "all_answers": [
            "\nMake sure you have this configuration in your angular.json\n    \"serve\": {\n      \"builder\": \"@angular-devkit/build-angular:dev-server\",\n      \"options\": {\n        \"browserTarget\": \"angular8:build\"\n      },\n      \"configurations\": {\n        \"production\": {\n          \"browserTarget\": \"angular8:build:production\"\n        }\n      }\n    }\n\nAnd make sure you have installed this package\n@angular-devkit/build-angular\n\n",
            "\nResolved my issue by using the below command:\nng update @angular/cli @angular/core --allow-dirty --force\n\n",
            "\nng update should have updated the version for your @angular-devkit/build-angular\nI ran into this as well and what I did was created a new Angular app and ensured that ng serve was working fine for that newly created Angular app. I then copied and used the following from the working Angular app's package.json, which is:\n\n`\"@angular-devkit/build-angular\": \"~0.802.2\",`\n\n\nEnsure you run npm install\n(The version would most probably change with each Angular update - so check what version you need to use by following the steps I have outlined - if ng update doesn't already update it for you)\n",
            "\nI had the same problem. Just two command solved my problem\nnpm uninstall @angular-devkit/build-angular\n\nnpm install --save-dev @angular-devkit/build-angular\n//OR\nnpm install @angular-devkit/build-angular\n\nIf this doesn't work. don't worry. run this command.\nng update @angular/cli @angular/core --allow-dirty --force\n\n",
            "\nI was able to solve this problem by installing the package @angular-devkit/build-angular using this command:\nnpm install @angular-devkit/build-angular --force\n\n",
            "\nAs of Node.js 10.12 there's an alternative that doesn't require creating multiple files and handles special characters in filenames across platforms:\nimport { dirname } from 'path';\nimport { fileURLToPath } from 'url';\n\nconst __dirname = dirname(fileURLToPath(import.meta.url));\n\n",
            "\nI got this working by reinstalling the build-angular package. Note the '--save-dev' flag on the install command:\nnpm uninstall @angular-devkit/build-angular\nnpm install --save-dev @angular-devkit/build-angular\n\n",
            "\nThere have been proposals about exposing these variables through import.meta, but for now, you need a hacky workaround that I found here:\n// expose.js\nmodule.exports = {__dirname};\n\n// use.mjs\nimport expose from './expose.js';\nconst {__dirname} = expose;\n\n"
        ],
        "answer": "A6",
        "tags": [
            "node.js",
            "ecmascript-6",
            "es6-modules"
        ]
    },
    {
        "question_id": "4728073",
        "question": "\nIn Python, what is the difference between expressions and statements?\n",
        "all_answers": [
            "\nExpressions only contain identifiers, literals and operators, where operators include arithmetic and boolean operators, the function call operator () the subscription operator [] and similar, and can be reduced to some kind of \"value\", which can be any Python object.  Examples:\n3 + 5\nmap(lambda x: x*x, range(10))\n[a.x for a in some_iterable]\nyield 7\n\nStatements (see 1, 2), on the other hand, are everything that can make up a line (or several lines) of Python code.  Note that expressions are statements as well.  Examples:\n# all the above expressions\nprint 42\nif x: do_y()\nreturn\na = 7\n\n",
            "\nAn expression is something that can be reduced to a value.\nLet's take the following examples and figure out what is what:\n\"1+3\" and \"foo = 1+3\".\nIt's easy to check:\nprint(foo = 1+3)\n\nIf it doesn't work, it's a statement, if it does, it's an expression. Try it out!\nAnother statement could be:\nclass Foo(Bar): pass\n\nas it cannot be reduced to a value.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "expression"
        ]
    },
    {
        "question_id": "7724188",
        "question": "\nIn newer version of Rails, I'm guessing from 3 up, database queries are output to the console. This is useful most of the time, but how can you hide it when you do not want to see it?\n",
        "all_answers": [
            "\nFrom a friend of mine:\nyour_query; nil\n\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nI see you already got your needed answer although I would like to advise the 'quiet assets' gem to you, most of the log data will be asset compiling and inclusions, this gem will remove that and still output the queries and data behavior.\nHave fun\n",
            "\nActiveRecord::Base.logger = nil\n\nfrom here\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nShort answer...\nIn the file development.rb change or add the value of config.log_level so that there's a line like\nconfig.log_level = :info\n\n",
            "\nA better way of doing this is by typing this into the console:\nActiveRecord::Base.logger.level = 1 \n\nas it prevents problems trying use a pointer to a logger that is set to nil (source: Disable Rails SQL logging in console)\nTo turn it back on\nActiveRecord::Base.logger.level = 0\n\n"
        ],
        "answer": "A7",
        "tags": [
            "ruby-on-rails"
        ]
    },
    {
        "question_id": "4912165",
        "question": "\nAs far as I know, wait() and notify() have been replaced with better concurrency mechanisms. So, what better alternative would you choose, say for implementing a synchronized queue?\nIn what sense exactly are they \"better\"?\nEdit: This (\"implement a synchronous queue\") is an interview question. An acceptable answer cannot use BlockingQueue or other queue implementation. It might, however, use other synchronization constructs such as CountDownLatch. I do not have an exhaustive list of allowed and forbidden classes - use your heads.\n",
        "all_answers": [
            "\nsynchronized/wait()/notify()/notifyAll() have been directly replaced by the Lock class methods lock()/unlock()/newCondition() and Condition's await()/signal()/signalAll().\nThere are several benefits to these, for a start allowing additional semantics such as fairness policies, as well as features such as distributed locking. The support for multiple Condition objects allows for much finer-grained signalling as well as uninterruptible waiting and waiting until some time etc.\nFor instance, the linked code has separate objects it attempts to use for signalling (which will fail due to the fact that the relevant monitors aren't held when waiting). This is directly replaceable by the use of a single Lock with multiple conditions.\nIn terms of improvements, the additional functionality may be of value. In Java5 the explicit Lock implementations actually performed better than the JVM monitors, but they basically nicked Doug Lea's code for the JVM and performance is now roughly equivalent.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nThere are pretty much implementations already existing in the java.util.concurrent package. E.g. -     ArrayBlockingQueue, DelayQueue, LinkedBlockingQueue, PriorityBlockingQueue, SynchronousQueue.\nAlso wait() and notify() have not been replaced. New utilities have been introduced that provide additional functionalities and performance benefits. See for example the java.util.concurrent.locks package.\nI would recommend you to read this introduction. It provides a high overview that should answer your question.\nCheers.\nEdit 1: Ok, then for example you can use an implementation of java.util.concurrent.locks\n.Lock to implement a dequeue operation that times-out and in the same time grants fairness to the threads accessing the queue. Such implementation is ReentrantLock which has a constructor that accepts the fairness policy. The timed tryLock() favors this property. Also you can add some debugging support for counting the waiting threads on the queue, etc. This would be much more difficult to implement simply with wait() and notify() I assume. \nIn conclusion ReentrantLock is \"better\" than the low level counterparts in its extended capabilities. The basic behavior is the same though. If you do not need these extras wait() and notify() are still acceptable alternative.\n",
            "\nReading the source of the ArrayBlockingQueue implementation reveals the use of Conditions as a replacement for the Object monitor methods \"wait/notify/notifyAll\".  Also, a ReentrantLock is used instead of the \"synchronized\" keyword to attain similar mutual exclusion behavior and semantics.  So it seems the java.util.concurrent.locks package is what you're looking for.  These new interfaces are better because they provide additional functionality not possible with the original synchronization and locking constructs, such as multiple wait-sets and selective read or write locks (rather than always both read and write).\nThe java.util.concurrent.atomic package also provides interfaces to compare-and-swap instructions which are useful for non-blocking algorithms, which are potentially much faster than their blocking alternatives but have their own challenges.\n"
        ],
        "answer": "A1",
        "tags": [
            "java",
            "multithreading",
            "concurrency"
        ]
    },
    {
        "question_id": "14808945",
        "question": "\nwhen my function f is called with a variable I want to check if var is a pandas dataframe:\ndef f(var):\n    if var == pd.DataFrame():\n        print \"do stuff\"\n\nI guess the solution might be quite simple but even with \ndef f(var):\n    if var.values != None:\n        print \"do stuff\"\n\nI can't get it to work like expected. \n",
        "all_answers": [
            "\nUse isinstance, nothing else:\nif isinstance(x, pd.DataFrame):\n    ... # do something\n\n\nPEP8 says explicitly that isinstance is the preferred way to check types\nNo:  type(x) is pd.DataFrame\nNo:  type(x) == pd.DataFrame\nYes: isinstance(x, pd.DataFrame)\n\nAnd don't even think about\nif obj.__class__.__name__ = 'DataFrame':\n    expect_problems_some_day()\n\nisinstance handles inheritance (see What are the differences between type() and isinstance()?). For example, it will tell you if a variable is a string (either str or unicode), because they derive from basestring)\nif isinstance(obj, basestring):\n    i_am_string(obj)\n\nSpecifically for pandas DataFrame objects:\nimport pandas as pd\nisinstance(var, pd.DataFrame)\n\n",
            "\nUse the built-in isinstance() function.\nimport pandas as pd\n\ndef f(var):\n    if isinstance(var, pd.DataFrame):\n        print(\"do stuff\")\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "pandas"
        ]
    },
    {
        "question_id": "39568301",
        "question": "\nUntil recently I was able to find all my public comments using a link on my profile page. I was using this functionality to keep track of all issues where I have commented, but not contributed anything. It was under a section called \"Public Activity\".\nThis function seems to have been removed. I can not find anything about it on the help page about profiles.\nDoes anybody have any information on when and why this was removed?\n",
        "all_answers": [
            "\nSince GitHub Universe 2016, the profile page has changed.\nIt still has a \"Contribution activity\" though, which includes your own comments. But you might need to click on  \"Show more activity\" to see past the last few weeks. \nAnd you can email yourself your own activity since last June: \"Email updates about your own activity\".\n",
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nYou can do this with an advanced search query. In the Issues search box, enter \"commenter:username\". \nOr if you want to search a specific repo: \"RepositoryName commenter:username\".\n"
        ],
        "answer": "A3",
        "tags": [
            "github",
            "user-profile"
        ]
    },
    {
        "question_id": "19151",
        "question": "\nHow would one create an iterative function (or iterator object) in python?\n",
        "all_answers": [
            "\nFirst of all the itertools module is incredibly useful for all sorts of cases in which an iterator would be useful, but here is all you need to create an iterator in python:\n\nyield\n\nIsn't that cool?  Yield can be used to replace a normal return in a function.  It returns the object just the same, but instead of destroying state and exiting, it saves state for when you want to execute the next iteration.  Here is an example of it in action pulled directly from the itertools function list:\ndef count(n=0):\n    while True:\n        yield n\n        n += 1\n\nAs stated in the functions description (it's the count() function from the itertools module...) , it produces an iterator that returns consecutive integers starting with n.\nGenerator expressions are a whole other can of worms (awesome worms!).  They may be used in place of a List Comprehension to save memory (list comprehensions create a list in memory that is destroyed after use if not assigned to a variable, but generator expressions can create a Generator Object... which is a fancy way of saying Iterator). Here is an example of a generator expression definition:\ngen = (n for n in xrange(0,11))\n\nThis is very similar to our iterator definition above except the full range is predetermined to be between 0 and 10.\nI just found xrange() (suprised I hadn't seen it before...) and added it to the above example.  xrange() is an iterable version of range() which has the advantage of not prebuilding the list.  It would be  very useful if you had a giant corpus of data to iterate over and only had so much memory to do it in.\n",
            "\nIterator objects in python conform to the iterator protocol, which basically means they provide two methods: __iter__()  and  __next__().  \n\nThe __iter__ returns the iterator object and is implicitly called\nat the start of loops.\nThe __next__() method returns the next value and is implicitly called at each loop increment.  This method raises a StopIteration exception when there are no more value to return, which is implicitly captured by looping constructs to stop iterating.\n\nHere's a simple example of a counter:\nclass Counter:\n    def __init__(self, low, high):\n        self.current = low - 1\n        self.high = high\n\n    def __iter__(self):\n        return self\n\n    def __next__(self): # Python 2: def next(self)\n        self.current += 1\n        if self.current < self.high:\n            return self.current\n        raise StopIteration\n\n\nfor c in Counter(3, 9):\n    print(c)\n\nThis will print:\n3\n4\n5\n6\n7\n8\n\nThis is easier to write using a generator, as covered in a previous answer:\ndef counter(low, high):\n    current = low\n    while current < high:\n        yield current\n        current += 1\n\nfor c in counter(3, 9):\n    print(c)\n\nThe printed output will be the same.  Under the hood, the generator object supports the iterator protocol and does something roughly similar to the class Counter.\nDavid Mertz's article, Iterators and Simple Generators, is a pretty good introduction. \n",
            "\nTo get a fully independent copy of an object you can use the copy.deepcopy() function.\nFor more details about shallow and deep copying please refer to the other answers to this question and the nice explanation in this answer to a related question.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "object",
            "iterator"
        ]
    },
    {
        "question_id": "4380945",
        "question": "\nI'm wondering how I can exclude an entire directory from my Git diff.  (In this case /spec).  I'm creating a diff for our entire software release using the git diff command.  However the changes to the specs are irrelevant for this procedure, and just create headaches.  now I know i can do\ngit diff previous_release..current_release app/\n\nThis would create a diff for all the changes in the app directory, but not for instance, in the lib/ directory.  Does anyone know how to accomplish this task?  Thanks!\nEdit:  I just want to be clear, I know I can just string the parameters of all of my directories on the end, minus /spec.  I was hoping there was a way to truly exclude a single directory in the command.\n",
        "all_answers": [
            "\nYou can try and unset the diff attribute for any files within the lib directory.\n.gitattributes:\nlib/* -diff\n\n\nracl101 adds in the comments:\n\nJust to add to this, for those of you who want to limit the git diff output of files of a specific type, within a specific directory and its subdirectories, like all the JavaScript generated by Webpack's bundling of your .js files, for example, you can add this to .gitattributes: \n\ndist/js/**/*.js -diff\n\n\nThen you don't see all that noise in your git diff output and it just shows as: Binary files ... differ which is more helpful. \n\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nBased on this answer you can also use:\ngit diff previous_release..current_release -- . ':!spec'\n\nThis is a newish git feature which allows excluding certain paths. It should be more reliable than various shell oneliners.\nI'm posting this here because this question is still the #1 hit for \"git diff exclude path\".\nSince Git 2.13 (Q2 2017), you can replace ! with ^. The latter doesn't need quotes. So you can write it as:\ngit diff previous_release..current_release -- . :^spec\n\n",
            "\nAssuming you use bash, and you've enabled extended globbing (shopt -s extglob), you could handle that from the shell side:\ngit diff previous_release current_release !(spec)\n\nSaves you having to list all other things.\nOr, shell-agnostic:\ngit diff previous_release current_release --name-only | grep -v '^spec/' \\\n    | xargs git diff previous_release current_release --\n\nYou could wrap that up in a one-liner shell script to save yourself having to retype the arguments.\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n"
        ],
        "answer": "A4",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "1790750",
        "question": "\nWhat is the difference between read() and recv(), and between send() and write() in socket programming in terms of performances, speed and other behaviors?\n",
        "all_answers": [
            "\nThere is not a system call to do it for you, unfortunately.  I'm guessing that's because there isn't a way to have really well-defined semantics for what should happen in error cases.  Should it leave the directories that have already been created?  Delete them?  What if the deletions fail? And so on...\nIt is pretty easy to roll your own, however, and a quick google for 'recursive mkdir' turned up a number of solutions.  Here's one that was near the top:\nhttp://nion.modprobe.de/blog/archives/357-Recursive-directory-creation.html\nstatic void _mkdir(const char *dir) {\n    char tmp[256];\n    char *p = NULL;\n    size_t len;\n\n    snprintf(tmp, sizeof(tmp),\"%s\",dir);\n    len = strlen(tmp);\n    if (tmp[len - 1] == '/')\n        tmp[len - 1] = 0;\n    for (p = tmp + 1; *p; p++)\n        if (*p == '/') {\n            *p = 0;\n            mkdir(tmp, S_IRWXU);\n            *p = '/';\n        }\n    mkdir(tmp, S_IRWXU);\n}\n\n",
            "\nHere is my solution. By calling the function below you ensure that all dirs leading to the file path specified exist. Note that file_path argument is not directory name here but rather a path to a file that you are going to create after calling mkpath().\nEg., mkpath(\"/home/me/dir/subdir/file.dat\", 0755) shall create /home/me/dir/subdir if it does not exist. mkpath(\"/home/me/dir/subdir/\", 0755) does the same.\nWorks with relative paths as well.\nReturns -1 and sets errno in case of an error.\nint mkpath(char* file_path, mode_t mode) {\n    assert(file_path && *file_path);\n    for (char* p = strchr(file_path + 1, '/'); p; p = strchr(p + 1, '/')) {\n        *p = '\\0';\n        if (mkdir(file_path, mode) == -1) {\n            if (errno != EEXIST) {\n                *p = '/';\n                return -1;\n            }\n        }\n        *p = '/';\n    }\n    return 0;\n}\n\nNote that file_path is modified during the action but gets restored afterwards. Therefore file_path is not strictly const.\n",
            "\nThe difference is that recv()/send() work only on socket descriptors and let you specify certain options for the actual operation. Those functions are slightly more specialized (for instance, you can set a flag to ignore SIGPIPE, or to send out-of-band messages...).\nFunctions read()/write() are the universal file descriptor functions working on all descriptors.\n",
            "\nPer the first hit on Google\n\nread() is equivalent to recv() with a flags parameter of 0. Other values for the flags parameter change the behaviour of recv(). Similarly, write() is equivalent to send() with flags == 0.\n\n",
            "\nhmm I thought that mkdir -p does that?\n\nmkdir -p this/is/a/full/path/of/stuff\n\n",
            "\n\"Performance and speed\"? Aren't those kind of ... synonyms, here?\nAnyway, the recv() call takes flags that read() doesn't, which makes it more powerful, or at least more convenient. That is one difference. I don't think there is a significant performance difference, but haven't tested for it.\n"
        ],
        "answer": "A3",
        "tags": [
            "c",
            "sockets",
            "unix",
            "network-programming",
            "posix"
        ]
    },
    {
        "question_id": "9065598",
        "question": "\nI use a FileUploader control in my application. I want to save a file to a specified folder. If this folder does not exist, I want to first create it, and then save my file to this folder.  If the folder already exists, then just save the file in it.\nHow can I do this?\n",
        "all_answers": [
            "\nusing System.IO\n\nif (!Directory.Exists(yourDirectory))\n    Directory.CreateDirectory(yourDirectory);\n\n",
            "\nUse System.IO.Directory.CreateDirectory.\n\nAccording to the official \".NET\" docs, you don't need to check if it exists first.\n\nSystem.io   >   Directory   >    Directory.CreateDirectory\nAny and all directories specified in path are created, unless they already exist or unless some part of path is invalid. If the directory already exists, this method does not create a new directory, but it returns a DirectoryInfo object for the existing directory.\n        — learn.microsoft.com/dotnet/api/\n\n\n",
            "\nYou can use a try/catch clause and check to see if it exist:\n  try\n  {\n    if (!Directory.Exists(path))\n    {\n       // Try to create the directory.\n       DirectoryInfo di = Directory.CreateDirectory(path);\n    }\n  }\n  catch (IOException ioex)\n  {\n     Console.WriteLine(ioex.Message);\n  }\n\n",
            "\nUse the below code as per How can I create a folder dynamically using the File upload server control?:\nstring subPath =\"ImagesPath\"; // Your code goes here\n\nbool exists = System.IO.Directory.Exists(Server.MapPath(subPath));\n\nif(!exists)\n    System.IO.Directory.CreateDirectory(Server.MapPath(subPath));\n\n",
            "\nDirectory.CreateDirectory explains how to try and to create the FilePath if it does not exist.\nDirectory.Exists explains how to check if a FilePath exists. However, you don't need this as CreateDirectory will check it for you.\n",
            "\nYou can create the path if it doesn't exist yet with a method like the following:\nusing System.IO;\n\nprivate void CreateIfMissing(string path)\n{\n  bool folderExists = Directory.Exists(Server.MapPath(path));\n  if (!folderExists)\n    Directory.CreateDirectory(Server.MapPath(path));\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "asp.net",
            "directory"
        ]
    },
    {
        "question_id": "25575073",
        "question": "\nI'm running this command:\npython manage.py test project.apps.app1.tests\n\nand it causes this error:\n\nAttributeError: 'module' object has no attribute 'tests'\n\nBelow is my directory structure. I've also added app1 to my installed apps config.\nTraceback (most recent call last):\n    File \"manage.py\", line 10, in <module> execute_from_command_line(sys.argv)\n    File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 385, in execute_from_command_line\n    utility.execute()\n    File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/__init__.py\", line 377, in execute\n    self.fetch_command(subcommand).run_from_argv(self.argv)\n    File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 50, in run_from_argv\n    super(Command, self).run_from_argv(argv)\n    File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 288, in run_from_argv\n    self.execute(*args, **options.__dict__)\n    File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 71, in execute\n    super(Command, self).execute(*args, **options)\n    File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/base.py\", line 338, in execute\n    output = self.handle(*args, **options)\n    File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/core/management/commands/test.py\", line 88, in handle\n    failures = test_runner.run_tests(test_labels)\n    File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 146, in run_tests\n    suite = self.build_suite(test_labels, extra_tests)\n    File \"/home/username/local/dev/local/lib/python2.7/site-packages/django/test/runner.py\", line 66, in build_suite\n    tests = self.test_loader.loadTestsFromName(label)\n    File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName\n    parent, obj = obj, getattr(obj, part)\n    AttributeError: 'module' object has no attribute 'tests'\n\nDirectory structure:\n\n",
        "all_answers": [
            "\nAccording to django document When you run your tests, the default behavior of the test utility is to find all the test cases (that is, subclasses of unittest.TestCase) in any file whose name begins with test, automatically build a test suite out of those test cases, and run that suite.\nso try this : python manage.py test tests.py\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nI finally figured it out working on another problem. The problem was that my test couldn't find an import. \nIt looks like you get the above error if your test fails to import. This makes sense because the test suite can't import a broken test. At least I think this is what is going on because I fixed the import within my test file and sure enough it started working.\nTo validate your test case just try import the test case file in python console. \nExample:\nfrom project.apps.app1.tests import *\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "django",
            "python-2.7",
            "python-unittest"
        ]
    },
    {
        "question_id": "33308482",
        "question": "\nRecently I was using GitExtension 2.46, but the Git version that has the same is 1.9.4.msysgit.2. Willing to use only Git commands, I uninstalled GitExtension and install the latest version available of Git and KDiff3.\nWhen I make a merge and have conflicts, I run the following command:\ngit mergetool\n\nThen I receive the message:\n\nThe merge tool kdiff3 is not available as 'kdiff3'.\n\nI guess it must be by the KDiff3 path.\nEnvironment\n\nOS: Windows 10\nGit 2.6.1.windows.1\nKDiff3 0.9.98 (64 bit)\n\nQuestions:\n\nWhat do I have to configure in the .gitconfig file for the command git mergetool to open the KDiff3 GUI with the versions LOCAL, REMOTE, BASE and MERGED of conflicted file?\n\nHow can I configure it to use it as a diff tool?\n\n\n",
        "all_answers": [
            "\nThese sites were very helpful, almost, mergetool and difftool. I used the global configuration, but can be used by repository without problems. You just need to execute the following commands:\ngit config --global merge.tool kdiff3\ngit config --global mergetool.kdiff3.path \"C:/Program Files/KDiff3/bin/kdiff3.exe\"\ngit config --global mergetool.kdiff3.trustExitCode false\n\ngit config --global diff.guitool kdiff3\ngit config --global difftool.kdiff3.path \"C:/Program Files/KDiff3/bin/kdiff3.exe\"\ngit config --global difftool.kdiff3.trustExitCode false\n\nNote that the latest version kdiff3 moved the executable from the root of the application folder C:/Program Files/KDiff3 into the bin/ folder inside the application folder. If you're using an older version, remove \"bin/\" from the paths above.\nThe use of the trustExitCode option depends on what you want to do when diff tool returns. From documentation:\n\ngit-difftool invokes a diff tool individually on each file. Errors reported by the diff tool are ignored by default. Use --trust-exit-code to make git-difftool exit when an invoked diff tool returns a non-zero exit code.\n\n",
            "\nWell, the problem is that Git can't find KDiff3 in the %PATH%.\nIn a typical Unix installation all executables reside in several well-known locations (/bin/, /usr/bin/, /usr/local/bin/, etc.), and one can invoke a program by simply typing its name in a shell processor (e.g. cmd.exe :) ).\nIn Microsoft Windows, programs are usually installed in dedicated paths so you can't simply type kdiff3 in a cmd session and get KDiff3 running.\nThe hard solution: you should tell Git where to find KDiff3 by specifying the full path to kdiff3.exe. Unfortunately, Git doesn't like spaces in the path specification in its config, so the last time I needed this, I ended up with those ancient \"C:\\Progra~1...\\kdiff3.exe\" as if it was late 1990s :)\nThe simple solution: Edit your computer settings and include the directory with kdiff3.exe in %PATH%. Then test if you can invoke it from cmd.exe by its name and then run Git.\n"
        ],
        "answer": "A1",
        "tags": [
            "git",
            "git-merge",
            "kdiff3",
            "mergetool"
        ]
    },
    {
        "question_id": "35700281",
        "question": "\nHow will I convert this datetime from the date?\n\nFrom this: 2016-02-29 12:24:26\nto: Feb 29, 2016\n\nSo far, this is my code and it returns a nil value:\nlet dateFormatter = NSDateFormatter()\ndateFormatter.dateFormat = \"MM-dd-yyyy\"\ndateFormatter.timeZone = NSTimeZone(name: \"UTC\")\nlet date: NSDate? = dateFormatter.dateFromString(\"2016-02-29 12:24:26\")\nprint(date)\n\n",
        "all_answers": [
            "\nYou have to declare 2 different NSDateFormatters, the first to convert the string to a NSDate and the second to print the date in your format.\nTry this code:\nlet dateFormatterGet = NSDateFormatter()\ndateFormatterGet.dateFormat = \"yyyy-MM-dd HH:mm:ss\"\n\nlet dateFormatterPrint = NSDateFormatter()\ndateFormatterPrint.dateFormat = \"MMM dd,yyyy\"\n\nlet date: NSDate? = dateFormatterGet.dateFromString(\"2016-02-29 12:24:26\")\nprint(dateFormatterPrint.stringFromDate(date!))\n\nSwift 3 and higher:\nFrom Swift 3 NSDate class has been changed to Date and NSDateFormatter to DateFormatter.\nlet dateFormatterGet = DateFormatter()\ndateFormatterGet.dateFormat = \"yyyy-MM-dd HH:mm:ss\"\n\nlet dateFormatterPrint = DateFormatter()\ndateFormatterPrint.dateFormat = \"MMM dd,yyyy\"\n\nif let date = dateFormatterGet.date(from: \"2016-02-29 12:24:26\") {\n    print(dateFormatterPrint.string(from: date))\n} else {\n   print(\"There was an error decoding the string\")\n}\n\n",
            "\nTo convert 2016-02-29 12:24:26 into a date, use this date formatter:\nlet dateFormatter = NSDateFormatter()\ndateFormatter.dateFormat = \"yyyy-MM-dd hh:mm:ss\"\n\nEdit: To get the output Feb 29, 2016 use this date formatter:\nlet dateFormatter = NSDateFormatter()\ndateFormatter.dateFormat = \"MMM dd, yyyy\"\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "swift",
            "nsdate",
            "nsdateformatter"
        ]
    },
    {
        "question_id": "5300493",
        "question": "\nI'm having trouble converting a UTC Time or TimeWithZone to local time in Rails 3.\nSay moment is some Time variable in UTC (e.g. moment = Time.now.utc). How do I convert moment to my time zone, taking care of DST (i.e. using EST/EDT)?\nMore precisely, I'd like to printout \"Monday March 14, 9 AM\" if the time correspond to this morning 9 AM EDT and \"Monday March 7, 9 AM\" if the time was 9 AM EST last monday.\nHopefully there's another way?\nEdit: I first thought that \"EDT\" should be a recognized timezone, but \"EDT\" is not an actual timezone, more like the state of a timezone. For instance it would not make any sense to ask for Time.utc(2011,1,1).in_time_zone(\"EDT\"). It is a bit confusing, as \"EST\" is an actual timezone, used in a few places that do not use Daylight savings time and are (UTC-5) yearlong.\n",
        "all_answers": [
            "\nRails has its own names. See them with:\nrake time:zones:us\n\nYou can also run rake time:zones:all for all time zones.\nTo see more zone-related rake tasks: rake -D time\nSo, to convert to EST, catering for DST automatically:\nTime.now.in_time_zone(\"Eastern Time (US & Canada)\")\n\n",
            "\nTime#localtime will give you the time in the current time zone of the machine running the code:\n> moment = Time.now.utc\n  => 2011-03-14 15:15:58 UTC \n> moment.localtime\n  => 2011-03-14 08:15:58 -0700 \n\nUpdate: If you want to conver to specific time zones rather than your own timezone, you're on the right track. However, instead of worrying about EST vs EDT, just pass in the general Eastern Time zone -- it will know based on the day whether it is EDT or EST:\n> Time.now.utc.in_time_zone(\"Eastern Time (US & Canada)\")\n  => Mon, 14 Mar 2011 11:21:05 EDT -04:00 \n> (Time.now.utc + 10.months).in_time_zone(\"Eastern Time (US & Canada)\")\n  => Sat, 14 Jan 2012 10:21:18 EST -05:00 \n\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "ruby-on-rails-3",
            "timezone",
            "activesupport"
        ]
    },
    {
        "question_id": "31722034",
        "question": "\nI am using android design library's TextinputLayout. But couldn't customize the hint color, label color and the underline color of EditText inside TextinputLayout. Please help.\n",
        "all_answers": [
            "\nChange bottom line color:\nFrom this answer\n\n <item name=\"colorControlNormal\">#c5c5c5</item>\n <item name=\"colorControlActivated\">@color/accent</item>\n <item name=\"colorControlHighlight\">@color/accent</item>\n\n\nChange hint color when it is floating\n<style name=\"MyHintStyle\" parent=\"@android:style/TextAppearance\">\n    <item name=\"android:textColor\">@color/main_color</item>\n</style>\n\nand use it like this:\n<android.support.design.widget.TextInputLayout\n    ...\n    app:hintTextAppearance=\"@style/MyHintStyle\">\n\nChange hint color when it is not a floating label:\n<android.support.design.widget.TextInputLayout\n    ...\n    app:hintTextAppearance=\"@style/MyHintStyle\"\n    android:textColorHint=\"#c1c2c4\">\n\nThanks to @AlbAtNf\n",
            "\n<style name=\"Widget.Design.TextInputLayout\" parent=\"android:Widget\">\n    <item name=\"hintTextAppearance\">@style/TextAppearance.Design.Hint</item>\n    <item name=\"errorTextAppearance\">@style/TextAppearance.Design.Error</item>\n</style>\n\nYou can override this style for layout\nAnd also you can change inner EditText-item style too.\n"
        ],
        "answer": "A1",
        "tags": [
            "android",
            "android-design-library",
            "android-textinputlayout"
        ]
    },
    {
        "question_id": "17777545",
        "question": "\nI'm writing an application in C# that opens an Excel template file for read/write operations. I want to when user closes the application, excel application process has been closed, without saving excel file. See my Task Manager after multiple runs of the app.\n\nI use this code to open the excel file :\npublic Excel.Application excelApp = new Excel.Application();\npublic Excel.Workbook excelBook;\nexcelBook = excelApp.Workbooks.Add(@\"C:/pape.xltx\");\n\nand for data access I use this code :\nExcel.Worksheet excelSheet = (Worksheet)(excelBook.Worksheets[1]);\nexcelSheet.DisplayRightToLeft = true;\nRange rng;\nrng = excelSheet.get_Range(\"C2\");\nrng.Value2 = txtName.Text;\n\nI see similar questions in stackoverflow such as this question and this, and test answers, but it doesn't works.\n",
        "all_answers": [
            "\nThink of this, it kills the process:\nSystem.Diagnostics.Process[] process=System.Diagnostics.Process.GetProcessesByName(\"Excel\");\nforeach (System.Diagnostics.Process p in process)\n{\n    if (!string.IsNullOrEmpty(p.ProcessName))\n    {\n        try\n        {\n            p.Kill();\n        }\n        catch { }\n    }\n}\n\nAlso, did you try just close it normally?\nmyWorkbook.SaveAs(@\"C:/pape.xltx\", missing, missing, missing, missing, missing, Microsoft.Office.Interop.Excel.XlSaveAsAccessMode.xlNoChange, missing, missing, missing, missing, missing);\nexcelBook.Close(null, null, null);                 // close your workbook\nexcelApp.Quit();                                   // exit excel application\nexcel = null;                                      // set to NULL\n\n",
            "\nexcelBook.Close();\nexcelApp.Quit();\n\nadd end of the code, it could be enough. it is working on my code\n",
            "\nTry this:\nexcelBook.Close(0); \nexcelApp.Quit();\n\nWhen closing the work-book, you have three optional parameters:\nWorkbook.close SaveChanges, filename, routeworkbook \n\nWorkbook.Close(false) or if you are doing late binding, it sometimes is easier to use zero\nWorkbook.Close(0)\nThat is how I've done it when automating closing of workbooks.\nAlso I went and looked up the documentation for it, and found it here:\nExcel Workbook Close\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "excel",
            "visual-studio-2012",
            "excel-interop",
            "kill-process"
        ]
    },
    {
        "question_id": "4441557",
        "question": "\nI'm using Spring MVC to handle JSON POST requests. Underneath the covers I'm using the MappingJacksonHttpMessageConverter built on the Jackson JSON processor and enabled when you use the mvc:annotation-driven.\nOne of my services receives a list of actions:\n@RequestMapping(value=\"/executeActions\", method=RequestMethod.POST)\n    public @ResponseBody String executeActions(@RequestBody List<ActionImpl> actions) {\n        logger.info(\"executeActions\");\n        return \"ACK\";\n    }\n\nI have found that Jackson maps the requestBody to a List of java.util.LinkedHashMap items (simple data binding). Instead, I would like the request to be bound to a List of typed objects (in this case \"ActionImpl\"). \nI know this is easy to do if you use Jackson's ObjectMapper directly:\nList<ActionImpl> result = mapper.readValue(src, new TypeReference<List<ActionImpl>>() { }); \n\nbut I was wondering what's the best way to achieve this when using Spring MVC and MappingJacksonHttpMessageConverter.  Any hints?\nThanks\n",
        "all_answers": [
            "\nI had a similar error today and the issue was the content-type header of the post request. Make sure the content type is what you expect. In my case a multipart/form-data content-type header was being sent to the API instead of application/json.\n",
            "\nimport com.fasterxml.jackson.core.JsonParser.Feature;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\nStatusResponses loginValidator = null;\n\nObjectMapper objectMapper = new ObjectMapper();\nobjectMapper.configure(Feature.AUTO_CLOSE_SOURCE, true);\n\ntry {\n    String res = result.getResponseAsString();//{\"status\":\"true\",\"msg\":\"success\"}\n    loginValidator = objectMapper.readValue(res, StatusResponses.class);//replaced result.getResponseAsString() with res\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nDon't know how it worked and why it worked? :( but it worked\n",
            "\nIn my case the problem was caused by my passing a null InputStream to the ObjectMapper.readValue call:\nObjectMapper objectMapper = ...\nInputStream is = null; // The code here was returning null.\nFoo foo = objectMapper.readValue(is, Foo.class)\n\nI am guessing that this is the most common reason for this exception.\n",
            "\nI could fix this error. In my case, the problem was at client side. By mistake I did not close the stream that I was writing to server. I closed stream and it worked fine. Even the error sounds like server was not able to identify the end-of-input.\nOutputStream out = new BufferedOutputStream(urlConnection.getOutputStream());\nout.write(jsonstring.getBytes());\nout.close() ; //This is what I did\n\n",
            "\nI suspect problem is due to type erasure, i.e. instead of passing generic parameter type, maybe only actions.getClass() is passed; and this would give type equivalent of List< ?>.\nIf this is true, one possibility would be to use an intermediate sub-class, like:\npublic class ActionImplList extends ArrayList<ActionImpl> { }\n\nbecause this will the retain type information even if only class is passed.\nSo then:\npublic @ResponseBody String executeActions(@RequestBody ActionImplList actions)\n\nwould do the trick. Not optimal but should work.\nI hope someone with more Spring MVC knowledge can shed light on why parameter type is not being passed (perhaps it's a bug?), but at least there is a work around.\n",
            "\nHave you tried declaring the method as:\nexecuteActions(@RequestBody TypeReference<List<ActionImpl>> actions)\n\nI haven't tried it, but based on your question it's the first thing I would try.\n",
            "\nThe problem for me was that I read the response twice as follows:\nSystem.out.println(response.body().string());\ngetSucherResponse = objectMapper.readValue(response.body().string(), GetSucherResponse.class);\n\nHowever, the response can only be read once as it is a stream.\n"
        ],
        "answer": "A5",
        "tags": [
            "json",
            "spring",
            "rest",
            "spring-mvc",
            "jackson"
        ]
    },
    {
        "question_id": "40242702",
        "question": "\nI was converting from Swift 2 to Swift 3. I noticed that I cannot convert a boolean value to integer value in Swift 3.\nlet p1 = (\"a\" == \"a\") //true\n\nprint(true)           //\"true\\n\"\nprint(p1)             //\"true\\n\"\n\nInt(true)             //1\n\nInt(p1)               //error\n\nFor example these syntaxes worked fine in Swift 2. But in Swift 3, print(p1) yields an error.\nThe error is error: cannot invoke initializer for type 'Int' with an argument list of type '((Bool))'\nI understand why the errors are happening. Can anyone explain what is the reason for this safety and how to convert from Bool to Int in Swift 3?\n",
        "all_answers": [
            "\nEDIT - From conversations in the comments, it is becoming clearer that the second way of doing this below (Int.init overload) is more in the style of where Swift is headed.\nAlternatively, if this were something you were doing a lot of in your app, you could create a protocol and extend each type you need to convert to Int with it.\nextension Bool: IntValue {\n    func intValue() -> Int {\n        if self {\n            return 1\n        }\n        return 0\n    }\n}\n\nprotocol IntValue {\n    func intValue() -> Int\n}\n\nprint(\"\\(true.intValue())\") //prints \"1\"\n\nEDIT- To cover an example of the case mentioned by Rob Napier in the comments below, one could do something like this:\nextension Int {\n    init(_ bool:Bool) {\n        self = bool ? 1 : 0\n    }\n}\n\nlet myBool = true\nprint(\"Integer value of \\(myBool) is \\(Int(myBool)).\")\n\n",
            "\nTry this,\nlet p1 = (\"a\" == \"a\") //true\nprint(true)           //\"true\\n\"\nprint(p1)             //\"true\\n\"\n\nInt(true)             //1\n\nInt(NSNumber(value:p1)) //1\n\n",
            "\nYou could use hashValue property:\nlet active = true\nactive.hashValue // returns 1\nactive = false\nactive.hashValue // returns 0\n\n",
            "\nSwift 5\n\nBool -> Int\n\nextension Bool {\n    var intValue: Int {\n        return self ? 1 : 0\n    }\n}\n\n\nInt -> Bool\n\nextension Int {\n    var boolValue: Bool {\n        return self != 0 \n    }\n}\n\n",
            "\nYou could use the ternary operator to convert a Bool to Int:\nlet result = condition ? 1 : 0\n\nresult will be 1 if condition is true, 0 is condition is false.\n"
        ],
        "answer": "A4",
        "tags": [
            "swift",
            "swift3",
            "integer",
            "boolean"
        ]
    },
    {
        "question_id": "25202770",
        "question": "\nWe know that we can use an if let statement as a shorthand to check for an optional nil then unwrap.\nHowever, I want to combine that with another expression using the logical AND operator &&.\nSo, for example, here I do optional chaining to unwrap and optionally downcast my rootViewController to tabBarController. But rather than have nested if statements, I'd like to combine them.\nif let tabBarController = window!.rootViewController as? UITabBarController {\n    if tabBarController.viewControllers.count > 0 {\n        println(\"do stuff\")\n     }\n }\n\nCombined giving:\nif let tabBarController = window!.rootViewController as? UITabBarController &&\n    tabBarController.viewControllers.count > 0 {\n        println(\"do stuff\")\n     }\n}\n\nThe above gives the compilation error Use of unresolved identifier 'tabBarController'\nSimplifying:\nif let tabBarController = window!.rootViewController as? UITabBarController && true {\n   println(\"do stuff\")\n}\n\nThis gives a compilation error Bound value in a conditional binding must be of Optional type. Having attempted various syntactic variations, each gives a different compiler error. I've yet to find the winning combination of order and parentheses.\nSo, the question is, is it possible and if so what is correct syntax?\nNote that I want to do this with an if statement not a switch statement or a ternary ? operator.\n",
        "all_answers": [
            "\nIt is not possible.\nFrom Swift grammar \n\nGRAMMAR OF AN IF STATEMENT\nif-statement → if ­if-condition­ code-block­ else-clause­opt­\nif-condition → expression­ | declaration­ \nelse-clause → else­ code-block­ | else­ if-statement­\nThe value of any condition in an if statement must have a type that conforms to the BooleanType protocol. The condition can also be an optional binding declaration, as discussed in Optional Binding\n\nif-condition must be expression­ or declaration­. You can't have both expression and declaration. \nlet foo = bar is a declaration, it doesn't evaluate to a value that conforms to BooleanType. It declares a constant/variable foo.\nYour original solution is good enough, it is much more readable then combining the conditions.\n",
            "\nAs of Swift 1.2, this is now possible. The Swift 1.2 and Xcode 6.3 beta release notes state:\n\nMore powerful optional unwrapping with if let — The if let construct\n  can now unwrap multiple optionals at once, as well as include\n  intervening boolean conditions. This lets you express conditional\n  control flow without unnecessary nesting.\n\nWith the statement above, the syntax would then be:\nif let tabBarController = window!.rootViewController as? UITabBarController where tabBarController.viewControllers.count > 0 {\n        println(\"do stuff\")\n}\n\nThis uses the where clause. \nAnother example, this time casting AnyObject to Int, unwrapping the optional, and checking that the unwrapped optional meets the condition:\nif let w = width as? Int where w < 500\n{\n    println(\"success!\")\n}\n\nFor those now using Swift 3, \"where\" has been replaced by a comma. The equivalent would therefore be:\nif let w = width as? Int, w < 500\n{\n    println(\"success!\")\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "swift",
            "expression"
        ]
    },
    {
        "question_id": "4081744",
        "question": "\nI am using a devise gem for sign_in/sign_out procedures.\nI generated views files from devise, using rails g devise views\nI saw there was a devise/sessions/new.html.erb file which contained a form for sign_in.\nI created another file devise/sessions/_form.html.erb and did <%= render 'form' %> within a new.html.erb file, and that worked out very fine.\nNow, I wanted to include this form from the different controller. So in a controller called 'main', (specifically, within view page) 'mains/index.html.erb' I included <%= render 'devise/sessions/form' %> file. It seems that inclusion worked fine, but I am getting the following error.\nNameError in Mains#index\n\nShowing /home/administrator/Ruby/site_v4_ruby/app/views/devise/sessions/_form.html.erb where line #1 raised:\n\nundefined local variable or method `resource' for #<#<Class:0x007f1aa042d530>:0x007f1aa042b870>\nExtracted source (around line #1):\n\n1: <%= form_for(resource, :as => resource_name, :url => session_path(resource_name)) do |f| %>\n2:   <p><%= f.label :email %><br />\n3:   <%= f.text_field :email %></p>\n4: \n\nIt seems that form_for(resource,...) part is causing the problem (which works fine if I am on the original devise sign_in page... How can I resolve this problem in rails way?\nI personally prefer to use 'render' function to include the form, rather than writing html codes inline.\nDo I have to specify something (resource) within the 'main' controller? \nI will appreciate your help. Thank you.\n",
        "all_answers": [
            "\nThe form you created works when rendered from a Devise controller because \"resource\" is defined through Devise. Take a look at the implementation of the Devise SessionsController - from what I understand, you're attempting to replicate the \"new\" action. The method \"build_resource\" is probably what you're looking after.\nThe Warden gem is where the \"resource\" objects are coming from. If you wish to dig deeper, that'd be the place to look.\n",
            "\nAs Andres says, the form calls helpers which are specified by Devise and so aren't present when you access a Devise form from a non-Devise controller.\nTo get around this, you need to add the following methods to the helper class of the controller you wish to display the form under. Alternatively, you can just add them to your application helper to make them available anywhere.\n  def resource_name\n    :user\n  end\n\n  def resource\n    @resource ||= User.new\n  end\n\n  def devise_mapping\n    @devise_mapping ||= Devise.mappings[:user]\n  end\n\nSource: http://pupeno.com/blog/show-a-devise-log-in-form-in-another-page/\n",
            "\nAs it turns outs 'domain: all' creates a cookie for all the different subdomains that are visited during that session (and it ensures that they are passed around between request). If no domain argument is passed, it means that a new cookie is created for every different domain that is visited in the same session and the old one gets discarded. What I needed was a single cookie that is persistent throughout the session, even when the domain changes. Hence, passing domain: \"lvh.me\" solved the problem in development. This creates a single cookie that stays there between different subdomains.\nFor anyone needing further explanation, this is a great link: \nhttp://excid3.com/blog/sharing-a-devise-user-session-across-subdomains-with-rails-3/\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby-on-rails-3",
            "devise"
        ]
    },
    {
        "question_id": "2490244",
        "question": "\n\n\n\nFor any given type i want to know its default value.\nIn C#, there is a keyword called default for doing this like\nobject obj = default(Decimal);\n\nbut I have an instance of Type (called myType) and if I say this,\nobject obj = default(myType);\n\nit doesn't work\nIs there any good way of doing this?\nI know that a huge switch block will work but thats not a good choice.\n",
        "all_answers": [
            "\nYou can only use just the name of the type (with its namespace, of course) if the type is in mscorlib or the calling assembly. Otherwise, you've got to include the assembly name as well:\nType type = Type.GetType(\"Namespace.MyClass, MyAssembly\");\n\nIf the assembly is strongly named, you've got to include all that information too. See the documentation for Type.GetType(string) for more information.\nAlternatively, if you have a reference to the assembly already (e.g. through a well-known type) you can use Assembly.GetType:\nAssembly asm = typeof(SomeKnownType).Assembly;\nType type = asm.GetType(namespaceQualifiedTypeName);\n\n",
            "\nHow about something like...\nclass Program\n{\n  static void Main(string[] args)\n  {\n    PrintDefault(typeof(object));\n    PrintDefault(typeof(string));\n    PrintDefault(typeof(int));\n    PrintDefault(typeof(int?));\n  }\n\n  private static void PrintDefault(Type type)\n  {\n    Console.WriteLine(\"default({0}) = {1}\", type,\n      DefaultGenerator.GetDefaultValue(type));\n  }\n}\n\npublic class DefaultGenerator\n{\n  public static object GetDefaultValue(Type parameter)\n  {\n    var defaultGeneratorType =\n      typeof(DefaultGenerator<>).MakeGenericType(parameter);\n\n    return defaultGeneratorType.InvokeMember(\n      \"GetDefault\", \n      BindingFlags.Static |\n      BindingFlags.Public |\n      BindingFlags.InvokeMethod,\n      null, null, new object[0]);\n  }\n}\n\npublic class DefaultGenerator<T>\n{\n  public static T GetDefault()\n  {\n    return default(T);\n  }\n}\n\nIt produces the following output:\ndefault(System.Object) =\ndefault(System.String) =\ndefault(System.Int32) = 0\ndefault(System.Nullable`1[System.Int32]) =\n\n",
            "\nTry:\nType type = Type.GetType(inputString); //target type\nobject o = Activator.CreateInstance(type); // an instance of target type\nYourType your = (YourType)o;\n\nJon Skeet is right as usually :)\nUpdate: You can specify assembly containing target type in various ways, as Jon mentioned, or:\nYourType your = (YourType)Activator.CreateInstance(\"AssemblyName\", \"NameSpace.MyClass\");\n\n",
            "\nIf you really want to get the type by name you may use the following:\nSystem.AppDomain.CurrentDomain.GetAssemblies().SelectMany(x => x.GetTypes()).First(x => x.Name == \"theassembly\");\n\nNote that you can improve the performance of this drastically the more information you have about the type you're trying to load.\n",
            "\nThere's really only two possibilities: null for reference types and new myType() for value types (which corresponds to 0 for int, float, etc) So you really only need to account for two cases:\nobject GetDefaultValue(Type t)\n{\n    if (t.IsValueType)\n        return Activator.CreateInstance(t);\n\n    return null;\n}\n\n(Because value types always have a default constructor, that call to Activator.CreateInstance will never fail).\n"
        ],
        "answer": "A5",
        "tags": [
            "c#",
            "types",
            "default"
        ]
    },
    {
        "question_id": "10978038",
        "question": "\npossible duplicate : android-singleline-true-not-working-for-edittext\n<EditText \n    android:id=\"@+id/searchbox\"  \n    android:layout_width=\"fill_parent\"\n    android:layout_height=\"wrap_content\"\n    android:lines=\"1\"\n    android:scrollHorizontally=\"true\"\n    android:ellipsize=\"end\"\n    android:layout_weight=\"1\"\n    android:layout_marginTop=\"2dp\"\n    android:drawablePadding=\"10dp\"\n    android:background=\"@drawable/edittext\"\n    android:drawableLeft=\"@drawable/folder_full\"\n    android:drawableRight=\"@drawable/search\"\n    android:paddingLeft=\"15dp\"\n    android:hint=\"search...\">\n</EditText>\n\nI want to make the above EditText to have only single line. Even if the user presses \"enter\" the cursor should not get down to the second line. Can anybody help me doing that?\n",
        "all_answers": [
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n",
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nInclude  android:singleLine=\"true\"\n",
            "\nUse android:maxLines=\"1\" and android:inputType=\"text\"\nYou forgot the android:maxLines attribute. And refer for android:inputType With your example, below will give this result: \n<EditText \n    android:id=\"@+id/searchbox\"  \n    android:layout_width=\"match_parent\"\n    android:layout_height=\"wrap_content\"\n    android:maxLines=\"1\"\n    android:inputType=\"text\"\n    android:scrollHorizontally=\"true\"\n    android:ellipsize=\"end\"\n    android:layout_weight=\"1\"\n    android:layout_marginTop=\"2dp\"\n    android:drawablePadding=\"10dp\"\n    android:background=\"@drawable/edittext\"\n    android:drawableLeft=\"@drawable/folder_full\"\n    android:drawableRight=\"@drawable/search\"\n    android:paddingLeft=\"15dp\"\n    android:hint=\"search...\">\n</EditText>\n\n"
        ],
        "answer": "A6",
        "tags": [
            "android",
            "android-edittext"
        ]
    },
    {
        "question_id": "1191553",
        "question": "\nI was reading the SQLite FAQ, and came upon this passage:\n\nThreads are evil. Avoid them. \n\nI don't quite understand the statement \"Thread are evil\". If that is true, then what is the alternative?\nMy superficial understanding of threads is:\n\nThreads make concurrence happen. Otherwise, the CPU horsepower will be wasted, waiting for (e.g.) slow I/O.\nBut the bad thing is that you must synchronize your logic to avoid contention and you have to protect shared resources. \n\nNote: As I am not familiar with threads on Windows, I hope the discussion will be limited to Linux/Unix threads.\n",
        "all_answers": [
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nCreating a lot of threads without constraint is indeed evil.. using a pooling mechanisme (threadpool) will mitigate this problem.\nAnother way threads are 'evil' is that most framework code is not designed to deal with multiple threads, so you have to manage your own locking mechanisme for those datastructures. \nThreads are good, but you have to think about how and when you use them and remember to measure if there really is a performance benefit.\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nWhen people say that \"threads are evil\", the usually do so in the context of saying \"processes are good\". Threads implicitly share all application state and handles (and thread locals are opt-in). This means that there are plenty of opportunities to forget to synchronize (or not even understand that you need to synchronize!) while accessing that shared data.\nProcesses have separate memory space, and any communication between them is explicit. Furthermore, primitives used for interprocess communication are often such that you don't need to synchronize at all (e.g. pipes). And you can still share state directly if you need to, using shared memory, but that is also explicit in every given instance. So there are fewer opportunities to make mistakes, and the intent of the code is more explicit.\n",
            "\nHere is a good write up about .NET events and race conditions with threads.  It covers some common scenarios and has some good references in it.\nHope this helps.\n"
        ],
        "answer": "A5",
        "tags": [
            "multithreading",
            "unix",
            "thread-safety"
        ]
    },
    {
        "question_id": "2016901",
        "question": "\nHow can I view any local commits I've made, that haven't yet been pushed to the remote repository? Occasionally, git status will print out that my branch is X commits ahead of origin/master, but not always.\nIs this a bug with my install of Git, or am I missing something?\n",
        "all_answers": [
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\ngit log origin/master..\n\nThis assumes that origin is the name of your upstream remote and master is the name of your upstream branch. Leaving off any revision name after .. implies HEAD, which lists the new commits that haven't been pushed.  [git log]\n",
            "\nThis gives a log of all commits between origin/master and HEAD:\ngit log origin/master..HEAD\n\nWhen HEAD is on the master branch, this gives a log of unpushed commits.\n\nSimilarly, to view the diff:\ngit diff origin/master..HEAD\n\n",
            "\nIt is not a bug. What you probably seeing is git status after a failed auto-merge where the changes from the remote are fetched but not yet merged.\nTo see the commits between local repo and remote do this:\ngit fetch\n\nThis is 100% safe and will not mock up your working copy. If there were changes git status wil show X commits ahead of origin/master.\nYou can now show log of commits that are in the remote but not in the local:\ngit log HEAD..origin\n\n"
        ],
        "answer": "A8",
        "tags": [
            "git",
            "git-commit",
            "git-diff",
            "git-log"
        ]
    },
    {
        "question_id": "6335521",
        "question": "\nI have a repo that has two files that supposedly I changed locally.\nSo I'm stuck with this:\n$ git status\n# On branch master\n# Changed but not updated:\n#   (use \"git add <file>...\" to update what will be committed)\n#   (use \"git checkout -- <file>...\" to discard changes in working directory)\n#\n#       modified:   dir1/foo.aspx\n#       modified:   dir2/foo.aspx\n#\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nDoing git diff says that the entire file contents have changed, even though from eyeballing it that seems untrue (there seem to be common line ranges that diff seems to be failing to see).\nInterestingly I don't remember changing these files locally. This repo is used with one remote repo (private, at GitHub.com, FWIW).\nNo matter what I've tried, I can't discard these local changes. I have tried all of:\n$ git checkout -- .\n$ git checkout -f\n$ git checkout -- dir1/checkout_receipt.aspx\n$ git reset --hard HEAD\n$ git stash save --keep-index && git stash drop\n$ git checkout-index -a -f\n\nIn other words I've tried everything described in How do I discard unstaged changes in Git? plus more. But the 2 files remain stuck as \"changed but not committed\".\nWhat the heck would cause two files to be stuck like this and seemingly \"un-revert-table\"??\nP.S. In the list above showing commands I'd already tried, I mistakenly wrote git revert when I meant git checkout. I'm sorry and thank you to those of you who answered that I should try checkout. I edited the question to correct it. I definitely did already try checkout.\n",
        "all_answers": [
            "\ngit checkout dir1/foo.aspx\ngit checkout dir2/foo.aspx\n\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nWhat are the line endings in the files?  I'm betting they're CRLF.  If they are, check out this guide: http://help.github.com/line-endings/\nIn short, you need to make sure git is set to convert the line endings to LF on commit, and then commit those files.  Files in the repo should always be LF, files checked out should be the OS's native, assuming you set git correctly.\n",
            "\nTry to revert local changes:\ngit checkout -- dir1/foo.aspx\ngit checkout -- dir2/foo.aspx\n\n"
        ],
        "answer": "A8",
        "tags": [
            "git",
            "github",
            "revert"
        ]
    },
    {
        "question_id": "548986",
        "question": "\n\n\n\nWhich is better, MySQL or MySQLi? And why? Which should I use?\nI mean better not just in terms of performance, but any other relevant feature.\n",
        "all_answers": [
            "\nIf you have a look at MySQL Improved Extension Overview, it should tell you everything you need to know about the differences between the two. \nThe main useful features are: \n\nan Object-oriented interface\nsupport for prepared statements\nsupport for multiple statements\nsupport for transactions\nenhanced debugging capabilities\nembedded server support.\n\n",
            "\nI assume you mean that you want the final SQL query, with parameter values interpolated into it.  I understand that this would be useful for debugging, but it is not the way prepared statements work.  Parameters are not combined with a prepared statement on the client-side, so PDO should never have access to the query string combined with its parameters.\nThe SQL statement is sent to the database server when you do prepare(), and the parameters are sent separately when you do execute().  MySQL's general query log does show the final SQL with values interpolated after you execute().  Below is an excerpt from my general query log.  I ran the queries from the mysql CLI, not from PDO, but the principle is the same.\n081016 16:51:28 2 Query       prepare s1 from 'select * from foo where i = ?'\n                2 Prepare     [2] select * from foo where i = ?\n081016 16:51:39 2 Query       set @a =1\n081016 16:51:47 2 Query       execute s1 using @a\n                2 Execute     [2] select * from foo where i = 1\n\nYou can also get what you want if you set the PDO attribute PDO::ATTR_EMULATE_PREPARES.  In this mode, PDO interpolate parameters into the SQL query and sends the whole query when you execute().  This is not a true prepared query.  You will circumvent the benefits of prepared queries by interpolating variables into the SQL string before execute().\n\nRe comment from @afilina:\nNo, the textual SQL query is not combined with the parameters during execution. So there's nothing for PDO to show you.\nInternally, if you use PDO::ATTR_EMULATE_PREPARES, PDO makes a copy of the SQL query and interpolates parameter values into it before doing the prepare and execute. But PDO does not expose this modified SQL query. \nThe PDOStatement object has a property $queryString, but this is set only in the constructor for the PDOStatement, and it's not updated when the query is rewritten with parameters.\nIt would be a reasonable feature request for PDO to ask them to expose the rewritten query. But even that wouldn't give you the \"complete\" query unless you use PDO::ATTR_EMULATE_PREPARES.\nThis is why I show the workaround above of using the MySQL server's general query log, because in this case even a prepared query with parameter placeholders is rewritten on the server, with parameter values backfilled into the query string. But this is only done during logging, not during query execution.\n",
            "\nWhat is better is PDO; it's a less crufty interface and also provides the same features as MySQLi.\nUsing prepared statements is good because it eliminates SQL injection possibilities; using server-side prepared statements is bad because it increases the number of round-trips.\n",
            "\nMySQLi stands for MySQL improved. It's an object-oriented interface to the MySQL bindings which makes things easier to use. It also offers support for prepared statements (which are very useful). If you're on PHP 5 use MySQLi.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "mysql",
            "mysqli"
        ]
    },
    {
        "question_id": "19581110",
        "question": "\nSince Django 1.5 raw post data is accessible via request.body.\nIn my application I sometimes get data send via a form and sometimes raw data (json for example). \nIs there any way to write a function like this that does not fail?\ndef get_post_var(request, name):\n    result = request.POST.get(name)\n    if result:\n        return result\n\n    post_body = dict(urlparse.parse_qsl(request.body))\n    result = post_body.get(name)\n    if result:\n        return result\n\n    return None\n\n",
        "all_answers": [
            "\nThe error You cannot access body after reading from request's data stream will be triggered on a request if (1) that request method is POST, (2) that request's POST dictionary is accessed in middleware, in either process_request or process_view and (3) within the view function, request.body is accessed. It is on (3) that the error will be raised, even though the real cause of the bug is (2).\nIn order to resolve the error, you need to examine your middleware for where it accesses request.POST and modify it such that it doesn't access request.POST anymore.\nThe Django docs say that middleware should not access request.POST, and this is one consequence of ignoring that recommendation.\nAlso check out this Django ticket on the issue, which includes the note:\n\n[M]iddleware that hits request.POST should (usually) be considered a\n  bug. It means that the view will be unable to set any custom upload\n  handlers, perform custom parsing of the request body, or enforce\n  permission checks prior to file uploads being accepted.\n\n",
            "\nUse request.data instead of request.body.\nrequest.data does not read the data stream again.\n",
            "\nI was able to read my request.POST after putting @csrf_exempt before my view function. Because CSRF middleware accesses POST data.\n",
            "\nAdding to Adam Easterling's answer it is worth noting that Django itself 'violates' the hint of not using request.POST in middleware:\n\nThe CsrfViewMiddleware class can be considered an exception, as it\n  provides the csrf_exempt() and csrf_protect() decorators which allow\n  views to explicitly control at what point the CSRF validation should\n  occur.\n\nWhich does not sanitilize the violation IMO\n",
            "\nUse a filter:\nLocation.objects.filter(name='Paul').first()\n\nOr import the exception:\nfrom django.core.exceptions import MultipleObjectsReturned\n...\ntry:\n    Location.objects.get(name='Paul')\nexcept MultipleObjectsReturned:\n    Location.objects.filter(name='Paul').first()\n\n",
            "\nThis is more pythonic way to do it.\ntry:\n    Location.objects.get(name='Paul')\nexcept Location.MultipleObjectsReturned:\n    Location.objects.filter(name='Paul')[0]\n\n",
            "\nThis isn't the best practice. You can technically do this without using exceptions. Did you intend to use Location and Car in this example?\nYou can do this:\nLocation.objects.filter(name='Paul').order_by('id').first()\n\nI strongly suggest you read the Django QuerySet API reference.\nhttps://docs.djangoproject.com/en/1.8/ref/models/querysets/\nTo answer your question about where the exception exists -- you can always access these QuerySet exceptions on the model itself. E.g. Location.DoesNotExist and Location.MultipleObjectsReturned. You don't need to import them if you already have the model imported.\n",
            "\nUse get when you know there is only one object that matches your query. If no items match the query, get() will raise a DoesNotExist exception. If multiple items matches the query, get() will raise a MultipleObjectsReturned exception. Use get() like this:\ntry:\n  one_entry = Entry.objects.get(blog=2000)\nexcept Entry.DoesNotExist:\n  # query did not match to any item.\n  pass\nexcept Entry.MultipleObjectsReturned:\n  # query matched multiple items.\n  pass\nelse:\n  # query matched to just one item\n  print(one_entry)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "django",
            "exception",
            "post",
            "request"
        ]
    },
    {
        "question_id": "17743549",
        "question": "\nI am trying to add a branch to the master branch on GitHub and push a folder onto that branch.\nThe folder structure of the branch looks like -\nSocialApp/SourceCode/DevTrunk/SocialApp and all the source code files are in the last folder.\nI am using the following Git commands:\ngit add *\ngit commit -m with the message\ngit push\n\nThis is pushing only the first folder \"SocialApp\" onto GitHub and ignoring the folder SourceCode that is inside the folder. How do I fix this?\n",
        "all_answers": [
            "\nCheck the .gitignore file, if the subdirectory is ignored.\nThen try again\ngit add --all\ngit commit -am \"<commit message>\"\ngit push\n\n",
            "\nRemove the last commit before push\ngit reset --soft HEAD~1\n1 means the last commit, if you want to remove two last use 2, and so forth*\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nSimply type in the console : \n$ git reset HEAD~\n\nThis command discards all local commits ahead of the remote HEAD\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nBoth \"git add *\" and \"git add SocialApp\" called from top directory should add recursively all directories.\nProbably you have no files in SocialApp/SourceCode/DevTrunk/SocialApp and this is the reason.\nTry to call \"touch SocialApp/SourceCode/DevTrunk/SocialApp/.temporary\" (and check .gitignore) and then try git add again.\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nThere are two branches to this question (Rolling back a commit does not mean I want to lose all my local changes):\n1. To revert the latest commit and  discard changes in the committed file do:\ngit reset --hard HEAD~1 \n2. To revert the latest commit but retain the local changes (on disk) do:\ngit reset --soft HEAD~1\nThis (the later command) will take you to the state you would have been if you did git add.\nIf you want to unstage the files after that, do \ngit reset\nNow you can make more changes before adding and then committing again.\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n"
        ],
        "answer": "A1",
        "tags": [
            "git",
            "github"
        ]
    },
    {
        "question_id": "8332333",
        "question": "\nI am using node.js + express.js + everyauth.js. I have moved all my everyauth logic into a module file\nvar login = require('./lib/everyauthLogin');\n\ninside this I load my oAuth config file with the key/secret combinations:\nvar conf = require('./conf');\n.....\ntwitter: {\n    consumerKey: 'ABC', \n    consumerSecret: '123'\n}\n\nThese codes are different for different environments - development / staging / production as the callbacks are to different urls.\nQuestion: How do I set these in the environmental config to filter through all modules or can I pass the path directly into the module?\nSet in env:\napp.configure('development', function(){\n  app.set('configPath', './confLocal');\n});\n\napp.configure('production', function(){\n  app.set('configPath', './confProduction');\n});\n\nvar conf = require(app.get('configPath'));\n\nPass in\napp.configure('production', function(){\n  var login = require('./lib/everyauthLogin', {configPath: './confProduction'});\n});\n\n? hope that makes sense\n",
        "all_answers": [
            "\nMy solution, \nload the app using \nNODE_ENV=production node app.js\n\nThen setup config.js as a function rather than an object\nmodule.exports = function(){\n    switch(process.env.NODE_ENV){\n        case 'development':\n            return {dev setting};\n\n        case 'production':\n            return {prod settings};\n\n        default:\n            return {error or other settings};\n    }\n};\n\nThen as per Jans solution load the file and create a new instance which we could pass in a value if needed, in this case process.env.NODE_ENV is global so not needed.\nvar Config = require('./conf'),\n    conf = new Config();\n\nThen we can access the config object properties exactly as before\nconf.twitter.consumerKey\n\n",
            "\nThe way we do this is by passing an argument in when starting the app with the environment. For instance:\nnode app.js -c dev\n\nIn app.js we then load dev.js as our configuration file. You can parse these options with optparse-js.\nNow you have some core modules that are depending on this config file. When you write them as such:\nvar Workspace = module.exports = function(config) {\n    if (config) {\n         // do something;\n    }\n}\n\n(function () {\n    this.methodOnWorkspace = function () {\n\n    };\n}).call(Workspace.prototype);\n\nAnd you can call it then in app.js like:\nvar Workspace = require(\"workspace\");\nthis.workspace = new Workspace(config);\n\n"
        ],
        "answer": "A1",
        "tags": [
            "node.js",
            "environment-variables",
            "everyauth"
        ]
    },
    {
        "question_id": "50522215",
        "question": "\nI am trying to install lerna using npm , packages are successfully added but when I run any command of lerna it comes out as.\n\nbash: lerna: command not found\n\nNode Version : v8.10.0\nNpm Version  : 3.10.9.\nHere's what I am trying:\n$ npm install --global lerna\nC:\\Users\\<user-name>\\AppData\\Roaming\\npm\\lerna -> C:\\Users\\<user-name>\\AppData\\Roaming\\npm\\node_modules\\lerna\\bin\\lerna.js\nC:\\Users\\<user-name>\\AppData\\Roaming\\npm\n`[email protected]\n\nVaibhavPC@Vaibhav MINGW64 ~/Projects/lerna init \nbash: lerna: command not found\n\n",
        "all_answers": [
            "\nI faced this issue when I installed lerna using yarn. Reinstalling using npm solved the issue.\n",
            "\nThree things:\n\nPlease check environment, if the path is correctly setup or not, for command not found error. \nSecond, you can go directly lerna folder and execute the command. If you are able to run from here that means problem is there in path ie point 1\nThe third option is re-install and install it again.\n\n",
            "\nInstall the MSI file:\nGo to the installed directory C:\\Program Files\\nodejs from command prompt n \nC:\\>cd C:\\Program Files\\nodejs enter..\nnode helloworld.js\noutput:\nHello World\n",
            "\n1) Check the ENVIRONMENT_VARIABLES that is NODE_PATH is present or not.\nIf not, then have to append the path to PATH environment variable.\n2) Re-install again \n\n",
            "\nHere are the exact steps I just took to run the \"Hello World\" example found at http://nodejs.org/. This is a quick and dirty example. For a permanent installation you'd want to store the executable in a more reasonable place than the root directory and update your PATH to include its location.\n\nDownload the Windows executable here: http://nodejs.org/#download\nCopy the file to C:\\\nCreate C:\\hello.js\nPaste in the following content:\n\n    var http = require('http');\n    http.createServer(function (req, res) {\n      res.writeHead(200, {'Content-Type': 'text/plain'});\n      res.end('Hello World\\n');\n    }).listen(1337, \"127.0.0.1\");\n    console.log('Server running at http://127.0.0.1:1337/');\n\n\nSave the file\nStart -> Run... -> cmd\nc:\nC:>node hello.js\nServer running at http://127.0.0.1:1337/\n\n\nThat's it. This was done on Windows XP.\n",
            "\nYou need to make sure that node is in your PATH. To set up your path, this out.\nMake sure that the directory that has node.exe is in your PATH. Then you should be able to \nrun node path_to_js_file.js.\nFor a good \"Hello World\" example, check out: http://howtonode.org/hello-node\n",
            "\nanother simple way \n\ndownload nodejs to your system\nopen a notepad write js command \"console.log('Hello World');\"\nsave the file as hello.js preferably same location as nodejs\nopen command prompt navigate to the location where the nodejs is located\nc:\\program files\\nodejs\nand run the command from the location like c:\\program files\\nodejs>node hello.js\nin case the js file in another location give the path of file \n  c:\\program files\\nodejs>node path\\hello.js\n\n"
        ],
        "answer": "A4",
        "tags": [
            "node.js",
            "windows",
            "npm",
            "lerna"
        ]
    },
    {
        "question_id": "42015081",
        "question": "\nI have a generic class that I want to be able to use with a default type. Right now I can initialize it with any type, but I have to be explicit.\n//Initialize with a type\nMyManager<MyCustomerObject>()\n\n// Initialize with NSObject (what I want to be my default type)\nMyManager<NSObject>()\n\n// This doesn't work, but I want this kind of functionality\nclass MyManager<T = NSObject> {}\n\n// So I can create my manager like so and it inserts the default type as NSObject\nMyManager() //Or MyManager<>()\n\nIs this possible in Swift?\n",
        "all_answers": [
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nNo, this currently isn't possible – although it is a part of the Generics Manifesto, so might be something that the Swift team will consider for a future version of the language.\n\nDefault generic arguments\nGeneric parameters could be given the ability to provide default\n  arguments, which would be used in cases where the type argument is not\n  specified and type inference could not determine the type argument.\n  For example:\npublic final class Promise<Value, Reason=Error> { ... }\n\nfunc getRandomPromise() -> Promise<Int, Error> { ... }\n\nvar p1: Promise<Int> = ... \nvar p2: Promise<Int, Error> = p1     // okay: p1 and p2 have the same type Promise<Int, Error>\nvar p3: Promise = getRandomPromise() // p3 has type Promise<Int, Error> due to type inference\n\n\nIn the meantime however, a somewhat unsatisfactory compromise would be the use of a typealias:\nclass MyManager<T> {}\n\ntypealias MyManagerDefault = MyManager<NSObject>\n\nlet defaultManager = MyManagerDefault()\n\nNot nearly as slick as just being able to say MyManager(), but it does show up next to MyManager in auto-complete, which is pretty handy.\n",
            "\nThere's no support for default generic arguments, but you can fake it by defining the default init() on a type-constrained extension, in which case the compiler will be smart enough to use that type. E.g.:\nclass MyManager<T> {\n    let instance: T\n\n    init(instance: T) {\n        self.instance = instance\n    }\n}\n\nextension MyManager where T == NSObject {\n    convenience init() {\n        self.init(instance: NSObject())\n    }\n}\n\nAnd now you can initialize the type with no argument and it will default to MyManager<NSObject>:\nlet mm1 = MyManager(instance: \"Foo\") // MyManager<String>\nlet mm2 = MyManager(instance: 1) // MyManager<Int>\nlet mm3 = MyManager() // MyManager<NSObject>\n\nSwiftUI uses this technique quite a lot.\n"
        ],
        "answer": "A3",
        "tags": [
            "swift",
            "generics"
        ]
    },
    {
        "question_id": "1600962",
        "question": "\nI currently have an app displaying the build number in its title window.  That's well and good except it means nothing to most of the users, who want to know if they have the latest build - they tend to refer to it as \"last Thursday's\" rather than build 1.0.8.4321.\nThe plan is to put the build date there instead - So \"App built on 21/10/2009\" for example.\nI'm struggling to find a programmatic way to pull the build date out as a text string for use like this.\nFor the build number, I used:\nAssembly.GetExecutingAssembly().GetName().Version.ToString()\n\nafter defining how those came up.\nI'd like something like that for the compile date (and time, for bonus points).\nPointers here much appreciated (excuse pun if appropriate), or neater solutions...\n",
        "all_answers": [
            "\nI'm not sure, but maybe the Build Incrementer helps.\n",
            "\nJeff Atwood had a few things to say about this issue in Determining Build Date the hard way.\nThe most reliable method turns out to be retrieving the linker timestamp from the PE header embedded in the executable file -- some C# code (by Joe Spivey) for that from the comments to Jeff's article:\npublic static DateTime GetLinkerTime(this Assembly assembly, TimeZoneInfo target = null)\n{\n    var filePath = assembly.Location;\n    const int c_PeHeaderOffset = 60;\n    const int c_LinkerTimestampOffset = 8;\n\n    var buffer = new byte[2048];\n\n    using (var stream = new FileStream(filePath, FileMode.Open, FileAccess.Read))\n        stream.Read(buffer, 0, 2048);\n\n    var offset = BitConverter.ToInt32(buffer, c_PeHeaderOffset);\n    var secondsSince1970 = BitConverter.ToInt32(buffer, offset + c_LinkerTimestampOffset);\n    var epoch = new DateTime(1970, 1, 1, 0, 0, 0, DateTimeKind.Utc);\n\n    var linkTimeUtc = epoch.AddSeconds(secondsSince1970);\n\n    var tz = target ?? TimeZoneInfo.Local;\n    var localTime = TimeZoneInfo.ConvertTimeFromUtc(linkTimeUtc, tz);\n\n    return localTime;\n}\n\nUsage example:\nvar linkTimeLocal = Assembly.GetExecutingAssembly().GetLinkerTime();\n\n\nNote: this method works for .NET Core 1.0, but stopped working after .NET Core 1.1 - it gives random years in the 1900-2020 range.\n",
            "\nYou can't change a DateTime value - it's immutable. However, you can change the variable to have a new value. The easiest way of doing that to change just the time is to create a TimeSpan with the relevant time, and use the DateTime.Date property:\nDateTime s = ...;\nTimeSpan ts = new TimeSpan(10, 30, 0);\ns = s.Date + ts;\n\ns will now be the same date, but at 10.30am.\nNote that DateTime disregards daylight saving time transitions, representing \"naive\" Gregorian time in both directions (see Remarks section in the DateTime docs). The only exceptions are .Now and .Today: they retrieve current system time which reflects these events as they occur.\nThis is the kind of thing which motivated me to start the Noda Time project, which is now production-ready. Its ZonedDateTime type is made \"aware\" by linking it to a tz database entry.\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "date",
            "time",
            "compilation"
        ]
    },
    {
        "question_id": "6316987",
        "question": "\nI've seen both full definitions of structs in headers and just declarations—is there any advantage to one method over the other?\nIf it makes a difference, I usually typedef a struct like so in the .h\ntypedef struct s s_t;\n\n\nTo be clear, the options are declaration in the header file and definition in the class, or both declaration and definition in the header file. Both should result in the same usability, even if one is by linkage, shouldn't they?\n\nI see many almost duplicates, e.g. here but no exact matches. Please correct me if I'm wrong in this regard.\n",
        "all_answers": [
            "\nIf the struct is to be used by other compilation units (.c files) , place it in the header file so you can include that header file wherever it is needed.\nIf the struct is only used in one compilation unit (.c file), you place it in that .c file.\n",
            "\nI put them into the C file to make it more Object Oriented, see this article.\n",
            "\nPrivate structures for that file should go in the .c file, with a declaration in the .h file if they are used by any functions in the .h .\nPublic structures should go in the .h file.\n",
            "\nThe point is, placing it in a header file allows you to use the structure (or any other definition) from multiple source files, just by including that header file.\nBut if you are sure it will only be used from one source file, then it really doesn't make any difference.\n"
        ],
        "answer": "A3",
        "tags": [
            "c",
            "header",
            "struct"
        ]
    },
    {
        "question_id": "4945119",
        "question": "\n\n\n\nI'm about to build an Android application that will use a RESTful Web Service. I don't want to write the REST client by myself, as I want it to be as effective and stable as possible (this is the first time I'm using REST).\nAre there any (free) frameworks or utilities avaibale for Android/Java that I can use in my project?\n",
        "all_answers": [
            "\nRestlet is an excellent REST framework and has an Android edition.\n",
            "\nI could fix this error. In my case, the problem was at client side. By mistake I did not close the stream that I was writing to server. I closed stream and it worked fine. Even the error sounds like server was not able to identify the end-of-input.\nOutputStream out = new BufferedOutputStream(urlConnection.getOutputStream());\nout.write(jsonstring.getBytes());\nout.close() ; //This is what I did\n\n",
            "\nIn my case the problem was caused by my passing a null InputStream to the ObjectMapper.readValue call:\nObjectMapper objectMapper = ...\nInputStream is = null; // The code here was returning null.\nFoo foo = objectMapper.readValue(is, Foo.class)\n\nI am guessing that this is the most common reason for this exception.\n",
            "\nI had a similar error today and the issue was the content-type header of the post request. Make sure the content type is what you expect. In my case a multipart/form-data content-type header was being sent to the API instead of application/json.\n",
            "\nAny HTTP Client library should be perfectly adequate to interact RESTfully with a web API.   E.g. http://developer.android.com/reference/org/apache/http/client/HttpClient.html\n",
            "\nThis error is sometimes (often?) hiding the real problem: a failure condition could be causing the content to be incorrect, which then fails to deserialize.\nIn my case, today, I was making HTTP calls and (foolishly) omitted to check the HTTP status code before trying to unmarshal the body of the response => my real problem was actualy that I had some authentication error, which caused a 401 Unauthorized to be sent back to me, with an empty body. Since I was unmarshalling that empty body directly without checking anything, I was getting this No content to map due to end-of-input, without getting any clue about the authentication issue.\n",
            "\nI got this error when sending a GET request with postman.\nThe request required no parameters.\nMy mistake was I had a blank line in the request body.\n",
            "\nIn my case I was reading the stream in a jersey RequestEventListener I created on the server side to log the request body prior to the request being processed. I then realized that this probably resulted in the subsequent read to yield no string (which is what is passed over when the business logic is run). I verified that to be the case.\nSo if you are using streams to read the JSON string be careful of that.\n",
            "\nThe problem for me was that I read the response twice as follows:\nSystem.out.println(response.body().string());\ngetSucherResponse = objectMapper.readValue(response.body().string(), GetSucherResponse.class);\n\nHowever, the response can only be read once as it is a stream.\n",
            "\nimport com.fasterxml.jackson.core.JsonParser.Feature;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\nStatusResponses loginValidator = null;\n\nObjectMapper objectMapper = new ObjectMapper();\nobjectMapper.configure(Feature.AUTO_CLOSE_SOURCE, true);\n\ntry {\n    String res = result.getResponseAsString();//{\"status\":\"true\",\"msg\":\"success\"}\n    loginValidator = objectMapper.readValue(res, StatusResponses.class);//replaced result.getResponseAsString() with res\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nDon't know how it worked and why it worked? :( but it worked\n"
        ],
        "answer": "A1",
        "tags": [
            "java",
            "android",
            "json",
            "rest"
        ]
    },
    {
        "question_id": "1622793",
        "question": "\nI have a web site which shows different content based on a location\nthe visitor chooses. e.g: User enters in 55812 as the zip. I know what\ncity and area lat/long. that is and give them their content pertinent\nto that area. My question is how can I store this in a cookie so that\nwhen they return they are not required to always enter their zip code?\nI see it as follows:\n\nSet persistent cookie based on their area.\nWhen they return read cookie, grab zipcode.\nReturn content based on the zip code in their cookie.\n\nI can't seem to find any solid information on setting a cookie. Any\nhelp is greatly appreciated.\n",
        "all_answers": [
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nYou could manually set the cookie, but depending on your use case (and if you might want to add more types of persistent/session data in future) it might make more sense to use Django's sessions feature.  This will let you get and set variables tied internally to the user's session cookie.  Cool thing about this is that if you want to store a lot of data tied to a user's session, storing it all in cookies will add a lot of weight to HTTP requests and responses.  With sessions the session cookie is all that is sent back and forth (though there is the overhead on Django's end of storing the session data to keep in mind).\n",
            "\nUPDATE : check Peter's answer below for a builtin solution :\nThis is a helper to set a persistent cookie:\nimport datetime\n\ndef set_cookie(response, key, value, days_expire=7):\n    if days_expire is None:\n        max_age = 365 * 24 * 60 * 60  # one year\n    else:\n        max_age = days_expire * 24 * 60 * 60\n    expires = datetime.datetime.strftime(\n        datetime.datetime.utcnow() + datetime.timedelta(seconds=max_age),\n        \"%a, %d-%b-%Y %H:%M:%S GMT\",\n    )\n    response.set_cookie(\n        key,\n        value,\n        max_age=max_age,\n        expires=expires,\n        domain=settings.SESSION_COOKIE_DOMAIN,\n        secure=settings.SESSION_COOKIE_SECURE or None,\n    )\n\nUse the following code before sending a response.\ndef view(request):\n    response = HttpResponse(\"hello\")\n    set_cookie(response, 'name', 'jujule')\n    return response\n\nUPDATE : check Peter's answer below for a builtin solution :\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n"
        ],
        "answer": "A3",
        "tags": [
            "python",
            "django",
            "cookies",
            "browser",
            "django-cookies"
        ]
    },
    {
        "question_id": "3393612",
        "question": "\n\n\n\nIs there a way to, for example, print Hello World! every n seconds?\nFor example, the program would go through whatever code I had, then once it had been 5 seconds (with time.sleep()) it would execute that code. I would be using this to update a file though, not print Hello World.\nFor example:\nstartrepeat(\"print('Hello World')\", .01) # Repeats print('Hello World') ever .01 seconds\n\nfor i in range(5):\n    print(i)\n\n>> Hello World!\n>> 0\n>> 1\n>> 2\n>> Hello World!\n>> 3\n>> Hello World!\n>> 4\n\n",
        "all_answers": [
            "\ndef update():\n    import time\n    while True:\n        print 'Hello World!'\n        time.sleep(5)\n\nThat'll run as a function. The while True: makes it run forever. You can always take it out of the function if you need.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nYou can start a separate thread whose sole duty is to count for 5 seconds, update the file, repeat. You wouldn't want this separate thread to interfere with your main thread.\n",
            "\nimport threading\n\ndef printit():\n  threading.Timer(5.0, printit).start()\n  print \"Hello, World!\"\n\nprintit()\n\n# continue with the rest of your code\n\nhttps://docs.python.org/3/library/threading.html#timer-objects\n",
            "\nBetter alternatives to join() method have been evolved over a period of time.\nExecutorService.html#invokeAll is one alternative.\n\nExecutes the given tasks, returning a list of Futures holding their status and results when all complete. Future.isDone() is true for each element of the returned list. \n\nNote that a completed task could have terminated either normally or by throwing an exception. The results of this method are undefined if the given collection is modified while this operation is in progress.\nForkJoinPool or Executors.html#newWorkStealingPool provides other alternatives to achieve the same purpose. \nExample code snippet:\n\nimport java.util.concurrent.*;\n\nimport java.util.*;\n\npublic class InvokeAllDemo{\n    public InvokeAllDemo(){\n        System.out.println(\"creating service\");\n        ExecutorService service = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\n\n        List<MyCallable> futureList = new ArrayList<MyCallable>();\n        for ( int i=0; i<10; i++){\n            MyCallable myCallable = new MyCallable((long)i);\n            futureList.add(myCallable);\n        }\n        System.out.println(\"Start\");\n        try{\n            List<Future<Long>> futures = service.invokeAll(futureList);  \n        }catch(Exception err){\n            err.printStackTrace();\n        }\n        System.out.println(\"Completed\");\n        service.shutdown();\n    }\n    public static void main(String args[]){\n        InvokeAllDemo demo = new InvokeAllDemo();\n    }\n    class MyCallable implements Callable<Long>{\n        Long id = 0L;\n        public MyCallable(Long val){\n            this.id = val;\n        }\n        public Long call(){\n            // Add your business logic\n            return id;\n        }\n    }\n}\n\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "multithreading"
        ]
    },
    {
        "question_id": "11183788",
        "question": "\nI think it should work to copy the directory to be renamed to a new directory with desired name, and delete the old directory, and git add,  git commit and push everything.  But is this the best way?\n",
        "all_answers": [
            "\nBasic rename (or move):\ngit mv <old name> <new name>\n\nCase sensitive rename—eg. from casesensitive to CaseSensitive—you must use a two step:\ngit mv casesensitive tmp\ngit mv tmp CaseSensitive\n\n(More about case sensitivity in Git…)\n…followed by commit and push would be the simplest way to rename a directory in a git repo.\n",
            "\nYou can rename the directory using the file system. Then you can do git rm <old directory> and git add <new directory> (Help page). Then you can commit and push.\nGit will detect that the contents are the same and that it's just a rename operation, and it'll appear as a rename entry in the history. You can check that this is the case before the commit using git status\n",
            "\nCheck on which branch you are using the command below\ngit branch -a \n\nCheckout to the branch you want to rename\ngit checkout branch_to_rename\n\nRename the branch using\ngit branch -m new_name\n\nPush the changes\ngit push origin :old_name new_name\n\n",
            "\n\n\nThere are a few ways to accomplish that:\n\nChange your local branch and then push your changes\nPush the branch to remote with the new name while keeping the original name locally\n\nRenaming local and remote\n# Rename the local branch to the new name\ngit branch -m <old_name> <new_name>\n\n# Delete the old branch on remote - where <remote> is, for example, origin\ngit push <remote> --delete <old_name>\n\n# Or shorter way to delete remote branch [:]\ngit push <remote> :<old_name>\n\n# Prevent git from using the old name when pushing in the next step.\n# Otherwise, git will use the old upstream name instead of <new_name>.\ngit branch --unset-upstream <new_name>\n\n# Push the new branch to remote\ngit push <remote> <new_name>\n\n# Reset the upstream branch for the new_name local branch\ngit push <remote> -u <new_name>\n\n\n\nRenaming Only remote branch\nCredit: ptim\n# In this option, we will push the branch to the remote with the new name\n# While keeping the local name as is\ngit push <remote> <remote>/<old_name>:refs/heads/<new_name> :<old_name>\n\n\nImportant note:\nWhen you use the git branch -m (move), Git is also updating your tracking branch with the new name.\n\ngit remote rename legacy legacy\n\ngit remote rename is trying to update your remote section in your configuration file. It will rename the remote with the given name to the new name, but in your case, it did not find any, so the renaming failed.\nBut it will not do what you think; it will rename your local configuration remote name and not the remote branch. \n\nNote\nGit servers might allow you to rename Git branches using the web interface or external programs (like Sourcetree, etc.), but you have to keep in mind that in Git all the work is done locally, so it's recommended to use the above commands to the work.\n",
            "\nIf you have named a branch incorrectly AND pushed this to the remote repository follow these steps to rename that branch (based on this article):\n\nRename your local branch:\n\nIf you are on the branch you want to rename:\ngit branch -m new-name\nIf you are on a different branch:\ngit branch -m old-name new-name\n\nDelete the old-name remote branch and push the new-name local branch:\ngit push origin :old-name new-name\nReset the upstream branch for the new-name local branch:\nSwitch to the branch and then:\ngit push origin -u new-name\n\n"
        ],
        "answer": "A1",
        "tags": [
            "git",
            "directory",
            "rename"
        ]
    },
    {
        "question_id": "14320041",
        "question": "\nIs there any difference between \npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\n\nOr\npthread_mutex_t lock;\npthread_mutex_init ( &lock, NULL);\n\nAm I safe enough if I use only the first method ?\nNOTE: My question mostly refers to very small programs where at the most what I'll do is connect several clients to a server and resolve their inquiries with worker threads.\n",
        "all_answers": [
            "\nYou can set more attributes of the mutex with the dynamic initialisation, plus you can only use the dynamic method if you're adding a bunch of mutexes at run time.\nThere's nothing wrong with the static approach though, if that fits your needs.\n",
            "\nBy older versions of the POSIX standard the first method with an initializer is only guaranteed to work with statically allocated variables, not when the variable is an auto variable that is defined in a function body. Although I have never seen a platform where this would not be allowed, even for auto variables, and this restriction has been removed in the latest version of the POSIX standard.\nThe static variant is really preferable if you may, since it allows to write bootstrap code much easier. Whenever at run time you enter into code that uses such a mutex, you can be assured that the mutex is initialized. This is a precious information in multi-threading context.\nThe method using an init function is preferable when you need special properties for your mutex, such as being recursive e.g or being shareable between processes, not only between threads.\n",
            "\n\n\nWhat's the best way to control which thread\n  a signal is delivered to?\n\n\nAs @zoli2k indicated, explicitly nominating a single thread to handle all signals you want handled (or a set of threads each with specific signal responsibilities), is a good technique.\n\n\nWhat is the best way to tell another thread (that might actually be busy)\n  that the signal has arrived?[...]\nHow can I safely handle passing the information that a signal has occurred\n  to other threads? Does this need to happen in the signal handler?\n\n\nI won't say \"best,\" but here's my recommendation:\nBlock all desired signals in main, so that all threads are inherit that signal mask.  Then, fashion the special signal receiving thread as a signal-driven event loop, dispatching newly arrived signals as some other intra-thread communication.\nThe simplest way to do this is to have the thread accept signals in a loop using sigwaitinfo or sigtimedwait.  The thread then converts the signals somehow, perhaps broadcasting a pthread_cond_t, waking up other threads with more I/O, enqueuing a command in an application-specific thread-safe queue, whatever.\nAlternatively, the special thread could allow signals to be delivered to a signal handler, unmasking for delivery only when ready to handle signals.  (Signal delivery via handlers tends to be more error-prone than signal acceptance via the sigwait family, however.)  In this case, the receiver's signal handler performs some simple and async-signal-safe action:  setting sig_atomic_t flags, calling sigaddset(&signals_i_have_seen_recently, latest_sig), write() a byte to a non-blocking self-pipe, etc.  Then, back in its masked main loop, the thread communicates receipt of the signal to other threads as above.\n(UPDATED @caf rightly points out that sigwait approaches are superior.)\n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "ubuntu",
            "pthreads",
            "mutex"
        ]
    },
    {
        "question_id": "834283",
        "question": "\nDoes anyone know of some global state variable that is available so that I can check if the code is currently executing in design mode (e.g. in Blend or Visual Studio) or not? \nIt would look something like this:\n//pseudo code:\nif (Application.Current.ExecutingStatus == ExecutingStatus.DesignMode) \n{\n    ...\n}\n\nThe reason I need this is: when my application is being shown in design mode in Expression Blend, I want the ViewModel to instead use a \"Design Customer class\" which has mock data in it that the designer can view in design mode.\nHowever, when the application is actually executing, I of course want the ViewModel to use the real Customer class which returns real data.\nCurrently I solve this by having the designer, before he works on it, go into the ViewModel and change \"ApplicationDevelopmentMode.Executing\" to \"ApplicationDevelopmentMode.Designing\":\npublic CustomersViewModel()\n{\n    _currentApplicationDevelopmentMode = ApplicationDevelopmentMode.Designing;\n}\n\npublic ObservableCollection<Customer> GetAll\n{\n    get\n    {\n        try\n        {\n            if (_currentApplicationDevelopmentMode == ApplicationDevelopmentMode.Developing)\n            {\n                return Customer.GetAll;\n            }\n            else\n            {\n                return CustomerDesign.GetAll;\n            }\n        }\n        catch (Exception ex)\n        {\n            throw new Exception(ex.Message);\n        }\n    }\n}\n\n",
        "all_answers": [
            "\nAccepted answer no longer works on .NET Core 3. To make it work, use the following method:\nvar psi = new ProcessStartInfo\n{\n    FileName = url,\n    UseShellExecute = true\n};\nProcess.Start (psi);\n\n",
            "\nI believe you are looking for GetIsInDesignMode, which takes a DependencyObject.\nIe.\n// 'this' is your UI element\nDesignerProperties.GetIsInDesignMode(this);\n\nEdit: When using Silverlight / WP7, you should use IsInDesignTool since GetIsInDesignMode can sometimes return false while in Visual Studio:\nDesignerProperties.IsInDesignTool\n\nEdit: And finally, in the interest of completeness, the equivalent in WinRT / Metro / Windows Store applications is DesignModeEnabled:\nWindows.ApplicationModel.DesignMode.DesignModeEnabled\n\n",
            "\nWhile a good answer has been given (using Process.Start), it is safer to encapsulate it in a function that checks that the passed string is indeed a URI, to avoid accidentally starting random processes on the machine.  \npublic static bool IsValidUri(string uri)\n{\n    if (!Uri.IsWellFormedUriString(uri, UriKind.Absolute))\n        return false;\n    Uri tmp;\n    if (!Uri.TryCreate(uri, UriKind.Absolute, out tmp))\n        return false;\n    return tmp.Scheme == Uri.UriSchemeHttp || tmp.Scheme == Uri.UriSchemeHttps;\n}\n\npublic static bool OpenUri(string uri) \n{\n    if (!IsValidUri(uri))\n        return false;\n     System.Diagnostics.Process.Start(uri);\n     return true;\n}\n\n",
            "\nYou can do something like this:\nDesignerProperties.GetIsInDesignMode(new DependencyObject());\n\n",
            "\nI've been using this line to launch the default browser:\nSystem.Diagnostics.Process.Start(\"http://www.google.com\"); \n\n",
            "\nFor desktop versions of .NET:\nSystem.Diagnostics.Process.Start(\"http://www.webpage.com\");\n\nFor .NET Core, the default for ProcessStartInfo.UseShellExecute has changed from true to false, and so you have to explicitly set it to true for this to work:\nSystem.Diagnostics.Process.Start(new ProcessStartInfo\n    {\n        FileName = \"http://www.webpage.com\",\n        UseShellExecute = true\n    });\n\nTo further complicate matters, this property cannot be set to true for UWP apps (so none of these solutions are usable for UWP).\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "wpf",
            "expression-blend"
        ]
    },
    {
        "question_id": "9200951",
        "question": "\nI would like my thread to shut down more gracefully so I am trying to implement a simple signalling mechanism. I don't think I want a fully event-driven thread so I have a worker with a method to graceully stop it using a critical section Monitor (equivalent to a C# lock I believe):\nDrawingThread.h\nclass DrawingThread {\n    bool stopRequested;\n    Runtime::Monitor CSMonitor;\n    CPInfo *pPInfo;\n    //More..\n}\n\nDrawingThread.cpp\nvoid DrawingThread::Run() {\n    if (!stopRequested)\n        //Time consuming call#1\n    if (!stopRequested) {\n        CSMonitor.Enter();\n        pPInfo = new CPInfo(/**/);\n        //Not time consuming but pPInfo must either be null or constructed. \n        CSMonitor.Exit();\n    }\n    if (!stopRequested) {\n        pPInfo->foobar(/**/);//Time consuming and can be signalled\n    }\n    if (!stopRequested) {\n        //One more optional but time consuming call.\n    }\n}\n\n\nvoid DrawingThread::RequestStop() {\n    CSMonitor.Enter();\n    stopRequested = true;\n    if (pPInfo) pPInfo->RequestStop();\n    CSMonitor.Exit();\n}\n\nI understand (at least in Windows) Monitor/locks are the least expensive thread synchronization primitive but I am keen to avoid overuse. Should I be wrapping each read of this boolean flag? It is initialized to false and only set once to true when stop is requested (if it is requested before the task completes).\nMy tutors advised to protect even bool's because read/writing may not be atomic. I think this one shot flag is the exception that proves the rule?\n",
        "all_answers": [
            "\nGCC Atomic Built-ins\n",
            "\nOn my system the behavior is same, but as Maxim mentioned, rand is not thread safe. When I change rand to rand_r, then the multi threaded code is faster as expected.\nvoid add_multi(int N, double& result) {\ndouble sum=0;\nunsigned int seed = time(NULL);\nfor (int i = 0; i < N; ++i){\n    sum+= sqrt(1.0*rand_r(&seed)/RAND_MAX);\n}\nresult = sum/N;\n}\n\n",
            "\nIt is never OK to read something possibly modified in a different thread without synchronization. What level of synchronization is needed depends on what you are actually reading. For primitive types, you should have a look at atomic reads, e.g. in the form of std::atomic<bool>.\nThe reason synchronization is always needed is that the processors will have the data possibly shared in a cache line. It has no reason to update this value to a value possibly changed in a different thread if there is no synchronization. Worse, yet, if there is no synchronization it may write the wrong value if something stored close to the value is changed and synchronized.\n",
            "\nBoolean assignment is atomic. That's not the problem.\nThe problem is that a thread may not not see changes to a variable done by a different thread due to either compiler or CPU instruction reordering or data caching (i.e. the thread that reads the boolean flag may read a cached value, instead of the actual updated value).\nThe solution is a memory fence, which indeed is implicitly added by lock statements, but for a single variable it's overkill. Just declare it as std::atomic<bool>.\n",
            "\nNo, you have to protect every access, since modern compilers and cpus reorder the code without your multithreading tasks in mind. The read access from different threads might work, but don't have to work.\n"
        ],
        "answer": "A3",
        "tags": [
            "c++",
            "multithreading",
            "locking",
            "boolean",
            "monitor"
        ]
    },
    {
        "question_id": "32343",
        "question": "\nLet's say I had a program in C# that did something computationally expensive, like encoding a list of WAV files into MP3s. Ordinarily I would encode the files one at a time, but let's say I wanted the program to figure out how many CPU cores I had and spin up an encoding thread on each core. So, when I run the program on a quad core CPU, the program figures out it's a quad core CPU, figures out there are four cores to work with, then spawns four threads for the encoding, each of which is running on its own separate CPU. How would I do this?\nAnd would this be any different if the cores were spread out across multiple physical CPUs? As in, if I had a machine with two quad core CPUs on it, are there any special considerations or are the eight cores across the two dies considered equal in Windows?\n",
        "all_answers": [
            "\nDon't bother doing that.\nInstead use the Thread Pool. The thread pool is a mechanism (actually a class) of the framework that you can query for a new thread.\nWhen you ask for a new thread it will either give you a new one or enqueue the work until a thread get freed. In that way the framework is in charge on deciding wether it should create more threads or not depending on the number of present CPUs.\nEdit: In addition, as it has been already mentioned, the OS is in charge of distributing the threads among the different CPUs.\n",
            "\nWhere each thread goes is generally handled by the OS itself...so generate 4 threads on a 4 core system and the OS will decide which cores to run each on, which will usually be 1 thread on each core.\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            ".net",
            "windows",
            "multithreading"
        ]
    },
    {
        "question_id": "545091",
        "question": "\nI'm using +[NSUserDefaults standardUserDefaults] to store application settings. This consists of roughly a dozen string values. Is it possible to delete these values permanently instead of just setting them to a default value?\n",
        "all_answers": [
            "\nThis code resets the defaults to the registration domain:\n[[NSUserDefaults standardUserDefaults] setPersistentDomain:[NSDictionary dictionary] forName:[[NSBundle mainBundle] bundleIdentifier]];\n\nIn other words, it removeObjectForKey for every single key you ever registered in that app.\nCredits to Ken Thomases on this Apple Developer Forums thread.\n",
            "\nYou can remove the application's persistent domain like this:\nNSString *appDomain = [[NSBundle mainBundle] bundleIdentifier];\n[[NSUserDefaults standardUserDefaults] removePersistentDomainForName:appDomain];\n\nIn Swift 3 and later:\nif let bundleID = Bundle.main.bundleIdentifier {\n    UserDefaults.standard.removePersistentDomain(forName: bundleID)\n}\n\nThis is similar to the answer by @samvermette but is a little bit cleaner IMO.\n",
            "\nHere are two one-line macros that I use:\n#define TICK   NSDate *startTime = [NSDate date]\n#define TOCK   NSLog(@\"Time: %f\", -[startTime timeIntervalSinceNow])\n\nUse it like this:\nTICK;\n\n/* ... Do Some Work Here ... */\n\nTOCK;\n\n",
            "\nFor fine-grained timing on OS X, you should use mach_absolute_time( ) declared in <mach/mach_time.h>:\n#include <mach/mach_time.h>\n#include <stdint.h>\n\n// Do some stuff to setup for timing\nconst uint64_t startTime = mach_absolute_time();\n// Do some stuff that you want to time\nconst uint64_t endTime = mach_absolute_time();\n\n// Time elapsed in Mach time units.\nconst uint64_t elapsedMTU = endTime - startTime;\n\n// Get information for converting from MTU to nanoseconds\nmach_timebase_info_data_t info;\nif (mach_timebase_info(&info))\n   handleErrorConditionIfYoureBeingCareful();\n\n// Get elapsed time in nanoseconds:\nconst double elapsedNS = (double)elapsedMTU * (double)info.numer / (double)info.denom;\n\nOf course the usual caveats about fine-grained measurements apply; you're probably best off invoking the routine under test many times, and averaging/taking a minimum/some other form of processing.\nAdditionally, please note that you may find it more useful to profile your application running using a tool like Shark.  This won't give you exact timing information, but it will tell you what percentage of the application's time is being spent where, which is often more useful (but not always).\n",
            "\nNSDate *methodStart = [NSDate date];\n\n/* ... Do whatever you need to do ... */\n\nNSDate *methodFinish = [NSDate date];\nNSTimeInterval executionTime = [methodFinish timeIntervalSinceDate:methodStart];\nNSLog(@\"executionTime = %f\", executionTime);\n\nSwift:\nlet methodStart = NSDate()\n\n/* ... Do whatever you need to do ... */\n\nlet methodFinish = NSDate()\nlet executionTime = methodFinish.timeIntervalSinceDate(methodStart)\nprint(\"Execution time: \\(executionTime)\")\n\nSwift3:\nlet methodStart = Date()\n\n/* ... Do whatever you need to do ... */\n\nlet methodFinish = Date()\nlet executionTime = methodFinish.timeIntervalSince(methodStart)\nprint(\"Execution time: \\(executionTime)\")\n\nEasy to use and has sub-millisecond precision.\n",
            "\nDid you try using -removeObjectForKey?\n [[NSUserDefaults standardUserDefaults] removeObjectForKey:@\"defunctPreference\"];\n\n"
        ],
        "answer": "A2",
        "tags": [
            "ios",
            "objective-c",
            "cocoa-touch",
            "nsuserdefaults"
        ]
    },
    {
        "question_id": "46991237",
        "question": "\nI am building a map application using Angular Maps and want to import a JSON file as a list of markers defining locations. I'm hoping to use this JSON file as marker[] array inside the app.component.ts . Instead of defining a hardcoded array of markers inside the TypeScript file.\nWhat is the best process of importing this JSON file for use in my project? Any direction greatly appreciated!\n",
        "all_answers": [
            "\nIf you want to see what you you have inside an object in your web app, then use the json pipe in a component HTML template, for example:\n<li *ngFor=\"let obj of myArray\">{{obj | json}}</li>\n\nTested and valid using Angular 4.3.2.\n",
            "\nTo loop through JSON Object : In Angluar's (6.0.0+), now they provide the pipe keyvalue :\n<div *ngFor=\"let item of object| keyvalue\">\n  {{ item.key }} - {{ item.value }}\n</div>\n\nDO READ ALSO\nTo just display JSON\n{{ object | json }}\n\n",
            "\nlet fs = require('fs');\nlet markers;\nfs.readFile('./markers.json', handleJSONFile);\n\nvar handleJSONFile = function (err, data) {\n   if (err) {\n      throw err;\n   }\n   markers= JSON.parse(data);\n }\n\n",
            "\nFirst solution - simply change the extension of your .json file to .ts and add export default at the beginning of the file, like so:\nexport default {\n   property: value;\n}\n\nThen you can just simply import the file without the need to add typings, like so:\nimport data from 'data';\n\n\nSecond solution get the json via HttpClient.\nInject HttpClient into your component, like so:\nexport class AppComponent  {\n  constructor(public http: HttpClient) {}\n}\n\nand then use this code:\nthis.http.get('/your.json').subscribe(data => {\n  this.results = data;\n});\n\nhttps://angular.io/guide/http\nThis solution has one clear adventage over other solutions provided here - it doesn't require you to rebuild entire application if your json will change (it's loaded dynamically from a separate file, so you can modify only that file).\n",
            "\nAonepathan's one-liner was working for me until a recent typescript update. \nI found Jecelyn Yeen's post which suggests posting this snippet into your TS Definition file\nadd file typings.d.ts to the project's root folder with below content\ndeclare module \"*.json\" {\n    const value: any;\n    export default value;\n}\n\nand then import your data like this:\nimport * as data from './example.json';\nupdate July 2019:\nTypescript 2.9 (docs) introduced a better, smarter solution. Steps:\n\nAdd resolveJsonModule support with this line in your tsconfig.json file: \n\n\"compilerOptions\": {\n    ...\n    \"resolveJsonModule\": true\n  }\n\nthe import statement can now assumes a default export: \nimport data from './example.json';\nand intellisense will now check the json file to see whether you can use Array etc. methods. pretty cool. \n",
            "\nThanks for the input guys, I was able to find the fix, I added and defined the json on top of the app.component.ts file:\nvar json = require('./[yourFileNameHere].json');\n\nThis ultimately produced the markers and is a simple line of code.\n",
            "\nWe can use angular pipe json\n{{ jsonObject | json }}\n\n"
        ],
        "answer": "A5",
        "tags": [
            "json",
            "angular",
            "google-maps",
            "typescript",
            "maps"
        ]
    },
    {
        "question_id": "46160929",
        "question": "\nI am using Puppeteer to try to take a screenshot of a website after all images have loaded but can't get it to work.\nHere is the code I've got so far, I am using https://www.digg.com as the example website:\nconst puppeteer = require('puppeteer');\n\n(async () => {\n    const browser = await puppeteer.launch();\n    const page = await browser.newPage();\n    await page.goto('https://www.digg.com/');\n\n    await page.setViewport({width: 1640, height: 800});\n\n    await page.evaluate(() => {\n        return Promise.resolve(window.scrollTo(0,document.body.scrollHeight));\n    });\n\n    await page.waitFor(1000);\n\n    await page.evaluate(() => {\n        var images = document.querySelectorAll('img');\n\n        function preLoad() {\n\n            var promises = [];\n\n            function loadImage(img) {\n                return new Promise(function(resolve,reject) {\n                    if (img.complete) {\n                        resolve(img)\n                    }\n                    img.onload = function() {\n                        resolve(img);\n                    };\n                    img.onerror = function(e) {\n                        resolve(img);\n                    };\n                })\n            }\n\n            for (var i = 0; i < images.length; i++)\n            {\n                promises.push(loadImage(images[i]));\n            }\n\n            return Promise.all(promises);\n        }\n\n        return preLoad();\n    });\n\n    await page.screenshot({path: 'digg.png', fullPage: true});\n\n    browser.close();\n})();\n\n",
        "all_answers": [
            "\nI'm facing the exact same issue.\nI have a feeling the solution will involve using:\nawait page.setRequestInterceptionEnabled(true);\n\npage.on('request', interceptedRequest => {\n    //some code here that adds this request to ...\n    //a list and checks whether all list items have ...\n    //been successfully completed!\n});\n\nhttps://github.com/GoogleChrome/puppeteer/blob/master/docs/api.md#pagesetrequestinterceptionenabledvalue\n",
            "\nThere is a built-in option for that:\nawait page.goto('https://www.digg.com/', {\"waitUntil\" : \"networkidle0\"});\n\n\nnetworkidle0 - consider navigation to be finished when there are no more than 0 network connections for at least 500 ms\n\n\nnetworkidle2 - consider navigation to be finished when there are no more than 2 network connections for at least 500 ms.\n\nOf course it won't work if you're working with endless-scrolling-single-page-applications like Twitter.\nPuppeteer GitHub issue #1552 provides explanation for the motivation behind networkidle2.\n",
            "\nNo comment on why you want to do this, or what might be a more standard practice: here is a solution to your question.... Keep in mind that the type of quotes required by your command line may vary.\nIn your db.js, export the init function. There are many ways, but for example:\n    module.exports.init = function () {\n      console.log('hi');\n    };\n\nThen call it like this, assuming your db.js is in the same directory as your command prompt:\nnode -e 'require(\"./db\").init()'\n\nIf your db.js were a module db.mjs, use a dynamic import to load the module:\nnode -e 'import(\"./db.mjs\").then( loadedModule => loadedModule.init() )'\n\nTo other readers, the OP's  init function could have been called anything, it is not important, it is just the specific name used in the question.\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "node.js",
            "google-chrome",
            "automation",
            "puppeteer"
        ]
    },
    {
        "question_id": "576169",
        "question": "\n\n\n\nWhy is super() used?\nIs there a difference between using Base.__init__ and super().__init__?\nclass Base(object):\n    def __init__(self):\n        print \"Base created\"\n        \nclass ChildA(Base):\n    def __init__(self):\n        Base.__init__(self)\n        \nclass ChildB(Base):\n    def __init__(self):\n        super(ChildB, self).__init__()\n        \nChildA() \nChildB()\n\n",
        "all_answers": [
            "\nThere isn't, really. super() looks at the next class in the MRO (method resolution order, accessed with cls.__mro__) to call the methods. Just calling the base __init__ calls the base __init__. As it happens, the MRO has exactly one item-- the base. So you're really doing the exact same thing, but in a nicer way with super() (particularly if you get into multiple inheritance later).\n",
            "\nsuper() lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of fun stuff can happen. See the standard docs on super if you haven't already.\nNote that the syntax changed in Python 3.0: you can just say super().__init__() instead of super(ChildB, self).__init__() which IMO is quite a bit nicer. The standard docs also refer to a guide to using super() which is quite explanatory.\n",
            "\nUsing these magic methods (__enter__, __exit__) allows you to implement objects which can be used easily with the with statement. \nThe idea is that it makes it easy to build code which needs some 'cleandown' code executed (think of it as a try-finally block). Some more explanation here.\nA useful example could be a database connection object (which then automagically closes the connection once the corresponding 'with'-statement goes out of scope):\nclass DatabaseConnection(object):\n\n    def __enter__(self):\n        # make a database connection and return it\n        ...\n        return self.dbconn\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        # make sure the dbconnection gets closed\n        self.dbconn.close()\n        ...\n\nAs explained above, use this object with the with statement (you may need to do from __future__ import with_statement at the top of the file if you're on Python 2.5).\nwith DatabaseConnection() as mydbconn:\n    # do stuff\n\nPEP343 -- The 'with' statement' has a nice writeup as well.\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "class",
            "oop",
            "inheritance",
            "super"
        ]
    },
    {
        "question_id": "9320427",
        "question": "\nI'm thinking about embedding arbitrary JSON in the DOM like this:\n<script type=\"application/json\" id=\"stuff\">\n    {\n        \"unicorns\": \"awesome\",\n        \"abc\": [1, 2, 3]\n    }\n</script>\n\nThis is similar to the way one might store an arbitrary HTML template in the DOM for later use with a JavaScript template engine. In this case, we could later retrieve the JSON and parse it with:\nvar stuff = JSON.parse(document.getElementById('stuff').innerHTML);\n\nThis works, but is it the best way? Does this violate any best practice or standard?\nNote: I'm not looking for alternatives to storing JSON in the DOM, I've already decided that's the best solution for the particular problem I'm having. I'm just looking for the best way to do it.\n",
        "all_answers": [
            "\nI think your original method is the best. The HTML5 spec even addresses this use:\n\n\"When used to include data blocks (as opposed to scripts), the data\n  must be embedded inline, the format of the data must be given using\n  the type attribute, the src attribute must not be specified, and the\n  contents of the script element must conform to the requirements\n  defined for the format used.\"\n\nRead here: http://dev.w3.org/html5/spec/Overview.html#the-script-element\nYou've done exactly that. What is not to love? No character encoding as needed with attribute data. You can format it if you want. It's expressive and the intended use is clear. It doesn't feel like a hack (e.g. as using CSS to hide your \"carrier\" element does). It's perfectly valid. \n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n",
            "\nI'd suggest to put JSON into an inline script with a function callback (kind of JSONP):\n<script>\nsomeCallback({\n    \"unicorns\": \"awesome\",\n    \"abc\": [1, 2, 3]\n});\n</script>\n\nIf the executing script is loaded after the document you can store this somewhere, possibly with an additional identifier argument: someCallback(\"stuff\", { ... });\n",
            "\nMy recommendation would be to keep JSON data in external .json files, and then retrieve those files via Ajax. You don't put CSS and JavaScript code onto the web-page (inline), so why would you do it with JSON?\n",
            "\nAs a general direction, I would try using HTML5 data attributes instead. There's nothing to stop you putting in valid JSON. e.g.: \n<div id=\"mydiv\" data-unicorns='{\"unicorns\":\"awesome\", \"abc\":[1,2,3]}' class=\"hidden\"></div>\n\nIf you're using jQuery, then retrieving it is as easy as:\nvar stuff = JSON.parse($('#mydiv').attr('data-unicorns'));\n\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "json",
            "dom",
            "embedding",
            "decoupling"
        ]
    },
    {
        "question_id": "5796983",
        "question": "\nHow can I check if a float variable contains an integer value? So far, I've been using:\nfloat f = 4.5886;\nif (f-(int)f == 0)\n     printf(\"yes\\n\");\nelse printf(\"no\\n\");\n\nBut I wonder if there is a better solution, or if this one has any (or many) drawbacks.\n",
        "all_answers": [
            "\nif (f <= LONG_MIN || f >= LONG_MAX || f == (long)f) /* it's an integer */\n\n",
            "\nstdlib float modf (float x, float *ipart) splits into two parts, check if return value (fractional part) == 0. \n",
            "\nif (fmod(f, 1) == 0.0) {\n  ...\n}\n\nDon't forget math.h and libm.\n",
            "\nApart from the fine answers already given, you can also use ceilf(f) == f or floorf(f) == f. Both expressions return true if f is an integer. They also returnfalse for NaNs (NaNs always compare unequal) and true for ±infinity, and don't have the problem with overflowing the integer type used to hold the truncated result, because floorf()/ceilf() return floats.\n",
            "\nWhy C++ doesn't have support for unsigned floats is because there is no equivalent machine code operations for the CPU to execute.  So it would be very inefficient to support it.  \nIf C++ did support it, then you would be sometimes using an unsigned float and not realizing that your performance has just been killed.  If C++ supported it then every floating point operation would need to be checked to see if it is signed or not.  And for programs that do millions of floating point operations, this is not acceptable. \nSo the question would be why don't hardware implementers support it.  And I think the answer to that is that there was no unsigned float standard defined originally.  Since languages like to be backwards compatible, even if it were added languages couldn't make use of it.  To see the floating point spec you should look at the IEEE standard 754 Floating-Point.\nYou can get around not having an unsigned floating point type though by creating a unsigned float class that encapsulates a float or double and throws warnings if you try to pass in a negative number.   This is less efficient, but probably if you aren't using them intensely you won't care about that slight performance loss.\nI definitely see the usefulness of having an unsigned float.  But C/C++ tends to chose efficiency that works best for everyone over safety. \n"
        ],
        "answer": "A4",
        "tags": [
            "c",
            "floating-point",
            "int"
        ]
    },
    {
        "question_id": "10664244",
        "question": "\nI have been developing a basic app. Now at the deployment stage it has become clear I have need for both a local settings and production settings.\nIt would be great to know the following:\n\nHow best to deal with development and production settings. \nHow to keep apps such as django-debug-toolbar only in a development environment.\nAny other tips and best practices for development and deployment settings.\n\n",
        "all_answers": [
            "\nThe DJANGO_SETTINGS_MODULE environment variable controls which settings file Django will load. \nYou therefore create separate configuration files for your respective environments (note that they can of course both import * from a separate, \"shared settings\" file), and use DJANGO_SETTINGS_MODULE to control which one to use.\nHere's how:\nAs noted in the Django documentation:\n\nThe value of DJANGO_SETTINGS_MODULE should be in Python path syntax, e.g. mysite.settings. Note that the settings module should be on the Python import search path.\n\nSo, let's assume you created myapp/production_settings.py and myapp/test_settings.py in your source repository.\nIn that case, you'd respectively set DJANGO_SETTINGS_MODULE=myapp.production_settings to use the former and DJANGO_SETTINGS_MODULE=myapp.test_settings to use the latter.\n\nFrom here on out, the problem boils down to setting the DJANGO_SETTINGS_MODULE environment variable. \nSetting DJANGO_SETTINGS_MODULE using a script or a shell\nYou can then use a bootstrap script or a process manager to load the correct settings (by setting the environment), or just run it from your shell before starting Django: export DJANGO_SETTINGS_MODULE=myapp.production_settings.\nNote that you can run this export at any time from a shell — it does not need to live in your .bashrc or anything.\nSetting DJANGO_SETTINGS_MODULE using a Process Manager\nIf you're not fond of writing a bootstrap script that sets the environment (and there are very good reasons to feel that way!), I would recommend using a process manager:\n\nSupervisor lets you pass environment variables to managed processes using a program's environment configuration key.\nHoncho (a pure-Python equivalent of Ruby's Foreman) lets you define environment variables in an \"environment\" (.env) file.\n\n\nFinally, note that you can take advantage of the PYTHONPATH variable to store the settings in a completely different location (e.g. on a production server, storing them in /etc/). This allows for separating configuration from application files. You may or may not want that, it depends on how your app is structured. \n",
            "\nI'll be curious to see a better solution as well. I've used a custom method in my serializer to do that. It's a bit more verbose but at least it's explicit. \nSome pseudo code where a GarageSerializer would filter the nested relation of cars:\nclass MyGarageSerializer(...):\n    users = serializers.SerializerMethodField('get_cars')\n\n    def get_cars(self, garage):\n        cars_queryset = Car.objects.all().filter(Q(garage=garage) | ...).select_related()\n        serializer = CarSerializer(instance=cars_queryset, many=True, context=self.context)\n\n        return serializer.data\n\nObviously replace the queryset with whatever you want. You don't always need the to give the context (I used it to retrieve some query parameters in the nested serializer) and you probably don't need the .select_related (that was an optimisation).\n",
            "\nCreate multiple settings*.py files, extrapolating the variables that need to change per environment. Then at the end of your master settings.py file:\ntry:\n  from settings_dev import *\nexcept ImportError:\n  pass\n\nYou keep the separate settings_* files for each stage.\nAt the top of your settings_dev.py file, add this:\nimport sys\nglobals().update(vars(sys.modules['settings']))\n\nTo import variables that you need to modify.\nThis wiki entry has more ideas on how to split your settings.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "django"
        ]
    },
    {
        "question_id": "5199811",
        "question": "\n\n\n\nSo I installed the android sdk for Windows:\nhttp://developer.android.com/sdk/index.html   (the installation link) \nAnd ran into the path variable problem. So I fixed that by changing \"PATH\" in enviroment variables to include where my java.exe file is located from the JDK.  \nBut now when I open the android sdk manager, a cmd-like screen just briefly flashes on for half a second then disappears. I have no idea what's going on and how to get this thing working. \n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nMake sure your java\\bin directory is in your path statement before the windows\\system32 directory. \nThe SDK Manager uses java and it was finding the one in the system32 folder. \nIn a CMD window, you can run 'where java'.\nDon't forget to restart your CMD after changing the path variable for checking.\n",
            "\nYou can now do this by including the sound when building a notification rather than calling the sound separately.\n//Define Notification Manager\nNotificationManager notificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\n\n//Define sound URI\nUri soundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n\nNotificationCompat.Builder mBuilder = new NotificationCompat.Builder(getApplicationContext())\n        .setSmallIcon(icon)\n        .setContentTitle(title)\n        .setContentText(message)\n        .setSound(soundUri); //This sets the sound to play\n\n//Display notification\nnotificationManager.notify(0, mBuilder.build());\n\n",
            "\nIf you want a default notification sound to be played, then you can use setDefaults(int) method of NotificationCompat.Builder class:\nNotificationCompat.Builder mBuilder =\n        new NotificationCompat.Builder(this)\n                .setSmallIcon(R.drawable.ic_notification)\n                .setContentTitle(getString(R.string.app_name))\n                .setContentText(someText)\n                .setDefaults(Notification.DEFAULT_SOUND)\n                .setAutoCancel(true);\n\nI believe that's the easiest way to accomplish your task.\n",
            "\nIt's been a while since your question, but ... Have you tried setting the Audio stream type?\nmp.setAudioStreamType(AudioManager.STREAM_NOTIFICATION);\n\nIt must be done before prepare.\n",
            "\nhttp://quantumsupport.blogspot.com/2011/03/android-sdk-managerexe-wont-start.html\nCreate a new user account, either re-install or just start android.bat and it should work did for me\n",
            "\nTry this: \npublic void ringtone(){\n    try {\n        Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n        Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n        r.play();\n     } catch (Exception e) {\n         e.printStackTrace();\n     }\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "android",
            "path"
        ]
    },
    {
        "question_id": "2428572",
        "question": "\nHow can I escape a ' (single quote) in HTML?\nThis is where I'm trying to use it:\n<input type='text' id='abc' value='hel'lo'>\n\nThe result for the above code is \"hel\" populated in the text box. I tried to replace ' with \\', but this what I'm getting.\n<input type='text' id='abc' value='hel\\'lo'>\n\nThe result for the above code is \"hel\" populated in the text box.\nHow can I successfully escape the single quotes?\n",
        "all_answers": [
            "\nYou could try using: &#145;\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYou could use HTML entities:\n\n&#39; for '\n&#34; for \"\n...\n\nFor more, you can take a look at Character entity references in HTML.\n",
            "\nProbably the easiest way:\n<input type='text' id='abc' value=\"hel'lo\">\n\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n"
        ],
        "answer": "A3",
        "tags": [
            "html",
            "escaping"
        ]
    },
    {
        "question_id": "34100048",
        "question": "\nI want to create a new GitHub branch, called release.\nThis branch needs to be empty! However, there is an existing branch with x commits and I don't want to have its commit history.\nThe only method I found is to create a local --orphan branch.\n",
        "all_answers": [
            "\nYou can also follow the instructions here to create an empty commit at the root of your master branch. Then just create your release branch where that empty root commit is.\n",
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nNovember 2021 Update: As of git version 2.27, you can now use git switch --orphan <new branch> to create an empty branch with no history.\nUnlike git checkout --orphan <new branch>, this branch won't have any files from your current branch (save for those which git doesn't track).\nThis should be the preferred way to create empty branches with no prior history.\nOnce you actually have commits on this branch, it can be pushed to github via git push -u origin <branch name>:\ngit switch --orphan <new branch>\ngit commit --allow-empty -m \"Initial commit on orphan branch\"\ngit push -u origin <new branch>\n\nOriginal answer:\nWhat's wrong with the --orphan option? If you want a branch that is empty and have no history, this is the way to go...\ngit checkout --orphan empty-branch\n\nThen you can remove all the files you'll have in the staging area (so that they don't get committed):\ngit rm -rf .\n\nAt this point you have an empty branch, on your machine.\nBefore you can push to GitHub (or any other Git repository), you will need at least one commit, even if it does not have any content on it (i.e. empty commit), as you cannot push an empty branch\ngit commit --allow-empty -m \"root commit\"\n\nFinally, push it to the remote, and crack open a beer\ngit push origin empty-branch\n\n"
        ],
        "answer": "A3",
        "tags": [
            "git",
            "github"
        ]
    },
    {
        "question_id": "20435653",
        "question": "\n\n\n\nI have one simple question, that got stuck in my mind for a few days: What is VanillaJS? Some people refer to it as a framework, you can download a library from the official pages.\nBut when I check some examples or TodoMVC, they just use classic raw JavaScript functions without even including the library from the official pages or anything. Also the link \"Docs\" on the official webpage leads to the Mozilla specification of JavaScript.\nMy question is: Is VanillaJS raw JavaScript? And if yes, why people refer to it as \"framework\" when all you need is a browser without any special included scripts?\nI am sorry for a probably stupid question but I have no idea what people are talking about when they say \"VanillaJS\".\n",
        "all_answers": [
            "\nUsing \"VanillaJS\" means using plain JavaScript without any additional libraries like jQuery. \nPeople use it as a joke to remind other developers that many things can be done nowadays without the need for additional JavaScript libraries.  \nHere's a funny site that jokingly talks about this: http://vanilla-js.com/\n",
            "\nThis is VanillaJS (unmodified):\n// VanillaJS v1.0\n// Released into the Public Domain\n// Your code goes here:\n\nAs you can see, it's not really a framework or a library. It's just a running gag for framework-loving bosses or people who think you NEED to use a JS framework. It means you just use whatever your (for you own sake: non-legacy) browser gives you (using Vanilla JS when working with legacy browsers is a bad idea).\n",
            "\nVanillaJS is a term for library/framework free javascript.  \nIts sometimes ironically referred to as a library, as a joke for people who could be seen as mindlessly using different frameworks, especially jQuery.\nSome people have gone so far to release this library, usually with an empty or comment-only js file.\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript"
        ]
    },
    {
        "question_id": "982659",
        "question": "\nIn the same vein as Quickly create a large file on a Linux system, \nI'd like to quickly create a large file on a Windows system. By large I'm thinking 5 GB. The content doesn't matter. A built-in command or short batch file would be preferable, but I'll accept an application if there are no other easy ways.\n",
        "all_answers": [
            "\nfsutil file createnew <filename> <length>\n\nwhere <length> is in bytes.\nFor example, to create a 1MB (Windows MB or MiB) file named 'test', this code can be used.\nfsutil file createnew test 1048576\n\nfsutil requires administrative privileges though.\n",
            "\nI found a solution using DEBUG at http://www.scribd.com/doc/445750/Create-a-Huge-File, but I don't know an easy way to script it and it doesn't seem to be able to create files larger than 1 GB.\n",
            "\nCheck the Windows Server 2003 Resource Kit Tools. There is a utility called Creatfil.\n CREATFIL.EXE\n -? : This message\n -FileName -- name of the new file\n -FileSize -- size of file in KBytes, default is 1024 KBytes\n\nIt is the similar to mkfile on Solaris.\n",
            "\nUse:\n/*\nCreates an empty file, which can take all of the disk\nspace. Just specify the desired file size on the\ncommand line.\n*/\n\n#include <windows.h>\n#include <stdlib.h>\n\nint main (int argc, char* ARGV[])\n{\n    int size;\n    size = atoi(ARGV[1]);\n    const char* full = \"fulldisk.dsk\";\n    HANDLE hf = CreateFile(full,\n                           GENERIC_WRITE,\n                           0,\n                           0,\n                           CREATE_ALWAYS,\n                           0,\n                           0);\n    SetFilePointer(hf, size, 0, FILE_BEGIN);\n    SetEndOfFile(hf);\n    CloseHandle(hf);\n    return 0;\n}\n\n",
            "\nYou can use the Sysinternals Contig tool. It has a -n switch which creates a new file of a given size. Unlike fsutil, it doesn't require administrative privileges.\n",
            "\nShort of writing a full application, us Python guys can achieve files of any size with four lines, same snippet on Windows and Linux (the os.stat() line is just a check):\n>>> f = open('myfile.txt','w')\n>>> f.seek(1024-1) # an example, pick any size\n>>> f.write('\\x00')\n>>> f.close()\n>>> os.stat('myfile.txt').st_size\n1024L\n>>>\n\n"
        ],
        "answer": "A1",
        "tags": [
            "windows",
            "batch-file"
        ]
    },
    {
        "question_id": "206558",
        "question": "\nI continually get these errors when I try to update tables based on another table. I end up rewriting the query, change the order of joins, change some groupings and then it eventually works, but I just don't quite get it.\nWhat is a 'multi-part identifier'?\nWhen is a 'multi-part identifier' not able to be bound?\nWhat is it being bound to anyway?\nIn what cases will this error occur?\nWhat are the best ways to prevent it?\nThe specific error from SQL Server 2005 is:\n\nThe multi-part identifier \"...\" could not be bound.\n\nHere is an example:\nSELECT * FROM [MainDB].[dbo].[Company] \nWHERE [MainDB].[dbo].[Company].[CompanyName] = 'StackOverflow'\n\nThe actual error:\n\nMsg 4104, Level 16, State 1, Line 2 The multi-part identifier\n\"MainDB.dbo.Company.CompanyName\" could not be bound.\n\n",
        "all_answers": [
            "\nBinding = your textual representation of a specific column gets mapped to a physical column in some table, in some database, on some server.\nMultipart identifier could be: MyDatabase.dbo.MyTable. If you get any of these identifiers wrong, then you have a multipart identifier that cannot be mapped.\nThe best way to avoid it is to write the query right the first time, or use a plugin for management studio that provides intellisense and thus help you out by avoiding typos.\n",
            "\nA multipart identifier is any description of a field or table that contains multiple parts - for instance MyTable.SomeRow - if it can't be bound that means there's something wrong with it - either you've got a simple typo, or a confusion between table and column.  It can also be caused by using reserved words in your table or field names and not surrounding them with [].\nIt can also be caused by not including all of the required columns in the target table.\nSomething like redgate sql prompt is brilliant for avoiding having to manually type these (it even auto-completes joins based on foreign keys), but isn't free.  SQL server 2008 supports intellisense out of the box, although it isn't quite as complete as the redgate version.\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "sql-server"
        ]
    },
    {
        "question_id": "10147445",
        "question": "\nI opened a pull request to rails repo on github by using Fork & Edit this file file button.\nNow, \nAfter getting feedback on my PR, I wanted to add some more commits. so here is what I ended by doing\n$ git clone git@github.com:gaurish/rails.git #my forked repo\n$ git rebase -i 785a2e5 #commit hash of my commit using which PR was opened\n$ git checkout patch-3 #branch name I had to send my commits under to be shown in that PR\n$ git commit -am \"Changes done as per feedback\"\n$ git push origin patch-3\n\nThis worked fine but seems quite a complex workflow. Maybe I am wrong something wrong here? \nmy question is:\nAm I doing this the correct way? if not, then what is the proper way to do this?\n",
        "all_answers": [
            "\nYou might have changed your repository name\nIn your local repository edit the file:\n.git/config\n\nThen check:\n[remote \"origin\"]\n   url = \n\nthat the URL matches your remote repository\n",
            "\nIn my case my github account did not have permissions to the repo. Added the github account as a collaborator for the repo and that fixed it.\n",
            "\nSince you're using GitHub's tools and just changing one file, you could also browse to the file on GitHub, select the proper branch from the upper left corner under the \"tree:\" dropdown (patch-3 in your case), and now choose \"Edit this file\".  Now your changes will be committed to this branch and will show up in your pull request\n",
            "\nI got the same problem while using a github repository, and connecting to it via https, while using the OS X Keychain Credential helper.\nMy problem was that I had the wrong credentials stored in OS X's Keychain (I was using the email address that I used to sign up for github.com rather than the [username]@github.com address it provides you). I deleted the old account in the keychain and only left the @github.com one and it fixed the problem.\nNot sure if it is related, but when I checked the user.email local config:\ngit config -l\n\nit showed the incorrect email address as well, so I updated the local git user.email to use the correct account too:\ngit config user.email <username>@github.com\n\n",
            "\nThis error mostly caused by WRONG URL, please check:\n\nhttp or https\nURL Name\nusername@git_url\nwrong git name\n\n",
            "\nMy issue was that I used the clone https url widget provided by github. That URL doesn't work for private repositories as you need to add a username to the front of it.  \nExample: a private repo owned by john and named widget with collaborator sam the correct url would be: \nhttps://sam@github.com/john/widget.git\nThe github provided url: \nhttps://github.com/john/widget.git\nThe error message leaves much to be desired.\n",
            "\nDid you create a new repository on the http://github.com with the same name? \nIf not, do it! And make sure each letter is correct and case sensitive.\n",
            "\nAlso make sure the repo you've entered is cased correctly (it's case sensitive).\n",
            "\nMake sure that your user account is added to the repository as a collaborator.\nSetting --> Collaborators\n",
            "\nIt looks like that's a private (or deleted) repository; if you visit the repository page while logged it'll give you the real URL, which'll probably be https://TeaCodie@github.com/TeaCodie/TeaCodie-Website.git , i.e. with a username specified?\n",
            "\nYou could also create a new pull request which is bound to master instead of a specific abc1234 revision.\nThat way, any new commit/push to your repository will be added to the pull request.\n"
        ],
        "answer": "A3",
        "tags": [
            "git",
            "github",
            "pull-request"
        ]
    },
    {
        "question_id": "13196909",
        "question": "\nI'm using an enum defined in a class module in Excel VBA. This has been working fine, but I've started getting a compile error on every time I do a comparison on enum variables:\nIn class CExample:\nEnum MyEnum\n    Foo\n    Bar\nEnd Enum\n\nElsewhere:\nIf someValue = myEnum.Foo Then\n\nThe text .Foo will be highlighted, and a \"Compile error: Constant expression required\" message pops up.\nA search on Google suggests that this can randomly happen, and fixes such as restarting the IDE or adding a space after the enum declaration can make it start working again.\n\nhttp://www.tek-tips.com/viewthread.cfm?qid=1355882\nhttp://www.vbforums.com/showthread.php?405564-RESOLVED-Constant-Expression-Required-Error-when-checking-Enum\n\nIs this really a known bug in VBA? Is there anything I can do to avoid it happening, or reliably get VBA working again if it does crop up?\nIn my case, closing and reopening Excel hasn't helped. Excuse me while I reboot my PC.\nUpdate after reboot:\nThe problem persisted after rebooting my machine, which is surprising. I tried adding Public in front of the enum definition (they're meant to be public by default but I thought I'd give it a try), and the error disappeared. I've removed the Public keyword (so we're back to my original code) and it still compiles and runs fine.\nIt does look like this is a random bug in VBA. I'd be interested to know if experienced developers have found this comes up often - would you advise not using enums? Or does it pop up once in a blue moon and I was just unlucky?\nUpdate after 6 weeks of further development:\nThe problem didn't recur during the rest of my time developing this project, so it looks like it is a rare problem.\n",
        "all_answers": [
            "\nAs noted in the question, I got rid of the error by editing and saving the enum definition, then undoing the edit and saving again. Having recently done some more work on the project, I found a different but similar issue - one line of code would give a \"Type mismatch\" error, where there was no type mismatch and where the same function, unchanged, had been working fine with the same inputs.\nSome of the intermittent errors I'm seeing might be due to a buildup of code artefacts in the Excel file - having done some reading, I've found that VBA code gets compiled and saved into the file. There's no \"clean\" or \"rebuild all\" option - VBA tries to work out for itself what incremental changes are needed. This can lead to all kinds of odd runtime behaviour in projects where you've made lots of code changes. This is likely the cause of the enum errors I was finding during initial development of this workbook. The section \"What It Means to Decompile and Compact in VBA\" in this article gives a good overview.\nMost mentions of this problem recommend using VBA CodeCleaner: http://www.appspro.com/Utilities/CodeCleaner.htm. Chip Pearson, a well-known and respected VBA expert, says \" I very strongly recommend this add-in\". I'm surprised I haven't come across this before!\n",
            "\nSeems to be a bug.\nCopy the same module's code to a new one, and recompile. That seems to solve it for some. \nA similar fix exists, which involves editing and undoing on the enum definition's line. \nConsider switching to numeric constants if this is a frequent problem.\n",
            "\nFollow these steps and your problem will be solved ;)\n\nSet your formula to =$B2=1\nSelect the fill color Yellow\nApplies to =$A$2:$A$7\nOnce you click Apply, make sure your formula hasn't changed! (always happens to me)\n\n\n\n"
        ],
        "answer": "A1",
        "tags": [
            "excel",
            "vba"
        ]
    },
    {
        "question_id": "16404820",
        "question": "\nI'm using the Roboto light font in my app. To set the font I've to add the android:fontFamily=\"sans-serif-light\" to every view. Is there any way to declare the Roboto font as default font family to entire app? I've tried like this but it didn't seem to work.\n<style name=\"AppBaseTheme\" parent=\"android:Theme.Light\"></style>\n\n<style name=\"AppTheme\" parent=\"AppBaseTheme\">\n    <item name=\"android:fontFamily\">sans-serif-light</item>\n</style>\n\n",
        "all_answers": [
            "\nIf anyone's still looking for a solution to this, I found an answer at How to play ringtone/alarm sound in Android\ntry {\n    Uri notification = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION);\n    Ringtone r = RingtoneManager.getRingtone(getApplicationContext(), notification);\n    r.play();\n} catch (Exception e) {\n    e.printStackTrace();\n}\n\nYou can change TYPE_NOTIFICATION to TYPE_ALARM, but you'll want to keep track of your Ringtone r in order to stop playing it... say, when the user clicks a button or something.\n",
            "\nREAD UPDATES BELOW\nI had the same issue with embedding a new font and finally got it to work with extending the TextView and set the typefont inside.\npublic class YourTextView extends TextView {\n\n    public YourTextView(Context context, AttributeSet attrs, int defStyle) {\n        super(context, attrs, defStyle);\n        init();\n    }\n\n    public YourTextView(Context context, AttributeSet attrs) {\n        super(context, attrs);\n        init();\n    }\n\n    public YourTextView(Context context) {\n        super(context);\n        init();\n    }\n\n    private void init() {\n        Typeface tf = Typeface.createFromAsset(context.getAssets(),\n            \"fonts/helveticaneue.ttf\");\n        setTypeface(tf);\n    }\n}\n\nYou have to change the TextView Elements later to from  to  in every element. And if you use the UI-Creator in Eclipse, sometimes he doesn't show the TextViews right. Was the only thing which work for me...\nUPDATE\nNowadays I'm using reflection to change typefaces in whole application without extending TextViews. Check out this SO post\nUPDATE 2\nStarting with API Level 26 and available in 'support library' you can use \nandroid:fontFamily=\"@font/embeddedfont\"\n\nFurther information: Fonts in XML\n",
            "\nThe answer is yes.\nGlobal Roboto light for TextView and Button classes:\n<style name=\"AppTheme\" parent=\"AppBaseTheme\">\n    <item name=\"android:textViewStyle\">@style/RobotoTextViewStyle</item>\n    <item name=\"android:buttonStyle\">@style/RobotoButtonStyle</item>\n</style>\n\n<style name=\"RobotoTextViewStyle\" parent=\"android:Widget.TextView\">\n    <item name=\"android:fontFamily\">sans-serif-light</item>\n</style>\n\n<style name=\"RobotoButtonStyle\" parent=\"android:Widget.Holo.Button\">\n    <item name=\"android:fontFamily\">sans-serif-light</item>\n</style>\n\nJust select the style you want from list themes.xml, then create your custom style based on the original one. At the end, apply the style as the theme of the application.\n<application\n    android:theme=\"@style/AppTheme\" >\n</application>\n\nIt will work only with built-in fonts like Roboto, but that was the question. For custom fonts (loaded from assets for example) this method will not work.\nEDIT 08/13/15\nIf you're using AppCompat themes, remember to remove android: prefix. For example:\n<style name=\"AppTheme\" parent=\"Theme.AppCompat.Light.DarkActionBar\">\n    <item name=\"android:textViewStyle\">@style/RobotoTextViewStyle</item>\n    <item name=\"buttonStyle\">@style/RobotoButtonStyle</item>\n</style>\n\nNote the buttonStyle doesn't contain android: prefix, but textViewStyle must contain it.\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "android-fonts"
        ]
    },
    {
        "question_id": "8781240",
        "question": "\nI have four branches in my git repository, which is managed using GitHub:\n\nProduction\nStaging\nMaster\n[person's name]-development\n\nIs there a way to restrict write access to only a single branch ([person's name]-development)? How would I do this? \nFor reference, a similar question: How to write a git hook to restrict writing to branch?. \n",
        "all_answers": [
            "\n\nBut github show nothing for the math symbols! please help me, thanks!\n\nGitHub markdown parsing is performed by the SunDown (ex libUpSkirt) library.\nThe motto of the library is \"Standards compliant, fast, secure markdown processing library in C\". The important word being \"secure\" there, considering your question :).\nIndeed, allowing javascript to be executed would be a bit off of the MarkDown standard text-to-HTML contract.\nMoreover, everything that looks like a HTML tag is either escaped or stripped out.\n\nTell me how to show math symbols in general github markdown.\n\nYour best bet would be to find a website similar to yuml.me which can generate on-the-fly images from by parsing the provided URL querystring.\nUpdate\nI've found some sites providing users with such service: codedogs.com (no longer seems to support embedding) or iTex2Img.\nYou may want to try them out. Of course, others may exist and some Google-fu will help you find them.\ngiven the following markdown syntax\n![equation](http://www.sciweavers.org/tex2img.php?eq=1%2Bsin%28mc%5E2%29&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n\nit will display the following image\n\nNote: In order for the image to be properly displayed, you'll have to ensure the querystring part of the url is percent encoded. You can easily find online tools to help you with that task, such as www.url-encode-decode.com\n",
            "\nWhen using GitHub, your best option would be for each developer to have their own fork of the master repository. Everybody pushes to their own repository and somebody with push access to the master repository handles pulling from each developer's repository. This is how most open source projects work.\nIf using your own Git server, it should be possible to use hooks to prevent users from pushing to wrong branches.\n",
            "\nNot practically. Git branches aren't really distinct from one another in the way that you're probably thinking they are.\nWhat you probably want to do here is use a separate repository for each user's development branch.\n"
        ],
        "answer": "A2",
        "tags": [
            "git",
            "github"
        ]
    },
    {
        "question_id": "36174881",
        "question": "\nI have a json array stored in my postgres database.\nThe json looks like this:\n[\n    {\n        \"operation\": \"U\",\n        \"taxCode\": \"1000\",\n        \"description\": \"iva description\",\n        \"tax\": \"12\"\n    },\n    {\n        \"operation\": \"U\",\n        \"taxCode\": \"1001\",\n        \"description\": \"iva description\",\n        \"tax\": \"12\"\n    },\n    {\n        \"operation\": \"U\",\n        \"taxCode\": \"1002\",\n        \"description\": \"iva description\",\n        \"tax\": \"12\"\n    }\n]\n\nNow I need to SELECT the array so that any element is in a different row of the query result. So the SELECT statement I perform must return the data in this way:\n data\n--------------------------------------------------------------------------------------\n{ \"operation\": \"U\", \"taxCode\": \"1000\", \"description\": \"iva description\", \"tax\":\"12\"}\n{ \"operation\": \"U\", \"taxCode\": \"1001\", \"description\": \"iva description\", \"tax\":\"12\"}\n{ \"operation\": \"U\", \"taxCode\": \"1002\", \"description\": \"iva description\", \"tax\":\"12\"}\n\nI tried using the unnest() function\nSELECT unnest(json_data::json)\nFROM my_table\n\nbut it doesn't accept the jsonb type.\n",
        "all_answers": [
            "\nI would suggest using the json_to_recordset command in your case. Your SQL should then be:\nselect *\nfrom json_to_recordset('[{\"operation\":\"U\",\"taxCode\":1000},{\"operation\":\"U\",\"taxCode\":10001}]')\nas x(\"operation\" text, \"taxCode\" int);\n\nThe output is:\n------------------------\n|   |operation|taxCode |\n------------------------\n| 1 |   \"U\"   |   1000 |\n------------------------\n| 2 |   \"U\"   |  10001 |\n------------------------\n\nThe columns (or JSON keys) of the example can be freely further expanded.\n",
            "\nI post the answer originally written by pozs in the comment section. \nunnest() is for PostgreSQL's array types. \nInstead one of the following function can be used:\n\njson_array_elements(json) (9.3+)\njsonb_array_elements(jsonb) (9.4+)\njson[b]_array_elements_text(json[b]) (9.4+)\n\nExample:\nselect * from json_array_elements('[1,true, [2,false]]')\n\noutput value \n -------------\n | 1         |\n -------------\n | true      |\n -------------\n | [2,false] |\n -------------\n\nHere where the documentation for v9.4 can be found.\n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n"
        ],
        "answer": "A2",
        "tags": [
            "arrays",
            "json",
            "postgresql"
        ]
    },
    {
        "question_id": "7734077",
        "question": "\nBeing a self-taught newbie, I created a large problem for myself. Before inserting data in to my database, I've been converting apostrophes (') in a string, to double quotes (\"\"), instead of the required back-slash and apostrophe (\\'), which MySQL actually requires.\nBefore my table grows more than the 200,000 rows it already is, I thought it was best to rectify this issue immediately. So I did some research and found the SQL REPLACE function, which is great, but I'm now confused.\nIn ASP, I was doing this:\nstr = Replace(str,\"'\",\"\"\"\")\n\nIf I look at my database in SQL Workbench, the symbol I converted is now a single quote (\"), which has confused me a little. I understand why it changed from double to single, but I don't know which one I'm meant to be changing now. \nTo go through and rectify my problem using SQL REPLACE, do I now convert single quotes (\") to back-slash and apostrophes (\\') or do I convert double quotes (\"\") to back-slash and apostrophes (\\')?\nFor example, this:\nSQL = \" SELECT REPLACE(myColumn,\"\"\"\",\"\\'\") FROM myTable \"\n\nor this:\nSQL = \" SELECT REPLACE(myColumn,\"\"\",\"\\'\") FROM myTable \"\n\nI hope I explained myself well, any suggestions gratefully received as always. Any queries about my question, please comment.\nMany thanks\n-- UPDATE --\nI have tried the following queries but still fail to change the ( \" ) in the data:\nSELECT REPLACE(caption,'\\\"','\\'') FROM photos WHERE photoID = 3371\nSELECT REPLACE(caption,'\"','\\'') FROM photos WHERE photoID = 3371\nSELECT REPLACE(caption,'\"\"','\\'') FROM photos WHERE photoID = 3371\n\nYet if I search:\nSELECT COUNT(*) FROM photos WHERE caption LIKE '%\"%'\n\nI get 16,150 rows.\n-- UPDATE 2 --\nWell, I have created a 'workaround'. I managed to convert an entire column pretty quickly writing an ASP script, using this SQL:\nSELECT photoID, caption FROM photos WHERE caption LIKE '%\"\"%';\n\nand then in ASP I did:\ncaption = Replace(caption,\"\"\"\",\"\\'\")\n\nBut I would still like to know why I couldn't achieve that with SQL?\n",
        "all_answers": [
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nIf you have \"something\" and need 'something', use replace(col, \"\\\"\", \"\\'\") and viceversa.\n",
            "\nJust running the SELECT statement will have no effect on the data.  You have to use an UPDATE statement with the REPLACE to make the change occur:\nUPDATE photos\n   SET caption = REPLACE(caption,'\"','\\'')\n\nHere is a working sample: http://sqlize.com/7FjtEyeLAh\n",
            "\nmaybe I'd go by this.\n SQL = SELECT REPLACE(myColumn, '\"\"', '\\'') FROM myTable\n\nI used singlequotes because that's the one that registers string expressions in MySQL, or so I believe.\nHope that helps.\n"
        ],
        "answer": "A3",
        "tags": [
            "mysql",
            "sql",
            "database"
        ]
    },
    {
        "question_id": "135041",
        "question": "\nWhy or why not?\n",
        "all_answers": [
            "\nFor performance, especially when you're iterating over a large range, xrange() is usually better.  However, there are still a few cases why you might prefer range():\n\nIn python 3, range() does what xrange() used to do and xrange() does not exist.  If you want to write code that will run on both Python 2 and Python 3, you can't use xrange().\nrange() can actually be faster in some cases - eg. if iterating over the same sequence multiple times.  xrange() has to reconstruct the integer object every time, but range() will have real integer objects.  (It will always perform worse in terms of memory however)\nxrange() isn't usable in all cases where a real list is needed.  For instance, it doesn't support slices, or any list methods.\n\n[Edit] There are a couple of posts mentioning how range() will be upgraded by the 2to3 tool.  For the record, here's the output of running the tool on some sample usages of range() and xrange()\nRefactoringTool: Skipping implicit fixer: buffer\nRefactoringTool: Skipping implicit fixer: idioms\nRefactoringTool: Skipping implicit fixer: ws_comma\n--- range_test.py (original)\n+++ range_test.py (refactored)\n@@ -1,7 +1,7 @@\n\n for x in range(20):\n-    a=range(20)\n+    a=list(range(20))\n     b=list(range(20))\n     c=[x for x in range(20)]\n     d=(x for x in range(20))\n-    e=xrange(20)\n+    e=range(20)\n\nAs you can see, when used in a for loop or comprehension, or where already wrapped with list(), range is left unchanged.\n",
            "\nYou can just construct a list from the range object:\nmy_list = list(range(1, 1001))\n\nThis is how you do it with generators in python2.x as well.  Typically speaking, you probably don't need a list though since you can come by the value of my_list[i] more efficiently (i + 1), and if you just need to iterate over it, you can just fall back on range.\nAlso note that on python2.x, xrange is still indexable1.  This means that range on python3.x also has the same property2\n1print xrange(30)[12] works for python2.x\n2The analogous statement to 1 in python3.x is print(range(30)[12]) and that works also.\n",
            "\nxrange() is more efficient because instead of generating a list of objects, it just generates one object at a time. Instead of 100 integers, and all of their overhead, and the list to put them in, you just have one integer at a time. Faster generation, better memory use, more efficient code.\nUnless I specifically need a list for something, I always favor xrange()\n",
            "\nYou should favour range() over xrange() only when you need an actual list. For instance, when you want to modify the list returned by range(), or when you wish to slice it. For iteration or even just normal indexing, xrange() will work fine (and usually much more efficiently). There is a point where range() is a bit faster than xrange() for very small lists, but depending on your hardware and various other details, the break-even can be at a result of length 1 or 2; not something to worry about. Prefer xrange().\n",
            "\nGo with range for these reasons:\n1) xrange will be going away in newer Python versions.  This gives you easy future compatibility.\n2) range will take on the efficiencies associated with xrange.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "range",
            "xrange"
        ]
    },
    {
        "question_id": "1825720",
        "question": "\nI'm interested in measuring a specific point in time down to the nanosecond using C++ in Windows. Is this possible? If it isn't, is it possible to get the specific time in microseconds at least?. Any library should do, unless I suppose it's possible with managed code.\nthanks\n",
        "all_answers": [
            "\nIf you have a threaded application running on a multicore computer QueryPerformanceCounter can (and will) return different values depending on which core the code is executing on. See  this MSDN article. (rdtsc has the same problem)\nThis is not just a theoretical problem; we ran into it with our application and had to conclude that the only reliable time source is timeGetTime which only has ms precision (which fortunately was sufficient in our case). We also tried fixating the thread affinity for our threads to guarantee that each thread always got a consistent value from QueryPerformanceCounter, this worked but it absolutely killed the performance in the application. \nTo sum things up there isn't a reliable timer on windows that can be used to time thing with micro second precision (at least not when running on a multicore computer).\n",
            "\nusing QueryPerformanceCounter (for windows)\n",
            "\nWith respect to Konrad Rudolph's answer, note that in my experience the frequency of the performance counter is around 3.7MHz, so sub-microsecond, but certainly not nanosecond precision.  The actual frequency is hardware (and power-save mode) dependent.  Nanosecond precision is somewhat unreasonable in any case since interrupt latencies and process/thread context switching times are far longer than that, and that is also the order of magnitude of individual machine instructions.\n",
            "\nWindows has a high-performance counter API.\nYou need to get the ticks form QueryPerformanceCounter and divide by the frequency of the processor, provided by QueryPerformanceFrequency.\nLARGE_INTEGER frequency;\nif (::QueryPerformanceFrequency(&frequency) == FALSE)\n    throw \"foo\";\n\nLARGE_INTEGER start;\nif (::QueryPerformanceCounter(&start) == FALSE)\n    throw \"foo\";\n\n// Calculation.\n\n\nLARGE_INTEGER end;\nif (::QueryPerformanceCounter(&end) == FALSE)\n    throw \"foo\";\n\ndouble interval = static_cast<double>(end.QuadPart - start.QuadPart) / frequency.QuadPart;\n\nThis interval should be in seconds.\n",
            "\nYou can use the Performance Counter API as Konrad Rudolf proposed, but should be warned that it is based on the CPU frequency.  This frequency is not stable when e.g. a power save mode is enabled.  If you want to use this API, make sure the CPU is at a constant frequency.\nOtherwise, you can create some kind of 'statistical' system, correlating the CPU ticks to the PC BIOS clock.  The latter is way less precise, but constant.\n",
            "\nrdtsc instruction is  the most  accurate.\n"
        ],
        "answer": "A1",
        "tags": [
            "c++",
            "windows"
        ]
    },
    {
        "question_id": "2803852",
        "question": "\nHow do I convert a string to a date object in python? \nThe string would be: \"24052010\" (corresponding to the format: \"%d%m%Y\")\nI don't want a datetime.datetime object, but rather a datetime.date.\n",
        "all_answers": [
            "\nimport datetime\ndatetime.datetime.strptime('24052010', '%d%m%Y').date()\n\n",
            "\nYou can use strptime in the datetime package of Python:\n>>> import datetime\n>>> datetime.datetime.strptime('24052010', \"%d%m%Y\").date()\ndatetime.date(2010, 5, 24)\n\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "date"
        ]
    },
    {
        "question_id": "2478038",
        "question": "\n\n\n\nI'm looking for a JavaScript library that will allow me to query complex JSON objects using a LINQ-like syntax.  A quick search found a couple of promising options that look they might offer what I need:\nLINQ to JavaScript and jLinq\n\nDoes any one have any experience\nusing them?\nWhat are some pros and cons?\nIs the performance comparable?\nDoes the function-passing syntax of\nLINQ to JavaScript offer any hidden benefits\n(I personally find the syntax of\njLinq more appealing on first\nglance)?\nWhat have you found lacking\nin either project?\nDid you ever try contacting the authors?  How responsive were they?\nWhat project is more widely used?  \n\nI think it will be the first one to get a thorough try-out.\n",
        "all_answers": [
            "\nobject[\"property\"] = value;\n\nor\nobject.property = value;\n\nObject and Array in JavaScript are different in terms of usage.  Its best if you understand them:  \nObject vs Array: JavaScript\n",
            "\nvar array = new Array(); // or the shortcut: = []\narray.push ( {\"cool\":\"34.33\",\"also cool\":\"45454\"} );\narray.push (  {\"cool\":\"34.39\",\"also cool\":\"45459\"} );\n\nYour variable is a javascript object {} not an array [].\nYou could do:\nvar o = {}; // or the longer form: = new Object()\no.SomeNewProperty = \"something\";\no[\"SomeNewProperty\"] = \"something\";\n\nand\nvar o = { SomeNewProperty: \"something\" };\nvar o2 = { \"SomeNewProperty\": \"something\" };\n\nLater, you add those objects to your array: array.push (o, o2);\nAlso JSON is simply a string representation of a javascript object, thus:\nvar json = '{\"cool\":\"34.33\",\"alsocool\":\"45454\"}'; // is JSON\nvar o = JSON.parse(json); // is a javascript object\njson = JSON.stringify(o); // is JSON again\n\n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n",
            "\nThe most basic and frequently used Linq operators are very commonly defined in widely used JS libraries. They just have different names (in fact, they have more traditional names than in Linq). Select becomes map, Where becomes filter, First and FirstOrDefault become [0].\nAlmost no library I know of (including I think the ones you linked to) bother to make the implementation lazy as in .NET Linq, they just evaluate immediately using arrays.\nFor a very nice, complete set of functional list operations, try: http://osteele.com/sources/javascript/functional/\n",
            "\nHave you seen Rx for Javascript, yet?  That's what you want.\n",
            "\nThat is an object, not an array. So you would do:\nvar json = { cool: 34.33, alsocool: 45454 };\njson.supercool = 3.14159;\nconsole.dir(json);\n\n"
        ],
        "answer": "A5",
        "tags": [
            "javascript",
            "json",
            "linq"
        ]
    },
    {
        "question_id": "22279435",
        "question": "\nWhen I went through Laravel Document about Eloquent ORM topic part, I got a new term \"Mass Assignment\".\nDocument show How to do Mass Assignment and the $fillable or $guarded properties settings. But after went through that, I didn't have a clearly understand about \"Mass Assignment\" and how it works.\nIn my past experience in CodeIgniter, I also didn't hear about this term.\nDoes anyone have a simple explanation about that?\n",
        "all_answers": [
            "\nMass assignment is when you send an array to the model creation, basically setting a bunch of fields on the model in a single go, rather than one by one, something like:\n$user = new User(request()->all());\n\n(This is instead of explicitly setting each value on the model separately.) \nYou can use fillable to protect which fields you want this to actually allow for updating.\nYou can also block all fields from being mass-assignable by doing this:\nprotected $guarded = ['*'];\n\nLet's say in your user table you have a field that is user_type and that can have values of user / admin\nObviously, you don't want users to be able to update this value. In theory, if you used the above code, someone could inject into a form a new field for user_type and send 'admin' along with the other form data, and easily switch their account to an admin account... bad news.\nBy adding:\n$fillable = ['name', 'password', 'email'];\n\nYou are ensuring that only those values can be updated using mass assignment\nTo be able to update the user_type value, you need to explicitly set it on the model and save it, like this:\n$user->user_type = 'admin';\n$user->save();\n\n",
            "\nIt looks like you have everything correct according to Laravel docs, but you have a typo\n$item->push($product);\n\nShould be\n$items->push($product);\n\npush method appends an item to the end of the collection:\nI also want to think the actual method you're looking for is put\n$items->put('products', $product);\n\nput method sets the given key and value in the collection\n",
            "\nMass assignment means you are filling a row with more than one column using an array of data. (somewhat of a shortcut instead of manually building the array) using Input::all(). \nTechnically just from the top of my head. Fillable means what columns in the table are allowed to be inserted, guarded means the model can't insert to that particular column.\nNotice that when you try to do a mass assignment with like, insert to a column named \"secret\", and you have specified that it is guarded, you can try to insert to it via the model, but it will never really get inserted into the database. \nThis is for security, and protection on your table when using the model. Mass assignment seems to be just a notice or warning that you didn't tell the model which are fillable and guarded and makes it vulnerable to some kind of attacks.\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "laravel",
            "eloquent",
            "mass-assignment"
        ]
    },
    {
        "question_id": "34019977",
        "question": "\nI'm working on an old code base and pretty much every invocation of free() uses a cast on its argument. For example,\nfree((float *)velocity);\nfree((float *)acceleration);\nfree((char *)label);\n\nwhere each pointer is of the corresponding (and matching) type. I see no point in doing this at all. It's very old code, so I'm left wondering if it's a K&R thing. If so, I actually wish to support the old compilers that may have required this, so I don't want to remove them.\nIs there a technical reason to use these casts? I don't even see much of a pragmatic reason to use them. What's the point of reminding ourselves of the data type right before freeing it?\nEDIT: This question is not a duplicate of the other question. The other question is a special case of this question, which I think is obvious if the close voters would have read all the answers.\nColophon: I'm giving the checkmark to the answer that gave a reason why this might still need to be done; however, the answer about it being a pre-ANSI C custom (at least among some programmers) seems to be the reason it was used in my case. If there were two checkmarks to give they'd both get one. Lots of good points by many people here. Thank you for your contributions.\n",
        "all_answers": [
            "\nHere's an example where free would fail without a cast:\nvolatile int* p = (volatile int*)malloc(5 * sizeof(int));\nfree(p);        // fail: warning C4090: 'function' : different 'volatile' qualifiers\nfree((int*)p);  // success :)\nfree((void*)p); // success :)\n\nIn C you can get a warning (got one in VS2012). In C++ you'll get an error.\nRare cases aside, the casting just bloats the code...\nEdit:\nI casted to void* not int* to demo the failure. It will work the same as int* will be converted to void* implicitly. Added int* code.\n",
            "\nThe difference is due to operator precedence.\nThe post-increment operator ++ has higher precedence than the dereference operator *. So *ptr++ is equivalent to *(ptr++). In other words, the post increment modifies the pointer, not what it points to.\nThe assignment operator += has lower precedence than the dereference operator *, so *ptr+=1 is equivalent to (*ptr)+=1. In other words, the assignment operator modifies the value that the pointer points to, and does not change the pointer itself. \n",
            "\nCasting may be required to resolve compiler warnings if the pointers are const. Here is an example of code that causes a warning without casting the argument of free:\nconst float* velocity = malloc(2*sizeof(float));\nfree(velocity);\n\nAnd the compiler (gcc 4.8.3) says:\nmain.c: In function ‘main’:\nmain.c:9:5: warning: passing argument 1 of ‘free’ discards ‘const’ qualifier from pointer target type [enabled by default]\n     free(velocity);\n     ^\nIn file included from main.c:2:0:\n/usr/include/stdlib.h:482:13: note: expected ‘void *’ but argument is of type ‘const float *’\n extern void free (void *__ptr) __THROW;\n\nIf you use free((float*) velocity); the compiler stops complaining.\n"
        ],
        "answer": "A3",
        "tags": [
            "c",
            "pointers",
            "casting"
        ]
    },
    {
        "question_id": "33186051",
        "question": "\nI created a struct and want to save it as a JSON-file.\nstruct Sentence {\n    var sentence = \"\"\n    var lang = \"\"\n}\n\nvar s = Sentence()\ns.sentence = \"Hello world\"\ns.lang = \"en\"\nprint(s)\n\n...which results in:\nSentence(sentence: \"Hello world\", lang: \"en\")\n\nBut how can I convert the struct object to something like:\n{\n    \"sentence\": \"Hello world\",\n    \"lang\": \"en\"\n}\n\n",
        "all_answers": [
            "\nUse the NSJSONSerialization class.\nUsing this for reference, you may need to create a function which returns the JSON serialized string. In this function you could take the required properties and create a NSDictionary from them and use the class mentioned above. \nSomething like this:\nstruct Sentence {\n    var sentence = \"\"\n    var lang = \"\"\n\n    func toJSON() -> String? {\n        let props = [\"Sentence\": self.sentence, \"lang\": lang]\n        do {\n            let jsonData = try NSJSONSerialization.dataWithJSONObject(props,\n            options: .PrettyPrinted)\n            return String(data: jsonData, encoding: NSUTF8StringEncoding)\n        } catch let error {\n            print(\"error converting to json: \\(error)\")\n            return nil\n        }\n    }\n\n}\n\nBecause your struct only has two properties it might be easier to just build the JSON string yourself.\n",
            "\nSwift 4 introduces the Codable protocol which provides a very convenient way to encode and decode custom structs.\nstruct Sentence : Codable {\n    let sentence : String\n    let lang : String\n}\n\nlet sentences = [Sentence(sentence: \"Hello world\", lang: \"en\"), \n                 Sentence(sentence: \"Hallo Welt\", lang: \"de\")]\n\ndo {\n    let jsonData = try JSONEncoder().encode(sentences)\n    let jsonString = String(data: jsonData, encoding: .utf8)!\n    print(jsonString) // [{\"sentence\":\"Hello world\",\"lang\":\"en\"},{\"sentence\":\"Hallo Welt\",\"lang\":\"de\"}]\n    \n    // and decode it back\n    let decodedSentences = try JSONDecoder().decode([Sentence].self, from: jsonData)\n    print(decodedSentences)\n} catch { print(error) }\n\n"
        ],
        "answer": "A2",
        "tags": [
            "json",
            "swift",
            "struct",
            "nsjsonserialization"
        ]
    },
    {
        "question_id": "2696052",
        "question": "\nIn C# how does one achieve thread signaling?\n",
        "all_answers": [
            "\nHere is a good write up about .NET events and race conditions with threads.  It covers some common scenarios and has some good references in it.\nHope this helps.\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nHere is a custom-made console application example for you. Not really a good real world scenario, but the usage of thread signaling is there.\nusing System;\nusing System.Threading;\n\nclass Program\n{\n    static void Main()\n    {\n        bool isCompleted = false;\n        int diceRollResult = 0;\n\n        // AutoResetEvent is one type of the WaitHandle that you can use for signaling purpose.\n        AutoResetEvent waitHandle = new AutoResetEvent(false);\n\n        Thread thread = new Thread(delegate() {\n            Random random = new Random();\n            int numberOfTimesToLoop = random.Next(1, 10);\n\n            for (int i = 0; i < numberOfTimesToLoop - 1; i++) {\n                diceRollResult = random.Next(1, 6);\n\n                // Signal the waiting thread so that it knows the result is ready.\n                waitHandle.Set();\n\n                // Sleep so that the waiting thread have enough time to get the result properly - no race condition.\n                Thread.Sleep(1000);\n            }\n\n            diceRollResult = random.Next(1, 6);\n            isCompleted = true;\n\n            // Signal the waiting thread so that it knows the result is ready.\n            waitHandle.Set();\n        });\n\n        thread.Start();\n\n        while (!isCompleted) {\n            // Wait for signal from the dice rolling thread.\n            waitHandle.WaitOne();\n            Console.WriteLine(\"Dice roll result: {0}\", diceRollResult);\n        }\n\n        Console.Write(\"Dice roll completed. Press any key to quit...\");\n        Console.ReadKey(true);\n    }\n}\n\n",
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nFor understanding concepts like signaling, see Thread Synchronization which would be a good place to start. \nIt's got examples too. You can then drill down into specific .net types based on what you're trying to do.. signal between threads within a process or across processes etc..\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "multithreading",
            "signals"
        ]
    },
    {
        "question_id": "16005281",
        "question": "\nclass TestController < AplicationController\n  #....\n\n  private\n\n  def some_method\n    unless @my_variable.nil?\n      #...\n      return true\n    end\n  end\nend\n\nI want to test some_method directly in controller spec:\nrequire 'spec_helper'\n\ndescribe TestController do\n  it \"test some_method\"\n    phone = Phone.new(...)\n    controller.assign(:my_variable,phone) #does not work\n    controller.send(:some_method).should be_true\n  end\nend\n\nHow I can set TestController instance variable @my_variable from controller spec?\n",
        "all_answers": [
            "\nWhen testing private methods in controllers, rather than use send, I tend to use an anonymous controller due to not wanting to call the private method directly, but the interface to the private method (or, in the test below, effectively stubbing that interface).  So, in your case, perhaps something like: \nrequire 'spec_helper'\n\ndescribe TestController do\n  controller do\n    def test_some_method\n      some_method\n    end\n  end\n\n  describe \"a phone test with some_method\" do\n\n    subject { controller.test_some_method }\n\n    context \"when my_variable is not nil\" do\n      before { controller.instance_variable_set(:@my_variable, Phone.new(...)) }\n      it { should be_true }\n    end\n\n    context \"when my_variable is nil\" do\n      before { controller.instance_variable_set(:@my_variable, nil) } \n      it { should_not be_true } # or should be_false or whatever\n    end     \n  end\nend\n\nThere's some good discussion on the issue of directly testing private methods in this StackOverflow Q&A, which swayed me towards using anonymous controllers, but your opinion may differ.\n",
            "\nI don't think you want to access an instance variable from your spec controller, as the spec should test the behaviour, but you can always stub the private method.\nIn your case it should be something like this (in this example it doesn't make so much sense):\ndescribe TestController do\n  it \"test some_method\"\n    phone = Phone.new(...)\n    controller.stub(:some_method).and_return(true)\n    controller.send(:some_method).should be_true\n  end\nend\n\nIf this is not what you are looking for take a look at this: How to set private instance variable used within a method test?\n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "rspec"
        ]
    },
    {
        "question_id": "20183710",
        "question": "\nI'm trying to do something that I thought it would be simple but it seems not to be.\nI have a project model that has many vacancies.\nclass Project < ActiveRecord::Base\n\n  has_many :vacancies, :dependent => :destroy\n\nend\n\nI want to get all the projects that have at least 1 vacancy.\nI tried something like this:\nProject.joins(:vacancies).where('count(vacancies) > 0')\n\nbut it says\nSQLite3::SQLException: no such column: vacancies: SELECT  \"projects\".* FROM \"projects\" INNER JOIN \"vacancies\" ON \"vacancies\".\"project_id\" = \"projects\".\"id\" WHERE (\"projects\".\"deleted_at\" IS NULL) AND (count(vacancies) > 0).\n",
        "all_answers": [
            "\nPostgreSQL is more SQL compliant than MySQL. All fields - except computed field with aggregation function - in the output must be present in the GROUP BY clause.\n",
            "\nYeah, vacancies is not a field in the join.  I believe you want:\nProject.joins(:vacancies).group(\"projects.id\").having(\"count(vacancies.id)>0\")\n\n",
            "\nMySQL's totally non standards compliant GROUP BY can be emulated by Postgres' DISTINCT ON. Consider this:\nMySQL:\nSELECT a,b,c,d,e FROM table GROUP BY a\n\nThis delivers 1 row per value of a (which one, you don't really know). Well actually you can guess, because MySQL doesn't know about hash aggregates, so it will probably use a sort... but it will only sort on a, so the order of the rows could be random. Unless it uses a multicolumn index instead of sorting. Well, anyway, it's not specified by the query.\nPostgres:\nSELECT DISTINCT ON (a) a,b,c,d,e FROM table ORDER BY a,b,c\n\nThis delivers 1 row per value of a, this row will be the first one in the sort according to the ORDER BY specified by the query. Simple.\nNote that here, it's not an aggregate I'm computing. So GROUP BY actually makes no sense. DISTINCT ON makes a lot more sense.\nRails is married to MySQL, so I'm not surprised that it generates SQL that doesn't work in Postgres.\n",
            "\njoins uses an inner join by default so using Project.joins(:vacancies) will in effect only return projects that have an associated vacancy.\nUPDATE:\nAs pointed out by @mackskatz in the comment, without a group clause, the code above will return duplicate projects for projects with more than one vacancies.  To remove the duplicates, use\nProject.joins(:vacancies).group('projects.id')\n\nUPDATE:\nAs pointed out by @Tolsee, you can also use distinct.\nProject.joins(:vacancies).distinct\n\nAs an example\n[10] pry(main)> Comment.distinct.pluck :article_id\n=> [43, 34, 45, 55, 17, 19, 1, 3, 4, 18, 44, 5, 13, 22, 16, 6, 53]\n[11] pry(main)> _.size\n=> 17\n[12] pry(main)> Article.joins(:comments).size\n=> 45\n[13] pry(main)> Article.joins(:comments).distinct.size\n=> 17\n[14] pry(main)> Article.joins(:comments).distinct.to_sql\n=> \"SELECT DISTINCT \\\"articles\\\".* FROM \\\"articles\\\" INNER JOIN \\\"comments\\\" ON \\\"comments\\\".\\\"article_id\\\" = \\\"articles\\\".\\\"id\\\"\"\n\n"
        ],
        "answer": "A4",
        "tags": [
            "sql",
            "ruby-on-rails",
            "ruby-on-rails-3",
            "activerecord"
        ]
    },
    {
        "question_id": "38884164",
        "question": "\nI have a DataFrame\ndf = pd.DataFrame({'Data': [10, 20, 30, 20, 15, 30, 45]})\n\nThis is working:\nwriter = pd.ExcelWriter('pandas_simple.xlsx', engine='xlsxwriter')\ndf.to_excel(writer, sheet_name='Sheet1')\nwriter.save()\n\nbut when I try:\nout_path = \"C:\\Users\\Bala\\output\\temp-excel.xlsx\"\nwriter = pd.ExcelWriter(out_path , engine='xlsxwriter')\ndf.to_excel(writer, sheet_name='Sheet1')\nwriter.save()\n\nI'm getting error:\nIOError: [Errno 22] invalid mode ('wb') or filename: 'C:\\\\Users\\\\Bala Nadella\\\\output\\temp-excel.xlsx'. \n\nHow can I create a file at a given path?\n",
        "all_answers": [
            "\nThere is a way to make it more pythonic (works with three or more letters and uses less magic numbers):\ndef col2num(col):\n    num = 0\n    for c in col:\n        if c in string.ascii_letters:\n            num = num * 26 + (ord(c.upper()) - ord('A')) + 1\n    return num\n\nAnd as a one-liner using reduce (does not check input and is less readable so I don't recommend it):\ncol2num = lambda col: reduce(lambda x, y: x*26 + y, [ord(c.upper()) - ord('A') + 1 for c in col])\n\n",
            "\nString literals\nStudy the table in that link. You need to escape your '\\' with '\\\\'. Partly, DOS is responsible for this mess in the world.\nout_path = \"C:\\\\Users\\\\Bala\\\\output\\\\temp-excel.xlsx\"\n\nOr\nout_path = r\"C:\\Users\\Bala\\output\\temp-excel.xlsx\" # the `r` prefix means raw string\n\nBut best alternative is this:\nout_path = \"C:/Users/Bala/output/temp-excel.xlsx\"\n\nIt will work on any platform.\n\nEdited to remove the solution with os.path.abspath. After the comment below this answer, I read the documentation myself and realized that it has a different purpose. Although I have used it in the past to make my code dual OS friendly, because it neatly appends CWD to the path, and changes / to \\\\ when moving from Debian to Windows and vice versa. \n",
            "\nIn a string the backslash is an escape character. It means that you're giving a special command, not a regular character. Eg. \"Hello\\nWorld\" means, put a newline between \"Hello\" and \"World\".\nIf you actually want to use a backslash as a character, type it as \"\\\\\".\nOr better yet, just use forward slashes!\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "excel",
            "pandas"
        ]
    },
    {
        "question_id": "2507960",
        "question": "\nAfter android installs an application from the Marketplace, does it keep the .apk file?\nIs there a standard location where Android would keep such files?\n",
        "all_answers": [
            "\nThis is a problem that can arise from writing down a \"filename\" instead of a path, while generating the .jks file. Generate a new one, put it on the Desktop (or any other real path) and re-generate APK.\n",
            "\nI have same problem, because i don't have keystore path then i see Waffles.inc solutions and had a new problem In my Android Studio 3.1 for mac had a windows dialog problem when trying create new keystore path, it's like this\n\nif u have the same problem, don't worried about the black windows it's just typing your new keystore and then save.\n",
            "\nClick on choose existing and again choose the location where your jks file is located.\n\nI hope this trick works for you.\n",
            "\nEditing the path of the keystore file solved my problem.\n",
            "\nFile -> Invalidate Caches & Restart... \nBuild -> Build signed APK -> check the path in the dialog\n\n",
            "\nIn /data/app but for copy protection I don't think you can access it.\n",
            "\nI found the solution. I misplaced the path to the keystore.jks file. \nSearched for the file on my computer used that path and everything worked great.\n",
            "\nYou can pull apps with ADB.  They are in /data/App/, I believe.\nadb pull (location on device) (where to save)\n\nNote that you have to root your phone to pull copy protected apps.\n",
            "\nPreinstalled applications are in /system/app folder. User installed applications are in /data/app. I guess you can't access unless you have a rooted phone.\nI don't have a rooted phone here but try this code out:\npublic class Testing extends Activity {\n    private static final String TAG = \"TEST\";\n    @Override\n    public void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.main);\n        File appsDir = new File(\"/data/app\");\n\n        String[] files = appsDir.list();\n\n        for (int i = 0 ; i < files.length ; i++ ) {\n            Log.d(TAG, \"File: \"+files[i]);\n\n        }\n    }\n\nIt does lists the apks in my rooted htc magic and in the emu.\n",
            "\nTL;DR: Check the path to your keystore.jks file.\nIn my case, here's what happened:\nI moved the project folder of my entire app to another location on my PC. Much later, I wanted to generate a signed apk file. Unknown to me, the default location of the path to my keystore.jks had been reset to a wrong location and I had clicked okay. Since it could not find a keystore at the path I selected, I got that error.\nThe solution was to check whether the path to my keystore.jks file was correct.\n",
            "\nopen key.properties and check your path is correct. (replace from \\ to /)\nexample:-\nreplace from\n\"storeFile=D:\\Projects\\Flutter\\Key\\key.jks\"\nto\n\"storeFile=D:/Projects/Flutter/Key/key.jks\"\n",
            "\nFile path was culprit for me\nchanged filepath in app/build.gradle\nstoreFile file('upload-keystore.jks')\n\n"
        ],
        "answer": "A9",
        "tags": [
            "android",
            "package",
            "apk",
            "installation"
        ]
    },
    {
        "question_id": "849308",
        "question": "\nThe short: is there a way to have a git repo push to and pull from a list of remote repos (rather than a single \"origin\")?\nThe long: I often have a situation when I'm developing an app in multiple computers, with different connectivity – say a laptop while on transit, a computer \"A\" while I'm in a certain location, and another computer \"B\" while on another. Also, the laptop might have connectivity with only either \"A\" or \"B\", and sometimes both.\nWhat I would like to is for git to always \"pull\" from and \"push\" to all the computers it can currently connect to, so it's easier to jump from one machine to the other and continue working seamlessly.\n",
        "all_answers": [
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nYou can configure multiple remote repositories with the git remote command:\ngit remote add alt alt-machine:/path/to/repo\n\nTo fetch from all the configured remotes and update tracking branches, but not merge into HEAD, do:\ngit remote update\n\nIf it's not currently connected to one of the remotes, it will take time out or throw an error, and go on to the next. You'll have to manually merge from the fetched repositories, or cherry-pick, depending on how you want to organize collecting changes.\nTo fetch the master branch from alt and pull it into your current head, do:\ngit pull alt master\n\nSo in fact git pull is almost shorthand for git pull origin HEAD (actually it looks in the config file to determine this, but you get the idea).\nFor pushing updates, you have to do that to each repo manually.\nA push was, I think, designed with the central-repository workflow in mind.\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nYou'll need a script to loop through them. Git doesn't a provide a \"push all.\" You could theoretically do a push in multiple threads, but a native method is not available.\nFetch is even more complicated, and I'd recommend doing that linearly.\nI think your best answer is to have once machine that everybody does a push / pull to, if that's at all possible.\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n"
        ],
        "answer": "A2",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "3606907",
        "question": "\nIs it possible to order sql data rows by the total number of characters?\ne.g. SELECT * FROM database ORDER BY data.length()\n",
        "all_answers": [
            "\nI think you want to use this: http://dev.mysql.com/doc/refman/5.0/en/string-functions.html#function_char-length\n(MySQL/MariaDB specific)\nSELECT * FROM table ORDER BY CHAR_LENGTH(field)\n\nYou can use just simply LENGTH(), but beware, because it counts the byte number (which won't give you the expected result with multibyte strings).\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nSELECT * FROM table ORDER BY length(data) desc\n\nWhere data is varchar field\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "sql",
            "mysql"
        ]
    },
    {
        "question_id": "1009954",
        "question": "\nIn another question I posted someone told me that there is a difference between:\n@variable\n\nand:\nvariable\n\nin MySQL. He also mentioned how MSSQL has batch scope and MySQL has session scope. Can someone elaborate on this for me?\n",
        "all_answers": [
            "\nIn MySQL, @variable indicates a user-defined variable. You can define your own.\nSET @a = 'test';\nSELECT @a;\n\nOutside of stored programs, a variable, without @, is a system variable, which you cannot define yourself.\nThe scope of this variable is the entire session. That means that while your connection with the database exists, the variable can still be used.\nThis is in contrast with MSSQL, where the variable will only be available in the current batch of queries (stored procedure, script, or otherwise). It will not be available in a different batch in the same session.\n",
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nMySQL has a concept of user-defined variables.\nThey are loosely typed variables that may be initialized somewhere in a session and keep their value until the session ends.\nThey are prepended with an @ sign, like this: @var\nYou can initialize this variable with a SET statement or inside a query:\nSET @var = 1\n\nSELECT @var2 := 2\n\nWhen you develop a stored procedure in MySQL, you can pass the input parameters and declare the local variables:\nDELIMITER //\n\nCREATE PROCEDURE prc_test (var INT)\nBEGIN\n    DECLARE  var2 INT;\n    SET var2 = 1;\n    SELECT  var2;\nEND;\n//\n\nDELIMITER ;\n\nThese variables are not prepended with any prefixes.\nThe difference between a procedure variable and a session-specific user-defined variable is that a procedure variable is reinitialized to NULL each time the procedure is called, while the session-specific variable is not:\nCREATE PROCEDURE prc_test ()\nBEGIN\n    DECLARE var2 INT DEFAULT 1;\n    SET var2 = var2 + 1;\n    SET @var2 = @var2 + 1;\n    SELECT  var2, @var2;\nEND;\n\nSET @var2 = 1;\n\nCALL prc_test();\n\nvar2  @var2\n---   ---\n2     2\n\n\nCALL prc_test();\n\nvar2  @var2\n---   ---\n2     3\n\n\nCALL prc_test();\n\nvar2  @var2\n---   ---\n2     4\n\nAs you can see, var2 (procedure variable) is reinitialized each time the procedure is called, while @var2 (session-specific variable) is not.\n(In addition to user-defined variables, MySQL also has some predefined \"system variables\", which may be \"global variables\" such as @@global.port or \"session variables\" such as @@session.sql_mode; these \"session variables\" are unrelated to session-specific user-defined variables.)\n"
        ],
        "answer": "A3",
        "tags": [
            "mysql",
            "sql",
            "variables"
        ]
    },
    {
        "question_id": "5227676",
        "question": "\nHow does [ThreadStatic] attribute work? I assumed that the compiler would emit some IL to stuff/retrieve the value in the TLS, but looking at a disassembly it doesn't seem to do it at that level.\nAs a follow up, what happens if you put it on a non-static member? We had a developer make that mistake and the compiler doesn't even proffer up a warning.\nUpdate\nSecond question answered here: ThreadStatic Modified with Static C#\n",
        "all_answers": [
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\n\nHow does [ThreadStatic] attribute\nwork?\n\nYou can think that the field marked with ThreadStatic is attached to a thread and its lifetime is comparable to the lifetime of a thread.\nSo in pseudocode ThreadStatic is similar (by semantics) to having a key-value attached to a thread:\nThread.Current[\"MyClass.myVariable\"] = 1;\nThread.Current[\"MyClass.myVariable\"] += 1;\n\nbut the syntax is just a bit easier:\nclass MyClass {\n  [ThreadStatic]\n  static int myVariable;\n}\n// .. then\nMyClass.myVariable = 1;\nMyClass.myVariable += 1;\n\n\nwhat happens if you put it on a non-static member?\n\nI believe it is ignored:\n    class A {\n        [ThreadStatic]\n        public int a;\n    }\n    [Test]\n    public void Try() {\n        var a1 = new A();\n        var a2 = new A();\n        a1.a = 5;\n        a2.a = 10;\n        a1.a.Should().Be.EqualTo(5);\n        a2.a.Should().Be.EqualTo(10);\n    }\n\nAdditionally it is worth mentioning that ThreadStatic does not require any synchronisation mechanism as compared to normal static fields (because the state is not shared).\n",
            "\nThe implementation semantics of thread static are below the IL level, in the .NET jit compiler.  Compilers that emit to IL like VB.NET and C# don't need to know anything about Win32 TLS in order to emit IL code that can read and write a variable that has the ThreadStatic attribute.  There's nothing special about the variable as far as C# knows - it's just a location to read and write stuff.  The fact that it has an attribute on it is of no consequence to C#.  C# only needs to know to emit IL read or write instructions for that symbol name.\nThe 'heavy lifting' is done by the core CLR that is responsible for making the IL work on a particular hardware architecture.  \nThat would also explain why putting the attribute on an inappropriate (non-static) symbol doesn't get a reaction from the compiler.  The compiler doesn't know what special semantics the attribute requires. Code analysis tools like FX/Cop, though, should know about it.\nAnother way to look at it:  CIL defines a set of storage scopes:  static (global) storage, member storage, and stack storage.  TLS isn't on that list, very likely because TLS doesn't need to be on that list. If IL read and write instructions are sufficient to access TLS when the symbol is tagged with a TLS attribute, why should IL have any special representation or treatment for TLS? It's not needed.\n"
        ],
        "answer": "A3",
        "tags": [
            "c#",
            "multithreading",
            "static",
            "threadstatic"
        ]
    },
    {
        "question_id": "24003584",
        "question": "\nThe language guide has revealed no trace of list comprehension. What's the neatest way of accomplishing this in Swift? I'm looking for something similar to:\nevens = [ x for x in range(10) if x % 2 == 0]\n\n",
        "all_answers": [
            "\nOne way would be :\nvar evens: Int[]()\nfor x in 0..<10 {\n    if x%2 == 0 {evens += x} // or evens.append(x)\n}\n\n\nRange operators\nArrays\n\n",
            "\nAs of Swift 2.x, there are a few short equivalents to your Python-style list comprehension.\nThe most straightforward adaptations of Python's formula (which reads something like \"apply a transform to a sequence subject to a filter\") involve chaining the map and filter methods available to all SequenceTypes, and starting from a Range:\n// Python: [ x for x in range(10) if x % 2 == 0 ]\nlet evens = (0..<10).filter { $0 % 2 == 0 }\n\n// Another example, since the first with 'x for x' doesn't\n// use the full ability of a list comprehension:\n// Python: [ x*x for x in range(10) if x % 2 == 0 ]\nlet evenSquared = (0..<10).filter({ $0 % 2 == 0 }).map({ $0 * $0 })\n\nNote that a Range is abstract — it doesn't actually create the whole list of values you ask it for, just a construct that lazily supplies them on demand. (In this sense it's more like Python's xrange.) However, the filter call returns an Array, so you lose the \"lazy\" aspect there. If you want to keep the collection lazy all the way through, just say so:\n// Python: [ x for x in range(10) if x % 2 == 0 ]\nlet evens = (0..<10).lazy.filter { $0 % 2 == 0 }\n// Python: [ x*x for x in range(10) if x % 2 == 0 ]\nlet evenSquared = (0..<10).lazy.filter({ $0 % 2 == 0 }).map({ $0 * $0 })\n\nUnlike the list comprehension syntax in Python (and similar constructs in some other languages), these operations in Swift follow the same syntax as other operations. That is, it's the same style of syntax to construct, filter, and operate on a range of numbers as it is to filter and operate on an array of objects — you don't have to use function/method syntax for one kind of work and list comprehension syntax for another.\nAnd you can pass other functions in to the filter and map calls, and chain in other handy transforms like sort and reduce:\n// func isAwesome(person: Person) -> Bool\n// let people: [Person]\nlet names = people.filter(isAwesome).sort(<).map({ $0.name })\n\nlet sum = (0..<10).reduce(0, combine: +)\n\nDepending on what you're going for, though, there may be more concise ways to say what you mean. For example, if you specifically want a list of even integers, you can use stride:\nlet evenStride = 0.stride(to: 10, by: 2) // or stride(through:by:), to include 10\n\nLike with ranges, this gets you a generator, so you'll want to make an Array from it or iterate through it to see all the values:\nlet evensArray = Array(evenStride) // [0, 2, 4, 6, 8]\n\nEdit: Heavily revised for Swift 2.x. See the edit history if you want Swift 1.x.\n"
        ],
        "answer": "A2",
        "tags": [
            "swift",
            "list-comprehension"
        ]
    },
    {
        "question_id": "800383",
        "question": "\nPlease explain from  Linux, Windows perspectives? \nI am programming in C#, would these two terms make a difference. Please post as much as  you can, with examples and such....\nThanks\n",
        "all_answers": [
            "\nIn Windows, a critical section is local to your process. A mutex can be shared/accessed across processes. Basically, critical sections are much cheaper. Can't comment on Linux specifically, but on some systems they're just aliases for the same thing.\n",
            "\nA mutex is an object that a thread can acquire, preventing other threads from acquiring it. It is advisory, not mandatory; a thread can use the resource the mutex represents without acquiring it.\nA critical section is a length of code that is guaranteed by the operating system to not be interupted. In pseudo-code, it would be like:\nStartCriticalSection();\n    DoSomethingImportant();\n    DoSomeOtherImportantThing();\nEndCriticalSection();\n\n",
            "\nFor Windows, critical sections are lighter-weight than mutexes.\nMutexes can be shared between processes, but always result in a system call to the kernel which has some overhead.\nCritical sections can only be used within one process, but have the advantage that they only switch to kernel mode in the case of contention - Uncontended acquires, which should be the common case, are incredibly fast.  In the case of contention, they enter the kernel to wait on some synchronization primitive (like an event or semaphore).\nI wrote a quick sample app that compares the time between the two of them.  On my system for 1,000,000 uncontended acquires and releases, a mutex takes over one second.  A critical section takes ~50 ms for 1,000,000 acquires.\nHere's the test code, I ran this and got similar results if mutex is first or second, so we aren't seeing any other effects.\nHANDLE mutex = CreateMutex(NULL, FALSE, NULL);\nCRITICAL_SECTION critSec;\nInitializeCriticalSection(&critSec);\n\nLARGE_INTEGER freq;\nQueryPerformanceFrequency(&freq);\nLARGE_INTEGER start, end;\n\n// Force code into memory, so we don't see any effects of paging.\nEnterCriticalSection(&critSec);\nLeaveCriticalSection(&critSec);\nQueryPerformanceCounter(&start);\nfor (int i = 0; i < 1000000; i++)\n{\n    EnterCriticalSection(&critSec);\n    LeaveCriticalSection(&critSec);\n}\n\nQueryPerformanceCounter(&end);\n\nint totalTimeCS = (int)((end.QuadPart - start.QuadPart) * 1000 / freq.QuadPart);\n\n// Force code into memory, so we don't see any effects of paging.\nWaitForSingleObject(mutex, INFINITE);\nReleaseMutex(mutex);\n\nQueryPerformanceCounter(&start);\nfor (int i = 0; i < 1000000; i++)\n{\n    WaitForSingleObject(mutex, INFINITE);\n    ReleaseMutex(mutex);\n}\n\nQueryPerformanceCounter(&end);\n\nint totalTime = (int)((end.QuadPart - start.QuadPart) * 1000 / freq.QuadPart);\n\nprintf(\"Mutex: %d CritSec: %d\\n\", totalTime, totalTimeCS);\n\n",
            "\nCritical Section and Mutex are not Operating system specific, their concepts of multithreading/multiprocessing. \nCritical Section\nIs a piece of code that must only run by it self at any given time (for example, there are 5 threads running simultaneously and a function called \"critical_section_function\" which updates a array... you don't want all 5 threads updating the array at once. So when the program is running critical_section_function(), none of the other threads must run their critical_section_function. \nmutex*\nMutex is a way of implementing the critical section code (think of it like a token... the thread must have possession of it to run the critical_section_code)\n",
            "\nTry using Process explorer. It's much more powerful than task manager and should suit your needs.\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "linux",
            "multithreading",
            "programming-languages"
        ]
    },
    {
        "question_id": "17240725",
        "question": "\nI have tried below command to append some path to system path variable by batch-file :\nsetx PATH \"%PATH%;C:\\Program Files\\MySQL\\MySQL Server 5.5\\bin\"\n\nI have checked system variable path after running above batch-file, above path isn't in there.\n\nYou can see all windows Variable value content in below :\nC:\\Program Files (x86)\\AMD APP\\bin\\x86_64;C:\\Program Files (x86)\\AMDAPP\\bin\\x86;%SystemRoot%\\system32;%SystemRoot%;%SystemRoot%\\System32\\Wbem;%SYSTEMROOT%\\System32\\WindowsPowerShell\\v1.0\\;C:\\ProgramFiles (x86)\\ATI Technologies\\ATI.ACE\\Core-Static;\n\nWhat am i doing wrong?\n",
        "all_answers": [
            "\nAs others have already said, parameters passed through the command line can be accessed in batch files with the notation %1 to %9. There are also two other tokens that you can use:\n\n%0 is the executable (batch file) name as specified in the command line.\n%* is all parameters specified in the command line -- this is very useful if you want to forward the parameters to another program.\n\nThere are also lots of important techniques to be aware of in addition to simply how to access the parameters.\nChecking if a parameter was passed\nThis is done with constructs like IF \"%~1\"==\"\", which is true if and only if no arguments were passed at all. Note the tilde character which causes any surrounding quotes to be removed from the value of %1; without a tilde you will get unexpected results if that value includes double quotes, including the possibility of syntax errors.\nHandling more than 9 arguments (or just making life easier)\nIf you need to access more than 9 arguments you have to use the command SHIFT. This command shifts the values of all arguments one place, so that %0 takes the value of %1, %1 takes the value of %2, etc. %9 takes the value of the tenth argument (if one is present), which was not available through any variable before calling SHIFT (enter command SHIFT /? for more options).\nSHIFT is also useful when you want to easily process parameters without requiring that they are presented in a specific order. For example, a script may recognize the flags -a and -b in any order. A good way to parse the command line in such cases is\n:parse\nIF \"%~1\"==\"\" GOTO endparse\nIF \"%~1\"==\"-a\" REM do something\nIF \"%~1\"==\"-b\" REM do something else\nSHIFT\nGOTO parse\n:endparse\nREM ready for action!\n\nThis scheme allows you to parse pretty complex command lines without going insane.\nSubstitution of batch parameters\nFor parameters that represent file names the shell provides lots of functionality related to working with files that is not accessible in any other way. This functionality is accessed with constructs that begin with %~.\nFor example, to get the size of the file passed in as an argument use\nECHO %~z1\n\nTo get the path of the directory where the batch file was launched from (very useful!) you can use\nECHO %~dp0\n\nYou can view the full range of these capabilities by typing CALL /? in the command prompt.\n",
            "\nyou shouldn't look at the system environment variables but to your user environment variables:\n\n",
            "\nTo piggy-back on @Endoro's answer (I lack the rep to comment):\nIf you want to change the system-wide environment variables, you have to use /M, a la:\nsetx PATH \"%PATH%;C:\\Program Files\\MySQL\\MySQL Server 5.5\\bin\" /M\n\nsetx.exe is picky about placement of the /M, BTW. It needs to be at the end.\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "batch-file",
            "cmd",
            "system-variable",
            "setx"
        ]
    },
    {
        "question_id": "323517",
        "question": "\nWe need to see what methods/fields an object has in Javascript.\n",
        "all_answers": [
            "\nIf you use Firebug, you can use console.log to output an object and get a hyperlinked, explorable item in the console.\n",
            "\nAs the others said, you can use Firebug, and that will sort you out no worries on Firefox. Chrome & Safari both have a built-in developer console which has an almost identical interface to Firebug's console, so your code should be portable across those browsers. For other browsers, there's Firebug Lite.\nIf Firebug isn't an option for you, then try this simple script:\nfunction dump(obj) {\n    var out = '';\n    for (var i in obj) {\n        out += i + \": \" + obj[i] + \"\\n\";\n    }\n\n    alert(out);\n\n    // or, if you wanted to avoid alerts...\n\n    var pre = document.createElement('pre');\n    pre.innerHTML = out;\n    document.body.appendChild(pre)\n}\n\nI'd recommend against alerting each individual property: some objects have a LOT of properties and you'll be there all day clicking \"OK\", \"OK\", \"OK\", \"O... dammit that was the property I was looking for\".\n",
            "\nIf you are using firefox then the firebug plug-in console is an excellent way of examining objects\nconsole.debug(myObject);\n\nAlternatively you can loop through the properties (including methods) like this:\nfor (property in object) {\n    // do what you want with property, object[property].value\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "javascript"
        ]
    },
    {
        "question_id": "1000023",
        "question": "\nWhen should I go for a Windows Service and when should I go for a \"Background Application\" that runs in the notification area?\nIf I'm not wrong, my design decision would be, any app that needs to be running before the user logins to the computer should be a service. For everything else use a background app. Is my decision right?\nMoreover, if I need \"admin privileges\" for my background app, I would escalate using a manifest. Are there any other specific advantage of running as a service?\n",
        "all_answers": [
            "\nMy general rules of thumb are as follows\n\nIf it needs to always run, it's a service.\nIf it needs to be run under a particular user account, Network Service, Local System, generally it's a service (or a COM+ application)\nIf the user needs some control over it, it's generally a notification area application.\nIf it needs to notify the user of something, it's a notification area application\n\nThe fun comes when you have the need to run something as a system account, but also interact with it. IIS is a good example of this, it's a service, but the administration is an application - it needs to be running at the startup, it needs access to particular things a user can't normal access (c:\\inetpub), but the user needs to be able to start, stop and configure it.\n",
            "\nI believe your decision is almost right, however, I would add one more condition.  Take for example the mysqld service (you have a choice in this case, but most people run it as a service).  It's ran as a service because you want to access the service anytime through  potentially multiple applications.  It's important that it is responsive to all applications calling upon it, and itself, is not much of anything, other than waiting to serve other applications.\nJust something I would consider as well when making my decision.\n",
            "\nI would design an application as a service if the applcation has a critical purpose and should never (or rarely) be closed. Windows services provide good crash-recovery options, good notifications (see the recovery tab in service property).\nAlso a good reason to use services is because they can run under any user ( so if you \ndeploy them on a server that you remote to, you can safely log out after starting the service without worring that the application will close too).\nI also design services in combination with a desktop application that can interact with the service and can be used to monitor or reconfigure the service while running. This way you can have all the benefits of a tray application, in your service.\nHowever, you should not abuse using services and only use them, as I said, for cirtical applications.\n"
        ],
        "answer": "A1",
        "tags": [
            "c#",
            "windows",
            "winforms",
            "windows-services"
        ]
    },
    {
        "question_id": "962132",
        "question": "\nSuppose I have two C++ classes:\nclass A\n{\npublic:\n  A() { fn(); }\n\n  virtual void fn() { _n = 1; }\n  int getn() { return _n; }\n\nprotected:\n  int _n;\n};\n\nclass B : public A\n{\npublic:\n  B() : A() {}\n\n  virtual void fn() { _n = 2; }\n};\n\nIf I write the following code:\nint main()\n{\n  B b;\n  int n = b.getn();\n}\n\nOne might expect that n is set to 2.\nIt turns out that n is set to 1. Why?\n",
        "all_answers": [
            "\nCalling virtual functions from a constructor or destructor is dangerous and should be avoided whenever possible.  All C++ implementations should call the version of the function defined at the level of the hierarchy in the current constructor and no further.\nThe C++ FAQ Lite covers this in section 23.7 in pretty good detail.  I suggest reading that (and the rest of the FAQ) for a followup.\nExcerpt:\n\n[...] In a constructor, the virtual call mechanism is disabled because overriding from derived classes hasn’t yet happened. Objects are constructed from the base up, “base before derived”.\n[...]\nDestruction is done “derived class before base class”, so virtual functions behave as in constructors: Only the local definitions are used – and no calls are made to overriding functions to avoid touching the (now destroyed) derived class part of the object.\n\nEDIT Corrected Most to All (thanks litb)\n",
            "\nThrowing an exception is the best way of dealing with constructor failure. You should particularly avoid half-constructing an object and then relying on users of your class to detect construction failure by testing flag variables of some sort.\nOn a related point, the fact that you have several different exception types for dealing with mutex errors worries me slightly. Inheritance is a great tool, but it can be over-used. In this case I would probably prefer a single MutexError exception, possibly containing an informative error message.\n",
            "\nYes, throwing an exception from the failed constructor is the standard way of doing this. Read this FAQ about Handling a constructor that fails for more information. Having a init() method will also work, but everybody who creates the object of mutex has to remember that init() has to be called. I feel it goes against the RAII principle.\n",
            "\nThe reason is that C++ objects are constructed like onions, from the inside out. Base classes are constructed before derived classes. So, before a B can be made, an A must be made. When A's constructor is called, it's not a B yet, so the virtual function table still has the entry for A's copy of fn().\n",
            "\nIf you do throw an exception from a constructor, keep in mind that you need to use the function try/catch syntax if you need to catch that exception in a constructor initializer list.\ne.g.\nfunc::func() : foo()\n{\n    try {...}\n    catch (...) // will NOT catch exceptions thrown from foo constructor\n    { ... }\n}\n\nvs.\nfunc::func()\n    try : foo() {...}\n    catch (...) // will catch exceptions thrown from foo constructor\n    { ... }\n\n"
        ],
        "answer": "A1",
        "tags": [
            "c++",
            "constructor",
            "overriding",
            "virtual-functions"
        ]
    },
    {
        "question_id": "7428872",
        "question": "\nHi I wan't to validate the unique combination of 3 columns in my table.\nLet's say I have a table called cars with the values :brand, :model_name and :fuel_type.\nWhat I then want is to validate if a record is unique based on the combination of those 3. An example:\n    brand    model_name    fuel_type\n    Audi     A4            Gas\n    Audi     A4            Diesel\n    Audi     A6            Gas\n\nShould all be valid. But another record with 'Audi, A6, Gas' should NOT be valid.\nI know of this validation, but I doubt that it actually does what I want.\n    validates_uniqueness_of :brand, :scope => {:model_name, :fuel_type}\n\n",
        "all_answers": [
            "\nThere is a syntax error in your code snippet. The correct validation is :\nvalidates_uniqueness_of :car_model_name, :scope => [:brand_id, :fuel_type_id]\n\nor even shorter in ruby 1.9.x:\nvalidates_uniqueness_of :car_model_name, scope: [:brand_id, :fuel_type_id]\n\nwith rails 4 you can use:\nvalidates :car_model_name, uniqueness: { scope: [:brand_id, :fuel_type_id] }\n\nwith rails 5 you can use\nvalidates_uniqueness_of :car_model_name, scope: %i[brand_id fuel_type_id]\n\n",
            "\nI would make it this way:\nvalidates_uniqueness_of :model_name, :scope => {:brand_id, :fuel_type_id}\n\nbecause it makes more sense for me:\n\nthere should not be duplicated \"model names\" for combination of \"brand\" and \"fuel type\", vs\nthere should not be duplicated \"brands\" for combination of \"model name\" and \"fuel type\"\n\nbut it's subjective opinion.\nOf course if brand and fuel_type are relationships to other models (if not, then just drop \"_id\" part). With uniqueness validation you can't check non-db columns, so you have to validate foreign keys in model.\nYou need to define which attribute is validated - you don't validate all at once, if you want, you need to create separate validation for every attribute, so when user make mistake and tries to create duplicated record, then you show him errors in form near invalid field. \n"
        ],
        "answer": "A1",
        "tags": [
            "ruby-on-rails",
            "ruby-on-rails-3"
        ]
    },
    {
        "question_id": "821873",
        "question": "\nYou wouldn't imagine something as basic as opening a file using the C++ standard library for a Windows application was tricky ... but it appears to be. By Unicode here I mean UTF-8, but I can convert to UTF-16 or whatever, the point is getting an ofstream instance from a Unicode filename. Before I hack up my own solution, is there a preferred route here ? Especially a cross-platform one ?\n",
        "all_answers": [
            "\nThe C++ standard library is not Unicode-aware. char and wchar_t  are not required to be Unicode encodings.\nOn Windows, wchar_t is UTF-16, but there's no direct support for UTF-8 filenames in the standard library (the char datatype is not Unicode on Windows)\nWith MSVC (and thus the Microsoft STL), a constructor for filestreams is provided which takes a const wchar_t* filename, allowing you to create the stream as:\nwchar_t const name[] = L\"filename.txt\";\nstd::fstream file(name);\n\nHowever, this overload is not specified by the C++11 standard (it only guarantees the presence of the char based version). It is also not present on alternative STL implementations like GCC's libstdc++ for MinGW(-w64), as of version g++ 4.8.x.\nNote that just like char on Windows is not UTF8, on other OS'es wchar_t may not be UTF16. So overall, this isn't likely to be portable. Opening a stream given a wchar_t filename isn't defined according to the standard, and specifying the filename in chars may be difficult because the encoding used by char varies between OS'es.\n",
            "\nOpen an elevated Command Prompt (run cmd as administrator).\nquery your registry for available TT fonts to the console by:\n    REG query \"HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Console\\TrueTypeFont\"\n\nYou'll see an output like :\n    0    REG_SZ    Lucida Console\n    00    REG_SZ    Consolas\n    936    REG_SZ    *新宋体\n    932    REG_SZ    *ＭＳ ゴシック\n\nNow we need to add a TT font that supports the characters you need like Courier New, we do this by adding zeros to the string name, so in this case the next one would be \"000\" :\n    REG ADD \"HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Console\\TrueTypeFont\" /v 000 /t REG_SZ /d \"Courier New\"\n\nNow we implement UTF-8 support:\n    REG ADD HKCU\\Console /v CodePage /t REG_DWORD /d 65001 /f\n\nSet default font to \"Courier New\":\n    REG ADD HKCU\\Console /v FaceName /t REG_SZ /d \"Courier New\" /f\n\nSet font size to 20 :\n    REG ADD HKCU\\Console /v FontSize /t REG_DWORD /d 20 /f\n\nEnable quick edit if you like :\n    REG ADD HKCU\\Console /v QuickEdit /t REG_DWORD /d 1 /f\n\n",
            "\nThe current versions of Visual C++ the std::basic_fstream have an open() method that take a wchar_t* according to http://msdn.microsoft.com/en-us/library/4dx08bh4.aspx. \n",
            "\nAfter I tried algirdas' solution, my Windows crashed (Win 7 Pro 64bit) so I decided to try a different solution:\n\nStart Run (Win+R)\nType cmd /K chcp 65001\n\nYou will get mostly what you want. To start it from the taskbar or anywhere else, make a shortcut (you can name it cmd.unicode.exe or whatever you like) and change its Target to C:\\Windows\\System32\\cmd.exe /K chcp 65001.\n"
        ],
        "answer": "A1",
        "tags": [
            "c++",
            "windows",
            "unicode"
        ]
    },
    {
        "question_id": "10099128",
        "question": "\nI'm updating an old package and shortening a bunch of really long function names. How do I let a user know the the old function has been deprecated? I document everything with roxygen2 so  I'm wondering if #' @alias is what I should use? Thoughts?\n",
        "all_answers": [
            "\nEven though you are just shortening function names, I would still treat it with the same fanfare as any change to the public API of the package: with deprecation/defunct stages to the old functions as the new functions are brought in.  \nIn the first phase, for each function you want to shorten the name of (let's call it transmute_my_carefully_crafted_data_structure_into_gold), you keep a function with that signature, but move all the actual code into your newly named function (let's call it alchemy).\nInitially:\ntransmute_my_carefully_crafted_data_structure_into_gold <- function(lead, alpha=NULL, beta=3) {\n  # TODO: figure out how to create gold\n  # look like we are doing something\n  Sys.sleep(10)\n  return(\"gold\")\n}\n\nFirst release with new names:\ntransmute_my_carefully_crafted_data_structure_into_gold <- function(lead, alpha=NULL, beta=3) {\n  .Deprecated(\"alchemy\") #include a package argument, too\n  alchemy(lead=lead, alpha=alpha, beta=beta)\n}\n\nalchemy <- function(lead, alpha=NULL, beta=3) {\n  # TODO: figure out how to create gold\n  # look like we are doing something\n  Sys.sleep(10)\n  return(\"gold\")\n}\n\nSo that transmute_my_carefully_crafted_data_structure_into_gold starts as a thin wrapper around alchemy, with an additional .Deprecated call.\n> transmute_my_carefully_crafted_data_structure_into_gold()\n[1] \"gold\"\nWarning message:\n'transmute_my_carefully_crafted_data_structure_into_gold' is deprecated.\nUse 'alchemy' instead.\nSee help(\"Deprecated\") \n> alchemy()\n[1] \"gold\"\n\nIf you make changes to alchemy, it is still carried by transmute_my_carefully_crafted_data_structure_into_gold since that just calls the former. However, you don't change the signature of transmute_my_carefully_crafted_data_structure_into_gold even if alchemy does; in that case you need to map, as well as possible, the old arguments into the new arguments.\nIn a later release, you can change .Deprecated to .Defunct.\n> transmute_my_carefully_crafted_data_structure_into_gold()\nError: 'transmute_my_carefully_crafted_data_structure_into_gold' is defunct.\nUse 'alchemy' instead.\nSee help(\"Defunct\")\n\nNote that this is an error and stops; it does not go ahead and call alchemy.\nYou could, in some later release, delete this function entirely, but I'd leave it in this state as a signpost.\nYou mentioned using using roxygen.  When you make the first transition to deprecated, you can change the @rdname to package-deprecated, add a line at the beginning of the description saying it is deprecated, add the new function to the @seealso. When it changes to defunct, change the @rdname to package-defunct.\n",
            "\nIn the case of converting overly long function names to shorter versions, I'd recommend just exporting both names as the same function (see @Brandon's comment). This would allow old code to continue working while offering new users a more convenient alternative.\nIn my mind, the only reason to tag something as .Deprecated (see @GSEE) would be if you plan to fundamentally change the functionality or stop supporting some feature in a future release. If this is the case, you can use the .Defunct or .Deprecated.\n"
        ],
        "answer": "A1",
        "tags": [
            "r",
            "roxygen"
        ]
    },
    {
        "question_id": "34510",
        "question": "\nWhen writing multithreaded applications, one of the most common problems experienced is race conditions.\nMy questions to the community are:\n\nWhat is the race condition?\nHow do you detect them?\nHow do you handle them?\nFinally, how do you prevent them from occurring?\n\n",
        "all_answers": [
            "\nI have also been looking for such a book, they are very hard to come by. This one will be released in May, if that's any help:\nhttp://www.manning.com/williams/\nI purchased this book:\nhttp://www.amazon.co.uk/gp/product/0123705916/ref=oss_product\nIt's very good, it's in java, but most of the principles apply to c/c++ anyway.\n",
            "\nIf you will be working with UNIX-like systems, then I recommend Programming With POSIX Threads by David R. Butenhof.\nIf you will be working with Microsoft Windows, then I recommend Writing Multithreaded Applications in Win32 by Jim Beveridge and Robert Wiener.\nIrrespective of which threading package(s) you will end up using, I recommend you look at two presentations I wrote: Generic Synchronization Policies and Multi-threaded Performance Pitfalls. Those short presentations contain useful information that, unfortunately, is not discussed in many other books and articles.\n",
            "\n\nIntroduction to parallel computing: https://computing.llnl.gov/tutorials/parallel_comp/\nPOSIX threads programming: https://computing.llnl.gov/tutorials/pthreads/\n\n",
            "\nA race condition is a kind of bug, that happens only with certain temporal conditions.\nExample:\nImagine you have two threads, A and B.\nIn Thread A:\nif( object.a != 0 )\n    object.avg = total / object.a\n\nIn Thread B:\nobject.a = 0\n\nIf thread A is preempted just after having check that object.a is not null, B will do a = 0, and when thread A will gain the processor, it will do a \"divide by zero\". \nThis bug only happen when thread A is preempted just after the if statement, it's very rare, but it can happen.\n",
            "\nA race condition occurs when two or more threads can access shared data and they try to change it at the same time. Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data. Therefore, the result of the change in data is dependent on the thread scheduling algorithm, i.e. both threads are \"racing\" to access/change the data. \nProblems often occur when one thread does a \"check-then-act\" (e.g. \"check\" if the value is X, then \"act\" to do something that depends on the value being X) and another thread does something to the value in between the \"check\" and the \"act\". E.g:\nif (x == 5) // The \"Check\"\n{\n   y = x * 2; // The \"Act\"\n\n   // If another thread changed x in between \"if (x == 5)\" and \"y = x * 2\" above,\n   // y will not be equal to 10.\n}\n\nThe point being, y could be 10, or it could be anything, depending on whether another thread changed x in between the check and act. You have no real way of knowing.\nIn order to prevent race conditions from occurring, you would typically put a lock around the shared data to ensure only one thread can access the data at a time. This would mean something like this:\n// Obtain lock for x\nif (x == 5)\n{\n   y = x * 2; // Now, nothing can change x until the lock is released. \n              // Therefore y = 10\n}\n// release lock for x\n\n"
        ],
        "answer": "A5",
        "tags": [
            "multithreading",
            "concurrency",
            "terminology",
            "race-condition"
        ]
    },
    {
        "question_id": "16096627",
        "question": "\nI am curious as to why df[2] is not supported, while df.ix[2] and df[2:3] both work. \nIn [26]: df.ix[2]\nOut[26]: \nA    1.027680\nB    1.514210\nC   -1.466963\nD   -0.162339\nName: 2000-01-03 00:00:00\n\nIn [27]: df[2:3]\nOut[27]: \n                  A        B         C         D\n2000-01-03  1.02768  1.51421 -1.466963 -0.162339\n\nI would expect df[2] to work the same way as df[2:3] to be consistent with Python indexing convention. Is there a design reason for not supporting indexing row by single integer?\n",
        "all_answers": [
            "\nYou can take a look at the source code .\nDataFrame has a private function _slice() to slice the DataFrame, and it allows the parameter axis to determine which axis to slice. The __getitem__() for DataFrame doesn't set the axis while invoking _slice(). So the _slice() slice it by default axis 0.\nYou can take a simple experiment, that might help you:\nprint df._slice(slice(0, 2))\nprint df._slice(slice(0, 2), 0)\nprint df._slice(slice(0, 2), 1)\n\n",
            "\nechoing @HYRY, see the new docs in 0.11\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html\nHere we have new operators, .iloc to explicity support only integer indexing, and .loc to explicity support only label indexing\ne.g. imagine this scenario\nIn [1]: df = pd.DataFrame(np.random.rand(5,2),index=range(0,10,2),columns=list('AB'))\n\nIn [2]: df\nOut[2]: \n          A         B\n0  1.068932 -0.794307\n2 -0.470056  1.192211\n4 -0.284561  0.756029\n6  1.037563 -0.267820\n8 -0.538478 -0.800654\n\nIn [5]: df.iloc[[2]]\nOut[5]: \n          A         B\n4 -0.284561  0.756029\n\nIn [6]: df.loc[[2]]\nOut[6]: \n          A         B\n2 -0.470056  1.192211\n\n[] slices the rows (by label location) only\n",
            "\nYou can think DataFrame as a dict of Series. df[key] try to select the column index by key and returns a Series object.\nHowever slicing inside of [] slices the rows, because it's a very common operation.\nYou can read the document for detail:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#basics\n"
        ],
        "answer": "A2",
        "tags": [
            "python",
            "pandas",
            "dataframe",
            "indexing"
        ]
    },
    {
        "question_id": "10300414",
        "question": "\nI have the following SQL query:\nDECLARE @MyVar datetime = '1/1/2010'    \nSELECT @MyVar\n\nThis naturally returns '1/1/2010'.\nWhat I want to do is have a list of dates, say:\n1/1/2010\n2/1/2010\n3/1/2010\n4/1/2010\n5/1/2010\n\nThen i want to FOR EACH through the numbers and run the SQL Query.\nSomething like (pseudocode):\nList = 1/1/2010,2/1/2010,3/1/2010,4/1/2010,5/1/2010\n\nFor each x in List\ndo\n  DECLARE @MyVar datetime = x\n\n  SELECT @MyVar\n\nSo this would return:-\n1/1/2010\n    2/1/2010\n    3/1/2010\n    4/1/2010\n    5/1/2010\nI want this to return the data as one resultset, not multiple resultsets, so I may need to use some kind of union at the end of the query, so each iteration of the loop unions onto the next.\nedit\nI have a large query that accepts a 'to date' parameter, I need to run it 24 times, each time with a specific to date which I need to be able to supply (these dates are going to be dynamic) I want to avoid repeating my query 24 times with union alls joining them as if I need to come back and add additional columns it would be very time consuming.\n",
        "all_answers": [
            "\nHere is an option with a table variable:\nDECLARE @MyVar TABLE(Val DATETIME)\nDECLARE @I INT, @StartDate DATETIME\nSET @I = 1\nSET @StartDate = '20100101'\n\nWHILE @I <= 5\nBEGIN\n    INSERT INTO @MyVar(Val)\n    VALUES(@StartDate)\n\n    SET @StartDate = DATEADD(DAY,1,@StartDate)\n    SET @I = @I + 1\nEND\nSELECT *\nFROM @MyVar\n\nYou can do the same with a temp table:\nCREATE TABLE #MyVar(Val DATETIME)\nDECLARE @I INT, @StartDate DATETIME\nSET @I = 1\nSET @StartDate = '20100101'\n\nWHILE @I <= 5\nBEGIN\n    INSERT INTO #MyVar(Val)\n    VALUES(@StartDate)\n\n    SET @StartDate = DATEADD(DAY,1,@StartDate)\n    SET @I = @I + 1\nEND\nSELECT *\nFROM #MyVar\n\nYou should tell us what is your main goal, as was said by @JohnFx, this could probably be done another (more efficient) way.\n",
            "\nSQL is primarily a set-orientated language - it's generally a bad idea to use a loop in it.\nIn this case, a similar result could be achieved using a recursive CTE:\nwith cte as\n(select 1 i union all\n select i+1 i from cte where i < 5)\nselect dateadd(d, i-1, '2010-01-01') from cte\n\n",
            "\nYou could use a variable table, like this:\ndeclare @num int\n\nset @num = 1\n\ndeclare @results table ( val int )\n\nwhile (@num < 6)\nbegin\n  insert into @results ( val ) values ( @num )\n  set @num = @num + 1\nend\n\nselect val from @results\n\n"
        ],
        "answer": "A2",
        "tags": [
            "sql",
            "sql-server",
            "t-sql"
        ]
    },
    {
        "question_id": "15659779",
        "question": "\nThe contents of cell A1 is =test(2) where test is the function:\nFunction test(ByRef x As Double) As Double\n  Range(\"A2\") = x\n  test = x * x\nEnd Function\n\nCan you explain why this gives #VALUE! in cell A1 and nothing in cell A2? I expected A2 to contain 2 and A1 to contain 4. Without the line Range(\"A2\") = x the function works as expected (squaring the value of a cell).\nWhat is really confusing is if you wrap test with the subroutine calltest then it works: \nSub calltest()\n  t = test(2)\n  Range(\"A1\") = t\nEnd Sub\n\nFunction test(ByRef x As Double) As Double\n  Range(\"A2\") = x\n  test = x * x\nEnd Function\n\nBut this doesn't\nFunction test(ByRef x As Double) As Double\n  Range(\"A2\") = x\nEnd Function\n\n",
        "all_answers": [
            "\nIt sounds like you have the wrong error trapping option set.  Within the VBA Editor, Select Tools -> Options.  In the window that opens, select the General tab, and pick the Break on Unhandled Errors radio button.  This should allow Excel to properly process the On Error Resume Next command.\nI suspect that you have Break on All Errors selected.\n",
            "\nFollow these steps and your problem will be solved ;)\n\nSet your formula to =$B2=1\nSelect the fill color Yellow\nApplies to =$A$2:$A$7\nOnce you click Apply, make sure your formula hasn't changed! (always happens to me)\n\n\n\n",
            "\nDue to Function fundamentals which state that you can not change or set sheet cells. You need to delete the row with Range(\"A2\") = x\nEDIT Some additional link (which I believe is always useful to provide for those who want to analyse UDF topic): Creating custom functions by Microsoft\n",
            "\nWhen you call a function from a worksheet cell, you are effectively using the function as a User Defined Function, which has the limitations as described here:\nhttp://support.microsoft.com/kb/170787\nIn the text there is a line:\n\nAny environmental changes should be made through the use of a Visual\n  Basic subroutine.\n\nIt's interesting how they use the word should rather than must. I wonder if the author of the KB knew that environment changes can happen from a VBA Function.\nNow, when you call the function from another VBA Sub / Function, it is treated differently. From the help docs (sorry I couldn't find a web page reference - basically, in VBE, highlight the word Function and press F1):\n\nLike a Sub procedure, a Function procedure is a separate procedure\n  that can take arguments, perform a series of statements, and change\n  the values of its arguments. However, unlike a Sub procedure, you can\n  use a Function procedure on the right side of an expression in the\n  same way you use any intrinsic function, such as Sqr, Cos, or Chr,\n  when you want to use the value returned by the function.\n\nSo it sounds like Subs and functions can do the same things when used in VBA only, except that Functions can return values back to the calling function/sub.\nThis is pretty interesting, actually, since Excel can call a function with some sort of \"Read-Only\" restriction to Excel's environment.\nI think that, in the end, Excel can call the function from a worksheet cell in a different way than VBA does. When you call it from a Cell, it's considered a User Defined Function, which includes the restrictions of changing Excel's environment. Where when called from within VBA (where the original caller from a chain of calls is from VBA), it has all the power a Sub does, plus it can return values.\n"
        ],
        "answer": "A4",
        "tags": [
            "vba",
            "excel"
        ]
    },
    {
        "question_id": "30811668",
        "question": "\nI have an error when I start PHP 7 on Windows. When I run php on the command line, it returns a message box with system error:\n\nThe program can't start because VCRUNTIME140.dll is missing from your computer. Try reinstalling the program to fix this problem.\n\nAfter that, CLI is crashing.\nAs I don't want to install a DLL file from an external website, I don't know how to fix this!\nPHP version: 7.0.0alpha1 VC14 x64 Thread Safe\n",
        "all_answers": [
            "\nVisual C++ Redistributable for Visual Studio 2015 (x32 bit version) - RC.\nThis should correct that. You can google for what the DLL is, but that's not important.\nPS: It's officially from Microsoft too:)\nWhere I found it: Downloads (Visual Studio)\n",
            "\nOn the side bar of the PHP 7 alpha download page, it does say this:\n\nVC9, VC11 & VC14\n  More recent versions of PHP are built with VC9, VC11\n  or VC14 (Visual Studio 2008, 2012 or 2015 compiler respectively) and\n  include improvements in performance and stability.\n\nThe VC9 builds require you to have the Visual C++ Redistributable for Visual Studio 2008 SP1 x86 or x64 installed\nThe VC11 builds require to have the Visual C++ Redistributable for Visual Studio 2012 x86 or x64 installed\nThe VC14 builds require to have the Visual C++ Redistributable for Visual Studio 2015 x86 or x64 installed\n\n\nThere's been a problem with some of those links, so the files are also available from Softpedia.\nIn the case of the PHP 7 alpha, it's the last option that's required.\nI think that the placement of this information is poor, as it's kind of marginalized (i.e.: it's basically literally in the margin!) whereas it's actually critical for the software to run.\nI documented my experiences of getting PHP 7 alpha up and running on Windows 8.1 in PHP: getting PHP7 alpha running on Windows 8.1, and it covers some more symptoms that might crop up. They're out of scope for this question but might help other people.\nOther symptom of this issue:\n\nApache not starting, claiming php7apache2_4.dll is missing despite it definitely being in place, and offering nothing else in any log.\nphp-cgi.exe - The FastCGI process exited unexpectedly (as per @ftexperts's comment below)\n\nAttempted solution:\n\nUsing the php7apache2_4.dll file from an earlier PHP 7 dev build. This did not work.\n\n(I include those for googleability.)\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "windows",
            "dll",
            "php-7"
        ]
    },
    {
        "question_id": "24290358",
        "question": "\nI need to exclude a folder (name uploads) from tracking. I tried to run\ngit rm -r --cached wordpress/wp-content/uploads\n\nand after that I added the path to .gitignore\n/wordpress/wp-content/uploads\n\nbut when I ran git status they show up as deleted. If I try to commit the changes, the files will be deleted, not only removed from tracking.\nWhat am I doing wrong? \nI have also tried\ngit update-index --assume-unchanged <file>\n\nbut this seems to untrack only files. But I need to remove an entire folder (including subfolders) from tracking.\n",
        "all_answers": [
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\ngit reset --hard origin/main\n\nIt works for other branch:\ngit reset --hard origin/master\ngit reset --hard origin/staging\n\nto reset it to whatever the origin was at.\nThis was posted by @bdonlan in the comments.  I added this answer for people who don't read comments.\n",
            "\nI came across this question while Googling for \"git remove folder from tracking\". The OP's question lead me to the answer. I am summarizing it here for future generations.\nQuestion\nHow do I remove a folder from my git repository without deleting it from my local machine (i.e., development environment)?\nAnswer\nStep 1. Add the folder path to your repo's root .gitignore file.\npath_to_your_folder/\n\nStep 2. Remove the folder from your local git tracking, but keep it on your disk.\ngit rm -r --cached path_to_your_folder/\n\nStep 3. Push your changes to your git repo.\nThe folder will be considered \"deleted\" from Git's point of view (i.e. they are in past history, but not in the latest commit, and people pulling from this repo will get the files removed from their trees), but stay on your working directory because you've used --cached.\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n",
            "\nFrom the git documentation: \nAnother useful thing you may want to do is to keep the file in your working tree but remove it from your staging area. In other words, you may want to keep the file on your hard drive but not have Git track it anymore. This is particularly useful if you forgot to add something to your .gitignore file and accidentally staged it, like a large log file or a bunch of .a compiled files. To do this, use the --cached option:\n$ git rm --cached readme.txt\n\nSo maybe don't include the \"-r\"?\n"
        ],
        "answer": "A4",
        "tags": [
            "git",
            "git-rm"
        ]
    },
    {
        "question_id": "42089659",
        "question": "\nI have an input field who allaow peoples to upload files.\nI want that they can upload, word files like doc, and files like csv,xlsx.\nWhen i try with a .doc no problem at all but when i try with an excel files, the validator fail and say that not the good extension.\nHere you can see my code, the two lines of comments was an other solution i have try , and it don't work too :(.\nAny help is welcome.\npublic function postFile(Request $request)\n{ //Règle de validation avec les type de fichiers acceptés\n\n if(isset($request->file)){\n//dd($request);\n   $validator=Validator::make($request->all(),[\n     'file'=>'required|max:50000|mimes:xlsx,doc,docx,ppt,pptx,ods,odt,odp,application/csv,application/excel,\n      application/vnd.ms-excel, application/vnd.msexcel,\n      text/csv, text/anytext, text/plain, text/x-c,\n      text/comma-separated-values,\n      inode/x-empty,\n      application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n  /*  'extension'  => strtolower($request->file->getClientOriginalExtension()),\n     'extension'=>'required|in:doc,csv,xlsx,xls,docx,ppt,odt,ods,odp'*/\n   ]);\n  if ($validator->fails()) {\n     return back()\n                ->withErrors($validator);\n   }\n\n",
        "all_answers": [
            "\nFor second accuracy, yyyy-MM-dd HH:mm:ss should do the trick.\nI believe Excel is not very good with fractions of a second (loses them when interacting with COM object IIRC).\n",
            "\nOk, my fault. \nI had tried another solution, found on this website and it worked.\nThanks for help Odin.\nIt was my first question on this website. I am gonna see if I can help someone now.\nI post code for solution for someone in need :).\n$validator = Validator::make(\n  [\n      'file'      => $request->file,\n      'extension' => strtolower($request->file->getClientOriginalExtension()),\n  ],\n  [\n      'file'          => 'required',\n      'extension'      => 'required|in:doc,csv,xlsx,xls,docx,ppt,odt,ods,odp',\n  ]\n);\n\n",
            "\nUse \"mimes\" when you want to write an extentions (xlsx,doc,docx).\nIn case when use mime-type like application/vnd.ms-excel you must use validation rule mimetype\nMore mime types:  more mime-types\n$validator=Validator::make($request->all(),[\n //use this\n    'file'=>'required|max:50000|mimes:xlsx,doc,docx,ppt,pptx,ods,odt,odp'\n //or this\n    'file'=>'required|max:50000|mimetypes:application/csv,application/excel,\n        application/vnd.ms-excel, application/vnd.msexcel,\n        text/csv, text/anytext, text/plain, text/x-c,\n        text/comma-separated-values,\n        inode/x-empty,\n        application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n]);\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "excel",
            "laravel",
            "validation",
            "csv"
        ]
    },
    {
        "question_id": "14558150",
        "question": "\nI search the path where the php.ini file is located in our Linux Ubuntu server, and I found many php.ini files when executing the command find / -name php.ini. So how can I know exactly from a PHP script web page where the php.ini is located?\n",
        "all_answers": [
            "\nYou can use php_ini_loaded_file().\nTaken from php.net:\n$inipath = php_ini_loaded_file();\nif ($inipath) {\n    echo 'Loaded php.ini: ' . $inipath;\n} else {\n    echo 'A php.ini file is not loaded';\n}\n\nYou may also want to check php_ini_scanned_files().\nAlso, you should note that if you run a PHP script from CLI, it's possible that a different php.ini file will be used than if a server (e.g., nginx or Apache) runs it.\nOther options:\n\nphp -i|grep 'php.ini'\ncreate info.php that contains <?php phpinfo(); in the webroot, and run it in your browser\n\n",
            "\nJust add a file like this:\n<?php\n    phpinfo();\n?>\n\nThen look for\nLoaded Configuration File\n\nYou'll see the full path for the php.ini file.\n",
            "\nCreate a simple page and it will be listed there!\n<?php\n\nphpinfo();\n\n?>\n\n",
            "\nphp --ini\n\nFor the webserver-SAPIs use phpinfo()\nHere's some sample output:\nbash-3.2# php --ini\nConfiguration File (php.ini) Path: /usr/local/php5/lib\nLoaded Configuration File:         /usr/local/php5/lib/php.ini\nScan for additional .ini files in: /usr/local/php5/php.d\nAdditional .ini files parsed:      /usr/local/php5/php.d/10-extension_dir.ini,\n/usr/local/php5/php.d/20-extension-opcache.ini,\n/usr/local/php5/php.d/40-openssl.ini,\n/usr/local/php5/php.d/50-extension-apcu.ini,\n/usr/local/php5/php.d/50-extension-curl.ini,\n/usr/local/php5/php.d/50-extension-gmp.ini,\n/usr/local/php5/php.d/50-extension-imap.ini,\n/usr/local/php5/php.d/50-extension-intl.ini,\n/usr/local/php5/php.d/50-extension-mcrypt.ini,\n/usr/local/php5/php.d/50-extension-mssql.ini,\n/usr/local/php5/php.d/50-extension-pdo_pgsql.ini,\n/usr/local/php5/php.d/50-extension-pgsql.ini,\n/usr/local/php5/php.d/50-extension-propro.ini,\n/usr/local/php5/php.d/50-extension-raphf.ini,\n/usr/local/php5/php.d/50-extension-readline.ini,\n/usr/local/php5/php.d/50-extension-xdebug.ini,\n/usr/local/php5/php.d/50-extension-xsl.ini,\n/usr/local/php5/php.d/60-extension-pecl_http.ini,\n/usr/local/php5/php.d/99-liip-developer.ini\n\n",
            "\nYou have to use the PHP method php_ini_loaded_file (only after PHP 5.2.4)\n\nphp_ini_loaded_file — Retrieve a path to the loaded php.ini file\n\nPHP website example:\n<?php\n$inipath = php_ini_loaded_file();\n\nif ($inipath) {\n    echo 'Loaded php.ini: ' . $inipath;\n} else {\n    echo 'A php.ini file is not loaded';\n}\n?>\n\nSource: PHP site\n"
        ],
        "answer": "A1",
        "tags": [
            "php",
            "php-ini"
        ]
    },
    {
        "question_id": "28727845",
        "question": "\nDoes Swift have something like _.findWhere in Underscore.js?\nI have an array of structs of type T and would like to check if array contains a struct object whose name property is equal to Foo.\nTried to use find() and filter() but they only work with primitive types, e.g. String or Int. Throws an error about not conforming to Equitable protocol or something like that.\n",
        "all_answers": [
            "\nFWIW, if you don't want to use custom function or extension, you can:\nlet array = [ .... ]\nif let found = find(array.map({ $0.name }), \"Foo\") {\n    let obj = array[found]\n}\n\nThis generates name array first, then find from it.\nIf you have huge array, you might want to do:\nif let found = find(lazy(array).map({ $0.name }), \"Foo\") {\n    let obj = array[found]\n}\n\nor maybe:\nif let found = find(lazy(array).map({ $0.name == \"Foo\" }), true) {\n    let obj = array[found]\n}\n\n",
            "\nUse contains:\nvar yourItem:YourType!\nif contains(yourArray, item){\n    yourItem = item\n}\n\nOr you could try what Martin pointed you at, in the comments and give filter another try: Find Object with Property in Array.\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nYou can filter the array and then just pick the first element, as shown\nin Find Object with Property in Array.\nOr you define a custom extension\nextension Array {\n\n    // Returns the first element satisfying the predicate, or `nil`\n    // if there is no matching element.\n    func findFirstMatching<L : BooleanType>(predicate: T -> L) -> T? {\n        for item in self {\n            if predicate(item) {\n                return item // found\n            }\n        }\n        return nil // not found\n    }\n}\n\nUsage example:\nstruct T {\n    var name : String\n}\n\nlet array = [T(name: \"bar\"), T(name: \"baz\"), T(name: \"foo\")]\n\nif let item = array.findFirstMatching( { $0.name == \"foo\" } ) {\n    // item is the first matching array element\n} else {\n    // not found\n}\n\n\nIn Swift 3 you can use the existing first(where:) method\n(as mentioned in a comment):\nif let item = array.first(where: { $0.name == \"foo\" }) {\n    // item is the first matching array element\n} else {\n    // not found\n}\n\n"
        ],
        "answer": "A1",
        "tags": [
            "ios",
            "swift"
        ]
    },
    {
        "question_id": "7715124",
        "question": "\nHow can I make jQuery do something if my screen width is less than 960 pixels? The code below always fires the 2nd alert, regardless of my window size: \nif (screen.width < 960) {\n    alert('Less than 960');\n}\nelse {\n\n    alert('More than 960');\n}\n\n",
        "all_answers": [
            "\nuse \n$(window).width()\n\nor\n$(document).width()\n\nor\n$('body').width()\n\n",
            "\nYou've mixed different approaches how to include legacy vendor modules. This is how I'd tackle it:\n1. Prefer unminified CommonJS/AMD over dist\nMost modules link the dist version in the main field of their package.json. While this is useful for most developers, for webpack it is better to alias the src version because this way webpack is able to optimize dependencies better (e.g. when using the DedupePlugin).\n// webpack.config.js\n\nmodule.exports = {\n    ...\n    resolve: {\n        alias: {\n            jquery: \"jquery/src/jquery\"\n        }\n    }\n};\n\nHowever, in most cases the dist version works just fine as well.\n\n2. Use the ProvidePlugin to inject implicit globals\nMost legacy modules rely on the presence of specific globals, like jQuery plugins do on $ or jQuery. In this scenario you can configure webpack, to prepend var $ = require(\"jquery\") everytime it encounters the global $ identifier.\nvar webpack = require(\"webpack\");\n\n    ...\n    \n    plugins: [\n        new webpack.ProvidePlugin({\n            $: \"jquery\",\n            jQuery: \"jquery\"\n        })\n    ]\n\n\n3. Use the imports-loader to configure this\nSome legacy modules rely on this being the window object. This becomes a problem when the module is executed in a CommonJS context where this equals module.exports. In this case you can override this with the imports-loader.\nRun npm i imports-loader --save-dev and then\nmodule: {\n    loaders: [\n        {\n            test: /[\\/\\\\]node_modules[\\/\\\\]some-module[\\/\\\\]index\\.js$/,\n            loader: \"imports-loader?this=>window\"\n        }\n    ]\n}\n\nThe imports-loader can also be used to manually inject variables of all kinds. But most of the time the ProvidePlugin is more useful when it comes to implicit globals.\n\n4. Use the imports-loader to disable AMD\nThere are modules that support different module styles, like AMD, CommonJS and legacy. However, most of the time they first check for define and then use some quirky code to export properties. In these cases, it could help to force the CommonJS path by setting define = false.\nmodule: {\n    loaders: [\n        {\n            test: /[\\/\\\\]node_modules[\\/\\\\]some-module[\\/\\\\]index\\.js$/,\n            loader: \"imports-loader?define=>false\"\n        }\n    ]\n}\n\n\n5. Use the script-loader (no longer mantained) to globally import scripts\nIf you don't care about global variables and just want legacy scripts to work, you can also use the script-loader. It executes the module in a global context, just as if you had included them via the <script> tag.\n\n6. Use noParse to include large dists\nWhen there is no AMD/CommonJS version of the module and you want to include the dist, you can flag this module as noParse. Then webpack will just include the module without parsing it, which can be used to improve the build time. This means that any feature requiring the AST, like the ProvidePlugin, will not work.\nmodule: {\n    noParse: [\n        /[\\/\\\\]node_modules[\\/\\\\]angular[\\/\\\\]angular\\.js$/\n    ]\n}\n\n",
            "\nUse jQuery to get the width of the window. \nif ($(window).width() < 960) {\n   alert('Less than 960');\n}\nelse {\n   alert('More than 960');\n}\n\n"
        ],
        "answer": "A3",
        "tags": [
            "javascript",
            "jquery"
        ]
    },
    {
        "question_id": "32676771",
        "question": "\nI found the following Java code.\nfor (int type = 0; type < typeCount; type++)\n    synchronized(result) {\n        result[type] += parts[type];\n    }\n}\n\nwhere result and parts are double[].\nI know basic operations on primitive types are thread-safe, but I am not sure about +=. If the above synchronized is necessary, is there maybe a better class to handle such operation?\n",
        "all_answers": [
            "\nNo.  The += operation is not thread-safe.  It requires locking and / or a proper chain of \"happens-before\" relationships for any expression involving assignment to a shared field or array element to be thread-safe.\n(With a field declared as volatile, the \"happens-before\" relationships exist ... but only on read and write operations.  The += operation consists of a read and a write.  These are individually atomic, but the sequence isn't.  And most assignment expressions using = involve both one or more reads (on the right hand side) and a write.  That sequence is not atomic either.)\nFor the complete story, read JLS 17.4 ... or the relevant chapter of \"Java Concurrency in Action\" by Brian Goetz et al.\n\nAs I know basic operations on primitive types are thread-safe ...\n\nActually, that is an incorrect premise:\n\nconsider the case of arrays\nconsider that expressions are typically composed of a sequence of operations, and that a sequence of atomic operations is not guaranteed to be atomic.\n\n\nThere is an additional issue for the double type.  The JLS (17.7) says this:\n\n\"For the purposes of the Java programming language memory model, a single write to a non-volatile long or double value is treated as two separate writes: one to each 32-bit half. This can result in a situation where a thread sees the first 32 bits of a 64-bit value from one write, and the second 32 bits from another write.\"\n\"Writes and reads of volatile long and double values are always atomic.\"\n\n\nIn a comment, you asked:\n\nSo what type I should use to avoid global synchronization, which stops all threads inside this loop?\n\nIn this case (where you are updating a double[], there is no alternative to synchronization with locks or primitive mutexes.\nIf you had an int[] or a long[] you could replace them with AtomicIntegerArray or AtomicLongArray and make use of those classes' lock-free update.  However there is no AtomicDoubleArray class, or even an AtomicDouble class.\n(UPDATE - someone pointed out that Guava provides an AtomicDoubleArray class, so that would be an option.  A good one actually.)\nOne way of avoiding a \"global lock\" and massive contention problems might be to divide the array into notional regions, each with its own lock.  That way, one thread only needs to block another thread if they are using the same region of the array.  (Single writer / multiple reader locks could help too ... if the vast majority of accesses are reads.)\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nYou could use a CountDownLatch from the java.util.concurrent package. It is very useful when waiting for one or more threads to complete before continuing execution in the awaiting thread.\nFor example, waiting for three tasks to complete:\nCountDownLatch latch = new CountDownLatch(3);\n...\nlatch.await(); // Wait for countdown\n\nThe other thread(s) then each call latch.countDown() when complete with the their tasks. Once the countdown is complete, three in this example, the execution will continue.\n",
            "\nEven the normal 'double' data type is not thread-safe (because it is not atomic) in 32-bit JVMs as it takes eight bytes in Java (which involves 2*32 bit operations).\n"
        ],
        "answer": "A1",
        "tags": [
            "java",
            "multithreading"
        ]
    },
    {
        "question_id": "32203930",
        "question": "\nThis seems silly, but I haven't been able to get my values in the format of #/#### to write as the literal string rather than becoming formatted as a date within excel.\nI'm using ClosedXML to write to excel, and using the following:\n// snip\nIXLRangeRow tableRow = tableRowRange.Row(1);\ntableRow.Cell(1).DataType = XLCellValues.Text;\ntableRow.Cell(1).Value = \"2/1997\";\n// snip\n\nLooking at the output excel sheet I get in the cell 2/1/1997 - even though I'm setting the format as text in code, I'm getting it as a \"Date\" in the excel sheet - I checked this by right clicking the cell, format cell, seeing \"date\" as the format.\nIf I change things up to:\n// snip\nIXLRangeRow tableRow = tableRowRange.Row(1);\ntableRow.Cell(1).Value = \"2/1997\";\ntableRow.Cell(1).DataType = XLCellValues.Text;\n// snip\n\nI instead get 35462 as my output.  \nI just want my literal value of 2/1997 to be displayed on the worksheet.  Please advise on how to correct.\n",
        "all_answers": [
            "\nNot sure about from ClosedXML, but maybe try Range.NumberFormat (MSDN Link)\nFor example...\nRange(\"A1\").NumberFormat = \"@\"\n\nOr \nSelection.NumberFormat = \"#/####\"\n\n",
            "\nI've posted a proof-of-concept project to GitHub as the Excel-DNA IntelliSense project, implementing this.\nUsing the UI Automation classes to monitor the appropriate Excel user interface events, a form is displayed when appropriate.\nThe code is wrapped as an Excel-DNA add-in, and works on my Excel 2013 / Windows 8 machine. I've tested on one other configuration (64-bit Excel 2010 on Windows Server 2008) and had a serious problems.\nFor a C# function defined with the Excel-DNA attributes like this:\n[ExcelFunction(Description = \n    \"A useful test function that adds two numbers, and returns the sum.\")]\npublic static double AddThem(\n    [ExcelArgument(Name = \"Augend\", \n                   Description = \"is the first number, to which will be added\")] \n    double v1,\n    [ExcelArgument(Name = \"Addend\", \n                   Description = \"is the second number that will be added\")]     \n    double v2)\n{\n    return v1 + v2;\n}\n\nwe get both the function description\n\nand when selecting the function, we get argument help\n\nThat looks nice, but it's all still very flaky, only works on my machine and sometimes crashes Excel. It might be a start, though...\n\nUpdate 9 May 2014:\nI've made some progress figuring out how to make the argument help work under older Excel and Windows versions. However, it still needs quite a lot of work to get everything reliable. Anyone who would like to help with this should please contact me directly.\n\nUpdate 18 June 2016:\nExcel UDF IntelliSense support for both Excel-DNA add-ins and VBA functions is now being tested. See the Getting Started page on GitHub for instructions.\n",
            "\nConsider:\ntableRow.Cell(1).Value = \"'2/1997\";\n\nNote the single quote.\n",
            "\nHow about\n\nCapture inputting text on key press event of cell. like this\nCheck if the text matches with custom functions.\nIf matches, then show something like label or shape to pretend be a tooltip. like this\n\nIs this acceptable?\nIt is a little ugly but easier.\n",
            "\ntry this\nws.Cell(rowCounter, colCounter).SetValue<string>(Convert.ToString(fieldValue));\n\n"
        ],
        "answer": "A5",
        "tags": [
            "c#",
            "asp.net",
            "excel",
            "closedxml"
        ]
    },
    {
        "question_id": "5219175",
        "question": "\nI have an html input.\nThe input has padding: 5px 10px; I want it to be 100% of the parent div's width(which is fluid).\nHowever using width: 100%; causes the input to be 100% + 20px how can I get around this?\nExample\n",
        "all_answers": [
            "\nThere is .center-block class in Twitter Bootstrap 3 (Since v3.0.1), so use:\n<img src=\"...\" alt=\"...\" class=\"img-responsive center-block\" />\n\n",
            "\nMove the input box' padding to a wrapper element.\n<style>\ndiv.outer{ background: red; padding: 10px; }\ndiv.inner { border: 1px solid #888; padding: 5px 10px; background: white; }\ninput { width: 100%; border: none }\n</style>\n\n<div class=\"outer\">\n    <div class=\"inner\">\n       <input/>\n    </div>\n</div>\n\nSee example here: http://jsfiddle.net/L7wYD/1/\n",
            "\nUse padding in percentages too and remove from the width:\n\npadding: 5%;\nwidth: 90%;\n\n",
            "\nSimply put all the images thumbnails inside a row/col divs like this:\n<div class=\"row text-center\">\n <div class=\"col-12\">\n  # your images here...\n </div>\n</div>\n\nand everything will work fine!\n",
            "\nAdd only the class center-block to an image, this works with Bootstrap 4 as well:\n<img src=\"...\" alt=\"...\" class=\"center-block\" />\n\nNote: center-block works even when img-responsive is used\n",
            "\nIf you're using Bootstrap v3.0.1 or greater, you should use this solution instead. It doesn't override Bootstrap's styles with custom CSS, but instead uses a Bootstrap feature.\nMy original answer is shown below for posterity\n\nThis is a pleasantly easy fix. Because .img-responsive from Bootstrap already sets display: block, you can use margin: 0 auto to center the image:\n.product .img-responsive {\n    margin: 0 auto;\n}\n\n",
            "\nThis should center the image and make it responsive.\n<img src=\"...\" class=\"img-responsive\" style=\"margin:0 auto;\"/>\n\n",
            "\nI would suggest a more \"abstract\" classification. Add a new class \"img-center\" which can be used in combination with .img-responsive class:\n// Center responsive images\n.img-responsive.img-center {\n  margin: 0 auto;\n}\n\n",
            "\nYou can try some positioning tricks. You can put the input in a div with position: relative and a fixed height, then on the input have position: absolute; left: 0; right: 0;, and any padding you like.\nLive example\n",
            "\nJust use .text-center class if you're using Bootstrap 3.\n<div class=\"text-center\">\n    <img src=\"...\" alt=\"...\"/>\n</div>\n\nNote: This doesn't work with img-responsive\n",
            "\nbox-sizing: border-box is a quick, easy way to fix it:\nThis will work in all modern browsers, and IE8+.\nHere's a demo: http://jsfiddle.net/thirtydot/QkmSk/301/\n.content {\n    width: 100%;\n    box-sizing: border-box;\n}\n\nThe browser prefixed versions (-webkit-box-sizing, etc.) are not needed in modern browsers.\n"
        ],
        "answer": "A11",
        "tags": [
            "html",
            "css",
            "width",
            "fluid-layout"
        ]
    },
    {
        "question_id": "24853",
        "question": "\nIn C, what is the difference between using ++i and i++, and which should be used in the incrementation block of a for loop?\n",
        "all_answers": [
            "\nThe order of precedence for the 3 operators involved in your question is the following :\npost-increment ++ > dereference * > assignment +=\nYou can check this page for further details on the subject.\n\nWhen parsing an expression, an operator which is listed on some row will be bound tighter (as if by parentheses) to its arguments than any operator that is listed on a row further below it. For example, the expression *p++ is parsed as *(p++), and not as (*p)++.\n\nLong story short, in order to express this assignment *ptr+=1 using the post-increment operator you need to add parentheses to the dereference operator to give that operation precedence over ++ as in this (*ptr)++\n",
            "\n\n++i will increment the value of i, and then return the incremented value.\n i = 1;\n j = ++i;\n (i is 2, j is 2)\n\ni++ will increment the value of i, but return the original value that i held before being incremented.\n i = 1;\n j = i++;\n (i is 2, j is 1)\n\n\nFor a for loop, either works. ++i seems more common, perhaps because that is what is used in K&R.\nIn any case, follow the guideline \"prefer ++i over i++\" and you won't go wrong.\nThere's a couple of comments regarding the efficiency of ++i and i++. In any non-student-project compiler, there will be no performance difference.  You can verify this by looking at the generated code, which will be identical.\nThe efficiency question is interesting... here's my attempt at an answer:\nIs there a performance difference between i++ and ++i in C?\nAs @OnFreund notes, it's different for a C++ object, since operator++() is a function and the compiler can't know to optimize away the creation of a temporary object to hold the intermediate value.\n",
            "\nLet's apply parentheses to show the order of operations\na + b / c\na + (b/c)\n\nLet's do it again with\n*ptr   += 1\n(*ptr) += 1\n\nAnd again with\n*ptr++\n*(ptr++)\n\n\nIn *ptr += 1, we increment the value of the variable our pointer points to.\nIn *ptr++, we increment the pointer after our entire statement (line of code) is done, and return a reference to the variable our pointer points to.\n\nThe latter allows you to do things like:\nfor(int i = 0; i < length; i++)\n{\n    // Copy value from *src and store it in *dest\n    *dest++ = *src++;\n\n    // Keep in mind that the above is equivalent to\n    *(dest++) = *(src++);\n}\n\nThis is a common method used to copy a src array into another dest array.\n",
            "\n++i increments the value, then returns it.\ni++ returns the value, and then increments it.\nIt's a subtle difference.\nFor a for loop, use ++i, as it's slightly faster. i++ will create an extra copy that just gets thrown away.\n",
            "\nThe difference is due to operator precedence.\nThe post-increment operator ++ has higher precedence than the dereference operator *. So *ptr++ is equivalent to *(ptr++). In other words, the post increment modifies the pointer, not what it points to.\nThe assignment operator += has lower precedence than the dereference operator *, so *ptr+=1 is equivalent to (*ptr)+=1. In other words, the assignment operator modifies the value that the pointer points to, and does not change the pointer itself. \n"
        ],
        "answer": "A2",
        "tags": [
            "c",
            "for-loop",
            "post-increment",
            "pre-increment"
        ]
    },
    {
        "question_id": "574944",
        "question": "\nIs it possible to import css stylesheets into a html page using Javascript? If so, how can it be done?\nP.S the javascript will be hosted on my site, but I want users to be able to put in the <head> tag of their website, and it should be able to import a css file hosted on my server into the current web page. (both the css file and the javascript file will be hosted on my server).\n",
        "all_answers": [
            "\nYes. You can have a span within a span. Your problem stems from something else.\n",
            "\nHere's the \"old school\" way of doing it, which hopefully works across all browsers. In theory, you would use setAttribute unfortunately IE6 doesn't support it consistently.\nvar cssId = 'myCss';  // you could encode the css path itself to generate id..\nif (!document.getElementById(cssId))\n{\n    var head  = document.getElementsByTagName('head')[0];\n    var link  = document.createElement('link');\n    link.id   = cssId;\n    link.rel  = 'stylesheet';\n    link.type = 'text/css';\n    link.href = 'http://website.example/css/stylesheet.css';\n    link.media = 'all';\n    head.appendChild(link);\n}\n\nThis example checks if the CSS was already added so it adds it only once.\nPut that code into a JavaScript file, have the end-user simply include the JavaScript, and make sure the CSS path is absolute so it is loaded from your servers.\nVanillaJS\nHere is an example that uses plain JavaScript to inject a CSS link into the head element based on the filename portion of the URL:\n<script type=\"text/javascript\">\nvar file = location.pathname.split( \"/\" ).pop();\n\nvar link = document.createElement( \"link\" );\nlink.href = file.substr( 0, file.lastIndexOf( \".\" ) ) + \".css\";\nlink.type = \"text/css\";\nlink.rel = \"stylesheet\";\nlink.media = \"screen,print\";\n\ndocument.getElementsByTagName( \"head\" )[0].appendChild( link );\n</script>\n\nInsert the code just before the closing head tag and the CSS will be loaded before the page is rendered. Using an external JavaScript (.js) file will cause a Flash of unstyled content (FOUC) to appear.\n",
            "\nI guess something like this script would do:\n<script type=\"text/javascript\" src=\"/js/styles.js\"></script>\n\nThis JS file contains the following statement:\nif (!document.getElementById) document.write('<link rel=\"stylesheet\" type=\"text/css\" href=\"/css/versions4.css\">');\n\nThe address of the javascript and css would need to be absolute if they are to refer to your site.\nMany CSS import techniques are discussed in this \"Say no to CSS hacks with branching techniques\" article.\nBut the \"Using JavaScript to dynamically add Portlet CSS stylesheets\" article mentions also the CreateStyleSheet possibility (proprietary method for IE):\n<script type=\"text/javascript\">\n//<![CDATA[\nif(document.createStyleSheet) {\n  document.createStyleSheet('http://server/stylesheet.css');\n}\nelse {\n  var styles = \"@import url(' http://server/stylesheet.css ');\";\n  var newSS=document.createElement('link');\n  newSS.rel='stylesheet';\n  newSS.href='data:text/css,'+escape(styles);\n  document.getElementsByTagName(\"head\")[0].appendChild(newSS);\n}\n//]]>\n\n",
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n"
        ],
        "answer": "A2",
        "tags": [
            "javascript",
            "html",
            "css",
            "dhtml"
        ]
    },
    {
        "question_id": "9265274",
        "question": "\nI am trying to create and save a file to the root directory of my site, but I don't know where its creating the file as I cannot see any. And, I need the file to be overwritten every time, if possible.\nHere is my code:\n$content = \"some text here\";\n$fp = fopen(\"myText.txt\",\"wb\");\nfwrite($fp,$content);\nfclose($fp);\n\nHow can I set it to save on the root?\n",
        "all_answers": [
            "\nfopen() will open a resource in the same directory as the file executing the command.  In other words, if you're just running the file ~/test.php, your script will create ~/myText.txt.\nThis can get a little confusing if you're using any URL rewriting (such as in an MVC framework) as it will likely create the new file in whatever the directory contains the root index.php file.\nAlso, you must have correct permissions set and may want to test before writing to the file.  The following would help you debug:\n$fp = fopen(\"myText.txt\",\"wb\");\nif( $fp == false ){\n    //do debugging or logging here\n}else{\n    fwrite($fp,$content);\n    fclose($fp);\n}\n\n",
            "\nIt's creating the file in the same directory as your script.  Try this instead.\n$content = \"some text here\";\n$fp = fopen($_SERVER['DOCUMENT_ROOT'] . \"/myText.txt\",\"wb\");\nfwrite($fp,$content);\nfclose($fp);\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php"
        ]
    },
    {
        "question_id": "40694691",
        "question": "\nWhat is the advantage or difference of initializing:\nlazy var hintView: HintView = {\n        let hintView = HintView()\n        return hintView\n}()\n\nInstead of simply use:\nvar hintView = HintView()\n\n(HintView is: class HintView: UIView {})\nHelp is very appreciated.\n",
        "all_answers": [
            "\nIn certain cases, using lazy vars can be faster, because they are only calculated once, when you are accessing them for the first time.\n",
            "\nA lazy stored property is calculated only when it is accessed for the first time. \nIt is var and not let because, the value is not initialized during the initialization process. It is calculated later on. That's why a lazy stored  property need to be a variable and not a constant.\nlazy var hintView: HintView = {\n        let hintView = HintView()\n        return hintView\n}()\n\nlet h = hintView\n\nIn the above code, whenever, hintView is accessed for the first time, the closure assigned to it is executed and the value is returned and stored in h.\nFor more info refer to:\nSwift lazy stored property versus regular stored property when using closure \nhttps://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/Properties.html\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\nLazy Stored Property vs Stored Property\nThere are a few advantages in having a lazy property instead of a stored property.\n\nThe closure associated to the lazy property is executed only if you read that property. So if for some reason that property is not used (maybe because of some decision of the user) you avoid unnecessary allocation and computation.\nYou can populate a lazy property with the value of a stored property.\nYou can use self inside the closure of a lazy property\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n"
        ],
        "answer": "A4",
        "tags": [
            "swift"
        ]
    },
    {
        "question_id": "7848771",
        "question": "\nI am new to GDB, so I have some questions:\n\nHow can I look at content of the stack?\nExample: to see content of register, I type info registers. For the stack, what should it be?\nHow can I see the content of $0x4(%esp)? When I type print /d $0x4(%esp), GDB gives an error.\n\nPlatform: Linux and GDB\n",
        "all_answers": [
            "\ninfo frame to show the stack frame info\nTo read the memory at given addresses you should take a look at x\nx/x $esp for hex x/d $esp for signed x/u $esp for unsigned etc. x uses the format syntax, you could also take a look at the current instruction via x/i $eip etc.\n",
            "\nIf you are using separate assembly files, gas has a directive to support Intel syntax:\n.intel_syntax noprefix      # not recommended for inline asm\n\nwhich uses Intel syntax and doesn't need the % prefix before register names.\n(You can also run as with -msyntax=intel -mnaked-reg to have that as the default instead of att, in case you don't want to put .intel_syntax noprefix at the top of your files.)\n\nInline asm: compile with -masm=intel\nFor inline assembly, you can compile your C/C++ sources with gcc -masm=intel (See How to set gcc to use intel syntax permanently? for details.)  The compiler's own asm output (which the inline asm is inserted into) will use Intel syntax, and it will substitute operands into asm template strings using Intel syntax like [rdi + 8] instead of 8(%rdi).\nThis works with GCC itself and ICC, but for clang only clang 14 and later.\n(Not released yet, but the patch is in current trunk.)\n\nUsing .intel_syntax noprefix at the start of inline asm, and switching back with .att_syntax can work, but will break if you use any m constraints.  The memory reference will still be generated in AT&T syntax.  It happens to work for registers because GAS accepts %eax as a register name even in intel-noprefix mode.\nUsing .att_syntax at the end of an asm() statement will also break compilation with -masm=intel; in that case GCC's own asm after (and before) your template will be in Intel syntax.  (Clang doesn't have that \"problem\"; each asm template string is local, unlike GCC where the template string truly becomes part of the text file that GCC sends to as to be assembled separately.)\nRelated:\n\nGCC manual: asm dialect alternatives: writing an asm statement with {att | intel} in the template so it works when compiled with -masm=att or -masm=intel.  See an example using lock cmpxchg.\nhttps://stackoverflow.com/tags/inline-assembly/info for more about inline assembly in general; it's important to make sure you're accurately describing your asm to the compiler, so it knows what registers and memory are read / written.\nAT&T syntax: https://stackoverflow.com/tags/att/info\nIntel syntax: https://stackoverflow.com/tags/intel-syntax/info\nThe x86 tag wiki has links to manuals, optimization guides, and tutorials.\n\n",
            "\nYou need to use gdb's memory-display commands. The basic one is x, for examine. There's an example on the linked-to page that uses\ngdb> x/4xw $sp\n\nto print \"four words (w ) of memory above the stack pointer (here, $sp) in hexadecimal (x)\". The quotation is slightly paraphrased.\n"
        ],
        "answer": "A1",
        "tags": [
            "c",
            "assembly",
            "gdb"
        ]
    },
    {
        "question_id": "2763006",
        "question": "\nI have a repository in Git. I made a branch, then did some changes both to the master and to the branch.\nThen, tens of commits later, I realized the branch is in much better state than the master, so I want the branch to \"become\" the master and disregard the changes on master.\nI cannot merge it, because I don't want to keep the changes on master. What should I do?\nExtra: In this case, the 'old' master has already been push-ed to another repository such as GitHub. How does this change things?\n",
        "all_answers": [
            "\nThe solutions given here (renaming the branch in 'master') don't insist on the consequences for the remote (GitHub) repo:\n\nif you hadn't push anything since making that branch, you can rename it and push it without any problem.\nif you had push master on GitHub, you will need to 'git push -f' the new branch: you can no longer push in a fast forward mode.\n\n\n    -f\n    --force\n\n\nUsually, the command refuses to update a remote ref that is not an ancestor of the local ref used to overwrite it. This flag disables the check. This can cause the remote repository to lose commits; use it with care.\n\nIf others have already pulled your repo, they won't be able to pull that new master history without replacing their own master with that new GitHub master branch (or dealing with lots of merges).\nThere are alternatives to a git push --force for public repos.\nJefromi's answer (merging the right changes back to the original master) is one of them.\n",
            "\nRename the branch to master by:\ngit branch -M branch_name master\n\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nEdit: You didn't say you had pushed to a public repo! That makes a world of difference.\nThere are two ways, the \"dirty\" way and the \"clean\" way.  Suppose your branch is named new-master.  This is the clean way:\ngit checkout new-master\ngit branch -m master old-master\ngit branch -m new-master master\n# And don't do this part.  Just don't.  But if you want to...\n# git branch -d --force old-master\n\nThis will make the config files change to match the renamed branches.\nYou can also do it the dirty way, which won't update the config files.  This is kind of what goes on under the hood of the above...\nmv -i .git/refs/new-master .git/refs/master\ngit checkout master\n\n",
            "\nThe problem with the other two answers is that the new master doesn't have the old master as an ancestor, so when you push it, everyone else will get messed up. This is what you want to do:\ngit checkout better_branch\ngit merge --strategy=ours master    # keep the content of this branch, but record a merge\ngit checkout master\ngit merge better_branch             # fast-forward master up to the merge\n\nIf you want your history to be a little clearer, I'd recommend adding some information to the merge commit message to make it clear what you've done. Change the second line to:\ngit merge --strategy=ours --no-commit master\ngit commit          # add information to the template merge message\n\n"
        ],
        "answer": "A5",
        "tags": [
            "git"
        ]
    },
    {
        "question_id": "10825058",
        "question": "\nDoes RStudio support any automated roxygen template creation? \nIn Emacs-ESS, C-x C-o will produce an roxygen template for a function. For example, it will automagically convert this:\nfoo <- function(x,y) x+y\n\ninto this:\n##' .. content for \\description{} (no empty lines) ..\n##'\n##' .. content for \\details{} ..\n##' @title \n##' @param x \n##' @param y \n##' @return \n##' @author David\nfoo <- function(x,y) x+y\n\nDoes similar functionality exist within RStudio?\nupdates\n\nas of ESS 12.09-2, the command has been changed to C-c C-o C-o\nthis feature has been implemented in Rstudio: CTRL+ALT+SHIFT+R\n\n",
        "all_answers": [
            "\nYou could change the working directory. Get the address in the beginning getwd(), replace it by your project folder with setwd(). Then, when accessing a file just use read.table(\"./folder/file.R\"). \n",
            "\n(Converting @Crops comment into a full answer)\nIn RStudio v0.99 there is a new option under the \"Code\" menu for .R files: \"Insert Roxygen Skeleton\". There is an image of it in RStudio's blog post about v0.99 preview.\n\n",
            "\nThe silence that followed your question should tell you something...\nThe answer, currently, is NO is doesn't. I know of several people who use EMACS for precisely this reason, and would not consider switching to RStudio until that has full roxygen support.\nThat said, there has been some discussion about this between users and the makers of RStudio. Considering all the cool things that have been added to RStudio recently, I would not be surprised to see it happen. In fact, I think it is quite likely it will happen. But don't hold your breath for it, it may be a long wait...\n",
            "\nSo, pandoc does not parse the content of latex environments, but you can fool it by redefining the commands in your header.tex file:\n\\usepackage{lscape}\n\\newcommand{\\blandscape}{\\begin{landscape}}\n\\newcommand{\\elandscape}{\\end{landscape}}\n\nThus, here \\begin{landscape} is redefined to \\blandscape, and \\end{landscape} to \\elandscape. Using those newly defined command in the .Rmd file seems to work:\n---\ntitle: \"Mixing portrait and landscape\"\noutput:\n    pdf_document:\n        includes:\n            in_header: header.tex \n---\n\nPortrait\n```{r}\nsummary(cars)\n```\n\n\\newpage\n\\blandscape\nLandscape\n```{r}\nsummary(cars)\n```\n\\elandscape\n\n\\newpage\nMore portrait\n```{r}\nsummary(cars)\n```\n\n",
            "\nMy solution was to use a text expander (PhraseExpress in my case) to do this.\n",
            "\nThe so-called here package is really useful for avoiding absolute paths in (as well as outside of) RStudio. Suppose you have an RStudio project and want to access the file /data/file.txt. This would be done as follows. This way, you don't have to mess around with getwd(), just work relative to your project root using here().\nlibrary(here)\n#> here() starts at C:/test/someproject\nhere(\"data\", \"file.txt\")\n#> \"C:/test/someproject/data/file.txt\"\nreadLines(here(\"data\", \"file.txt\"))\n#> \"The here package is awesome!\"\n\nHow here figures out where your project root is is described in ?here and also in the \"Ode to the here package\" by Jenny Bryan.\n"
        ],
        "answer": "A2",
        "tags": [
            "r",
            "roxygen",
            "rstudio",
            "roxygen2"
        ]
    },
    {
        "question_id": "6500025",
        "question": "\nimage_path returns a path only (no host).\nThe url_for helper won't accept a single path, so something like url_for(image_path('image.png')) wouldn't work. While the internal url_for in ActionDispatch::Http::Url.url_for would appear to do the trick (source), there doesn't seem to be a public interface for it.\nHow should I go about doing it? Ultimately, it'd be nice to have a function like image_url that works like url_for does for routes so that I could call image_url('image.png') and get the absolute URL given all of the default_url_options.\n",
        "all_answers": [
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nI got a similar error.\nI did not modify assets.rb or anything, just restart my server and no error anymore.\n\nActionView::Template::Error (Asset was not declared to be precompiled in production.\nAdd Rails.application.config.assets.precompile += %w( rails.png ) to config/initializers/assets.rb and restart your server):\n    10:   <%= link_to \"Sign up now!\", '#', class: \"btn btn-lg btn-primary\" %>\n    11: \n    12: \n    13: <%= link_to image_tag(\"rails.png\", alt: \"Rails logo\"),\n    14:             'http://rubyonrails.org/' %>\n  app/views/static_pages/home.html.erb:13:in `_app_views_static_pages_home_html_erb___1806898863626708249_70312070486240'\n",
            "\nIt would appear that as of recently, sass-rails now interprets the image_url command within a scss file in the expected manner, resolving to the final location of the image in question.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nTry this in your application_helper.rb (from one of the comments on the page Spike listed):\ndef image_url(source)\n  \"#{root_url}#{image_path(source)}\"\nend\n\n"
        ],
        "answer": "A3",
        "tags": [
            "ruby-on-rails",
            "ruby-on-rails-3"
        ]
    },
    {
        "question_id": "9405180",
        "question": "\nCan I use the same lock object at two methods, accessed by two different threads? Goal is to make task1 and task2 thread safe.\nobject lockObject = new object();\n\n// Thread 1\nvoid Method1()\n{\n    lock(lockObject)\n    {\n        // task1\n    }\n}\n\n// Thread 2\nvoid Method2()\n{\n    lock(lockObject)\n    {\n        // task2\n    }\n}\n\n",
        "all_answers": [
            "\nBest practice is the second form. The reason is that another thread might null or alter SomeEvent between the 'if' test and the invocation.\n",
            "\nEvents are really syntactic sugar over a list of delegates. When you invoke the event, this is really iterating over that list and invoking each delegate with the parameters you have passed.\nThe problem with threads is that they could be adding or removing items from this collection by subscribing/unsubscribing. If they do this while you are iterating the collection this will cause problems (I think an exception is thrown)\nThe intent is to copy the list before iterating it, so you are protected against changes to the list. \nNote: It is however now possible for your listener to be invoked even after you unsubscribed, so you should make sure you handle this in your listener code. \n",
            "\nIMO, the other answers miss one key detail - that delegates (and therefore events) are immutable. The significance of this is that subscribing or unsubscribing an event handler doesn't simply append/remove to a list - rather, it replaces the list with a new one with an extra (or one less) item on it.\nSince references are atomic, this means that at the point you do:\nvar handler = SomeEvent;\n\nyou now have a rigid instance that cannot change, even if in the next picosecond another thread unsubscribes (causing the actual event field to become null).\nSo you test for null and invoke it, and all is well. Note of course that there is still the confusing scenario of the event being raised on an object that thinks it unsubscribed a picosecond ago!\n",
            "\nIf you want to prevent different threads from performing task1 and task2 at the same time, then you must use the same lock object.\nIf the two tasks do not contend for the same resources, you could use different lock objects.\n",
            "\nYes.\nYou can and it works. If you don't use the same object, the blocks could execute at the same time. If you do use the same object, they can't.\nAlso, you mean lock(lockObject), not using(lockObject).\n",
            "\nYes, you can use the same lock object (it's technically a monitor in the computer science sense, and is implemented with calls to methods in System.Monitor) in two different methods.\nSo, say that you had some static resource r, and you wanted two threads to access that resource, but only one thread can use it at a time (this is the classic goal of a lock).  Then you would write code like\npublic class Foo\n{\n    private static object _LOCK = new object();\n\n    public void Method1()\n    {\n        lock (_LOCK)\n        {\n            // Use resource r\n        }\n    }\n\n    public void Method2()\n    {\n        lock (_LOCK)\n        {\n            // Use resource r\n        }\n    }\n}\n\nYou need to lock around every use of r in your program, since otherwise two threads can use r at the same time.  Furthermore, you must use the same lock, since otherwise again two threads would be able to use r at the same time.  So, if you are using r in two different methods, you must use the same lock from both methods.\nEDIT: As @diev points out in the comments, if the resource were per-instance on objects of type Foo, we would not make _LOCK static, but would make _LOCK instance-level data.\n"
        ],
        "answer": "A6",
        "tags": [
            "c#",
            "multithreading",
            "locking"
        ]
    },
    {
        "question_id": "21548566",
        "question": "\nTo run powershell commands on a machine from a remote machine we have to add the remote machine to the trusted hosts list of the host machine.\nI am adding machine A to machine B's trusted hosts using the following command :\nwinrm set winrm/config/client ‘@{TrustedHosts=\"machineA\"}’\n\nHow to add more machines say machine C, machine D to trusted hosts list of machine B?\n",
        "all_answers": [
            "\nI prefer to work with the PSDrive WSMan:\\.\nGet TrustedHosts\nGet-Item WSMan:\\localhost\\Client\\TrustedHosts\n\nSet TrustedHosts\nprovide a single, comma-separated, string of computer names\nSet-Item WSMan:\\localhost\\Client\\TrustedHosts -Value 'machineA,machineB'\n\nor (dangerous) a wild-card\nSet-Item WSMan:\\localhost\\Client\\TrustedHosts -Value '*'\n\nto append to the list, the -Concatenate parameter can be used\nSet-Item WSMan:\\localhost\\Client\\TrustedHosts -Value 'machineC' -Concatenate\n\n",
            "\nCreate a PowerShell profile as follows. \n\nRun PowerShell as administrator and execute the following command:\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned\nThis will permit PowerShell to run local scripts and scripts downloaded from the Internet that have been signed. Read more about this command in the documentation.\nIn your Documents folder, find a folder named WindowsPowerShell for classic PowerShell or PowerShell for newer PowerShell Core. If it does not exist, that's ok; just create it.\nCreate a new file named profile.ps1 in the WindowsPowerShell folder (or PowerShell for PowerShell Core).\nOpen profile.ps1 and add the following command to set your default working directory:\nSet-Location C:\\my\\default\\working\\directory\n\nOpen a new PowerShell window... the changes should have taken effect.\n\n",
            "\nType this in PowerShell:\nNew-Item -path $profile -type file –force\n\nIt creates a .ps1 file in the PowerShell folder. Open it, and edit it as:\nSet-location C:\\files\n\nDone\nRefer to this link. It works fine.\nChange PowerShell Start Directory\n",
            "\nwinrm set winrm/config/client '@{TrustedHosts=\"machineA,machineB\"}'\n\n",
            "\nWrite-Output \"Set-Location C:\\\" >> $profile\n\n",
            "\nI had tried the above answers in Windows Server 2016 without success.\nBut I found this approach (it should be the same for Windows 10) working for me.\n\nStart a PowerShell session\nIn the Taskbar, right-click and pin to keep a link there\nAgain right click the icon in taskbar and then right-click Windows PowerShell and choose Properties\nEnter your preferred directory in the Start in: input field and press OK\nStart from the taskbar icon\n\nDone!\nIn the same Properties dialog you can also change many other settings like fonts, colors, sizes and on the Shortcut tab there via button Advanced. You can select if that PowerShell session is to be run with administrator privileges.\n",
            "\nYou could specify the directory to open when starting PowerShell:\npowershell.exe -NoExit -command \"& {Set-Location $env:systemroot}\"\n\nJust use it in your shortcut.\nOr use a profile to set a start directory.\n",
            "\nAn easier way to set the default directory is the following:\n\nRight click the Windows PowerShell icon and pin to Start\nRight click the Windows PowerShell icon in Start, and again right click Windows PowerShell and select Properties (not Run as Administrator and not Windows PowerShell ISE)\n\n\nIn the Shortcut tab -> 'Start in' field, change to the location you want PowerShell to start in.\n\n\n\n"
        ],
        "answer": "A1",
        "tags": [
            "windows",
            "powershell",
            "hosts",
            "winrm"
        ]
    },
    {
        "question_id": "9225567",
        "question": "\nC99 standard has integer types with bytes size like int64_t. I am using Windows's %I64d format currently (or unsigned %I64u), like:\n#include <stdio.h>\n#include <stdint.h>\nint64_t my_int = 999999999999999999;\nprintf(\"This is my_int: %I64d\\n\", my_int);\n\nand I get this compiler warning:\nwarning: format ‘%I64d’ expects type ‘int’, but argument 2 has type ‘int64_t’\n\nI tried with:\nprintf(\"This is my_int: %lld\\n\", my_int); // long long decimal\n\nBut I get the same warning. I am using this compiler:\n~/dev/c$ cc -v\nUsing built-in specs.\nTarget: i686-apple-darwin10\nConfigured with: /var/tmp/gcc/gcc-5664~89/src/configure --disable-checking --enable-werror --prefix=/usr --mandir=/share/man --enable-languages=c,objc,c++,obj-c++ --program-transform-name=/^[cg][^.-]*$/s/$/-4.2/ --with-slibdir=/usr/lib --build=i686-apple-darwin10 --program-prefix=i686-apple-darwin10- --host=x86_64-apple-darwin10 --target=i686-apple-darwin10 --with-gxx-include-dir=/include/c++/4.2.1\nThread model: posix\ngcc version 4.2.1 (Apple Inc. build 5664)\n\nWhich format should I use to print my_int variable without having a warning?\n",
        "all_answers": [
            "\nThe C99 way is\n#include <inttypes.h>\nint64_t my_int = 999999999999999999;\nprintf(\"%\" PRId64 \"\\n\", my_int);\n\nOr you could cast!\nprintf(\"%ld\", (long)my_int);\nprintf(\"%lld\", (long long)my_int); /* C89 didn't define `long long` */\nprintf(\"%f\", (double)my_int);\n\nIf you're stuck with a C89 implementation (notably Visual Studio) you can perhaps use an open source <inttypes.h> (and <stdint.h>): http://code.google.com/p/msinttypes/\n",
            "\nIn windows environment, use\n%I64d\n\nin Linux, use\n%lld\n\n",
            "\nFor int64_t type:\n#include <inttypes.h>\nint64_t t;\nprintf(\"%\" PRId64 \"\\n\", t);\n\nfor uint64_t type:\n#include <inttypes.h>\nuint64_t t;\nprintf(\"%\" PRIu64 \"\\n\", t);\n\nyou can also use PRIx64 to print in hexadecimal.\ncppreference.com has a full listing of available macros for all types including intptr_t (PRIxPTR).  There are separate macros for scanf, like SCNd64.\n\nA typical definition of PRIu16 would be \"hu\", so implicit string-constant concatenation happens at compile time.\nFor your code to be fully portable, you must use PRId32 and so on for printing int32_t, and \"%d\" or similar for printing int.\n",
            "\nFFCALL lets you build closures in C -- callback = alloc_callback(&function, data) returns a function pointer such that callback(arg1, ...) is equivalent to calling function(data, arg1, ...).  You will have to handle garbage collection manually, though.\nRelatedly, blocks have been added to Apple's fork of GCC; they're not function pointers, but they let you pass around lambdas while avoiding the need to build and free storage for captured variables by hand (effectively, some copying and reference counting happens, hidden behind some syntactic sugar and runtime libraries).\n"
        ],
        "answer": "A3",
        "tags": [
            "c",
            "stdint"
        ]
    },
    {
        "question_id": "9608547",
        "question": "\nWhen I try to generate an Excel file using EPPlus, Excel give me the following error message:\n\nExcel cannot open the file 'myfilename.xlsx' because the file format or file extension is not valid.  Verify the the file has not been corrupted and that the file extension matches the format of the file.\n\nHere's my code:\npublic ActionResult Index()\n{\n    using (ExcelPackage package = new ExcelPackage())\n    {\n        // I populate the worksheet here.  I'm 90% sure this is fine\n        // because the stream file size changes based on what I pass to it.\n\n        var stream = new MemoryStream();\n        package.SaveAs(stream);\n\n        string fileName = \"myfilename.xlsx\";\n        string contentType = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\";\n\n        var cd = new System.Net.Mime.ContentDisposition\n        {\n            Inline = false,\n            FileName = fileName\n        };\n        Response.AppendHeader(\"Content-Disposition\", cd.ToString());\n        return File(stream, contentType, fileName);\n    }\n}\n\nAny idea what I'm doing wrong?\n",
        "all_answers": [
            "\nYour code doesn't show stream being written to the HttpResponse - presumably being done in the File method which you haven't posted.\nOne way that does work is the following:\nResponse.Clear();\nResponse.ContentType = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\";\nResponse.AddHeader(\n            \"content-disposition\", String.Format(CultureInfo.InvariantCulture, \"attachment; filename={0}\", fileName));\nResponse.BinaryWrite(package.GetAsByteArray());\nResponse.End();\n\n",
            "\nAll you need to do is reset the stream position. stream.Position = 0;\nYou shouldn't write directly to the Response, it's not the MVC way. It doesn't follow the correct MVC pipeline and it tightly couples your controller action code to the Response object.\nWhen you add a file name as the 3rd parameter in File(), MVC automatically adds the correct Content-Disposition header... so you shouldn't need to add it manually.\nThe short of it is, this is what you want:\npublic ActionResult Index()\n{\n    using (ExcelPackage package = new ExcelPackage())\n    {\n        // I populate the worksheet here.  I'm 90% sure this is fine\n        // because the stream file size changes based on what I pass to it.\n\n        var stream = new MemoryStream();\n        package.SaveAs(stream);\n\n        string fileName = \"myfilename.xlsx\";\n        string contentType = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\";\n\n        stream.Position = 0;\n        return File(stream, contentType, fileName);\n    }\n}\n\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "asp.net-mvc",
            "excel",
            "epplus"
        ]
    },
    {
        "question_id": "25002017",
        "question": "\nI am trying to change the font of a UIButton using Swift...\nmyButton.font = UIFont(name: \"...\", 10)\n\nHowever .font is deprecated and I'm not sure how to change the font otherwise.\nAny suggestions?\n",
        "all_answers": [
            "\nFrom the documentation:\n\nThe font used to display text on the button. (Deprecated in iOS 3.0. Use the font property of the titleLabel instead.)\n\n",
            "\nIn swift5, use this\n   guard let instagram = URL(string: \"https://www.instagram.com/yourpagename\") else { return }\n   UIApplication.shared.open(instagram)\n\n",
            "\nTake a look at these links, it can help you:\nhttps://instagram.com/developer/mobile-sharing/iphone-hooks/\nhttp://wiki.akosma.com/IPhone_URL_Schemes\nOpen a facebook link by native Facebook app on iOS\nOtherwise, there is a quick example with Instagram for opening a specific profile (nickname: johndoe) here:\nvar instagramHooks = \"instagram://user?username=johndoe\"\nvar instagramUrl = NSURL(string: instagramHooks)\nif UIApplication.sharedApplication().canOpenURL(instagramUrl!) {  \n  UIApplication.sharedApplication().openURL(instagramUrl!)\n} else {\n  //redirect to safari because the user doesn't have Instagram\n  UIApplication.sharedApplication().openURL(NSURL(string: \"http://instagram.com/\")!)\n}\n\n",
            "\n\nUpdate for Swift 4 and iOS 10+\n\nOK, there are two easy steps to achieve this in Swift 3:\nFirst, you have to modify Info.plist to list instagram and facebook with LSApplicationQueriesSchemes. Simply open Info.plist as a Source Code, and paste this:\n<key>LSApplicationQueriesSchemes</key>\n<array>\n    <string>instagram</string>\n    <string>fb</string>\n</array>\n\nAfter that, you can open instagram and facebook apps by using instagram:// and fb://. Here is a complete code for instagram and you can do the same for facebook, you can link this code to any button you have as an Action:\n@IBAction func InstagramAction() {\n\n    let Username =  \"instagram\" // Your Instagram Username here\n    let appURL = URL(string: \"instagram://user?username=\\(Username)\")!\n    let application = UIApplication.shared\n\n    if application.canOpenURL(appURL) {\n        application.open(appURL)\n    } else {\n        // if Instagram app is not installed, open URL inside Safari\n        let webURL = URL(string: \"https://instagram.com/\\(Username)\")!\n        application.open(webURL)\n    }\n\n}\n\nFor facebook, you can use this code:\nlet appURL = URL(string: \"fb://profile/\\(Username)\")!\n\n",
            "\nTake a look here. \nYou should set the font of the button's titleLabel instead.\nmyButton.titleLabel!.font = UIFont(name: \"...\", 10)\n\n",
            "\nYou actually don't need to use a web and app URL anymore. The web URL will automatically open in the app if the user has it. Instagram or other apps implement this on their end as a Universal Link\nSwift 4\nfunc openInstagram(instagramHandle: String) {\n    guard let url = URL(string: \"https://instagram.com/\\(instagramHandle)\")  else { return }\n    if UIApplication.shared.canOpenURL(url) {\n        if #available(iOS 10.0, *) {\n            UIApplication.shared.open(url, options: [:], completionHandler: nil)\n        } else {\n            UIApplication.shared.openURL(url)\n        }\n    }\n}\n\n",
            "\nUse titleLabel instead. The font property is deprecated in iOS 3.0. It also does not work in Objective-C. titleLabel is label used for showing title on UIButton.\nmyButton.titleLabel?.font =  UIFont(name: YourfontName, size: 20)\n\nHowever, while setting title text you should only use setTitle:forControlState:. Do not use titleLabel to set any text for title directly.\n"
        ],
        "answer": "A7",
        "tags": [
            "ios",
            "uibutton",
            "swift",
            "uifont"
        ]
    },
    {
        "question_id": "8735792",
        "question": "\nthe github API sends the pagination data for the json results in the http link header:\nLink: <https://api.github.com/repos?page=3&per_page=100>; rel=\"next\",\n<https://api.github.com/repos?page=50&per_page=100>; rel=\"last\"\n\nsince the github API is not the only API using this method (i think) i wanted to ask if someone has a useful little snippet to parse the link header (and convert it to an array for example) so that i can use it for my js app.\ni googled around but found nothing useful regarding how to parse pagination from json APIs\n",
        "all_answers": [
            "\nThe parse-link-header NPM module exists for this purpose; its source can be found on github under a MIT license (free for commercial use).\nInstallation is as simple as:\nnpm install parse-link-header\n\nUsage looks like the following:\nvar parse = require('parse-link-header');\nvar parsed = parse('<https://api.github.com/repos?page=3&per_page=100>; rel=\"next\", <https://api.github.com/repos?page=50&per_page=100>; rel=\"last\"')\n\n...after which one has parsed.next, parsed.last, etc:\n{ next:\n   { page: '3',\n     per_page: '100',\n     rel: 'next',\n     url: 'https://api.github.com/repos?page=3&per_page=100' },\n  last:\n   { page: '50',\n     per_page: '100',\n     rel: 'last',\n     url: ' https://api.github.com/repos?page=50&per_page=100' } }\n\n",
            "\nI found this Gist that:\n\nParse Github Links header in JavaScript\n\nTested it out on the Github API and it returns an object like:\nvar results = {\n    last: \"https://api.github.com/repositories/123456/issues?access_token=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&state=open&since=2013-07-24T02%3A12%3A30.309Z&direction=asc&page=4\"\n    next: \"https://api.github.com/repositories/123456/issues?access_token=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&state=open&since=2013-07-24T02%3A12%3A30.309Z&direction=asc&page=2\"\n};\n\n",
            "\nI found wombleton/link-headers on github. It appears to be made for the browser, as opposed to being an npm module, but it seems like it wouldn't be hard to modify it to work in a server-side environment. It uses pegjs to generate a real RFC 5988 parser rather than string splits, so it should work well for any link header, rather than just Github's.\n",
            "\nIt's not an array.\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson.coolness = 34.33;\n\nor\nvar json = {\"cool\":\"34.33\",\"alsocool\":\"45454\"};\njson['coolness'] = 34.33;\n\nyou could do it as an array, but it would be a different syntax (and this is almost certainly not what you want)\nvar json = [{\"cool\":\"34.33\"},{\"alsocool\":\"45454\"}];\njson.push({\"coolness\":\"34.33\"});\n\nNote that this variable name is highly misleading, as there is no JSON here. I would name it something else.\n",
            "\nThere is a PageLinks class in the GitHub Java API that shows how to parse the Link header.\n"
        ],
        "answer": "A1",
        "tags": [
            "javascript",
            "json",
            "github",
            "jsonp",
            "github-api"
        ]
    },
    {
        "question_id": "819263",
        "question": "\nI'd like to get a person's age from its birthday. now - birthday / 365 doesn't work, because some years have 366 days. I came up with the following code:\nnow = Date.today\nyear = now.year - birth_date.year\n\nif (date+year.year) > now\n  year = year - 1\nend\n\nIs there a more Ruby'ish way to calculate age?\n",
        "all_answers": [
            "\nUse this: \ndef age\n  now = Time.now.utc.to_date\n  now.year - birthday.year - (birthday.to_date.change(:year => now.year) > now ? 1 : 0)\nend\n\n",
            "\nI know I'm late to the party here, but the accepted answer will break horribly when trying to work out the age of someone born on the 29th February on a leap year. This is because the call to birthday.to_date.change(:year => now.year) creates an invalid date.\nI used the following code instead:\nrequire 'date'\n\ndef age(dob)\n  now = Time.now.utc.to_date\n  now.year - dob.year - ((now.month > dob.month || (now.month == dob.month && now.day >= dob.day)) ? 0 : 1)\nend\n\n",
            "\nThe answers so far are kinda weird.  Your original attempt was pretty close to the right way to do this:\nbirthday = DateTime.new(1900, 1, 1)\nage = (DateTime.now - birthday) / 365.25 # or (1.year / 1.day)\n\nYou will get a fractional result, so feel free to convert the result to an integer with to_i.  This is a better solution because it correctly treats the date difference as a time period measured in days (or seconds in the case of the related Time class) since the event.  Then a simple division by the number of days in a year gives you the age.  When calculating age in years this way, as long as you retain the original DOB value, no allowance needs to be made for leap years.\n",
            "\nThe following seems to work (but I'd appreciate it if it was checked).\nage = now.year - bday.year\nage -= 1 if now.to_a[7] < bday.to_a[7]\n\n",
            "\nI've found this solution to work well and be readable for other people:\n    age = Date.today.year - birthday.year\n    age -= 1 if Date.today < birthday + age.years #for days before birthday\n\nEasy and you don't need to worry about handling leap year and such.\n"
        ],
        "answer": "A2",
        "tags": [
            "ruby-on-rails",
            "ruby"
        ]
    },
    {
        "question_id": "13411544",
        "question": "\nTo delete a column in a DataFrame, I can successfully use:\ndel df['column_name']\n\nBut why can't I use the following?\ndel df.column_name\n\nSince it is possible to access the Series via df.column_name, I expected this to work.\n",
        "all_answers": [
            "\nAs you've guessed, the right syntax is \ndel df['column_name']\n\nIt's difficult to make del df.column_name work simply as the result of syntactic limitations in Python. del df[name] gets translated to df.__delitem__(name) under the covers by Python.\n",
            "\nI'm not entirely sure what you want, and your last line of code does not help either, but anyway:\n\"Chained\" filtering is done by \"chaining\" the criteria in the boolean index.\nIn [96]: df\nOut[96]:\n   A  B  C  D\na  1  4  9  1\nb  4  5  0  2\nc  5  5  1  0\nd  1  3  9  6\n\nIn [99]: df[(df.A == 1) & (df.D == 6)]\nOut[99]:\n   A  B  C  D\nd  1  3  9  6\n\nIf you want to chain methods, you can add your own mask method and use that one.\nIn [90]: def mask(df, key, value):\n   ....:     return df[df[key] == value]\n   ....:\n\nIn [92]: pandas.DataFrame.mask = mask\n\nIn [93]: df = pandas.DataFrame(np.random.randint(0, 10, (4,4)), index=list('abcd'), columns=list('ABCD'))\n\nIn [95]: df.ix['d','A'] = df.ix['a', 'A']\n\nIn [96]: df\nOut[96]:\n   A  B  C  D\na  1  4  9  1\nb  4  5  0  2\nc  5  5  1  0\nd  1  3  9  6\n\nIn [97]: df.mask('A', 1)\nOut[97]:\n   A  B  C  D\na  1  4  9  1\nd  1  3  9  6\n\nIn [98]: df.mask('A', 1).mask('D', 6)\nOut[98]:\n   A  B  C  D\nd  1  3  9  6\n\n",
            "\nIt's good practice to always use the [] notation. One reason is that attribute notation (df.column_name) does not work for numbered indices:\nIn [1]: df = DataFrame([[1, 2, 3], [4, 5, 6]])\n\nIn [2]: df[1]\nOut[2]:\n0    2\n1    5\nName: 1\n\nIn [3]: df.1\n  File \"<ipython-input-3-e4803c0d1066>\", line 1\n    df.1\n       ^\nSyntaxError: invalid syntax\n\n",
            "\nFilters can be chained using a Pandas query:\ndf = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\ndf_filtered = df.query('a > 0').query('0 < b < 2')\n\nFilters can also be combined in a single query:\ndf_filtered = df.query('a > 0 and 0 < b < 2')\n\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "pandas",
            "dataframe"
        ]
    },
    {
        "question_id": "32552450",
        "question": "\nHow to specify a separate file for logging INFO in Laravel 5.1?\n",
        "all_answers": [
            "\nAs mentioned above  if you wish to add as a new element your queried collection you can use:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n        $product = DB::select(DB::raw(' select * from product\n               where product_id = '. $id.';' ));\n\n        $items->push($product);\n        // or \n        // $items->put('products', $product);\n    }\n\nbut if you wish to add new element to each queried element you need to do like:\n    $items = DB::select(DB::raw('SELECT * FROM items WHERE items.id = '.$id.'  ;'));\n    foreach($items as $item){\n           $product = DB::select(DB::raw(' select * from product\n                 where product_id = '. $id.';' ));\n    \n          $item->add_whatever_element_you_want = $product;\n    }\n\nadd_whatever_element_you_want can be whatever you wish that your element is named (like product for example).\n",
            "\nIf you want to add item to the beginning of the collection you can use prepend:\n$item->prepend($product, 'key');\n\n",
            "\nI have solved this if you are using array called for 2 tables. Example you have,\n$tableA['yellow'] and $tableA['blue'] . You are getting these 2 values and you want to add another element inside them to separate them by their type.\nforeach ($tableA['yellow'] as $value) {\n    $value->type = 'YELLOW';  //you are adding new element named 'type'\n}\n\nforeach ($tableA['blue'] as $value) {\n    $value->type = 'BLUE';  //you are adding new element named 'type'\n}\n\nSo, both of the tables value will have new element called type.\n",
            "\nIf you want to add a product into the array you can use:\n$item['product'] = $product;\n\n",
            "\nIt looks like you have everything correct according to Laravel docs, but you have a typo\n$item->push($product);\n\nShould be\n$items->push($product);\n\npush method appends an item to the end of the collection:\nI also want to think the actual method you're looking for is put\n$items->put('products', $product);\n\nput method sets the given key and value in the collection\n",
            "\nIf you would like add another monolog handler, you may use the application's configureMonologUsing method. \nPlace a call to this method in bootstrap/app.php file right before the $app variable is returned:\n$app->configureMonologUsing(function($monolog) {\n    $monolog->pushHandler(new StreamHandler('path/to/info.log', Logger::INFO, false)); // false value as third argument to disable bubbling up the stack\n});\n\nreturn $app;\n\n",
            "\nDo you want to specifically log info to one log file and another log type to another location? My solution might not help in that case, but could still be useful.\nTo write a log file to another location, use the method useDailyFiles or useFiles, and then info to log to the log file at the path you just specified. Like so:\n    Log::useDailyFiles(storage_path().'/logs/name-of-log.log');\n    Log::info([info to log]);\n\nThe first parameter for both methods is the path of the log file (which is created if it doesn't already exist) and for useDailyFiles the second argument is the number of days Laravel will log for before erasing old logs. The default value is unlimited, so in my example I haven't entered a value.\n"
        ],
        "answer": "A7",
        "tags": [
            "php",
            "laravel",
            "laravel-5",
            "monolog"
        ]
    },
    {
        "question_id": "852414",
        "question": "\nFrom an example you can see a multiple OR query filter:\nArticle.objects.filter(Q(pk=1) | Q(pk=2) | Q(pk=3))\n\nFor example, this results in:\n[<Article: Hello>, <Article: Goodbye>, <Article: Hello and goodbye>]\n\nHowever, I want to create this query filter from a list. How to do that?\ne.g. [1, 2, 3] -> Article.objects.filter(Q(pk=1) | Q(pk=2) | Q(pk=3))\n",
        "all_answers": [
            "\nI've done this way:\nfrom django import template\nregister = template.Library()\n\ndef do_test_request(parser,token):\n    try:\n        tag_name = token.split_contents() # Not really useful\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])\n    return RequestTestNode()\n\nclass RequestTestNode(template.Node):\n    def __init__(self,):\n        self.request = template.Variable('request')\n    def render(self, context):\n        rqst = self.request.resolve(context)\n        return \"The URL is: %s\" % rqst.get_full_path()\n\nregister.tag('test_request', do_test_request)\n\nThere is also a function called resolve_variable, but it's deprecated.\nHope it helps!\n",
            "\nSee the docs:\n>>> Blog.objects.in_bulk([1])\n{1: <Blog: Beatles Blog>}\n>>> Blog.objects.in_bulk([1, 2])\n{1: <Blog: Beatles Blog>, 2: <Blog: Cheddar Talk>}\n>>> Blog.objects.in_bulk([])\n{}\n\nNote that this method only works for primary key lookups, but that seems to be what you're trying to do.\nSo what you want is:\nArticle.objects.in_bulk([1, 2, 3])\n\n",
            "\nrequest is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.\nLike this:\n@register.inclusion_tag('new/userinfo.html', takes_context=True)\ndef address(context):\n    request = context['request']\n    address = request.session['address']\n    return {'address':address}\n\n",
            "\nThe error log is straightforward. As it suggested,You need to add 198.211.99.20  to your ALLOWED_HOSTS setting.\nIn your project settings.py file,set ALLOWED_HOSTS like this :\nALLOWED_HOSTS = ['198.211.99.20', 'localhost', '127.0.0.1']\n\nFor further reading\nread from here.\n",
            "\nYou can use the |= operator to programmatically update a query using Q objects.\n",
            "\nYou could chain your queries as follows:\nvalues = [1,2,3]\n\n# Turn list of values into list of Q objects\nqueries = [Q(pk=value) for value in values]\n\n# Take one Q object from the list\nquery = queries.pop()\n\n# Or the Q object with the ones remaining in the list\nfor item in queries:\n    query |= item\n\n# Query the model\nArticle.objects.filter(query)\n\n",
            "\nMaybe it's better to use sql IN statement.\nArticle.objects.filter(id__in=[1, 2, 3])\n\nSee queryset api reference.\nIf you really need to make queries with dynamic logic, you can do something like this (ugly + not tested):\nquery = Q(field=1)\nfor cond in (2, 3):\n    query = query | Q(field=cond)\nArticle.objects.filter(query)\n\n",
            "\nI've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.\nSo in main view method you should add the following line:\nfrom django.template import RequestContext        \nreturn render_to_response('index.html', {'form': form, }, \n                              context_instance = RequestContext(request))\n\n"
        ],
        "answer": "A6",
        "tags": [
            "python",
            "django",
            "django-q"
        ]
    },
    {
        "question_id": "6382354",
        "question": "\nI'm beginning the planning phase of creating a testing suite for my rails 3.0.8 application. I'm trying to decide on which testing framework/gems to use. Normally I prefer to stick to Rails convention as much as possible. However, this means using TestUnit. There are many competing test frameworks to choose from that were created as an alternative to TestUnit. Has TestUnit gotten better over the years, or is it not a very good contender? \nI've also heard of a lot of good things about rspec. Are rspec and TestUnit close in terms of functionality, or does rspec blow TestUnit out of the water?\nWhatever framework I choose, I'd prefer it to have a good support base(lots of users and documentation), ease of use/simplicity, and a lasting future.\n",
        "all_answers": [
            "\nThe answer is matter of taste, use both in one project and find yourself what do you prefer. (I do Test::Unit, RSpec has to much sugar for me).\nUpdate 2014: As Ruby 2.x has MiniTest built-in I would suggest to check MiniTest::Spec eventually which is simple BDD extension. You can mix \"describe\" and \"it\" blocks to nicely structure test contexts with. It also provides \"must_be..\" matchers if you want to more than assert.\n",
            "\nLong Answer + Explanation\nI think the correct fix is to add the file to the precompiled assets, as recommended by the error message. Maybe that isn't fixing the issue for you because you've got an erb file that needs to be rendered at run time. I imagine if the file was a static json file then you would not still experience the issue after adding it to the precompiled assets.\nWhen you use the image_path helper, Sprockets is assuming that you've got a static asset. The fact that your app didn't raise errors before sprockets-rails 3.0 is somewhat surprising. This new version is doing a better job, apparently, at enforcing the standards. (it also looks like there are other problems with 3.0 that might be updated shortly)\nIf you need to have erb inside the manifest, then it would be best practice to use a route path helper rather than image_path or asset_path to get the url. This would require you to add a manifest route to your config/routes.rb file and render the json file through a controller action. The view file would be your .erb manifest.\n\nShort Answer\nThis started happening to me after doing a bundler update that changed my sprockets-rails version from 2.3.3 to 3.0.0. A simple fix is to revert sprockets-rails back to version 2.3.3 in your Gemfile and running bundle install again:\ngem 'sprockets-rails', '2.3.3'\nAs an aside: I was experiencing this issue in development environment and was able to fix it there by running rake assets:precompile. Unfortunately, it didn't get my tests passing.\n",
            "\nThough people have given long answers I suggest very simple and concise answer\nJust go to \n\nconfig/initializers/assets.rb\n  and\n\nAdd the following line\n\nRails.application.config.assets.precompile += %w( style.css )\n\nwhere style.css can be replaced by your any file name for css\n",
            "\nBoth Test::Unit and Rspec are very nice solutions. As for me I prefer to use RSpec in my Rails project - because it has many automatic solutions like autotest, highlighting syntax, shortcut commands like rake spec and other stuff that make using test easer. But in my plain ruby scripts I use Test::Unit - it is very lightweight and staightforward when you don't need complex testing (integrational and others)\n"
        ],
        "answer": "A4",
        "tags": [
            "ruby-on-rails",
            "ruby",
            "ruby-on-rails-3",
            "testing",
            "testunit"
        ]
    },
    {
        "question_id": "1361741",
        "question": "\nI want to get the characters after the last / in an url like http://www.vimeo.com/1234567\nHow do I do with php?\n",
        "all_answers": [
            "\nYou could explode based on \"/\", and return the last entry:\nprint end( explode( \"/\", \"http://www.vimeo.com/1234567\" ) );\n\nThat's based on blowing the string apart, something that isn't necessary if you know the pattern of the string itself will not soon be changing. You could, alternatively, use a regular expression to locate that value at the end of the string:\n$url = \"http://www.vimeo.com/1234567\";\n\nif ( preg_match( \"/\\d+$/\", $url, $matches ) ) {\n    print $matches[0];\n}\n\n",
            "\nVery simply:\n$id = substr($url, strrpos($url, '/') + 1);\n\nstrrpos gets the position of the last occurrence of the slash; substr returns everything after that position.\n\nAs mentioned by redanimalwar if there is no slash this doesn't work correctly since strrpos returns false. Here's a more robust version:\n$pos = strrpos($url, '/');\n$id = $pos === false ? $url : substr($url, $pos + 1);\n\n"
        ],
        "answer": "A2",
        "tags": [
            "php",
            "string"
        ]
    },
    {
        "question_id": "10523849",
        "question": "\nI am trying to rename a file to have different capitalization from what it had before:\ngit mv src/collision/b2AABB.js src/collision/B2AABB.js\nfatal: destination exists, source=src/collision/b2AABB.js, destination=src/collision/B2AABB.js\n\nAs you can see, Git throws a fit over this. I tried renaming using just the plain old mv command as well, but Git doesn't pick up the rename (as a rename or as a new untracked file).\nHow can I change a file to have a different capitalization of the same name? I am on Mac OS X v10.7.3 (Lion) with Git 1.7.9.1 using Z shell (zsh) 4.3.15.\n",
        "all_answers": [
            "\nSometimes you want to change the capitalization of a lot of file names on a case insensitive filesystem (e.g. on macOS or Windows). Doing individual git mv commands will tire quickly. To make things a bit easier this is what I do:\n\nMove all affected files outside of the directory to, let’s say, the desktop.\nDo a git add . -A to stage the removal of those files.\nRename all files on the desktop to the proper capitalization.\nMove all the files back to the original directory.\nDo a git add .. Git should see that the files are renamed.\n\nNow you can make a commit saying you have changed the file name capitalization.\n",
            "\nStarting Git 2.0.1 (June 25th, 2014), a git mv will just work on a case-insensitive OS.\nSee commit baa37bf by David Turner (dturner-tw).\nmv: allow renaming to fix case on case-insensitive filesystems\n\"git mv hello.txt Hello.txt\" on a case-insensitive filesystem always triggers \"destination already exists\" error, because these two names refer to the same path from the filesystem's point of view and requires the user to give \"--force\" when correcting the case of the path recorded in the index and in the next commit.\n\nDetect this case and allow it without requiring \"--force\".\n\ngit mv hello.txt Hello.txt just works (no --force required anymore).\n\nThe other alternative is:\ngit config --global core.ignorecase false\n\nAnd rename the file directly; git add and commit.\nIt does work in a CMD. It might fail in a git bash (on Windows) session (see Louis-Caron's answer)\nAs noted by jaquinocode in the comments, if your local repository itself has that setting:\ngit config --local core.ignorecase false\n\n",
            "\nConsidering larsks' answer, you can get it working with a single command with --force:\ngit mv --force myfile MyFile\n\n",
            "\nFile names under OS X are not case sensitive (by default). This is more of an OS problem than a Git problem. If you remove and readd the file, you should get what you want, or rename it to something else and then rename it back.\n"
        ],
        "answer": "A2",
        "tags": [
            "git",
            "rename",
            "case-sensitive",
            "file-rename"
        ]
    },
    {
        "question_id": "19121448",
        "question": "\nSay you have an in-memory list of strings, and a multi-threaded system, with many readers but just one writer thread.\nIn general, is it possible to implement this kind of system in C#, without using a lock? Would  the implementation make any assumptions about how the threads interact (or place restrictions on what they can do, when)?\n",
        "all_answers": [
            "\nTo avoid locks, you might want to consider Microsoft's concurrent collections. These collections provide thread safe access to collections of objects in both ordered and unordered forms. They use some neat tricks to avoid locking internally in as many instances as possible.\n",
            "\nYes. The trick is to make sure the list remains immutable. The writer will snapshot the main collection, modify the snapshot, and then publish the snapshot to the variable holding the reference to the main collection. The following example demonstrates this.\npublic class Example\n{\n  // This is the immutable master collection.\n  volatile List<string> collection = new List<string>();\n\n  void Writer()\n  {\n    var copy = new List<string>(collection); // Snapshot the collection.\n    copy.Add(\"hello world\"); // Modify the snapshot.\n    collection = copy; // Publish the snapshot.\n  }\n\n  void Reader()\n  {\n    List<string> local = collection; // Acquire a local reference for safe reading.\n    if (local.Count > 0)\n    {\n      DoSomething(local[0]);\n    }\n  }\n}\n\nThere are a couple of caveats with this approach.\n\nIt only works because there is a single writer.\nWrites are O(n) operations.\nDifferent readers may be using different version of the list simultaneously.\nThis is a fairly dangerous trick. There are very specific reasons why volatile was used, why a local reference is acquired on the reader side, etc. If you do not understand these reasons then do not use the pattern. There is too much that can go wrong.\nThe notion that this is thread-safe is semantic. No, it will not throw exceptions, blow up, or tear a whole in spacetime. But, there are other ways in which this pattern can cause problems. Know what the limitations are. This is not a miracle cure for every situation.\n\nBecause of the above constraints the scenarios where this would benefit you are quite limited. The biggest problem is that writes require a full copy first so they may be slow. But, if the writes are infrequent then this might be tolerable.\nI describe more patterns in my answer here as well including one that is safe for multiple writers.\n",
            "\nThread has a method that does that for you join which will block until the thread has finished executing.\n",
            "\nThat is a fairly common request for a threading library to fulfill - that sort of lock is generally just called a \"reader-writer lock\", or some variation on that theme. I haven't ever needed to use the C# implementation specifically, but there is one: http://msdn.microsoft.com/en-us/library/system.threading.readerwriterlockslim.aspx\nOf course, you run into the issue that if readers will always be reading, you'll never be able to get the writer in to write. You'll have to handle that yourself, I believe. \n(Ok, so it's still technically a \"lock\", but it's not the C# \"lock\" construct, it's a more sophisticated object specifically designed for the purpose stated in the question. So I guess whether it's a correct answer depends somewhat on semantics and on why he was asking the question.)\n"
        ],
        "answer": "A2",
        "tags": [
            "c#",
            "multithreading"
        ]
    },
    {
        "question_id": "3856435",
        "question": "\nI know I can issue an alter table individually to change the table storage from MyISAM to InnoDB.\nI am wondering if there is a way to quickly change all of them to InnoDB?\n",
        "all_answers": [
            "\nYou need to use HAVING, not WHERE.\nThe difference is: the WHERE clause filters which rows MySQL selects. Then MySQL groups the rows together and aggregates the numbers for your COUNT function.\nHAVING is like WHERE, only it happens after the COUNT value has been computed, so it'll work as you expect. Rewrite your subquery as:\n(                  -- where that pid is in the set:\nSELECT c2.pid                  -- of pids\nFROM Catalog AS c2             -- from catalog\nWHERE c2.pid = c1.pid\nHAVING COUNT(c2.sid) >= 2)\n\n",
            "\nThe classic way would be to add commas to the left and right:\nselect * from shirts where CONCAT(',', colors, ',') like '%,1,%'\n\nBut find_in_set also works:\nselect * from shirts where find_in_set('1',colors) <> 0\n\n",
            "\nFIND_IN_SET is your friend in this case\nselect * from shirts where FIND_IN_SET(1,colors) \n\n",
            "\nIf you don't have an aggregate function in your where clause, another possible source of the 1111 - Invalid use of group function error is if you have nested aggregate functions:\nselect sum(avg(close)) from prices;\n(1111, 'Invalid use of group function')\n\nYou can get around this by breaking up the problem into two steps:\n\nSave the inner aggregation into a variable\n\nselect @avg:=avg(close) from prices;\n\n\nRun the outer aggregation against the variable\n\nselect sum(@avg) from prices;\n\n",
            "\nThis is actually how your query works and is a normal behaviour. Using LIMIT you will not limit the count or sum but only the returned rows. So your query will return n rows as stated in your LIMIT clause. And since your query actually returns only one row, applying a (non-zero) limit has no effect on the results.\nHowever, your second query will work as expected and is an established way of solving this problem.\n",
            "\n<?php\n    // connect your database here first \n    // \n\n    // Actual code starts here \n\n    $sql = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES\n        WHERE TABLE_SCHEMA = 'your_database_name' \n        AND ENGINE = 'MyISAM'\";\n\n    $rs = mysql_query($sql);\n\n    while($row = mysql_fetch_array($rs))\n    {\n        $tbl = $row[0];\n        $sql = \"ALTER TABLE `$tbl` ENGINE=INNODB\";\n        mysql_query($sql);\n    }\n?>\n\n",
            "\nTake a look at the FIND_IN_SET function for MySQL.\nSELECT * \n    FROM shirts \n    WHERE FIND_IN_SET('1',colors) > 0\n\n",
            "\nFirst, the error you're getting is due to where you're using the COUNT function -- you can't use an aggregate (or group) function in the WHERE clause.\nSecond, instead of using a subquery, simply join the table to itself:\nSELECT a.pid \nFROM Catalog as a LEFT JOIN Catalog as b USING( pid )\nWHERE a.sid != b.sid\nGROUP BY a.pid\n\nWhich I believe should return only rows where at least two rows exist with the same pid but there is are at least 2 sids.  To make sure you get back only one row per pid I've applied a grouping clause.\n",
            "\nYou could write a script to do it in your favourite scripting language. The script would do the following:\nIssue SHOW FULL TABLES.For each row returned, check that the second column says 'BASE TABLE' and not 'VIEW'.If it is not 'VIEW', issue the appropriate ALTER TABLE command.\n"
        ],
        "answer": "A6",
        "tags": [
            "mysql",
            "sql",
            "innodb"
        ]
    },
    {
        "question_id": "283645",
        "question": "\n\n\n\nI have a Python list, say\nl = [1,5,8]\n\nI want to write a SQL query to get the data for all the elements of the list, say\nselect name from students where id = |IN THE LIST l|\n\nHow do I accomplish this?\n",
        "all_answers": [
            "\nstring.join the list values separated by commas, and use the format operator to form a query string.\nmyquery = \"select name from studens where id in (%s)\" % \",\".join(map(str,mylist))\n\n(Thanks, blair-conrad)\n",
            "\nThe SQL you want is\nselect name from studens where id in (1, 5, 8)\n\nIf you want to construct this from the python you could use\nl = [1, 5, 8]\nsql_query = 'select name from studens where id in (' + ','.join(map(str, l)) + ')'\n\nThe map function will transform the list into a list of strings that can be glued together by commas using the str.join method.\nAlternatively:\nl = [1, 5, 8]\nsql_query = 'select name from studens where id in (' + ','.join((str(n) for n in l)) + ')'\n\nif you prefer generator expressions to the map function.\nUPDATE: S. Lott mentions in the comments that the Python SQLite bindings don't support sequences. In that case, you might want\nselect name from studens where id = 1 or id = 5 or id = 8\n\nGenerated by \nsql_query = 'select name from studens where ' + ' or '.join(('id = ' + str(n) for n in l))\n\n",
            "\nYou are dropping it, then creating it, then trying to create it again by using SELECT INTO.  Change to:\nDROP TABLE #TMPGUARDIAN\nCREATE TABLE #TMPGUARDIAN(\nLAST_NAME NVARCHAR(30),\nFRST_NAME NVARCHAR(30))  \n\nINSERT INTO #TMPGUARDIAN \nSELECT LAST_NAME,FRST_NAME  \nFROM TBL_PEOPLE\n\nIn MS SQL Server you can create a table without a CREATE TABLE statement by using SELECT INTO\n",
            "\nAnswers so far have been templating the values into a plain SQL string. That's absolutely fine for integers, but if we wanted to do it for strings we get the escaping issue.\nHere's a variant using a parameterised query that would work for both:\nplaceholder= '?' # For SQLite. See DBAPI paramstyle.\nplaceholders= ', '.join(placeholder for unused in l)\nquery= 'SELECT name FROM students WHERE id IN (%s)' % placeholders\ncursor.execute(query, l)\n\n"
        ],
        "answer": "A4",
        "tags": [
            "python",
            "sql"
        ]
    },
    {
        "question_id": "2657935",
        "question": "\nHow can I check if I have any uncommitted changes in my git repository:\n\nChanges added to the index but not committed\nUntracked files\n\nfrom a script?\ngit-status seems to always return zero with git version 1.6.4.2.\n",
        "all_answers": [
            "\nWhy not encapsulate 'git status with a script which:\n\nwill analyze the output of that command\nwill return the appropriate error code based on what you need\n\nThat way, you can use that 'enhanced' status in your script.\n\nAs 0xfe mentions in his excellent answer, git status --porcelain is instrumental in any script-based solution\n--porcelain\n\n\nGive the output in a stable, easy-to-parse format for scripts.\n  Currently this is identical to --short output, but is guaranteed not to change in the future, making it safe for scripts.\n\n",
            "\nIF you have NOT pushed your changes to remote\ngit reset HEAD~1\n\nCheck if the working copy is clean by git status.\nELSE you have pushed your changes to remote\ngit revert HEAD\n\nThis command will revert/remove the local commits/change and then you can push\n",
            "\nActually, when you use git reset, you should refer to the commit that you are resetting to; so you would want the db0c078 commit, probably.\nAn easier version would be git reset --hard HEAD^, to reset to the previous commit before the current head; that way you don't have to be copying around commit IDs.\nBeware when you do any git reset --hard, as you can lose any uncommitted changes you have. You might want to check git status to make sure your working copy is clean, or that you do want to blow away any changes that are there.\nIn addition, instead of HEAD you can use origin/master as reference, as suggested by @bdonlan in the comments: git reset --hard origin/master\n",
            "\nGreat timing! I wrote a blog post about exactly this a few days ago, when I figured out how to add git status information to my prompt.\nHere's what I do:\n\nFor dirty status:\n# Returns \"*\" if the current git branch is dirty.\nfunction evil_git_dirty {\n  [[ $(git diff --shortstat 2> /dev/null | tail -n1) != \"\" ]] && echo \"*\"\n}\n\nFor untracked files (Notice the --porcelain flag to git status which gives you nice parse-able output):\n# Returns the number of untracked files\n\nfunction evil_git_num_untracked_files {\n  expr `git status --porcelain 2>/dev/null| grep \"^??\" | wc -l` \n}\n\n\nAlthough git diff --shortstat is more convenient, you can also use git status --porcelain for getting dirty files:\n# Get number of files added to the index (but uncommitted)\nexpr $(git status --porcelain 2>/dev/null| grep \"^M\" | wc -l)\n\n# Get number of files that are uncommitted and not added\nexpr $(git status --porcelain 2>/dev/null| grep \"^ M\" | wc -l)\n\n# Get number of total uncommited files\nexpr $(git status --porcelain 2>/dev/null| egrep \"^(M| M)\" | wc -l)\n\nNote: The 2>/dev/null filters out the error messages so you can use these commands on non-git directories. (They'll simply return 0 for the file counts.)\nEdit:\nHere are the posts:\nAdding Git Status Information to your Terminal Prompt\nImproved Git-enabled Shell Prompt\n",
            "\nI believe that one of those will fit your need\n1 - Undo commit and keep all files staged:\ngit reset --soft HEAD~\n2 - Undo commit and unstage all files:\ngit reset HEAD~\n3 - Undo the commit and completely remove all changes:\ngit reset --hard HEAD~\nhere is were I found the answer\n"
        ],
        "answer": "A4",
        "tags": [
            "git",
            "shell"
        ]
    },
    {
        "question_id": "4038479",
        "question": "\nI want to do something simple on android app. \nHow is it possible to go back to a previous activity. \nWhat code do I need to go back to previous activity\n",
        "all_answers": [
            "\nAre you wanting to take control of the back button behavior?  You can override the back button (to go to a specific activity) via one of two methods.\nFor Android 1.6 and below:\n@Override\npublic boolean onKeyDown(int keyCode, KeyEvent event)  {\n    if (keyCode == KeyEvent.KEYCODE_BACK && event.getRepeatCount() == 0) {\n        // do something on back.\n        return true;\n    }\n\n    return super.onKeyDown(keyCode, event);\n}\n\nOr if you are only supporting Android 2.0 or greater:\n@Override\npublic void onBackPressed() {\n    // do something on back.\n    return;\n}\n\nFor more details: http://android-developers.blogspot.com/2009/12/back-and-other-hard-keys-three-stories.html\n",
            "\nWhen you are creating an object of intent, you can take advantage of following two methods\nfor passing objects between two activities.\nputParcelable\nputSerializable\nYou can have your class implement either Parcelable or Serializable. Then you can pass around your custom classes across activities. I have found this very useful.\nHere is a small snippet of code I am using\nCustomListing currentListing = new CustomListing();\nIntent i = new Intent();\nBundle b = new Bundle();\nb.putParcelable(Constants.CUSTOM_LISTING, currentListing);\ni.putExtras(b);\ni.setClass(this, SearchDetailsActivity.class);\nstartActivity(i);\n\nAnd in newly started activity code will be something like this...\nBundle b = this.getIntent().getExtras();\nif (b != null)\n    mCurrentListing = b.getParcelable(Constants.CUSTOM_LISTING);\n\n",
            "\nAndroid activities are stored in the activity stack. Going back to a previous activity could mean two things.\n\nYou opened the new activity from another activity with startActivityForResult. In that case you can just call the finishActivity() function from your code and it'll take you back to the previous activity.\nKeep track of the activity stack. Whenever you start a new activity with an intent you can specify an intent flag like FLAG_ACTIVITY_REORDER_TO_FRONT or FLAG_ACTIVITY_PREVIOUS_IS_TOP. You can use this to shuffle between the activities in your application. Haven't used them much though. Have a look at the flags here: http://developer.android.com/reference/android/content/Intent.html\n\nAs mentioned in the comments, if the activity is opened with startActivity() then one can close it with finish().\nIf you wish to use the Up button you can catch that in onOptionsSelected(MenuItem item) method with checking the item ID against android.R.id.home unlike R.id.home as mentioned in the comments.\n",
            "\nYou can create a subclass of Application and store your shared object there.  The Application object should exist for the lifetime of your app as long as there is some active component.\nFrom your activities, you can access the application object via getApplication().\n",
            "\nTry Activity#finish(). This is more or less what the back button does by default.\n"
        ],
        "answer": "A3",
        "tags": [
            "android",
            "android-intent",
            "android-activity"
        ]
    },
    {
        "question_id": "10487292",
        "question": "\nI have two divs inside another div, and I want to position one child div to the top right of the parent div, and the other child div to the bottom of the parent div using css. Ie, I want to use absolute positioning with the two child divs, but position them relative to the parent div rather than the page. How can I do this?\nSample html:\n<div id=\"parent\">\n   <div id=\"child1\"></div>\n   <div id=\"child2\"></div>\n</div>\n\n",
        "all_answers": [
            "\nHTML4 specification states that:\n\nInline elements may contain only data and other inline elements\n\nSpan is an inline element, therefore having span inside span is valid.\nThere's a related question: Can <span> tags have any type of tags inside them? which makes it completely clear.\nHTML5 specification (including the most current draft of HTML 5.3 dated November 16, 2017) changes terminology, but it's still perfectly valid to place span inside another span.\n",
            "\nYes, by adding an extra wrapping element. Assign the desired line-through color to an outer element, then the desired text color to the inner element. For example:\n\n\n<span style='color:red;text-decoration:line-through'>\r\n  <span style='color:black'>black with red strikethrough</span>\r\n</span>\n\n\n\n...or...\n\n<strike style='color:red'>\r\n  <span style='color:black'>black with red strikethrough<span>\r\n</strike>\n\n\n\n(Note, however, that <strike> is considered deprecated in HTML4 and obsolete in HTML5 (see also W3.org). The recommended approach is to use <del> if a true meaning of deletion is intended, or otherwise to use an <s> element or style with text-decoration CSS as in the first example here.)\nTo make the strikethrough appear for a:hover, an explicit stylesheet (declared or referenced in <HEAD>) must be used. (The :hover pseudo-class can't be applied with inline STYLE attributes.) For example:\n\n<head>\r\n  <style>\r\n    a.redStrikeHover:hover {\r\n      color:red;\r\n      text-decoration:line-through;\r\n    }\r\n  </style>\r\n</head>\r\n<body>\r\n  <a href='#' class='redStrikeHover'>\r\n    <span style='color:black'>hover me</span>\r\n  </a>\r\n</body>\n\n\r\n\n(IE7 seems to require some href be set on the <a> before :hover has an effect; FF and WebKit-based browsers do not.)\n",
            "\n#parent {\n   position: relative;\n}\n    \n#child1 {\n   position: absolute;\n   top: 0;\n}\n  \n#child2 {\n   position: absolute;\n   bottom: 0;\n}\n\nThis works because position: absolute means something like \"use top, right, bottom, left to position yourself in relation to the nearest ancestor who has position: absolute or position: relative.\"\nSo we make #parent have position: relative, and the children have position: absolute, then use top and bottom to position the children.\n",
            "\ndiv#father {\n    position: relative;\n}\ndiv#son1 {\n    position: absolute;\n    /* put your coords here */\n}\ndiv#son2 {\n    position: absolute;\n    /* put your coords here */\n}\n\n",
            "\nYes. You can have a span within a span. Your problem stems from something else.\n"
        ],
        "answer": "A3",
        "tags": [
            "html",
            "css"
        ]
    },
    {
        "question_id": "240660",
        "question": "\nI have an associative array in the form key => value where key is a numerical value, however it is not a sequential numerical value. The key is actually an ID number and the value is a count. This is fine for most instances, however I want a function that gets the human-readable name of the array and uses that for the key, without changing the value.\nI didn't see a function that does this, but I'm assuming I need to provide the old key and new key (both of which I have) and transform the array. Is there an efficient way of doing this?\n",
        "all_answers": [
            "\nCompare them as other values:\nif($array_a == $array_b) {\n  //they are the same\n}\n\nYou can read about all array operators here:\nhttp://php.net/manual/en/language.operators.array.php\nNote for example that === also checks that the types and order of the elements in the arrays are the same.\n",
            "\n$arraysAreEqual = ($a == $b); // TRUE if $a and $b have the same key/value pairs.\n$arraysAreEqual = ($a === $b); // TRUE if $a and $b have the same key/value pairs in the same order and of the same types.\n\nSee Array Operators.\nEDIT\nThe inequality operator is != while the non-identity operator is !== to match the equality \noperator == and the identity operator ===.\n",
            "\nAccording to this page.\nNOTE: The accepted answer works for associative arrays, but it will not work as expected with indexed arrays (explained below). If you want to compare either of them, then use this solution. Also, this function may not works with multidimensional arrays (due to the nature of array_diff function).\nTesting two indexed arrays, which elements are in different order, using $a == $b or $a === $b fails, for example:\n<?php\n    (array(\"x\",\"y\") == array(\"y\",\"x\")) === false;\n?>\n\nThat is because the above means:\narray(0 => \"x\", 1 => \"y\") vs. array(0 => \"y\", 1 => \"x\").\nTo solve that issue, use:\n<?php\nfunction array_equal($a, $b) {\n    return (\n         is_array($a) \n         && is_array($b) \n         && count($a) == count($b) \n         && array_diff($a, $b) === array_diff($b, $a)\n    );\n}\n?>\n\nComparing array sizes was added (suggested by super_ton) as it may improve speed.\n",
            "\n$arr[$newkey] = $arr[$oldkey];\nunset($arr[$oldkey]);\n\n",
            "\nTry serialize. This will check nested subarrays as well.\n$foo =serialize($array_foo);\n$bar =serialize($array_bar);\nif ($foo == $bar) echo \"Foo and bar are equal\";\n\n",
            "\nYou could use a second associative array that maps human readable names to the id's.  That would also provide a Many to 1 relationship.  Then do something like this:\n\necho 'Widgets: ' . $data[$humanreadbleMapping['Widgets']];\n\n\n",
            "\nShort solution that works even with arrays which keys are given in different order:\npublic static function arrays_are_equal($array1, $array2)\n{\n    array_multisort($array1);\n    array_multisort($array2);\n    return ( serialize($array1) === serialize($array2) );\n}\n\n",
            "\nfunction compareIsEqualArray(array $array1,array $array2):bool\n{\n\n   return (array_diff($array1,$array2)==[] && array_diff($array2,$array1)==[]);\n\n}\n\n"
        ],
        "answer": "A4",
        "tags": [
            "php",
            "arrays",
            "mapping",
            "key",
            "associative-array"
        ]
    },
    {
        "question_id": "6960019",
        "question": "\n\n\n\nI am unable to start GlassFish, because it keeps showing this error message:\nSEVERE: Shutting down v3 due to startup exception : No free port within range: 8080=com.sun.enterprise.v3.services.impl.monitor.MonitorableSelectorHandler@ed7d1\n\nHow can I find what applications are using what ports on Windows Vista?\nI have tried using nmap zenmap using the following target:\nhttp://127.0.0.1:8080\nBut all I get is this:\nStarting Nmap 5.51 ( http://nmap.org ) at 2011-08-05 12:05 Central Daylight Time\n\nNSE: Loaded 57 scripts for scanning.\n\nRead data files from: C:\\Program Files\\Nmap\nNmap done: 0 IP addresses (0 hosts up) scanned in 4.55 seconds\n           Raw packets sent: 0 (0B) | Rcvd: 0 (0B)\nWARNING: No targets were specified, so 0 hosts scanned.\n\n",
        "all_answers": [
            "\nIrina, make sure you have configured your endpoint properly by setting the private and public port. Here's a documentation that explains the steps to accomplish this...\nhttp://www.windowsazure.com/en-us/documentation/articles/virtual-machines-set-up-endpoints/\n",
            "\nOn the command prompt, do:\nnetstat -nb\n\n",
            "\nHow about netstat?\nhttp://support.microsoft.com/kb/907980\nThe command is netstat -anob.\n(Make sure you run command as admin)\nI get:\nC:\\Windows\\system32>netstat -anob\n\nActive Connections\n     Proto  Local Address          Foreign Address        State           PID\n  TCP           0.0.0.0:80                0.0.0.0:0                LISTENING         4\n Can not obtain ownership information\n\n  TCP    0.0.0.0:135            0.0.0.0:0              LISTENING       692\n  RpcSs\n [svchost.exe]\n\n  TCP    0.0.0.0:443            0.0.0.0:0              LISTENING       7540\n [Skype.exe]\n\n  TCP    0.0.0.0:445            0.0.0.0:0              LISTENING       4\n Can not obtain ownership information\n  TCP    0.0.0.0:623            0.0.0.0:0              LISTENING       564\n [LMS.exe]\n\n  TCP    0.0.0.0:912            0.0.0.0:0              LISTENING       4480\n [vmware-authd.exe]\n\nAnd If you want to check for the particular port, command to use is:\nnetstat -aon | findstr 8080\nfrom the same path\n",
            "\nTo see which ports are available on your machine run:\nC:>  netstat -an |find /i \"listening\"\n\n",
            "\nthis has changed to this\n\nI would recommend ignoring 100% of what is on google at the moment\n"
        ],
        "answer": "A3",
        "tags": [
            "windows",
            "port",
            "windows-vista",
            "netstat"
        ]
    },
    {
        "question_id": "2629680",
        "question": "\nI'd like to parallelize my Python program so that it can make use of multiple processors on the machine that it runs on.  My parallelization is very simple, in that all the parallel \"threads\" of the program are independent and write their output to separate files.  I don't need the threads to exchange information but it is imperative that I know when the threads finish since some steps of my pipeline depend on their output.\nPortability is important, in that I'd like this to run on any Python version on Mac, Linux, and Windows. Given these constraints, which is the most appropriate Python module for implementing this? I am trying to decide between thread, subprocess, and multiprocessing, which all seem to provide related functionality.\nAny thoughts on this?  I'd like the simplest solution that's portable.\n",
        "all_answers": [
            "\nmultiprocessing is a great Swiss-army knife type of module.  It is more general than threads, as you can even perform remote computations.  This is therefore the module I would suggest you use.\nThe subprocess module would also allow you to launch multiple processes, but I found it to be less convenient to use than the new multiprocessing module.\nThreads are notoriously subtle, and, with CPython, you are often limited to one core, with them (even though, as noted in one of the comments, the Global Interpreter Lock (GIL) can be released in C code called from Python code).\nI believe that most of the functions of the three modules you cite can be used in a platform-independent way.  On the portability side, note that multiprocessing only comes in standard since Python 2.6 (a version for some older versions of Python does exist, though).  But it's a great module!\n",
            "\nIt's pretty simple to delegate a method to a thread or sub-process using BaseEventLoop.run_in_executor:\nimport asyncio\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef cpu_bound_operation(x):\n    time.sleep(x) # This is some operation that is CPU-bound\n\n@asyncio.coroutine\ndef main():\n    # Run cpu_bound_operation in the ProcessPoolExecutor\n    # This will make your coroutine block, but won't block\n    # the event loop; other coroutines can run in meantime.\n    yield from loop.run_in_executor(p, cpu_bound_operation, 5)\n\n\nloop = asyncio.get_event_loop()\np = ProcessPoolExecutor(2) # Create a ProcessPool with 2 processes\nloop.run_until_complete(main())\n\nAs for whether to use a ProcessPoolExecutor or ThreadPoolExecutor, that's kind of hard to say; pickling a large object will definitely eat some CPU cycles, which initially would make you think ProcessPoolExecutor is the way to go. However, passing your 100MB object to a Process in the pool would require pickling the instance in your main process, sending the bytes to the child process via IPC, unpickling it in the child, and then pickling it again so you can write it to disk. Given that, my guess is the pickling/unpickling overhead will be large enough that you're better off using a ThreadPoolExecutor, even though you're going to take a performance hit because of the GIL.\nThat said, it's very simple to test both ways and find out for sure, so you might as well do that.\n",
            "\nTo use multiple processors in CPython your only choice is the multiprocessing module. CPython keeps a lock on it's internals (the GIL) which prevents threads on other cpus to work in parallel. The multiprocessing module creates new processes ( like subprocess ) and manages communication between them.\n"
        ],
        "answer": "A1",
        "tags": [
            "python",
            "multithreading",
            "parallel-processing"
        ]
    }
]